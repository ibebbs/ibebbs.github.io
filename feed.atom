<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<link rel="self" href="http://ian.bebbs.co.uk/" />
	<id>http://ian.bebbs.co.uk/</id>
	<title>Ian Bebbington</title>
	<rights>2017</rights>
	<updated>2017-04-12T18:01:02Z</updated>
	<logo>http://ian.bebbs.co.uk/y3mVYjKPwLNM4SpxZ-xLtIcMigGcxEzKTdUxFym5tI2hMna1NOz6e5axIvMYoGFlV1ftnmELd2YUX4QowbgtJ_iJkEHUEXpngrQ47dG5_hm88hO2ZJM1mRZLWwhDoB0KfKuu6WFFqmWoKb_2f18gkAqJQ20PkRodrAj4PzkSSgO9A4%253Fwidth=660&amp;height=371&amp;cropmode=none</logo>
	<subtitle>IObservable&lt;Opinion&gt;</subtitle>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/DockerAndKafka" />
		<id>http://ian.bebbs.co.uk/posts/DockerAndKafka</id>
		<title>Getting started with Docker and Apache Kafka</title>
		<updated>2017-01-04T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;For my first blog post of the new year (Happy New Year everyone!!!), I'd like to share some of my recent adventures with Docker on Windows, or, more specifically, Docker on Windows using Nanoserver as the container OS.&lt;/p&gt;
&lt;p&gt;I've been meaning to get up to speed with Docker for a while and, having &lt;a href="http://ian.bebbs.co.uk/posts/ARipStoringTime"&gt;recently acquired a decent new server for the purpose&lt;/a&gt;, decided that a festive period break from some of my &lt;a href="http://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl"&gt;longer term projects&lt;/a&gt;, would be an ideal time to finally dive in. In typical Bebbs style, "diving in" invariably involves the "deep end" and, as such, it seemed that a great initiation into the containerization waters would be to take &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; - a service typically run on Linux - and deploy it within a Windows &lt;a href="https://blogs.technet.microsoft.com/windowsserver/2015/04/08/microsoft-announces-nano-server-for-modern-apps-and-cloud/"&gt;Nanoserver&lt;/a&gt; container - a recent release from Microsoft and still a very-much bleeding-edge OS.&lt;/p&gt;
&lt;p&gt;I've been interested in Apache Kafka for quite a while. Described as a "distributed streaming platform" it very much resonates with my "everything is a stream" philosophy. Furthermore, some of &lt;a href="https://www.confluent.io/product/connectors/"&gt;it's connectors&lt;/a&gt; to various traditional RDBMS's offer an intriguing means of moving between 'state store' and 'event store' methodologies.&lt;/p&gt;
&lt;h2&gt;Getting started&lt;/h2&gt;
&lt;p&gt;For the host system, I started with a fresh install of Windows Server 2016 (Desktop Experience for convenience) on a &lt;a href="http://www.dell.com/uk/business/p/poweredge-t20/pd"&gt;Dell T20 Xeon&lt;/a&gt;. Following &lt;a href="https://msdn.microsoft.com/en-gb/virtualization/windowscontainers/quick_start/quick_start_windows_server"&gt;this quick start guide&lt;/a&gt; quickly led to an issue whereby the Docker package couldn't be verified by it's SHA256 hash and therefore refused to install. Fortunately I found a report of the issue and a work around &lt;a href="https://github.com/OneGet/MicrosoftDockerProvider/issues/15"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I have since reinstalled docker on Windows Server 2016 and did not experience the issue again so it must have been resolved.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With Docker installed and the &lt;a href="https://hub.docker.com/r/microsoft/dotnet-samples/"&gt;dotnet-samples&lt;/a&gt; example container running, my attention turned to Nanoserver.&lt;/p&gt;
&lt;p&gt;A quick pull and run of the &lt;a href="https://hub.docker.com/r/microsoft/nanoserver/"&gt;Nanoserver image&lt;/a&gt; and I found myself at an interactive command prompt of a deployed container running Nanoserver. This can be done as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;docker pull microsoft/nanoserver:latest
docker run -it --rm microsoft/nanoserver:latest cmd
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Kafka &amp;amp; Zookeeper&lt;/h2&gt;
&lt;p&gt;While looking for a pre-built image of Kafka running on Nanoserver, it quickly became apparent that in order to get an instance of &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; running, you first need a running instance of &lt;a href="https://zookeeper.apache.org/"&gt;Apache Zookeeper&lt;/a&gt;. While you could technically run both services from within a single container (indeed, Kafka is pre-configured to look for a Zookeeper instance on localhost) I wanted to utilize the core value propositions of containers vs VM instances; namely minimal overhead and composability.&lt;/p&gt;
&lt;p&gt;This meant that I would therefore be building two container images, one for Zookeeper and one for Kafka, both of which would be running on Nanoserver.&lt;/p&gt;
&lt;h2&gt;Building the Zookeeper image&lt;/h2&gt;
&lt;h3&gt;Take 1&lt;/h3&gt;
&lt;img src="https://mbt4mw-dm2306.files.1drv.com/y3m4bDPZgQ871xh0PU_QAcxaL1v9QKVFYFi8Q2uAb82woT97il9OZ_njULBYVK8aNohSJIgAAawJaj-tNunCWe4oXs5LpggjuVv41JGAQ2TFPco7IB1Xx57j6y2X0TUAtNfOQvoJWLxFFHjL5eSgzVeooe_OjURV4VJ8q_QDhN7coA?width=660&amp;amp;height=363&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="I built this container up from nothing. When I started here, all there was was nanoserver. Other developers said it was daft to build Zookeeper on nanoserver, but I did it all the same. Just to show'em."&gt;
&lt;blockquote&gt;
&lt;p&gt;I built this [container] up from nothing. When I started here, all there was was [nanoserver]. Other [developers] said it was daft to build [Zookeeper] on [nanoserver], but I did it all the same. Just to show'em.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, from most of everything I have read about building docker images, it seemed the thing to do was use a &lt;a href="https://docs.docker.com/engine/reference/builder/"&gt;Dockerfile&lt;/a&gt; to start an intermediate container based on the source image (Microsoft/Nanoserver in this instance) then run a script within the intermediate container (as part of the dockerfile) to download, install and configure all the required components. The output of this docker build process would be a new image with the appropriate services running on startup.&lt;/p&gt;
&lt;p&gt;I therefore started by preparing a powershell script that would do just that. Following &lt;a href="http://stackoverflow.com/a/38895811"&gt;this post on StackOverflow&lt;/a&gt; I developed and tested a script on a Windows Server 2016 (Desktop Experience) Virtual Machine. This was done so that I could use &lt;a href="https://technet.microsoft.com/en-us/library/dn818483(v=ws.11).aspx"&gt;snapshotting&lt;/a&gt; in order to roll-back to a clean image anytime a issue with the script was encountered.&lt;/p&gt;
&lt;p&gt;Unfortunately, when it came time to try running Zookeeper I hit the following error at start-up:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;log4j:WARN No appenders could be found for logger (org.apache.zookeeper.server.quorum.QuorumPeerConfig).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
Invalid config, exiting abnormally
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some quick googling turned up &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c5"&gt;this issue&lt;/a&gt; but every subsequent comment seemed to suggest that the issue had been resolved. I tried a &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c8"&gt;frustrating&lt;/a&gt; &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c9"&gt;number&lt;/a&gt; of &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c4"&gt;unsuccessful&lt;/a&gt; &lt;a href="http://tech.donghao.org/tag/zookeeper/"&gt;workarounds&lt;/a&gt; until I realized that it was a &lt;a href="https://en.wiktionary.org/wiki/PICNIC"&gt;PICNIC error&lt;/a&gt;. Specifically, while following the StackOverflow post above, I had failed to realize that the version of Zookeeper they specified wasn't actually the latest version and that the issue really had been resolved in a later version. This took a frustratingly and embarrassingly long time but hey, &lt;a href="http://www.goodreads.com/quotes/7678-when-people-say-it-s-always-the-last-place-you-look"&gt;it's always the last place you look&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, a morning of trial and error resulted in a thing of beauty; a script that would - completely automatically - download, extract, configure, install (as a service!) and run a Zookeeper instance. This is shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;## Download sources
$zipUri = "http://homeserver/download/7z1604-x64.exe" # http://www.7-zip.org/a/7z1604-x64.exe";
$nssmUri = "http://homeserver/download/nssm-2.24.zip" # "https://nssm.cc/release/nssm-2.24.zip"
$javaUri = "http://homeserver/download/jre-8u111-windows-x64.exe" # "http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jre-8u111-windows-x64.exe"
$zookeeperUri = "http://homeserver/download/zookeeper-3.4.9.tar.gz" # "http://apache.mirrors.nublue.co.uk/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz"
$kafkaUri = "http://homeserver/download/kafka_2.11-0.10.1.0.tgz" # "http://apache.mirror.anlx.net/kafka/0.10.1.0/kafka_2.11-0.10.1.0.tgz"

## Application locations
$appDir = "c:\Apps"
$zipDir = $appDir + "\7zip"
$nssmDir = $appDir + "\nssm"
$zookeeperDir = $appDir + "\Zookeeper"

## Data locations
$zookeeperDataDir = $zookeeperDir + "\Data"

## Application executables
$zip = $zipDir + "\7z.exe"
$nssm = $nssmDir + "\nssm.exe"
$zookeeper = $zookeeperDir + "\bin\zkServer.cmd"

function New-TempPath()
{
    if (!(Test-Path -Path C:\Temp))
    {
        New-Item c:\Temp -ItemType Directory
    }
}

function Expand-File($zipFile, $targetPath)
{
    $args = @("e", $zipFile, "-o$targetPath", '-y')
    &amp;amp;$zip $args
}

function Expand-Directory($zipFile, $targetPath)
{
    $args = @("x", $zipFile, "-o$targetPath", '-aoa')
    &amp;amp;$zip $args
}

function Install-7zip()
{
    New-Item "c:\Temp\7zip" -ItemType Directory -Force
    Invoke-WebRequest -Uri $zipUri -OutFile c:\Temp\7zip\7zip.exe
    &amp;amp;"C:\Temp\7zip\7zip.exe" /S /D=$zipDir | Out-Null
    Remove-Item -Path "c:\Temp\7zip\7zip.exe"
}

function Install-NSSM()
{
    New-Item "c:\Temp\NSSM" -ItemType Directory -Force
    Invoke-WebRequest -Uri $nssmUri -OutFile c:\Temp\NSSM\NSSM.zip

    Expand-Directory c:\Temp\NSSM\NSSM.zip c:\Temp\NSSM

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path c:\Temp\NSSM -Filter "nssm-*"
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination c:\Temp\NSSM -Force

    New-Item $nssmDir -ItemType Directory -Force
    Copy-Item -Path "c:\Temp\NSSM\win64\nssm.exe" $nssm -Force
}

function Install-Java()
{
    New-Item c:\Temp\Java -ItemType Directory -Force
    Invoke-WebRequest -Uri $javaUri -OutFile c:\temp\Java\Java.exe

    Start-Process "C:\Temp\Java\Java.exe" -ArgumentList "INSTALL_SILENT=Enable INSTALLDIR=C:\Java\Jre AUTO_UPDATE=Disable WEB_JAVA=Disable WEB_ANALYTICS=Disable EULA=Disable REBOOT=Disable NOSTARTMENU=Enable SPONSORS=Disable REMOVEOUTOFDATEJRES=0" -NoNewWindow -Wait

    [Environment]::SetEnvironmentVariable("JAVA_HOME", "C:\Java\Jre", "Machine")

    Remove-Item -Path "C:\Temp\Java\Java.exe"
}

function Get-Zookeeper()
{
    New-Item c:\Temp\Zookeeper -ItemType Directory -Force
    Invoke-WebRequest -Uri $zookeeperUri -OutFile c:\temp\Zookeeper\Zookeeper.tar.gz
    Expand-File c:\temp\Zookeeper\Zookeeper.tar.gz c:\temp\Zookeeper
    Expand-Directory c:\temp\Zookeeper\Zookeeper.tar $zookeeperDir

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path $zookeeperDir -Filter "zookeeper-*"
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination $zookeeperDir -Force

    Remove-Item -Path $folder.FullName
    Remove-Item -Path "c:\temp\Zookeeper" -Recurse
}

function Initialize-Zookeeper()
{
    New-Item -Path $zookeeperDataDir -ItemType Directory -Force
    $zookeeperDataLinuxDir = $zookeeperDataDir.Replace('\', '/')

    Copy-Item -Path ($zookeeperDir + '\conf\zoo_sample.cfg') -Destination ($zookeeperDir + '\conf\zoo.cfg') -Force

    $configFile = $zookeeperDir + '\conf\zoo.cfg'
    $logFile = $zookeeperDir + '\conf\log4j.properties'

    $config = [IO.File]::ReadAllText($configFile) -replace "dataDir=[\/\w]*", ("dataDir=" + $zookeeperDataLinuxDir)
    [IO.File]::WriteAllText($configFile, $config)

    $logProperties = [IO.File]::ReadAllText($logFile) -replace "#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE", "log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE"
    [IO.File]::WriteAllText($logFile, $logProperties)
}

function Install-Zookeeper()
{
    &amp;amp;$nssm install Zookeeper $zookeeper | Out-Null
    &amp;amp;$nssm set Zookeeper AppDirectory $zookeeperDir | Out-Null

    &amp;amp;$nssm set Zookeeper DisplayName "Zookeeper" | Out-Null
    &amp;amp;$nssm set Zookeeper Description "Apache Zookeeper. Running from $zookeeperDir" | Out-Null
    &amp;amp;$nssm set Zookeeper Start SERVICE_AUTO_START | Out-Null
    &amp;amp;$nssm set Zookeeper ObjectName LocalSystem | Out-Null
    &amp;amp;$nssm set Zookeeper Type SERVICE_WIN32_OWN_PROCESS | Out-Null
}

function Start-Zookeeper()
{
    &amp;amp;$nssm start Zookeeper | Out-Null
}

function Stop-Zookeeper()
{
    &amp;amp;$nssm stop Zookeeper | Out-Null
}

New-TempPath

Install-7zip
Install-NSSM
Install-Java

Get-Zookeeper
Initialize-Zookeeper
Install-Zookeeper
Start-Zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this mighty script in hand I prepared the following dockerfile:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;FROM microsoft/nanoserver
MAINTAINER Ian Bebbington &amp;lt;docker@bebbs.co.uk&amp;gt;
LABEL Description="Zookeeper running on Microsoft Nanoserver" Version="0.1"
ADD Install-Zookeeper.ps1 /
RUN [ "powershell.exe", "C:/Install-Zookeeper.ps1" ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And watched in dismay as it completely failed to build a container.&lt;/p&gt;
&lt;p&gt;You see, while the script ran perfectly on Windows Server 2016, Nanoserver is a far more constrained environment. It has neither support for 32-bit assemblies nor any graphic stack to speak of so, in short-order, the 7zip utility, Java installer and &lt;a href="https://nssm.cc/"&gt;Non-Sucking Service Manager&lt;/a&gt; executables all failed.&lt;/p&gt;
&lt;p&gt;Well, crap.&lt;/p&gt;
&lt;h3&gt;Take 2&lt;/h3&gt;
&lt;img src="https://mbt5mw-dm2306.files.1drv.com/y3mDYUaDMt02GzcHWl0DE1ASfBA6QbYzEwY-koD_MSkQGr3oRavQLf5jyRBH5TVFEBASZyRxAL00cuoRKuNNJ6lvSfEJD42p0QkZNzUQAFV-TKzdglya78e_ON8lHg7vQBS96aSQL-Hz0AobNgzQ83uHZN1T3nyDQKlumWgM50OZBc?width=660&amp;amp;height=440&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="So! I built a second one!"&gt;
&lt;blockquote&gt;
&lt;p&gt;So! I built a second one!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My next thought was to try salvaging as much of the script as possible by using &lt;a href="https://technet.microsoft.com/en-us/library/ff700227.aspx"&gt;Powershell Remoting&lt;/a&gt; to interactively install the required components and then &lt;a href="https://docs.docker.com/engine/reference/commandline/commit/"&gt;committing&lt;/a&gt; the changes to a new image.&lt;/p&gt;
&lt;p&gt;While, in retrospect, this was undoubtedly the wrong way forward, I was simultaneously fortunate and frustrated by the fact that it simply doesn't seem possible to use powershell remoting with Nanoserver when running within a container. Indeed, after learning more about &lt;a href="https://msdn.microsoft.com/en-us/library/aa384426(v=vs.85).aspx"&gt;WinRM&lt;/a&gt; than I thought possible, posting on &lt;a href="https://social.msdn.microsoft.com/Forums/en-US/e0652324-30e4-4ebb-8689-55205e6d8bc9/enterpssession-to-nanoserver-container-in-docker-access-is-denied?forum=windowscontainers"&gt;Microsoft's Windows Container forums&lt;/a&gt; and even offering my &lt;a href="http://stackoverflow.com/questions/39195068/powershell-remote-access-to-nanoserver-on-docker"&gt;first bounty on StackOverflow&lt;/a&gt; I simply could not find an answer to why it wasn't possible to establish a remote session.&lt;/p&gt;
&lt;p&gt;In the mean time...&lt;/p&gt;
&lt;h3&gt;Take 3&lt;/h3&gt;
&lt;img src="https://mbt3mw-dm2306.files.1drv.com/y3m5x6G99So08jPRwR0n1Msb-8SrSKNaOsB6aLd-CYAk8kSo9xRsa6i9Kd44QzRHin_EKMOpsNMZpacjCkoeGaMsODu6S7zI3NavsVz89vKF4Ot3b9pLEwaHxmg2mxXzvG8rQqCyf7C769ScaTkbPQ5WG2RwwcTHOyRqm0A-4RDNuQ?width=660&amp;amp;height=441&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="So, I built a third one..."&gt;
&lt;blockquote&gt;
&lt;p&gt;I built a third one...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Powershell remoting works beautifully with Nanoserver when running in a Hyper-V virtual machine but Hyper-V networking and Docker networking configurations don't seem to play well together. Indeed, after creating a new virtual-router so that I could access the Nanoserver virtual machine from the host PC, the Docker NAT network became inaccessible. Now, I'm sure it would be possible to dig into the virtual networking configuration and find a way to resolve this but, having spent an incredibly frustrating few hours reconfiguring WinRM, I decided it would be quicker to simply re-install the host OS and start from scratch.&lt;/p&gt;
&lt;h3&gt;Take 4&lt;/h3&gt;
&lt;img src="https://oltxmw-dm2306.files.1drv.com/y3mGaNRc9vDgPZnXfcJZfjYwIEFL32s3nCdk_kA84gB5NGOAoC3SLqP5D7ZffgKPO1VHXQEaRXvVuGCwFjoLKyo7o-gaUXFvGRcZPRPQrifhGNlBmU8RfqR5ZTgKIhxRvzJIMPoXydQ_N5UROZmaUXtKHH3jKtxIobDubPEdWsp-GM?width=660&amp;amp;height=495&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="But the fourth one stayed up!"&gt;
&lt;blockquote&gt;
&lt;p&gt;But the fourth one stayed up!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To accompany the fresh host environment, I decided to employ a fresh approach to building the container image. Namely, use a script to build the container's file system structure on the host PC and then simply copy it wholesale to the container from within the dockerfile. This meant deploying the Java Runtime Environment from a compressed archive rather than silent executable and using the &lt;a href="https://docs.docker.com/engine/reference/builder/#/entrypoint"&gt;dockerfile entrypoint&lt;/a&gt; instruction to run Zookeeper rather than installing it as a service.&lt;/p&gt;
&lt;p&gt;After all the faff and frustration of the previous two attempts (not to mention reinstallation of OS on host PC), this approach was remarkably smooth. Again, in retrospect this was undoubtedly the correct approach but this approach almost certainly benefited from all the knowledge I had accrued from the previous failed attempts. As always, &lt;a href="http://www.goodreads.com/quotes/390439-we-learn-wisdom-from-failure-much-more-than-from-success"&gt;you can learn more from failure than success&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, in relatively short order, I had a script that prepared and configured the container's file system structure on the host PC and a dockerfile that copied this structure to a new image and set the Zookeeper service as the entrypoint for the image. These are shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;## Download sources
$zipUri = "http://homeserver/download/7z1604-x64.exe" # http://www.7-zip.org/a/7z1604-x64.exe";
$javaUri = "http://homeserver/download/jre-8u111-windows-x64.tar.gz" # "http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jre-8u111-windows-x64.tar.gz"
$zookeeperUri = "http://homeserver/download/zookeeper-3.4.9.tar.gz" # "http://apache.mirrors.nublue.co.uk/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz"
$dockerModuleUri = "http://homeserver/download/Docker.0.1.0.zip" # "https://github.com/Microsoft/Docker-PowerShell/releases/download/v0.1.0/Docker.0.1.0.zip"

## Build location
$buildDir = Get-Location
$tmpDir = $buildDir.Path + "\Temp"
$rootDir = $buildDir.Path + "\Root"
$biuldAppDir = $rootDir + "\Apps"
$buildDataDir = $rootDir + "\Data"
$buildDockerZip = $tmpDir + "\Docker.zip"
$buildDockerModule = $tmpDir + "\Docker"
$buildZipDir = $tmpDir + "\7zip"
$buildJreDir = $biuldAppDir + "\Jre"
$buildZookeeperDir = $biuldAppDir + "\Zookeeper"
$buildZookeeperDataDir = $buildDataDir + "\Zookeeper"

## Temp files
$zipInstaller = $tmpDir + "\7zInstaller.exe"
$jreGzip = $tmpDir + "\Jre.tar.gz"
$jreTar = $tmpDir + "\Jre.tar"
$zooKeeperGzip = $tmpDir + "\Zookeeper.tar.gz"
$zooKeeperTar = $tmpDir + "\Zookeeper.tar"

## Target locations
$targetDir = "C:\"
$appDir = $targetDir + "\Apps"
$dataDir = $targetDir + "\Data"
$jreDir = $appDir + "\Jre"
$zookeeperDir = $appDir + "\Zookeeper"
$zookeeperDataDir = $dataDir + "\Zookeeper"

## Executables
$zip = $buildZipDir + "\7z.exe"
$zookeeper = $zookeeperDir + "\bin\zkServer.cmd"
$docker = "docker"

function New-TempPath()
{
    if (!(Test-Path -Path $tmpDir))
    {
        New-Item $tmpDir -ItemType Directory
    }
}

function Remove-TempPath()
{
    Remove-Item $tmpDir -Recurse -Force
}

function New-RootPath()
{
    Remove-Item $rootDir -Recurse -Force
    New-Item $rootDir -ItemType Directory
}

function Remove-RootPath()
{
    Remove-Item $rootDir -Recurse -Force
}

function Expand-File($zipFile, $targetPath)
{
    $args = @("e", $zipFile, "-o$targetPath", '-y')
    &amp;amp;$zip $args | Out-Host
}

function Expand-Directory($zipFile, $targetPath)
{
    $args = @("x", $zipFile, "-o$targetPath", '-aoa')
    &amp;amp;$zip $args | Out-Host
}

function Install-DockerModule()
{
    Invoke-WebRequest -Uri $dockerModuleUri -OutFile $buildDockerZip
    Expand-Archive -Path $buildDockerZip -DestinationPath $buildDockerModule -Force

    Import-Module $buildDockerModule
}

function Remove-DockerModule()
{
    Remove-Module $buildDockerModule
}

function Install-7zip()
{
    $folder = New-Item $buildZipDir -ItemType Directory -Force
    Invoke-WebRequest -Uri $zipUri -OutFile $zipInstaller
    &amp;amp;$zipInstaller /S /D=$folder | Out-Null
    Remove-Item -Path $zipInstaller
}

function Remove-7zip()
{
    Remove-Item $buildZipDir -Recurse -Force
}

function Get-Java()
{
    Invoke-WebRequest -Uri $javaUri -OutFile $jreGzip
    Expand-File $jreGzip $tmpDir
    Expand-Directory $jreTar $buildJreDir

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path $buildJreDir -Filter "jre*"
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination $buildJreDir -Force

    Remove-Item -Path $folder.FullName -Force
    Remove-Item -Path $jreGzip -Force
    Remove-Item -Path $jreTar -Force
}

function Get-Zookeeper()
{
    Invoke-WebRequest -Uri $zookeeperUri -OutFile $zooKeeperGzip
    Expand-File $zooKeeperGzip $tmpDir
    Expand-Directory $zooKeeperTar $buildZookeeperDir

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path $buildZookeeperDir -Filter "zookeeper-*"
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination $buildZookeeperDir -Force

    Remove-Item -Path $folder.FullName -Force
    Remove-Item -Path $zooKeeperTar -Force
    Remove-Item -Path $zooKeeperGzip -Force
}

function Initialize-Zookeeper()
{
    New-Item -Path $buildDataDir -ItemType Directory -Force
    New-Item -Path $buildZookeeperDataDir -ItemType Directory -Force

    $zookeeperDataLinuxDir = $zookeeperDataDir.Replace('\', '/')

    Copy-Item -Path ($buildZookeeperDir + '\conf\zoo_sample.cfg') -Destination ($buildZookeeperDir + '\conf\zoo.cfg') -Force

    $configFile = $buildZookeeperDir + '\conf\zoo.cfg'
    $logFile = $buildZookeeperDir + '\conf\log4j.properties'

    $config = [IO.File]::ReadAllText($configFile) -replace "dataDir=[\/\w]*", ("dataDir=" + $zookeeperDataLinuxDir)
    [IO.File]::WriteAllText($configFile, $config)

    $logProperties = [IO.File]::ReadAllText($logFile) -replace "#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE", "log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE"
    [IO.File]::WriteAllText($logFile, $logProperties)
}

function New-DockerImage()
{
    Build-ContainerImage -Path $buildDir -Repository "ibebbs/nanozoo:latest"
}


# Setup directory structure
New-TempPath
New-RootPath

# Install required tools
Install-DockerModule
Install-7zip

# Get components
Get-Java
Get-Zookeeper
Initialize-Zookeeper

# Build docker image
New-DockerImage

# Cleanup
Remove-DockerModule
Remove-7zip
Remove-TempPath
Remove-RootPath
&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;FROM microsoft/nanoserver
MAINTAINER Ian Bebbington &amp;lt;docker@bebbs.co.uk&amp;gt;
LABEL Description="Zookeeper running on Microsoft Nanoserver" Version="0.1"
ADD Root /
ADD Start-Zookeeper.ps1 /
RUN setx /M JAVA_HOME C:\Apps\Jre
EXPOSE 2181
ENTRYPOINT [ "powershell.exe", "C:/Start-Zookeeper.ps1" ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And this one worked. This one started. This one stayed up!&lt;/p&gt;
&lt;h2&gt;Building the Kafka image&lt;/h2&gt;
&lt;p&gt;With the Zookeeper scripts as a pattern, it was ludicrously easy to script up another image for Kafka. Just a few changes to file names and configuration parameters and Kafka started almost first time.&lt;/p&gt;
&lt;p&gt;I won't copy the script or dockerfile here as they're extremely similar to the Zookeeper versions. Instead, all scripts and files used above can be found in my &lt;a href="https://github.com/ibebbs/Docker"&gt;Docker repository on Github&lt;/a&gt; and the resultant images can be found on &lt;a href="https://hub.docker.com/r/ibebbs/"&gt;Docker hub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Moving forward&lt;/h2&gt;
&lt;img src="https://oltymw-dm2306.files.1drv.com/y3mIddKC619ngQYu9mwpyXXi9YgUp-MVwZ9_lR8JRla2AKvMm91LwnW2p0G3GkOZj5X_TXQUap_XULDAaiCWMC5Hx0ZvjKdAjeW7YWqacnwEAgCSZgmgBF1DCH83Zcywki6qKmOXbKkZO_SWmvQHpajyOQRHO1pJNB3ak2YpT6DmX8?width=660&amp;amp;height=371&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="But I don't want any of that!"&gt;
&lt;blockquote&gt;
&lt;p&gt;But I don't want any of that!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Moving forward, I need to address a couple of short-comings in the Kafka script (specifically the hard-coded IP address for the Zookeeper container) and then look to use Docker Compose to automatically bring up Zookeeper and Kafka on demand.&lt;/p&gt;
&lt;p&gt;It's been an interesting journey so far and I've not even begun to actually use the deployed services yet! Still, it is truly magical to run a docker container and see it boot an entire Windows server and service in just 10-20 seconds and a few hundred Mb.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;For my first blog post of the new year (Happy New Year everyone!!!), I'd like to share some of my recent adventures with Docker on Windows, or, more specifically, Docker on Windows using Nanoserver as the container OS.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII" />
		<id>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII</id>
		<title>A sentiment(al) analysis of why Red Dwarf is no longer funny</title>
		<updated>2017-04-12T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;I've recently been working on a project that required some natural language processing. After a surprisingly brief search I came upon the &lt;a href="https://stanfordnlp.github.io/CoreNLP/"&gt;Stanford CoreNLP&lt;/a&gt; suite of tools and after playing with their &lt;a href="http://corenlp.run/"&gt;online demo&lt;/a&gt; was astounded at the capabilities it provided. Furthermore, it was free, could be run such that it provided a basic HTTP API and came packaged with everything it needed save a copy of the JRE.&lt;/p&gt;
&lt;p&gt;Having recently &lt;a href="http://ian.bebbs.co.uk/posts/DockerAndKafka"&gt;enjoyed a lot of success&lt;/a&gt; running &lt;a href="https://zookeeper.apache.org/"&gt;various&lt;/a&gt; &lt;a href="https://kafka.apache.org/"&gt;JAVA&lt;/a&gt; &lt;a href="https://neo4j.com/product/"&gt;services&lt;/a&gt; inside a &lt;a href="https://www.docker.com/"&gt;Docker container&lt;/a&gt; running &lt;a href="https://technet.microsoft.com/en-us/windows-server-docs/get-started/getting-started-with-nano-server"&gt;Windows Nano Server&lt;/a&gt;, I decided to see if CoreNLP could be run like this too. Copying my previous &lt;a href="https://github.com/ibebbs/Docker/blob/master/Nanoserver-Zookeeper/Build.ps1"&gt;build script&lt;/a&gt; and &lt;a href="https://github.com/ibebbs/Docker/blob/master/Nanoserver-CoreNLP/Build.ps1"&gt;amending it&lt;/a&gt; to build a &lt;a href="https://hub.docker.com/r/ibebbs/nanonlp/"&gt;container running CoreNLP&lt;/a&gt; was ludicrously easy and in no time I had a local API I could hit to perform all the natural language processing I needed.&lt;/p&gt;
&lt;p&gt;Now, while the project I was working on mainly required the &lt;a href="https://stanfordnlp.github.io/CoreNLP/ner.html"&gt;"Named Entity Recognition"&lt;/a&gt; and &lt;a href="https://stanfordnlp.github.io/CoreNLP/openie.html"&gt;"Open IE"&lt;/a&gt; annotators, I was intrigued to see that CoreNLP also included a basic &lt;a href="https://stanfordnlp.github.io/CoreNLP/sentiment.html"&gt;Sentiment&lt;/a&gt; annotator. Given that I had written part one of this post back in January, had noted at the time how much I'd like to do sentiment analysis on the transcripts of Red Dwarf, and that I hadn't written a blog post since, I decided to take some time out and perform the sentiment analysis so that I could write this post.&lt;/p&gt;
&lt;p&gt;Again employing &lt;a href="https://jupyter.org/"&gt;Project Jupyter&lt;/a&gt; hosted on &lt;a href="https://notebooks.azure.com/"&gt;Azure Notebooks&lt;/a&gt; and using &lt;a href="http://fsharp.org/"&gt;F#&lt;/a&gt; coupled with &lt;a href="https://fslab.org/"&gt;FsLab&lt;/a&gt; as my primary language and toolkit, I had a lot of fun performing the analysis. Like last time, you can find the &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis/blob/master/SentimentAnalysisWithCoreNLP.ipynb"&gt;full notebook&lt;/a&gt; and source material in my &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis"&gt;Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note: As before, Github provides a "limited rendering only" so, to see all the charts running correctly you need to use the 'nbviewer' link shown below to see a full rendering of the notepad.&lt;/p&gt;
&lt;img src="https://mvpfyw-dm2306.files.1drv.com/y3mppldGfaYEhvWkV7mdUw26-lP3SOzlMTGFbf8slchIfjBL57IH-GrJev6ai_rISiHBKrom7Abg9YFjfhZ1ArOFT7a7mh4gJuGq-CErv1dun48GQC_BdhMV08fh6hbw400d9nHSEXJ0jA2nPBIrpOPNrOz0I3lVY1tu_L656ylQKg?width=660&amp;amp;height=283&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660; margin-top: 6px; margin-bottom: 6px;" alt="Open external view with nbviewer"&gt;
&lt;p&gt;The best bit of all (note: spoilers ahead!) is that it seems my original conclusion may indeed have been wrong... or at least mis-attributed.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;I've recently been working on a project that required some natural language processing. After a surprisingly brief search I came upon the &lt;a href="https://stanfordnlp.github.io/CoreNLP/"&gt;Stanford CoreNLP&lt;/a&gt; suite of tools and after playing with their &lt;a href="http://corenlp.run/"&gt;online demo&lt;/a&gt; was astounded at the capabilities it provided. Furthermore, it was free, could be run such that it provided a basic HTTP API and came packaged with everything it needed save a copy of the JRE.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/UWPCommunityToolkitv1_1" />
		<id>http://ian.bebbs.co.uk/posts/UWPCommunityToolkitv1_1</id>
		<title>UWP Community Toolkit v1.1 Released</title>
		<updated>2016-10-10T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Shortly after my blog post about &lt;a href="http://ian.bebbs.co.uk/posts/UsingHyperlinkInMVVM"&gt;Using a Hyperlink in MVVM&lt;/a&gt; a group of developers at Microsoft collated and released the &lt;a href="https://blogs.windows.com/buildingapps/2016/08/17/introducing-the-uwp-community-toolkit/#pRVgJbZbTBMHPyGG.97"&gt;UWP Community Toolkit&lt;/a&gt;. They were actively asking for contributions and, given the self contained nature of the Hyperlink extension, it seemed like a natural fit for the toolkit so I decided to try contributing it via pull request.&lt;/p&gt;
&lt;p&gt;The toolkit's contribution guidelines and conventions closely matched my own coding style so I had to change very little of the code in my article but did have to add XML summary blocks to each public class and members. With that done I could add the class to the &lt;a href="https://github.com/ibebbs/UWPCommunityToolkit/tree/dev/Microsoft.Toolkit.Uwp/Helpers"&gt;Helpers folder on the dev branch of my fork of the toolkit&lt;/a&gt; and &lt;a href="https://github.com/Microsoft/UWPCommunityToolkit/pull/226"&gt;issue a pull request&lt;/a&gt;. I was also asked to produce some documentation and a sample for the class which was then pulled into the document repo.&lt;/p&gt;
&lt;p&gt;The rest, as they say, is history. &lt;a href="https://blogs.windows.com/buildingapps/2016/10/05/announcing-uwp-community-toolkit-1-1/#1QBL3lQjtLbY537i.97"&gt;Version 1.1 of the toolkit released&lt;/a&gt; with yours truly in the &lt;a href="https://github.com/Microsoft/UWPCommunityToolkit/releases/"&gt;list of contributors&lt;/a&gt;. It's a small contribution but I really think the toolkit is a promising project and absolutely intend to contribute further in the near future.&lt;/p&gt;
&lt;p&gt;In the mean time, well done to all the maintainers of, and contributors to, the toolkit on this important milestone.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Shortly after my blog post about &lt;a href="http://ian.bebbs.co.uk/posts/UsingHyperlinkInMVVM"&gt;Using a Hyperlink in MVVM&lt;/a&gt; a group of developers at Microsoft collated and released the &lt;a href="https://blogs.windows.com/buildingapps/2016/08/17/introducing-the-uwp-community-toolkit/#pRVgJbZbTBMHPyGG.97"&gt;UWP Community Toolkit&lt;/a&gt;. They were actively asking for contributions and, given the self contained nature of the Hyperlink extension, it seemed like a natural fit for the toolkit so I decided to try contributing it via pull request.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ToddlerBoxReleasedToStore" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mVAxtKFjUEGk7Hdhzjl4UZ2INnFdBbw9K-tnYZ8DYoJ-VoKxpAN6w8Ng0DFTYdSxpHY6IvL5-VwJpLkQl6qWRmMQXSExLXopz5CFuSxIbyaMLrnL2Vy3yPZlISAAknXZdT4HwiZJ55zg2UtKwucBL88-xHh6rn5Mh97yzfRsCPjI%253Fwidth=1919&amp;height=1075&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/ToddlerBoxReleasedToStore</id>
		<title>ToddlerBox Released to the XBox Store</title>
		<updated>2016-11-16T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;My little girl loves playing with the XBox controller. In fact, she'll make a beeline for it as soon as she sees it and sit for ages twiddling the thumb-sticks and mashing the buttons. So I thought it'd be great to provide some visual accompaniment to the tactile experience of playing with the controller. Furthermore, I'd been looking for an excuse to play with Win2D as part of a UWP app and this felt like a perfect opportunity.&lt;/p&gt;
&lt;p&gt;To this end, I cracked open Visual Studio, started a blank UWP app, added a nuget reference to Win2D and started coding. Using a &lt;a href="https://microsoft.github.io/Win2D/html/T_Microsoft_Graphics_Canvas_UI_Xaml_CanvasAnimatedControl.htm"&gt;CanvasAnimatedControl&lt;/a&gt; it was simple to use the &lt;a href="https://microsoft.github.io/Win2D/html/E_Microsoft_Graphics_Canvas_UI_Xaml_CanvasAnimatedControl_Update.htm"&gt;Update&lt;/a&gt; callback to read the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.gaming.input.gamepad"&gt;Gamepad&lt;/a&gt; input and then use the &lt;a href="https://microsoft.github.io/Win2D/html/E_Microsoft_Graphics_Canvas_UI_Xaml_CanvasAnimatedControl_Draw.htm"&gt;Draw&lt;/a&gt; callback to draw a series of sprites based on the values read.&lt;/p&gt;
&lt;p&gt;All in, from not having used Win2D before, it took just a few hours to get a minimal app working with a variety of sprites and manipulation mechanisms. Flipping my &lt;a href="https://msdn.microsoft.com/en-gb/windows/uwp/xbox-apps/devkit-activation"&gt;XBox into developer mode&lt;/a&gt; allowed me to deploy the app directly to the Xbox and have a play. And I must say, I was very pleased with the result:&lt;/p&gt;
&lt;img src="https://zphxkg.dm2302.livefilestore.com/y3mynwGeO7sZByGMtgH7TP5ykDeabNNlbyLCFHZfLu2Ml9QbQft2wq6-MeIxMukEXnVpiqZfLa_lh7h15xlStRf8Eo81_y5J-zSplYIIDh5dKAkS-j2q2wS4-GUHpOpwW5eltQ8_CLhSQNoRRJwdZWs_AhjvxhhOMdCS5PB-stLlTE?width=1024&amp;amp;height=575&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="Lots of animals"&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;Lots of animals&lt;/h6&gt;
&lt;img src="https://zphykg.dm2302.livefilestore.com/y3mVAxtKFjUEGk7Hdhzjl4UZ2INnFdBbw9K-tnYZ8DYoJ-VoKxpAN6w8Ng0DFTYdSxpHY6IvL5-VwJpLkQl6qWRmMQXSExLXopz5CFuSxIbyaMLrnL2Vy3yPZlISAAknXZdT4HwiZJ55zg2UtKwucBL88-xHh6rn5Mh97yzfRsCPjI?width=1024&amp;amp;height=574&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="Lots of colours"&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;Lots of colours&lt;/h6&gt;
&lt;img src="https://zphwkg.dm2302.livefilestore.com/y3m8XFQkqAgfzj1Yt9EqXW14XVybPwILZ0Hn_yGK2sbayqyeGZVqwSOGpT_xAJS3WwzYFeyQ4Gw66Fa-QyRpM71WpPUktEfgvgteIKAXfp9qCSW_my9s-7kb4Ys7Qz1JYRHv-k8fl1Y8xTTDpLhfY5xG2m56hT_ObFWrKxFhV-N-lw?width=1024&amp;amp;height=575&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="Big..."&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;Big...&lt;/h6&gt;
&lt;img src="https://zphvkg.dm2302.livefilestore.com/y3mN4YESAkR1YSr8YbSDJtqi2DGD20bBa_w5RR2cYyAm9aXKXxib1A65RnVBxraAGCEXRELh0QMYDSASbm7F8ADzvh7EizJXlz-odd9Vhvq0ccfd0yNyL4v1f2qex5ol96GP6qvxE35Fo1L-hdlu9cfo08lDWZielw6ffr-vZ92aYE?width=1024&amp;amp;height=575&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="...or small"&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;...or small&lt;/h6&gt;
&lt;img src="https://zphukg.dm2302.livefilestore.com/y3mcH_fRNs467C1gL7rApW6mWiFYB-eCoUexIuW3CwX4Cb0seAy8IxNhjyiGFQx3jDrcB8ToLQJgekRDInIwMkMHQvVZ05vWCPrptx2vxkcu-KG40ldNAqOZu2ulyL7OPSGt7uuFNnZLOdtycCFVs3Tl5IWJltKR6uhEgxNW_j-4tI?width=1024&amp;amp;height=575&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="And monkeys!!!"&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;And monkeys!!!!&lt;/h6&gt;
&lt;p&gt;The real test came when I handed to the controller to my 14 month old baby girl. It took a few seconds for her to realise that what she did on the controller affected what was displayed on screen but then there was no stopping her. For three or four minutes (a record for her!!!) she sat still, mashing away on the controller and staring at the screen while I sat mesmerized by how quickly she picked it all up.&lt;/p&gt;
&lt;p&gt;I'd call that a win!&lt;/p&gt;
&lt;p&gt;Given this success, I made some final touches and submitted it to the store; specifically for XBox. To my amazement, it passed certification first time, within 24 hours of submission despite submitting it on a Sunday. And here it is:&lt;/p&gt;
&lt;img src="https://1y8kkg.dm2302.livefilestore.com/y3mRbMDxeVB6f5ArIwJ6FjYCPRmwpPTp6LL2IGiIFOrFVgHzox_2HUl9lPNSq09KxXP5M3LD1E3nwgFi1a8HUCT-0dTH_VmemTLCQwHggxqy8u04C85i51eLPBj1op_n2ppnjK2zkhGDHcWWAyYvkncmNy4bqw58vumGP8BY4f9nZU?width=1024&amp;amp;height=576&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800px; margin-top: 6px; margin-bottom: 6px;" alt="ToddlerBox in the store"&gt;
&lt;p&gt;Installing from the store and ready to entertain my little one whenever I need a break.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;My little girl loves playing with the XBox controller. In fact, she'll make a beeline for it as soon as she sees it and sit for ages twiddling the thumb-sticks and mashing the buttons. So I thought it'd be great to provide some visual accompaniment to the tactile experience of playing with the controller. Furthermore, I'd been looking for an excuse to play with Win2D as part of a UWP app and this felt like a perfect opportunity.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ReactiveBehaviors" />
		<id>http://ian.bebbs.co.uk/posts/ReactiveBehaviors</id>
		<title>Reactive Behaviors</title>
		<updated>2015-11-14T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;I am a firm believer in the notion "&lt;a href="http://slides.com/robwormald/everything-is-a-stream#/" title="Everything is a stream - Rob Wormald"&gt;Everything&lt;/a&gt; &lt;a href="https://gist.github.com/staltz/868e7e9bc2a7b8c1f754" title="The introduction to Reactive Programming you've been missing - andrestaltz"&gt;is&lt;/a&gt; &lt;a href="http://weareadaptive.com/blog/2014/05/05/everything-is-a-stream/" title="Reactive Trader 2: Everything is a Stream - Matt Barrett"&gt;a&lt;/a&gt; &lt;a href="http://colintheshots.com/blog/?p=85" title="Be Reactive - Colintheshots"&gt;stream&lt;/a&gt;". After all, at it's root what is a computer program but a stream of instructions toggling the state of transistors on the CPU die. As such, I have been gradually moving away from traditional imperative coding and embracing a declarative approach to implementing behavior.&lt;/p&gt;
&lt;p&gt;Starting with the UI, my &lt;a href="https://github.com/ibebbs/Caliburn.Micro.Reactive.Extensions" title="Caliburn.Micro.Reactive.Extensions Github Repository"&gt;Reactive Extensions for Caliburn Micro&lt;/a&gt; allowed me to escape the scourge of state variables and property change non-sense and have read-model changes update the view or user input changes update the view model in a declarative fashion.&lt;/p&gt;
&lt;p&gt;With this in place, I sort of stumbled onto a pattern I quite liked and gradually developed into a pattern I am now referring to as "Reactive Behaviors". To explain this pattern, lets take a basic example of a log in page for an application.&lt;/p&gt;
&lt;p&gt;Traditionally, in WPF MVVM parlance, the view model for the log in page might look something like this:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;public class LogInPageViewModel : Screen, ILogInPageViewModel
{
    private readonly IAuthenticationService _authenticationService;

    private readonly DelegateCommand _logInCommand;
    private readonly DelegateCommand _cancelCommand;

    private CancellationTokenSource _cts;

    private string _username;
    private string _password;
    private string _error;

    public LogInPageViewModel(IAuthenticationService authenticationService)
    {
        _authenticationService = authenticationService;

        _cts = new CancellationTokenSource();
        _logInCommand = new DelegateCommand(CanLogIn, PerformLogIn);
        _cancelCommand = new DelegateCommand(_ =&amp;gt; true, CancelLogIn);
    }

    public void Dispose()
    {
        if (_cts != null)
        {
            _cts.Cancel();
            _cts.Dispose();
            _cts = null;
        }
    }

    private bool CanLogIn(object parameter)
    {
        return (!string.IsNullOrWhiteSpace(_username) &amp;amp;&amp;amp; !string.IsNullOrWhiteSpace(_password));
    }

    private async void PerformLogIn(object parameter)
    {
        AuthenticationResponse response = await _authenticationService.AuthenticateAsync(new AuthenticationRequest(_username, _password), _cts.Token);

        if (response.Successful)
        {
            TryClose(true);
        }
        else
        {
            Error = response.Error.Message;
        }
    }

    private void CancelLogIn(object parameter)
    {
        TryClose(false);
    }

    public string Username
    {
        get { return _username; }
        set
        {
            if (!string.Equals(value, _username))
            {
                _username = value;

                NotifyOfPropertyChange(() =&amp;gt; Username);

                _logInCommand.RaiseCanExecuteChanged();
            }
        }
    }

    public string Password
    {
        get { return _password; }
        set
        {
            if (!string.Equals(value, _password))
            {
                _password = value;

                NotifyOfPropertyChange(() =&amp;gt; Password);

                _logInCommand.RaiseCanExecuteChanged();
            }
        }
    }

    public string Error
    {
        get { return _error; }
        private set
        {
            if (!string.Equals(value, _error))
            {
                _error = value;

                NotifyOfPropertyChange(() =&amp;gt; Error);
            }
        }
    }

    public ICommand LogInCommand
    {
        get { return _logInCommand; }
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, we have a bunch of state variables that are updated from property setters and when certain state variables are updated we need to perform specific actions. Now, can you quickly identify all the behaviors of this view model?&lt;/p&gt;
&lt;p&gt;Well, it's not a complicated view model so it'll probably just take a few minutes to work out the behaviors. To summarize, they are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When the user has entered a value in both the user name and password text boxes then enable the "Log in" button&lt;/li&gt;
&lt;li&gt;When the user clicks the "Log in" button, asynchronously attempt to log in with the supplied credentials.&lt;/li&gt;
&lt;li&gt;When a successful login attempt is made, close the dialog&lt;/li&gt;
&lt;li&gt;When an unsuccessful login attempt is made, display an error&lt;/li&gt;
&lt;li&gt;When the user clicks the "Cancel" button, close the dialog&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But that took a few minutes of scanning back and forth over the class right? Also, while we have been good developers and applied DRY by centralizing the logic to determine when the log in button should be enabled, in order to know under what circumstances the logic will be called, we need to perform a "Find References" on the method. The cause and effect of this behavior are &lt;strong&gt;disassociated&lt;/strong&gt;. In fact, in this instance it's event worse, as this method is only passed to the &lt;code&gt;DelegateCommand&lt;/code&gt; instance, we have to &lt;em&gt;know&lt;/em&gt; that the &lt;code&gt;DelegateCommand&lt;/code&gt; will invoke this method everytime the &lt;code&gt;RaiseCanExecuteChanged&lt;/code&gt; is called &lt;em&gt;and then&lt;/em&gt; perform another "Find References" to find all the locations &lt;code&gt;RaiseCanExecuteChanged&lt;/code&gt; is called. Phew!&lt;/p&gt;
&lt;p&gt;Wouldn't it be better if we could somehow centralize this logic in discreet methods with names that describe exactly the behavior of the class? Ladies and gentlemen, I present to you the same class re-written using "Reactive Behaviors":&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;public class LogInPageViewModel : Screen, ILogInPageViewModel
{
    private readonly IAuthenticationService _authenticationService;

    private ObservableProperty&amp;lt;string&amp;gt; _username;
    private ObservableProperty&amp;lt;string&amp;gt; _password;
    private ObservableProperty&amp;lt;string&amp;gt; _error;
    private ObservableCommand _logInCommand;
    private ObservableCommand _cancelCommand;

    private Subject&amp;lt;AuthenticationResponse&amp;gt; _logInResponse;

    private IDisposable _behaviors;

    public LogInPageViewModel(IAuthenticationService authenticationService)
    {
        _authenticationService = authenticationService;

        _username = new ObservableProperty&amp;lt;string&amp;gt;(this, () =&amp;gt; Username);
        _password = new ObservableProperty&amp;lt;string&amp;gt;(this, () =&amp;gt; Password);
        _error = new ObservableProperty&amp;lt;string&amp;gt;(this, () =&amp;gt; Error);
        _logInCommand = new ObservableCommand();
        _cancelCommand = new ObservableCommand();

        _logInResponse = new Subject&amp;lt;AuthenticationResponse&amp;gt;();

        _behaviors = new CompositeDisposable(
            WhenTheUserHasEnteredBothUsernameAndPasswordThenEnableLogInButton(),
            WhenTheUserClicksTheLogInButtonAttemptToLogIn(),
            WhenASuccessfulLogInAttemptIsMadeCloseTheDialog(),
            WhenAnUnsuccessfulLogInAttemptIsMadeDisplayTheError(),
            WhenTheUserClicksTheCancelButtonCloseTheDialog()
        );
    }

    public void Dispose()
    {
        if (_behaviors != null)
        {
            _behaviors.Dispose();
            _behaviors = null;
        }
    }

    private IDisposable WhenTheUserHasEnteredBothUsernameAndPasswordThenEnableLogInButton()
    {
        return Observable
            .CombineLatest(_username, _password, (username, password) =&amp;gt; !string.IsNullOrWhiteSpace(username) &amp;amp;&amp;amp; !string.IsNullOrWhiteSpace(password))
            .Subscribe(_logInCommand);
    }

    private IDisposable WhenTheUserClicksTheLogInButtonAttemptToLogIn()
    {
        return _logInCommand
            .SelectMany(_ =&amp;gt; Observable.CombineLatest(_username, _password, (username, password) =&amp;gt; new AuthenticationRequest(username, password)).Take(1))
            .SelectMany(request =&amp;gt; _authenticationService.AuthenticateAsync(request))
            .Subscribe(_logInResponse);
    }

    private IDisposable WhenASuccessfulLogInAttemptIsMadeCloseTheDialog()
    {
        return _logInResponse
            .Where(response =&amp;gt; response.Successful)
            .Subscribe(response =&amp;gt; TryClose(true));
    }

    private IDisposable WhenAnUnsuccessfulLogInAttemptIsMadeDisplayTheError()
    {
        return _logInResponse
            .Where(response =&amp;gt; !response.Successful)
            .Select(response =&amp;gt; response.Error.Message)
            .Subscribe(_error);
    }

    private IDisposable WhenTheUserClicksTheCancelButtonCloseTheDialog()
    {
        return _cancelCommand
            .Subscribe(_ =&amp;gt; TryClose(false));
    }

    public string Username
    {
        get { return _username.Get(); }
        set { _username.Set(value); }
    }

    public string Password
    {
        get { return _password.Get(); }
        set { _password.Set(value); }
    }

    public string Error
    {
        get { return _error.Get(); }
    }

    public ICommand LogInCommand
    {
        get { return _logInCommand; }
    }

    public ICommand CancelCommand
    {
        get { return _cancelCommand; }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As shown, the constructor instantiates a &lt;code&gt;CompositeDisposable&lt;/code&gt; containing calls to methods implementing the behavior of the class and which return an &lt;code&gt;IDisposable&lt;/code&gt; that, when disposed, will tear down the behavior. Each method is named after exactly one desired behavior and comprises a subscription to all the required inputs for the behavior, a series of projections which implement the behavior and, finally, a subscription which surfaces the result of the behavior.&lt;/p&gt;
&lt;p&gt;Lets take the example of the &lt;code&gt;WhenTheUserHasEnteredBothUsernameAndPasswordThenEnableLogInButton&lt;/code&gt; method. Here we subscribe to both the &lt;code&gt;_username&lt;/code&gt; and &lt;code&gt;_password&lt;/code&gt; properties, and use a selector function to return a boolean indicating whether they're both populated. The &lt;code&gt;_logInCommand&lt;/code&gt; subscribes to the result which will enable or disable the command (by raising CanExecuteChanged events) appropriately.&lt;/p&gt;
&lt;p&gt;Furthermore, by leveraging Observables we become thread safe. It doesn't matter on which thread the source properties are updated from, the behavior will be performed and output applied without the risk of missing values or race-conditions between updates to the appropriate inputs.&lt;/p&gt;
&lt;p&gt;With behaviors implemented in this fashion, behavioral unit testing becomes incredibly obvious. Simply copy the behavior method names into your test fixture and assert that it performs as expected.&lt;/p&gt;
&lt;p&gt;I believe this pattern provides numerous benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Promotes behavior driven development and unit testing.&lt;/li&gt;
&lt;li&gt;Promotes functional and thread safe programming practises.&lt;/li&gt;
&lt;li&gt;Reduces the risk of (and if done well, can eliminate) side effects as specific behaviors are isolated in a single well named method.&lt;/li&gt;
&lt;li&gt;Stops 'code rot' as all behavior is encapsulated within specifically named methods. Want new behaviour? Add a new method. Don't want a specific behavior anymore? Just removed it. Want a specific behavior to change? Change the one method and know that you haven't broken anything else.&lt;/li&gt;
&lt;li&gt;Provides concise mechanisms for aggregating multiple inputs and promotes asynchronous processes to first-class status.&lt;/li&gt;
&lt;li&gt;Reduces the need for utility classes as data can be passed through the pipeline as strongly typed anonymous classes.&lt;/li&gt;
&lt;li&gt;Prevents memory leaks as all behaviors return a disposable that when disposed removes all subscriptions and disposed all managed resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While this example targets the UI and leverages Caliburn Micro with Reactive Extensions for projection to IObservable&lt;t&gt; instances (and property change notification), this pattern can be employed across any class which treats inputs and outputs as a stream.&lt;/t&gt;&lt;/p&gt;
&lt;p&gt;I have been employing this pattern very successfully across a variety of functional layers for quite some time now. I'd be really interested to hear your thoughts.&lt;/p&gt;
&lt;p&gt;Code for above examples available on &lt;a href="https://github.com/ibebbs/Blog.ReactiveBehaviors" title="ReactiveBehaviors Repository on Github"&gt;Github&lt;/a&gt;&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;I am a firm believer in the notion "&lt;a href="http://slides.com/robwormald/everything-is-a-stream#/" title="Everything is a stream - Rob Wormald"&gt;Everything&lt;/a&gt; &lt;a href="https://gist.github.com/staltz/868e7e9bc2a7b8c1f754" title="The introduction to Reactive Programming you've been missing - andrestaltz"&gt;is&lt;/a&gt; &lt;a href="http://weareadaptive.com/blog/2014/05/05/everything-is-a-stream/" title="Reactive Trader 2: Everything is a Stream - Matt Barrett"&gt;a&lt;/a&gt; &lt;a href="http://colintheshots.com/blog/?p=85" title="Be Reactive - Colintheshots"&gt;stream&lt;/a&gt;". After all, at it's root what is a computer program but a stream of instructions toggling the state of transistors on the CPU die. As such, I have been gradually moving away from traditional imperative coding and embracing a declarative approach to implementing behavior.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/RxWeb" />
		<id>http://ian.bebbs.co.uk/posts/RxWeb</id>
		<title>Using Rx on the Web</title>
		<updated>2016-03-04T00:00:00Z</updated>
		<content>
                                        


&lt;h2&gt;Finding a framework&lt;/h2&gt;
&lt;p&gt;So, I have recently found myself with a need to dive into the depths of modern web-development and, as I am currently looking to write a highly interactive single-page web application, the first thing to decide on was a client side framework to use. You won't have to read too many of my blog posts to realise that I'm a big fan of &lt;a href="https://msdn.microsoft.com/en-us/data/gg577609.aspx?f=255&amp;amp;MSPPError=-2147217396"&gt;Rx&lt;/a&gt;. I am also keen on the MVVM approach to separating concerns when writing user interfaces. Therefore, during my research of modern web UI frameworks, I was extremely interested when I came across &lt;a href="http://webrxjs.org/"&gt;WebRx&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;Billed as "a browser-based MVVM-Framework that combines functional-reactive programming with declarative Data-Binding, Templating and Client-Side Routing" it struck a chord with my UI development style. In fact, it elevates &lt;a href="http://reactivex.io/documentation/observable.html"&gt;Observables&lt;/a&gt; to a first class concept in a manner eerily similar to the ObservableProperty/ObservableCommand classes I wrote for my &lt;a href="https://github.com/ibebbs/Caliburn.Micro.Reactive.Extensions"&gt;Caliburn.Micro.Reactive.Extensions&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;Unfortunately, as a framework, WebRx seems to be struggling to achieve critical mass and therefore there was very limited information available when I decided to attempt to implement the &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;WebRx "Hello World"&lt;/a&gt; example using Visual Studio. As is almost par for the course when using a new framework, I fell at a frustratingly early hurdle and, given the lack of info (seriously, only one tagged post on &lt;a href="https://stackoverflow.com/questions/tagged/webrx"&gt;stackoverflow&lt;/a&gt;!), I had to work through the problem 'old-skool'... ya'know, by actually finding and solving the problem rather than just googling a solution.&lt;/p&gt;
&lt;p&gt;Anyway, I thought I'd put together a post outlining how to get started with this framework in Visual Studio in an attempt to start addressing the lack of info regarding this promising framework.&lt;/p&gt;
&lt;h2&gt;The name is Bart Simpson&lt;/h2&gt;
&lt;p&gt;Rather than the traditional 'Hello World' app, WebRx's 'Getting Started' guide displays a page stating 'The name is Bart Simpson'. This is done in order to demonstrates the MVVM separation of concerns through the use of a view bound to an underlying view model which provides the name 'Bart Simpson'.&lt;/p&gt;
&lt;p&gt;I don't intend to cover the entirety of the getting started guide here, merely the additional/different steps needed to get the project work from Visual Studio. As such, I suggest &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;opening the guide&lt;/a&gt; in a browser and leaving it open while working through the steps below as I will be referring to it extensively.&lt;/p&gt;
&lt;p&gt;First up, open Visual Studio. Pretty much any modern version is fine, I am using Visual Studio 2015 Professional. Start a new project and select 'ASP.NET Web Application'&lt;/p&gt;
&lt;img src="/Content/RxWeb/NewAspWebApplication.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="New ASP.NET Web Application"&gt;
&lt;p&gt;In the following dialog, select an empty ASP.NET Template and click ok.&lt;/p&gt;
&lt;img src="/Content/RxWeb/EmptyAsp452Project.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Empty ASP.NET Template"&gt;
&lt;p&gt;Now we have a web project, lets add a reference to WebRx. This can be done using either the Package Manager Console using the command &lt;code&gt;Install-Package WebRx&lt;/code&gt; or via the visual Nuget package manager as shown below:&lt;/p&gt;
&lt;img src="/Content/RxWeb/InstallWebRxPackage.png" class="img-responsive" style="margin: auto; width:66%; margin-top: 6px; margin-bottom: 6px;" alt="Install WebRx Package"&gt;
&lt;p&gt;Regardless of how you add the reference to WebRx, you will be asked whether you wish to 'Search for TypeScript Typings' as shown below. Just click 'Yes'.&lt;/p&gt;
&lt;img src="/Content/RxWeb/AddTypeScriptTypings.png" class="img-responsive" style="margin: auto; width:300px; margin-top: 6px; margin-bottom: 6px;" alt="Add TypeScript Typings"&gt;
&lt;p&gt;You will also be prompted to accept the license aggrement for a number of RxJs packages which WebRx depends upon; you should accept these too.&lt;/p&gt;
&lt;p&gt;One the reference is added, you should find that a Scripts directory has been added to your solution and which contains a number of 'ts' and 'js' files for both WebRx and RxJs. With this in place, we can then continue with the getting started guide by adding an 'index.html' file to the project and copy pasting the sample 'index.html' file from the WebRx &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;getting started guide&lt;/a&gt;. It should look something like this:&lt;/p&gt;
&lt;img src="/Content/RxWeb/CopyPasteIndexFromGettingStarted.png" class="img-responsive" style="margin: auto; width:400px; margin-top: 6px; margin-bottom: 6px;" alt="Copy Paste Index From Getting Started"&gt;
&lt;p&gt;At this point the eagle-eyed amongst you will notice three things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Our scripts are now in a 'bower_modules' directory&lt;br&gt;
As we used Nuget and not bower to install our WebRx dependencies, the script references should be changed to refer to the Scripts directory&lt;/li&gt;
&lt;li&gt;Our scripts directory does not contain a rx.all.js file.&lt;br&gt;
For some reason, WebRx depends on a version of RxJs that does not include an rx.all.js file. To resolve this, simply upgrade to the latest version of RxJs-All, as shown below:
&lt;img src="/Content/RxWeb/UpgradeRxJsAll.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Upgrade RxJs All"&gt;&lt;/li&gt;
&lt;li&gt;We don't have a 'js' folder containing an 'app.js' file.&lt;br&gt;
Because we've not got to that bit yet.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now add a 'js' folder to the solution and add a 'app.js' to it. In this file copy the full 'app.js' sample from the WebRx  &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;getting started guide&lt;/a&gt; as shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;wx.app.component('hello', {
  viewModel: function() {
    this.firstName = 'Bart';
    this.lastName = 'Simpson';
  },
  template: 'The name is &amp;lt;span data-bind="text: firstName + \' \' + lastName"&amp;gt;&amp;lt;/span&amp;gt;'
});

wx.router.state({
  name: "$",
  views: { 'main': "hello" }
});

wx.router.reload();

wx.applyBindings();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save all, set 'index.html' as the start page and hit F5. If everything went as planned you should now see 'The name is Bart Simpson' displayed in your default browser:&lt;/p&gt;
&lt;img src="/Content/RxWeb/TheNameIsBartSimpson.png" class="img-responsive" style="margin: auto; width:400px; margin-top: 6px; margin-bottom: 6px;" alt="The Name Is Bart Simpson"&gt;
&lt;p&gt;And that's it. While the getting started example doesn't seem very complex, it does show a separation of view and view model. I'm very much looking forward to digging into the details of this very promising framework.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/WebRxWithAsp4"&gt;completed project&lt;/a&gt; for this post can be found in my &lt;a href="https://github.com/ibebbs/BlogProjects"&gt;BlogProjects repository&lt;/a&gt; on &lt;a href="https://github.com/ibebbs"&gt;Github&lt;/a&gt;&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;So, I have recently found myself with a need to dive into the depths of modern web-development and, as I am currently looking to write a highly interactive single-page web application, the first thing to decide on was a client side framework to use. You won't have to read too many of my blog posts to realise that I'm a big fan of &lt;a href="https://msdn.microsoft.com/en-us/data/gg577609.aspx?f=255&amp;amp;MSPPError=-2147217396"&gt;Rx&lt;/a&gt;. I am also keen on the MVVM approach to separating concerns when writing user interfaces. Therefore, during my research of modern web UI frameworks, I was extremely interested when I came across &lt;a href="http://webrxjs.org/"&gt;WebRx&lt;/a&gt; .&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/DartInVisualStudioCode" />
		<id>http://ian.bebbs.co.uk/posts/DartInVisualStudioCode</id>
		<title>Dart web development with Visual Studio Code</title>
		<updated>2017-01-17T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Visual Studio Code is rapidly becoming my go-to editor for anything not project-oriented C#/F#. I've switched from &lt;a href="https://atom.io/"&gt;Atom&lt;/a&gt; to &lt;a href="(https://code.visualstudio.com/)"&gt;VSC&lt;/a&gt; for editing my (&lt;a href="http://ian.bebbs.co.uk/posts/NewBlogUsingWyam"&gt;statically-generated, Markdown driven&lt;/a&gt;) blog and have used it for authoring powershell scripts, dockerfiles and much, much more. So, when I decided I wanted to write some &lt;a href="https://www.dartlang.org/"&gt;Dart&lt;/a&gt; code, it was the obvious choice.&lt;/p&gt;
&lt;h2&gt;Why Dart?&lt;/h2&gt;
&lt;p&gt;Why did I decide on Dart? Well, I had project I wanted to undertake that featured some... shock horror... dynamic web content. If that isn't enough to send chills down your spine, you've either &lt;a href="https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.fqoett4pt"&gt;never had to look at getting started with modern web development&lt;/a&gt; or &lt;a href="https://medium.com/@pistacchio/i-m-a-web-developer-and-i-ve-been-stuck-with-the-simplest-app-for-the-last-10-days-fb5c50917df#.glf30ovv1"&gt;you've already drunk the cool-aid&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Either way, most rational people in the industry will (in the moments of clarity between writing off the last framework as dated and evangelising the next) reluctantly admit that &lt;a href="https://medium.com/@wob/the-sad-state-of-web-development-1603a861d29f#.lqu2r4xup"&gt;modern web development is a mess&lt;/a&gt;. But this is the world we live in and the best one can do is dodge the analysis paralysis and mitigate the majority of the risks. For me, this was adopting a &lt;a href="https://www.dartlang.org/guides/language/language-tour"&gt;strongly-typed modern development language&lt;/a&gt; that has a &lt;a href="https://webdev.dartlang.org/"&gt;strong web pedegry&lt;/a&gt; and just get on with it.&lt;/p&gt;
&lt;h2&gt;But in Visual Studio Code?&lt;/h2&gt;
&lt;p&gt;Why not? It's a great editor and already has great support for Dart courtesy of Danny Tuppeny's &lt;a href="https://marketplace.visualstudio.com/items?itemName=DanTup.dart-code"&gt;excellent Dart extension&lt;/a&gt;. Furthermore, I try to keep my development machine as lean and clean as possible so I didn't want to have to &lt;a href="https://www.jetbrains.com/webstorm/"&gt;install an IDE specifically for Dart development&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fortunately, as you'll see, getting set up for Dart development with Visual Studio Code is very easy, doesn't require any installation (everything is "xcopy" deployed) and you can start being productive almost right away.&lt;/p&gt;
&lt;h2&gt;Ingredients&lt;/h2&gt;
&lt;p&gt;You will need the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://code.visualstudio.com/Download"&gt;Visual Studio Code&lt;/a&gt; - obviously&lt;/li&gt;
&lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=DanTup.dart-code"&gt;Dart Code&lt;/a&gt; - the Dart language extension for Visual Studio Code&lt;/li&gt;
&lt;li&gt;&lt;a href="https://storage.googleapis.com/dart-archive/channels/stable/release/1.21.0/sdk/dartsdk-windows-x64-release.zip"&gt;The Dart SDK&lt;/a&gt; - the code Dart binaries and tools needed for dart development&lt;/li&gt;
&lt;li&gt;&lt;a href="https://storage.googleapis.com/dart-archive/channels/stable/release/latest/dartium/dartium-windows-ia32-release.zip"&gt;Dartium&lt;/a&gt; - a version of Chrome (even called "Chrome.exe") with a built in Dart runtime&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Steps&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Download and extract the Dart SDK to a location on your HD (I use &lt;code&gt;C:\Apps&lt;/code&gt; for "manually" installed tools/applications so will be using the path &lt;code&gt;C:\Apps\dart-sdk&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Download and extract Dartium to a location on your HD (&lt;code&gt;C:\Apps\chromium&lt;/code&gt; for me).&lt;/li&gt;
&lt;li&gt;Create a new directory wherever you keep your source files and name it &lt;code&gt;GettingStartedWithDart&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;In this directory, create two further directories named &lt;code&gt;lib&lt;/code&gt; and &lt;code&gt;web&lt;/code&gt; (this structure follows the &lt;a href="https://www.dartlang.org/tools/pub/package-layout"&gt;Pub Package Layout Conventions&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Start Visual Studio Code and open the &lt;code&gt;GettingStartedWithDart&lt;/code&gt; folder. You should see something like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt6eg-dm2306.files.1drv.com/y3m_WQkZhj4Xo-vjZzyUVujyGYAM3lM7Gs84uuf59zCfPKJQzrT9d--PF8Ns9Gwm3qluxzW26f_H9OU5PZQEq37lEKy9aKY553bzGzZLNU_CBIRGUWA_9_QbE-a0WgQz284pvZY2-Voc83pjQc2h9iMUIzap8At--sCEdhJXyO6sXw?width=660&amp;amp;height=497&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Empty Project"&gt;
&lt;ol start="6"&gt;
&lt;li&gt;If you haven't already, install the Dart Code extension by hitting &lt;code&gt;Ctrl-Shift-X&lt;/code&gt; (the keyboard shortcut for "View-&amp;gt;Extensions") and type Dart in the search box. This should show the "Dart Code" extension by "Danny Tuppeny". Click install and reload the window when complete.&lt;/li&gt;
&lt;li&gt;As we haven't elected to add the Dart SDK to the path, we need to tell the Dart extension where it can find the SDK. This is done by editing the User Settings (&lt;code&gt;File-&amp;gt;Preferences-&amp;gt;User Settings&lt;/code&gt;) and adding the following settings:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;    "dart.sdkPath": "C:\\Apps\\dart-sdk",
    "dart.debugSdkLibraries": false,
    "dart.debugExternalLibraries": false
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="8"&gt;
&lt;li&gt;Back in the Explorer view (&lt;code&gt;Ctrl-Shift-E&lt;/code&gt;) add a new file to the &lt;code&gt;web&lt;/code&gt; directory named &lt;code&gt;main.dart&lt;/code&gt;. We'll populate this file shortly but, for now, it's just so that VSC (and Dart Code) realises that this is a Dart project.&lt;/li&gt;
&lt;li&gt;Add another new file named &lt;code&gt;pubspec.yaml&lt;/code&gt; to the root directory. This file tells the Dart compiler (named &lt;code&gt;Pub&lt;/code&gt;) how to build your Dart project and follows a very &lt;a href="https://www.dartlang.org/tools/pub/pubspec"&gt;simply format&lt;/a&gt;. In this file add &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;dependencies&lt;/code&gt; and &lt;code&gt;transformers&lt;/code&gt; as shown below:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;name: GettingStartedWithDart
dependencies:
transformers:
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="10"&gt;
&lt;li&gt;When you save this file, you should see the &lt;code&gt;Output&lt;/code&gt; panel appear showing the output of the &lt;code&gt;Pub&lt;/code&gt; command. This is a feature of the Dart Code extension which runs a &lt;code&gt;pub get&lt;/code&gt; command whenever you save the &lt;code&gt;pubspec.yaml&lt;/code&gt; file. As you can probably guess from the output (shown below) the purpose of this command is to retrieve/update any dependencies you've declared in the &lt;code&gt;dependencies&lt;/code&gt; section. Also, once the &lt;code&gt;pub get&lt;/code&gt; command has run, you should see a new &lt;code&gt;pubspec.lock&lt;/code&gt; file appear in the root directory.&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt5eg-dm2306.files.1drv.com/y3mCavvhl_SorCHUuY_oZ01TMQ9jkjpMy_I48Eotp3TlC5s-TRU0JaznDIYoihtHpfFj6A3Aqwu9eEKDhOQaK7jnEO7g6UscYBqeBp5yLg_PnzxGgWQpVTwgrxkJeOw8EUet6KhgGEn2Lkm3IYfP4-K-SEXXvKT4G64DcweiAsnQ-k?width=660&amp;amp;height=497&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Get Dependencies"&gt;
&lt;ol start="11"&gt;
&lt;li&gt;As we're focusing on using Dart for web development, we'll also add an HTML document we'll manipulate using Dart. To do this, simply add new file named &lt;code&gt;index.html&lt;/code&gt; to the &lt;code&gt;web&lt;/code&gt; directory and populate it with the following:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;Getting Started With Dart&amp;lt;/title&amp;gt;
    &amp;lt;script type="application/dart" src="main.dart"&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;h1 id="header"&amp;gt;Hmm... what should I say?&amp;lt;/h1&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="12"&gt;
&lt;li&gt;At this point you should have the following layout in your project and we're ready start start writing some Dart.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;    [Source Directory]
    |-&amp;gt; [Project Name] (i.e. "GettingStartedWithDart")
    | | -&amp;gt; lib
    | | -&amp;gt; web
    | | | -&amp;gt; index.html
    | | | -&amp;gt; main.dart
    | | -&amp;gt; pubspec.lock
    | | -&amp;gt; pubspec.yaml
&lt;/pre&gt;
&lt;ol start="13"&gt;
&lt;li&gt;In the &lt;code&gt;main.dart&lt;/code&gt; file, add the following code. (Note, if you type this code rather than copy-pasting it, you'll notice the excellent intellisense features provided by VSC and implemented beautifully by Dart VS.)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;import 'dart:html';

void main() {
  querySelector('#header').text = 'Ah yes... Hello World!!!';
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="14"&gt;
&lt;li&gt;Right, now we have an HTML file and some Dart code and we're ready to run. While you could run this code manually from the command line, if you're intending on doing more than just this getting started guide, I'd very much recommend setting up some task runners in VSC. This is done by opening the command palette (&lt;code&gt;Ctrl-Shift-P&lt;/code&gt;) and typing &lt;code&gt;Configure Task Runner&lt;/code&gt;, which should show you the command &lt;code&gt;Tasks: Configure Task Runner&lt;/code&gt;. Select this and you will see a list of build systems VSC can automatically create a task runner for (shown below). As Dart isn't one of the predefined templates, select "Others" to create an empty Tasks file.&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt4eg-dm2306.files.1drv.com/y3mjQOmP0yb0-3KfLb34MamSLnq13qKN0jSNcEHLMIOn7u2kbunZuaN74mec-0mquSOr05it5RZC6Uov1rnpiweb1sL6a96iKFJYLWC_6hSlldbQjHriAKAa71-k_8Dop-6iLRxL38BNzOMqii4VNZVfIlFgV_Ow2hG1GtMwXjB7A4?width=660&amp;amp;height=497&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Configure Task Runner"&gt;
&lt;ol start="15"&gt;
&lt;li&gt;This command should create a new file called &lt;code&gt;tasks.json&lt;/code&gt; in a new &lt;code&gt;.vscode&lt;/code&gt; directory and will contain the following json.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
    // See https://go.microsoft.com/fwlink/?LinkId=733558
    // for the documentation about the tasks.json format
    "version": "0.1.0",
    "command": "echo",
    "isShellCommand": true,
    "args": ["Hello World"],
    "showOutput": "always"
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="16"&gt;
&lt;li&gt;If you're not familiar with configuring VSC task runners, I'd very much recommend clicking the link in this file to see what the task runner is able to do and how to configure it. However, for your convenience, I have provided my configuration below:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
    // See https://go.microsoft.com/fwlink/?LinkId=733558
    // for the documentation about the tasks.json format
    "version": "0.1.0",
    "command": "C:\\Apps\\dart-sdk\\bin\\pub.bat",
    "isShellCommand": true,
    "args": [],
    "showOutput": "always",
    "echoCommand": true,
    "tasks": [
        {
            "taskName": "build",
            "args": [],
            "isWatching": false
         },
        {
            "taskName": "serve",
            "args": [],
            "isWatching": true
         }
    ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="17"&gt;
&lt;li&gt;&lt;p&gt;As you will probably be able to determine, this file contains two tasks; one named &lt;code&gt;build&lt;/code&gt; and the other named &lt;code&gt;serve&lt;/code&gt;. The &lt;code&gt;build&lt;/code&gt; command compiles your code and checks for errors while the &lt;code&gt;serve&lt;/code&gt; command sets up a local web-server (by default bound to port 8080) capable of serving the content of the &lt;code&gt;web&lt;/code&gt; directory. Lets try both.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open the command palette (&lt;code&gt;Ctrl-Shift-P&lt;/code&gt;), delete the '&amp;gt;' prompt and then type &lt;code&gt;task&lt;/code&gt; followed by a space. You should see the two tasks defined above appear. Continue to &lt;code&gt;build&lt;/code&gt; and then hit return. At this point, the output pane should appear displaying the &lt;code&gt;Tasks&lt;/code&gt; output and your code should be compiled (and, transpiled into JS!). This is shown below:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt3eg-dm2306.files.1drv.com/y3ma_gmHNRQHH3HaNTz8ytRLamtMwlzmi0dRSYl1aqncp0Zy-RaUW_qLGOebg_PpgRdCoYLQYFcuRWZ3FC_Y6jJ0Qw6n5rWbGxvUMzi5_yqitbOf3DrJUVAkQi9Th0JvQmzLysrJGrnhrVe7Z2eYY6uUse_0o88veVTn8eYaIZsHnw?width=660&amp;amp;height=497&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Tasks and Build output"&gt;
&lt;ol start="19"&gt;
&lt;li&gt;&lt;p&gt;If everything is successful, you should see the message '&lt;code&gt;Built 2 files to "build"&lt;/code&gt;'. Now we can test our Dart code by serving it through &lt;code&gt;pub server&lt;/code&gt;. To do this, start the &lt;code&gt;task serve&lt;/code&gt; task in a similar manner to the &lt;code&gt;task build&lt;/code&gt; above. As this task is an &lt;code&gt;isWatching&lt;/code&gt; command, the task won't complete when run but will emit messages to the output pane when changes occur. This is shown below:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;With a local web-server serving out HTML file and Dart code, we can finally start to use Dartium to run the code. Note that, we're using Dartium because we'll be executing the Dart code directly (rather than the transpiled JavaScript) and Dartium has a built-in Dart runtime which allows for advanced debugging of our Dart code. Start Dartium but executing it from either command line or GUI (exists at &lt;code&gt;C:\Apps\chromium\chrome.exe&lt;/code&gt; for me) and, once started, navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; and you should see the following:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://nbtqeg-dm2306.files.1drv.com/y3m2wj9PACazah5vdBUyW8AOGu__v3AbjHyzU66QtsvCuHVA4Ya710e4bjVJv4GdNiXlige7q8waQcphwiH8FtLZG8eu-z7cOiBPi-vqx8KfgkYPvwVrtPIpJoCmdIDR8LmO8DIqkHSvNe6Kz5q65IoWi1DRivqqpX5YUET_9zEmS4?width=660&amp;amp;height=542&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Success!!"&gt;
&lt;p&gt;Congratulations, you've just run your first Dart code.&lt;/p&gt;
&lt;p&gt;If something went wrong and you don't see the header text change from 'Hmm... what should I say?' to 'Ah yes... Hello World!!!' then you can use Dartium's Developer Tools (&lt;code&gt;Ctrl-Shift-I&lt;/code&gt;) to view errors and add breakpoints so you can work out what has gone wrong. The developer tools are shown here:&lt;/p&gt;
&lt;img src="https://nbtpeg-dm2306.files.1drv.com/y3my4JbT3bsQcqBOB3NANuaB-FMf_vBHNlAc1qm5QaXuFVEWxIV1YuoIj7gu-QJZtFOgS_gHJBknLl8J_LY9shZ_YtYf8Jf0BL9T0r4NMf3dv5XXvZt0x_J0IqZ7lurmX5MJP7oyA9FMO8oMkm29BAxoQI2jV-s6dyO2APv8dvXRTM?width=660&amp;amp;height=542&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Dartium Developer Tools"&gt;
&lt;p&gt;You can find loads more information online about the &lt;a href="https://www.dartlang.org/"&gt;Dart Language&lt;/a&gt; and &lt;a href="https://webdev.dartlang.org/"&gt;Dart Web Development&lt;/a&gt;. Versions of Dart are changing rapidly (there was a minor update while writing this post!) and a thriving &lt;a href="https://www.dartlang.org/community"&gt;support community&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As a (mainly) C# developer I found Dart super easy to get up to speed with and the Visual Studio Code/Dartium combo to be extremely productive. Hopefully you will too.&lt;/p&gt;
&lt;p&gt;Have fun.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Visual Studio Code is rapidly becoming my go-to editor for anything not project-oriented C#/F#. I've switched from &lt;a href="https://atom.io/"&gt;Atom&lt;/a&gt; to &lt;a href="(https://code.visualstudio.com/)"&gt;VSC&lt;/a&gt; for editing my (&lt;a href="http://ian.bebbs.co.uk/posts/NewBlogUsingWyam"&gt;statically-generated, Markdown driven&lt;/a&gt;) blog and have used it for authoring powershell scripts, dockerfiles and much, much more. So, when I decided I wanted to write some &lt;a href="https://www.dartlang.org/"&gt;Dart&lt;/a&gt; code, it was the obvious choice.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartII" />
		<id>http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartII</id>
		<title>Home Network Monitoring - Part II</title>
		<updated>2016-04-10T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;In part one of this series I set up my home router to send a variety of Syslog messages to LogStash which then forwarded these messages to ElasticSearch for indexing and querying by Kibana in a simplistic dashboard. In this post, I'm going to start parsing out some of the details of the Syslog messages to start giving us a clearer idea about which devices on my local network are opening sessions with remote servers.&lt;/p&gt;
&lt;h1&gt;message types&lt;/h1&gt;
&lt;p&gt;My router sends a number of different messages types; everything from router/dsl bandwidth information to the firewall log as can be seen below:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/DrayTek-Syslog.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="DrayTek Syslog Administration"&gt;
&lt;p&gt;For now, I'm really only interested in the 'User Access Log' which tells us when a local device resolves an IP address for a domain name or accesses a remote server. This log constitutes a number of message types such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;TCP / UDP access
This message is sent by the router when a device on the local network accesses a remote server via TCP or UDP. It looks like this: &lt;code&gt;&amp;lt;150&amp;gt;Apr 10 16:55:38 Vigor: Local User (MAC=00-00-00-00-00-00): 192.168.1.205:64281 -&amp;gt; 5.10.110.36:80 (TCP)Web&lt;/code&gt;. From this type of message I am interested in parsing out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Syslog timestamp&lt;/li&gt;
&lt;li&gt;Syslog username&lt;/li&gt;
&lt;li&gt;Source Mac Address&lt;/li&gt;
&lt;li&gt;Source IP Address&lt;/li&gt;
&lt;li&gt;Destination IP Address&lt;/li&gt;
&lt;li&gt;Protocol&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;DNS lookup
This message is sent by the router when a device on the local network resolves an IP address for a remote server DNS nane. It looks like this: &lt;code&gt;&amp;lt;150&amp;gt;Apr 10 18:52:49 Vigor: Local User (MAC=00-00-00-00-00-00): 192.168.1.62 DNS -&amp;gt; 192.168.1.1 inquire a.root-servers.net&lt;/code&gt;. From this type of message I am interested in parsing out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Syslog timestamp&lt;/li&gt;
&lt;li&gt;Syslog username&lt;/li&gt;
&lt;li&gt;Source Mac Address&lt;/li&gt;
&lt;li&gt;Source IP Address&lt;/li&gt;
&lt;li&gt;Domain being resolved&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this post I'll focus on enriching the incoming message with information from the access message but will move on to parsing multiple message types in a future post.&lt;/p&gt;
&lt;h1&gt;parsing access messages&lt;/h1&gt;
&lt;p&gt;Logstash provides a great tool for parsing messages: the 'grok' filter. As explained in &lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html"&gt;the documentation&lt;/a&gt; 'grok' allows you to 'Parse arbitrary text and structure it. This tool is perfect for syslog logs, apache and other webserver logs, mysql logs, and in general, any log format that is generally written for humans and not computer consumption.'&lt;/p&gt;
&lt;p&gt;This filter applies a regular expression like patterns to a field in the incoming message and, if matched successfully, adds each matched expression to the message being processed as a new field. The fields to capture are defined in the format &lt;code&gt;%{SYNTAX:SEMANTIC}&lt;/code&gt; where the &lt;code&gt;SYNTAX&lt;/code&gt; element is a known pattern (see below) or a regular expression and the &lt;code&gt;SEMANTIC&lt;/code&gt; is a name of the field to capture.&lt;/p&gt;
&lt;p&gt;Logstash ships with over 120 known &lt;code&gt;SYNTAX&lt;/code&gt; patterns and these patterns can be supplemented by adding new pattern files to a specific directory. However, the default patterns supplied cover nearly all common scenarios and allow almost all the pertinent information in the TCP access message above to be parsed.&lt;/p&gt;
&lt;p&gt;So, by just using the default patterns, I can write the expression&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;&amp;lt;%{POSINT:syslog_pri}&amp;gt;%{SYSLOGTIMESTAMP:syslog_timestamp} Vigor\: Local User \(MAC=%{MAC:source_mac}\): %{IP:source_address}(?::%{POSINT:source_port})? -&amp;gt; %{IP:destination_address}(?::%{POSINT:destination_port})?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which gives us the following additional fields in the message:&lt;/p&gt;
&lt;p&gt;|field|value|
|-----|-----|
|source_address|192.168.1.205|
|source_port|64281|
|source_mac|00-00-00-00-00-00|
|syslog_pri|150|
|syslog_timestamp|Apr·10·16:55:38|
|destination_address|5.10.110.36|
|destination_port|80|&lt;/p&gt;
&lt;p&gt;Neat huh! I'd also like to know whether the access message is TCP or UDP so I'm going to add a custom regular expression to the end of the pattern to parse the protocol string out of the message. In full the pattern is now:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;&amp;lt;%{POSINT:syslog_pri}&amp;gt;%{SYSLOGTIMESTAMP:syslog_timestamp} Vigor\: Local User \(MAC=%{MAC:source_mac}\): %{IP:source_address}(?::%{POSINT:source_port})? -&amp;gt; %{IP:destination_address}(?::%{POSINT:destination_port})? \((?&amp;lt;protocol&amp;gt;TCP|UDP)\)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This would result in the following fields available in the message:&lt;/p&gt;
&lt;p&gt;|field|value|
|-----|-----|
|source_address|192.168.1.205|
|source_port|64281|
|source_mac|00-00-00-00-00-00|
|syslog_pri|150|
|syslog_timestamp|Apr·10·16:55:38|
|destination_address|5.10.110.36|
|destination_port|80|
|&lt;strong&gt;protocol&lt;/strong&gt;|&lt;strong&gt;TCP&lt;/strong&gt;|&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: You can use &lt;a href="http://grokconstructor.appspot.com/"&gt;Grok Constructor&lt;/a&gt; to help you perfect your grok expressions prior to trying them in Logstash&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;adding the grok filter to logstash&lt;/h1&gt;
&lt;p&gt;So, now I know how to extract all the information I'm interested in from the access message, I need to get Logstash to actually do it. This is done by adding a &lt;code&gt;grok&lt;/code&gt; filter to the &lt;code&gt;filter { }&lt;/code&gt; section of the &lt;code&gt;syslog.config&lt;/code&gt; file authored in the previous post as shown here:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;input {
  tcp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
  udp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
}

filter {
    grok {
      match =&amp;gt; [ "message", "&amp;lt;%{POSINT:syslog_pri}&amp;gt;%{SYSLOGTIMESTAMP:syslog_timestamp} Vigor\: Local User \(MAC=%{MAC:source_mac}\): %{IP:source_address}(?::%{POSINT:source_port})? -&amp;gt; %{IP:destination_address}(?::%{POSINT:destination_port})? \((?&amp;lt;protocol&amp;gt;TCP|UDP)\)" ]
    }
}

output {
  elasticsearch {
    hosts =&amp;gt; ["192.168.1.30:9200"]
    index =&amp;gt; "syslog-%{+YYYY.MM.dd}"
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice the grok section in which we specify a 'match' field. This field takes an array of two strings; the first string is the field containing the text to match and the second is the pattern to match the text to.&lt;/p&gt;
&lt;p&gt;Once this is added to the &lt;code&gt;syslog.config&lt;/code&gt; file and Logstash restarted, these new fields should be being written to ElasticSearch. The easiest way to see if this is working is to return to Kibana and, from the 'Settings/Indices' area, click the 'syslog-*' pattern on the left and then click the orange 'Refresh field list' button and the field list appears like this:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-RefreshSyslogIndex.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Refresh Syslog Index"&gt;
&lt;h1&gt;exploring network access information&lt;/h1&gt;
&lt;p&gt;Now the additional fields are available to Kibana, I can start exploring the data to learn about which devices on my network are access which remote servers.&lt;/p&gt;
&lt;p&gt;To do this I first need to add the new fields to the 'Syslog Messages' saved search. This can be done by navigating to the 'Discover' page, loading the 'Syslog Messages' search (using the 'Load Saved Search' button in the top right of the screen), adding the new fields and re-saving it. This is shown below:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-AddingNewFieldsToSyslogMessagesSavedSearch.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Adding New Fields To Syslog Messages Saved Search"&gt;
&lt;p&gt;I'm now able to add some very interesting new visualizations to our dashboard such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Number of access by each local device&lt;/li&gt;
&lt;li&gt;Number of access by port&lt;/li&gt;
&lt;li&gt;Number of access to each remote server&lt;/li&gt;
&lt;li&gt;Number of access by protocol&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'll only run through adding the first visualization is they're all very similar.&lt;/p&gt;
&lt;p&gt;First, I navigate to the 'Visualization' area and click the 'New Visualization' button. I want to see the number of accesses being made by each device as a fraction of the whole so will use a donut chart. This is done by selecting 'Pie chart' from the "Create new Visualization" menu and selecting our 'Syslog Messages' saved search in the "Select a search source" menu. Once this is done, I get a pie chart with a single section as shown here:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-NewPieChartVisualization.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana New Pie Chart Visualization"&gt;
&lt;p&gt;I then need to select the 'Split Slices' bucket type, choose 'Terms' as the aggregation type and finally select 'source_address' as the field on which to aggregate (i.e. count) unique terms. Applying this to the pie-chart (using the 'Apply' button) results in the following:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-SplitSlicePieChartUsingSourceAddress.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Split Slice Pie Chart Using Source  ddres s"&gt;
&lt;p&gt;I'll  then  turn  this into a donut chart by ticking the 'Donut' check box from the 'Options' area as shown below:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-SplitSliceDonutChartUsingSourceAddress.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Split Slice Donut Chart Using Source Address"&gt;
&lt;p&gt;Now I'll use the same process for adding donut charts for each of the other metrics outlined above and add all the charts to my dashboard giving me the following:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardWithAccessCharts.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard With Access Charts"&gt;
&lt;h1&gt;summary&lt;/h1&gt;
&lt;p&gt;In this post, I showed how to extract structured information from unstructured text data in our source message. I then showed how this can be used within Kibana to highlight which devices on the local network are accessing which remote servers, on which ports and using which protocols.&lt;/p&gt;
&lt;p&gt;In the next post, I'll examine how to further enhance the information we've extracted from the access messages to make it easier to relate ip address to actual devices on the network and out in the world.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In part one of this series I set up my home router to send a variety of Syslog messages to LogStash which then forwarded these messages to ElasticSearch for indexing and querying by Kibana in a simplistic dashboard. In this post, I'm going to start parsing out some of the details of the Syslog messages to start giving us a clearer idea about which devices on my local network are opening sessions with remote servers.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/WotNoBlogPosts" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mKlqOBjK9u-QOTjr8e6t2pOev7BN2vWZHyEDf2l27_HhaNgR_aVCXi2-GJh_KZMQV-naegShjBydS0blOk2kSndI2eTXnRhuqA5Ry0VYn8a0HdOEj_RvSUJ8uVdzsiDmcn4XRkyaAn7kScarmtvlf5nua4L9lkP_bWrKG5Ai7JdQ%253Fwidth=660&amp;height=371&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/WotNoBlogPosts</id>
		<title>Wot No Blog Posts?</title>
		<updated>2016-07-26T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Yes, it's been over three months since my last blog post. "What have you been doing?" I hear you (the hypothetical reader) ask. Well... well I'll tell you.&lt;/p&gt;
&lt;p&gt;Having left my previous permanent position in January, I decided the time was right for a &lt;strong&gt;career break&lt;/strong&gt;. Having been &lt;a href="https://www.ted.com/talks/stefan_sagmeister_the_power_of_time_off?language=en"&gt;inspired to take a career break&lt;/a&gt; some six years ago, I knew how rejuvenating time off work can be and how reinvigorating it is when you finally have some time to pick and choose what it is you want to do and, more importantly, how. Indeed, last time I took a career break I ended up founding a company which - while not successful enough to prevent me having to return to employment - was massively educational, incredibly liberating and a whole lot of fun.&lt;/p&gt;
&lt;p&gt;However, my motivations for this career break are vastly different to those of six years ago. At that time I had just emerged from a somewhat turbulent relationship and was looking to - &lt;em&gt;sorry for the cliché&lt;/em&gt; - "re-find" myself; this time I am in a stable and happy relationship with my partner who last year gave birth to our little baby girl. And while, six years ago, I could - and was happy to - survive on very meagre savings, I am now lucky enough to be in a position where financial pressures are not an issue, at least in the short-term. Finally, while I had very little idea of what I was going to do during my last career break (which itself was extremely liberating in that you are suddenly open to being able to say "yes" to pretty much anything) this time I have a much more developed concept of how I want to use this opportunity.&lt;/p&gt;
&lt;p&gt;While my motivations and desires for the coming months will be the subject of future blog posts, I have started putting together a &lt;a href="https://trello.com/b/KoTWuFUi/public-board"&gt;public Trello board&lt;/a&gt; of ideas/projects I want to undertake. It's just a start and by no means comprehensive but I thought some transparency around my ideas and goals (not to mention progress!) would be good for me.&lt;/p&gt;
&lt;p&gt;For now though I want to share what I've been doing - and why there have been no blog posts - for the last three months. You see, a primary motivation for taking time out of my career now was to spend time with my young family and maximise the use of my partner's remaining maternity leave. To this end, shortly after leaving my previous job, my partner and I decided to &lt;strong&gt;take our baby on a road trip around Europe&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The timing really couldn't have been better; my partner still had a few months of maternity leave remaining, the baby was still happy to have long naps in the back of the car whenever we drove anywhere and I was still keen on buying a day-van (it's been a &lt;em&gt;thing&lt;/em&gt; with me for a while now). So in February we started planning and looking for a motor that could comfortably cart the three of us around Europe and by mid March we'd bought an imported Nissan Elgrand E51 Ryder Autech.&lt;/p&gt;
&lt;img src="https://zdfcta.dm2302.livefilestore.com/y3mRDVqstf6XsjN73biGoYnN5s-SzVcHx9pEdYl2S_wM803HpiosWK5Skxm-kskeHTMkahk_PIdejAp70x14KCaOwmZb6OvAvAig8uqI4bdBs2Pb_lAUsm-O_2lO8krW_18ReDVMLXqVkJWUGUSJ-d80bOIi8ciWIgyxDzL5fw4qF4?width=1796&amp;amp;height=1347&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="My other baby"&gt;
&lt;p&gt;Now the Elgrand is an MPV and not a campervan (a mostly pragmatic decision based on the fact we could use it on a daily basis after the trip and only a little bit due to "love at first drive") so there was a lot of work to do in order to prepare it for such a long journey. Therefore, between March and May, I researched, built and installed a bunch of modifications for the Elgrand to support us on our adventure. This included a custom built leisure battery / charging system enclosure, custom built frame to mount the electrical systems and luggage, routing of cabling around the Elgrand and several internal modifications for enhancing the navigation / ICE systems.&lt;/p&gt;
&lt;p&gt;I documented these modifications on the &lt;a href="http://elgrandoc.uk/"&gt;Elgrand Owners Club website&lt;/a&gt;. This site proved invaluable in terms of information about working on the Elgrand and I wanted to give something back to the active and very helpful community there. Due to limitations in the website's forum, the details had to be split across five posts which - if you're interested - can be found here: &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-i.3311/"&gt;Part I&lt;/a&gt;, &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-ii.3312/"&gt;Part II&lt;/a&gt;, &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-iii.3313/"&gt;Part III&lt;/a&gt;, &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-iv.3314/"&gt;Part IV&lt;/a&gt;, &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-v.3315/"&gt;Part V&lt;/a&gt;. After just a couple of days these posts have already garnered significant praise and numerous follow on questions so I feel pretty good about having spent the time writing these posts.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;As an aside, it occurred to me that this work could almost have been a case-study in Agile development. Not being a carpenter or mechanic and my work on cars to date having been pretty much limited to topping up the oil, I started this project from an absolute level of maximum ignorance. Fortunately as both a stake holder and engineer, it was easy to outline use-cases for the work which, while I didn't actually document them at the time, would have included some choice ones such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"As a driver I need a non-Japanese navigation system so I know where the smeg I'm supposed to be going!",&lt;/li&gt;
&lt;li&gt;"As a parent I need a fridge in the van so that we can keep food for the baby food fresh and - hopefully - the baby healthy" and,&lt;/li&gt;
&lt;li&gt;"As a caffeine junkie I need a means of making coffee in the van so that I don't murder everyone the morning after we spend a night in it!"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These could then be naturally prioritized and, where possible, undertaken concurrently by my partner and I. If something went well, we could close it off and move onto the next thing; if it didn't we could reevaluate it's value / priority in light of what we had. This way we managed to hit our deadline (the ferry departure - which we put off "committing" to until as late as possible) with as much high value work done as possible. More importantly, at departure (aka deployment) time, we had a significantly lower level of ignorance such that, should anything go wrong while we were "live", we'd actually stand a chance of fixing it without having to - possibly literally - "roll back" to England.&lt;/p&gt;
&lt;p&gt;Yes, yes, some of this terminology is undoubtedly tenuous but, having had hours and hours to reflect on this work while driving around Europe, it was rewarding to see how much more effective an iterative approach to problem solving can be. Who knows if we'd ever have got away if we'd tried to plan &lt;em&gt;everything&lt;/em&gt; up front.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Anyway, we departed England in mid-May and returned mid-July and had a truly fantastic adventure. In &lt;strong&gt;58 days&lt;/strong&gt; we travelled &lt;strong&gt;7912 miles&lt;/strong&gt; and visited &lt;strong&gt;20 countries&lt;/strong&gt;. Along the way we met a number of old friends, made a lot of new friends and saw some amazing sites and scenery. We learned a lot, not only about the various cultures / histories around Europe but also about ourselves and our daughter. And we laughed a lot, mostly about the quirks of the various cultures we were experiencing but also - in retrospect at least - about some of the challenges we faced along the way; like having to park up in a field at a border crossing in order to buy the vignette that would allow us to drive the car in the country we were about to cross in to, and getting visited by both a swarm of monstrously huge locust type insects and a heavily armed and somewhat suspicious (the Elgrand has very dark privacy glass) border guard.&lt;/p&gt;
&lt;p&gt;We really did experience so much that I frequently find myself remembering something from the trip that a) I had somehow already forgotten and b) seems like both a lifetime &lt;em&gt;and&lt;/em&gt; just a few days ago. Fortunately my partner kept a very detailed (and anonymised) blog of our journey in which she does an terrific job of capturing the fun and freedom we enjoyed while away. Should you be interested, you can read it &lt;a href="https://bigspune.wordpress.com/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And now we're home. The baby has started nursery and my partner is returning to work. While I'm still having to consciously work out where I am when I wake up in the night (seriously, after two months of staying somewhere different every night, this seems to be a thing at the moment) and we're still trying to get the house back into some semblance of order, life is returning to our own special approximation of normality.&lt;/p&gt;
&lt;p&gt;For four days a week and for the foreseeable future, I will have pretty much all day to do... well, pretty much anything I want. It's an exciting time in the world of .NET given the recent release of .NET Core and Microsoft's assimilation of Xamarin. Graph and document data stores (aka NoSQL) continue to make inroads on the traditional strong holds of legacy relational databases. And there are some profound changes in the broader world of software development such as the continuing move towards containerized deployment and cloud infrastructures. I'm very much looking forward to investigating / leveraging all these in the months to come.&lt;/p&gt;
&lt;p&gt;Who knows where it will lead. I will certainly be keeping my ear to the ground should an exciting job/contract come around. Ideally I'd want something remote / freelance which I could do on my terms and, should the right opportunity drop in my lap, I'd certainly be open to it. That said, what I'd really like to do is resurrect my company and see where I can take it. I have a couple of ideas with potential but will hold off on developing them until I've refamiliarised myself with the current trends in software development because, even though it's only been a few months, it feels like I've been out of the game for years.&lt;/p&gt;
&lt;p&gt;Well, game on.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Yes, it's been over three months since my last blog post. "What have you been doing?" I hear you (the hypothetical reader) ask. Well... well I'll tell you.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/NewBlogUsingWyam" />
		<id>http://ian.bebbs.co.uk/posts/NewBlogUsingWyam</id>
		<title>Using Wyam</title>
		<updated>2015-11-09T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;I've been meaning to create a blog for a &lt;strong&gt;long&lt;/strong&gt; time but never found a system with the right combination of features (power vs flexibility vs learning curve, cost, technology stack, etc). CMSs (Wordpress, Drupal, etc) were always way too much faff and most static site generators required the installation of numerous languages / run-times / sdks, etc.&lt;/p&gt;
&lt;p&gt;Then I found &lt;a href="http://wyam.io/" title="Wyam Homepage"&gt;Wyam&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Being .NET based it could be used from my day-to-day development machine and, by cleverly leveraging the  Roslyn compiler platform, can be set up to be as simple or flexible as desired. A quick flick through the module and API pages and I knew I'd found a potential candidate for my statically generated blog.&lt;/p&gt;
&lt;p&gt;Being a... ahem... pragmatic developer with somewhat dated web skills I decided to take the path of least resistance and copy someone else's blog layout. Afterall, imitation is the sincerest form of flattery, right? As such, I contacted Dave Glick - the most-excellent author of Wyam - to see if he would mind me 'borrowing' the layout he used for &lt;a href="http://daveaglick.com/" title="Dave Glick's blog"&gt;his blog&lt;/a&gt;. He quickly replied to my cheeky request and said he didn't mind at all if used his layout, even refusing my offer of attribution (which I hope this blog post somewhat makes up for).&lt;/p&gt;
&lt;p&gt;With the all clear, I &lt;a href="https://github.com/Wyamio/Wyam/releases/tag/v0.10.0-beta" title="download page for Wyam version 0.10.0-beta"&gt;downloaded the latest version of Wyam&lt;/a&gt;, cloned the &lt;a href="https://github.com/Wyamio/Wyam" title="Github repository for Wyam "&gt;Wyam repository&lt;/a&gt;, invoked Wyam to generate an &lt;a href="https://github.com/Wyamio/Wyam/tree/develop/Examples" title="Wyam Example sites in Github repository"&gt;example site&lt;/a&gt;... and got an exception.&lt;/p&gt;
&lt;p&gt;Another quick chat with Mr. Glick revealed that the project is iterating quickly and currently in a "move fast and break things" mode. Fortunately the issue was already resolved in the development branch so, after local build of Wyam, I managed to successfully generate the example sites.&lt;/p&gt;
&lt;p&gt;"Now for some blatant plagiarism with his blog" I thought to myself but again, after cloning his (generously shared and CC licensed) &lt;a href="https://github.com/daveaglick/daveaglick" title="Github repository for Dave Glick's blog"&gt;blog&lt;/a&gt;, asking Wyam to generate the site threw an exception. This time, a &lt;a href="https://github.com/Wyamio/Wyam/issues/112#issuecomment-155165316" title="Wyam PostFile issue comment on Github"&gt;short bit of call-stack sleuthing&lt;/a&gt; revealed another breaking change which was easily resolved by examining the &lt;a href="http://wyam.io/modules/" title="Module documentation for Wyam"&gt;Wyam module documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once more with feeling and ét voila, a MVB (Minimal Viable Blog).&lt;/p&gt;
&lt;p&gt;All in all, not a bad experience with an early beta of a very clever project. Moving forward, I actually hope to do very little with Wyam other than post blog entries but will certainly endeavour to keep up to date with Wyam and share my experiences here.&lt;/p&gt;
&lt;p&gt;If you're looking for a flexible yet powerful .NET based static-site generator, go check out &lt;a href="http://wyam.io/" title="Wyam Homepage"&gt;Wyam&lt;/a&gt;. If you experience any problems with it I'd definitely recommend posting an issue on Github, Dave seems to be very on the ball responding to issues (and extremely friendly to boot).&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;I've been meaning to create a blog for a &lt;strong&gt;long&lt;/strong&gt; time but never found a system with the right combination of features (power vs flexibility vs learning curve, cost, technology stack, etc). CMSs (Wordpress, Drupal, etc) were always way too much faff and most static site generators required the installation of numerous languages / run-times / sdks, etc.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/EndOfStreak" />
		<id>http://ian.bebbs.co.uk/posts/EndOfStreak</id>
		<title>Breaking News - Forgot to commit</title>
		<updated>2015-12-07T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;After 41 days of continuous commits to Github, yesterday I forgot. What's really annoying is that I actually spent a long time working yesterday but found myself battling a stupid limitation of VisualStates in UWP apps (blog post incoming) and didn't have anything finished.&lt;/p&gt;
&lt;p&gt;Ho-hum. 41 days was a pretty good streak and it was inevitably going to end over the Xmas period. New Year's resolution: Beat it!&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;After 41 days of continuous commits to Github, yesterday I forgot. What's really annoying is that I actually spent a long time working yesterday but found myself battling a stupid limitation of VisualStates in UWP apps (blog post incoming) and didn't have anything finished.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/CombiningUwpSpeechSynthesizerWithAudioGraph" />
		<id>http://ian.bebbs.co.uk/posts/CombiningUwpSpeechSynthesizerWithAudioGraph</id>
		<title>Combining the UWP SpeechSynthesizer and AudioGraph APIs</title>
		<updated>2017-01-25T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Synchronicity is a wonderful thing.&lt;/p&gt;
&lt;p&gt;Just this morning I was considering using the new &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.speechsynthesis.speechsynthesizer.aspx"&gt;SpeechSynthesizer&lt;/a&gt; capabilities of the UWP platform to add spoken language to my &lt;a href="https://www.microsoft.com/en-gb/store/p/toddlerbox/9nblggh3zr4l"&gt;ToddlerBox app for Xbox&lt;/a&gt;. I had already started using the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiograph.aspx"&gt;AudioGraph&lt;/a&gt; classes to play sounds in the app so ideally wanted to continue using this API to emit speech.&lt;/p&gt;
&lt;p&gt;Then, during my morning... ahem... ablutions, I came across &lt;a href="https://mtaulty.com/2017/01/15/windows-10-uwp-iot-core-speechsynthesizer-raspberry-pi-and-audio-popping/"&gt;this post&lt;/a&gt; by Mike Taulty who was looking to do the same thing but for different reasons. It seems that the RaspberryPi has a firmware issue that causes a &lt;a href="https://social.msdn.microsoft.com/Forums/en-US/7c312972-6a09-4acd-8a3f-c59485a81d74/clicking-sound-during-start-and-stop-of-audio-playback?forum=WindowsIoT"&gt;popping noise&lt;/a&gt;  every time speech is emitted using the MediaPlayer and AudioGraph seems to be a way of resolving it.&lt;/p&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;Mike had implemented a means of emitting speech via AudioGraph by saving the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.speechsynthesis.speechsynthesisstream.aspx?f=255&amp;amp;MSPPError=-2147217396"&gt;SpeechSynthesisStream&lt;/a&gt; to a  temporary file and then using multiple &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiofileinputnode.aspx"&gt;AudioFileInputNode&lt;/a&gt; instances to render the speech to the AudioGraph.&lt;/p&gt;
&lt;p&gt;"Well", I thought, "there's got to be a better way. How hard can this be..."&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Turns out the answer is: "Not all that hard, but...".&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;My approach&lt;/h2&gt;
&lt;p&gt;I wanted to find a way to eliminate the need for the temporary files and render the speech stream directly to the graph.&lt;/p&gt;
&lt;p&gt;To do this, I first saved the SpeechSynthesisStream to a file so that I could examine the content. As expected, the file turned out to be a simple 32-bit, mono, ADPCM waveform in &lt;a href="http://soundfile.sapp.org/doc/WaveFormat/"&gt;WAV/RIFF format&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Having previously messed about with AudioGraph I knew there was a way of creating an in-memory waveform and that the &lt;a href="https://github.com/Microsoft/Windows-universal-samples"&gt;Windows-Universal-Samples github repository&lt;/a&gt; had an &lt;a href="https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/AudioCreation"&gt;AudioCreation sample&lt;/a&gt; that &lt;a href="https://github.com/Microsoft/Windows-universal-samples/blob/master/Samples/AudioCreation/cs/AudioCreation/Scenario3_FrameInputNode.xaml.cs"&gt;showed how to do this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fundamentally, this sample shows how to use the &lt;a href="https://msdn.microsoft.com/en-gb/library/windows/apps/windows.media.audio.audioframeinputnode.quantumstarted"&gt;QuantumStarted event&lt;/a&gt; of the &lt;a href="https://msdn.microsoft.com/library/windows/apps/dn914147"&gt;AudioFrameInputNode&lt;/a&gt; to dynamically add &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audioframe.aspx"&gt;AudioFrame&lt;/a&gt; to the AudioFrameInputNode which are then rendered to the &lt;a href="https://msdn.microsoft.com/en-gb/library/windows/apps/dn914151"&gt;output node&lt;/a&gt;. An extract from the sample is shown here:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;  unsafe private AudioFrame GenerateAudioData(uint samples)
  {
      // Buffer size is (number of samples) * (size of each sample)
      // We choose to generate single channel (mono) audio. For multi-channel, multiply by number of channels
      uint bufferSize = samples * sizeof(float);
      AudioFrame frame = new Windows.Media.AudioFrame(bufferSize);

      using (AudioBuffer buffer = frame.LockBuffer(AudioBufferAccessMode.Write))
      using (IMemoryBufferReference reference = buffer.CreateReference())
      {
          byte* dataInBytes;
          uint capacityInBytes;
          float* dataInFloat;

          // Get the buffer from the AudioFrame
          ((IMemoryBufferByteAccess)reference).GetBuffer(out dataInBytes, out capacityInBytes);

          // Cast to float since the data we are generating is float
          dataInFloat = (float*)dataInBytes;

          float freq = 1000; // choosing to generate frequency of 1kHz
          float amplitude = 0.3f;
          int sampleRate = (int)graph.EncodingProperties.SampleRate;
          double sampleIncrement = (freq * (Math.PI * 2)) / sampleRate;

          // Generate a 1kHz sine wave and populate the values in the memory buffer
          for (int i = 0; i &amp;lt; samples; i++)
          {
              double sinValue = amplitude * Math.Sin(theta);
              dataInFloat[i] = (float)sinValue;
              theta += sampleIncrement;
          }
      }

      return frame;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Imitation being the sincerest form of flattery, I then refactored this code to read the binary data from the SpeechSynthesisStream rather than generate a sine wave as shown above. This was greatly facilited by the &lt;a href="https://msdn.microsoft.com/en-us/library/hh582142.aspx"&gt;WindowsRuntimeStreamExtensions.AsStreamForRead&lt;/a&gt; method which allowed me to use basic &lt;a href="https://msdn.microsoft.com/en-us/library/system.io.stream.aspx"&gt;Stream&lt;/a&gt; methods  (specifically &lt;a href="https://msdn.microsoft.com/en-us/library/system.io.stream.readbyte.aspx"&gt;Stream.ReadByte()&lt;/a&gt;) instead of having to mess about with &lt;a href="https://msdn.microsoft.com/en-us/library/windows.media.speechsynthesis.speechsynthesisstream.readasync.aspx"&gt;IBuffer&lt;/a&gt; instances.&lt;/p&gt;
&lt;p&gt;In short order, I ended up with the code below (where &lt;code&gt;_stream&lt;/code&gt; is a member of the containing class pointing to the underlying SpeechSynthesisStream):&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;    private unsafe void QuantumStarted(AudioFrameInputNode sender, FrameInputNodeQuantumStartedEventArgs args)
    {
        uint numSamplesNeeded = (uint)args.RequiredSamples;

        if (numSamplesNeeded != 0 &amp;amp;&amp;amp; _stream.Position &amp;lt; _stream.Length)
        {
            uint bufferSize = numSamplesNeeded * sizeof(float);
            AudioFrame frame = new AudioFrame(bufferSize);

            using (AudioBuffer buffer = frame.LockBuffer(AudioBufferAccessMode.Write))
            {
                using (IMemoryBufferReference reference = buffer.CreateReference())
                {
                    byte* dataInBytes;
                    uint capacityInBytes;

                    // Get the buffer from the AudioFrame
                    ((IMemoryBufferByteAccess)reference).GetBuffer(out dataInBytes, out capacityInBytes);

                    for (int i = 0; i &amp;lt; bufferSize; i++)
                    {
                        if (_stream.Position &amp;lt; _stream.Length)
                        {
                            dataInBytes[i] = (byte)_stream.ReadByte();
                        }
                        else
                        {
                            dataInBytes[i] = 0;
                        }
                    }
                }
            }

            _frameInputNode.AddFrame(frame);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to my surprised, it worked!&lt;/p&gt;
&lt;p&gt;I encapsulated this code into a class named &lt;a href="https://github.com/ibebbs/BlogProjects/blob/master/UwpSpeechAudio/GraphExtensions.cs"&gt;AudioSpeechInputNode&lt;/a&gt; and made this class implement &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudioinputnode.aspx"&gt;IAudioInputNode&lt;/a&gt; so it could be treated like any other node in the AudioGraph. Finally I added an extension method to AudioGraph that created instance of this node in the same way that other nodes are created. This is shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;    AudioSpeechInputNode speechInputNode = await _graph.CreateSpeechInputNodeAsync(new SpeechSynthesizer(), "As input node");
    speechInputNode.AddOutgoingConnection(_outputNode); // device output node
    speechInputNode.Stop();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this node in hand you're then at liberty to call the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudionode.start.aspx"&gt;Start&lt;/a&gt;, &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudionode.stop.aspx"&gt;Stop&lt;/a&gt; and &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudionode.reset.aspx"&gt;Reset&lt;/a&gt; methods as you see fit.&lt;/p&gt;
&lt;p&gt;Et voila, a SpeechSynthesisStream rendered in an AudioGraph without the need for an intermediary file.&lt;/p&gt;
&lt;h2&gt;You said there was a 'but' ...&lt;/h2&gt;
&lt;p&gt;Well, yes. Three of them actually.&lt;/p&gt;
&lt;h3&gt;The big 'but'&lt;/h3&gt;
&lt;p&gt;While this approach certainly solves the issue with needing temporary files and a 'popping' sound each time speech is emitted, I'm afraid to say it does not resolve the 'popping' noise encountered when the application starts on a RaspberryPi.&lt;/p&gt;
&lt;p&gt;Being a good nerd, I had a spare RaspberryPi 3 hanging around with a recent version of Windows 10 IoT Core installed. It took just a few minutes to recompile my &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/UwpSpeechAudio"&gt;sample app&lt;/a&gt; to ARM and deploy it to the Pi whereupon I could confirm that there is no popping when emitting speech but there is when the application starts. In fact, I receive three distinct 'pops' during application start-up which, by studiously placing breakpoints, I isolated to &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiograph.createasync.aspx"&gt;AudioGraph.CreateAsync&lt;/a&gt; (two pops) and &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiograph.start.aspx"&gt;AudioGraph.Start&lt;/a&gt; (one pop).&lt;/p&gt;
&lt;p&gt;Microsoft would have us believe that this is an issue with the RaspberryPi firmware but, as it also occurs on &lt;a href="https://developer.qualcomm.com/hardware/dragonboard-410c"&gt;DragonBoard 410c&lt;/a&gt; I'm more inclined to believe it's an issue with the Windows drivers. On a hunch, I've just ordered a &lt;a href="https://www.amazon.co.uk/dp/B016CU2PEU"&gt;USB Sound Adapter from Amazon&lt;/a&gt;. This device is &lt;em&gt;meant&lt;/em&gt; to be Windows and RaspberryPi compatible (which doesn't necessarily mean it'll work with IoT Core on RPi) and, if it works, I'll be very interested to see if I still get the popping noises when the application starts. I'll update this post once I have an answer...&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Update: I'm pleased to say that, not only does &lt;a href="https://www.amazon.co.uk/dp/B016CU2PEU"&gt;this device&lt;/a&gt; work with Windows 10 IoT Core running on the RaspberryPi 3, but it also resolves the issue with popping noises when the application starts. Of course, this would probably also solve the issue with popping noises when rendering speech through MediaPlayer too making my solution above less necessary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;The intermediate 'but'&lt;/h3&gt;
&lt;p&gt;My code makes a number of assumptions about the format of the SpeechSynthesisStream and encapsulates these as constants. It would be much better to read the format from the WAVE 'fmt ' chunk of the underlying RIFF structures in the stream but, being a pragmatic, &lt;a href="https://martinfowler.com/bliki/Yagni.html"&gt;YAGNI principled&lt;/a&gt; developer... I skipped this for now.&lt;/p&gt;
&lt;h3&gt;The small 'but'&lt;/h3&gt;
&lt;p&gt;As is probably very obvious, the code above is in no way optimised. I'm sure there are &lt;em&gt;much&lt;/em&gt; better and faster ways of storing and copying the binary data from the SpeechSynthesisStream into the AudioBuffer (perhaps just using an intermediate byte array would help) but, for now, this code works fine.&lt;/p&gt;
&lt;h2&gt;Show me the code&lt;/h2&gt;
&lt;p&gt;All the code for the above can be found in a &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/UwpSpeechAudio"&gt;UWP sample app&lt;/a&gt; within the &lt;a href="https://github.com/ibebbs/BlogProjects"&gt;BlogProjects&lt;/a&gt; repository of my &lt;a href="https://github.com/ibebbs"&gt;Github&lt;/a&gt; account.&lt;/p&gt;
&lt;p&gt;Do &lt;a href="https://twitter.com/ibebbs"&gt;get in touch&lt;/a&gt; if you find this code helpful or have suggestions for improving it.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Synchronicity is a wonderful thing.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/MonsterPi" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mJgriVgVEFWAdldfy7Bj9MEJznwpJtJ4NFHotqnwZ0rWbC2h8ewxTr9MSxr6LCGyQBB-TvmYCV9j4YVZbu2EtVHagPnyc6O_LIZV2NqAiPfrfNkZ8P-XBV6SI0GiL7zx0iuOTniKjZ-Gq9_lN6SLkkIMHMx14EE3l2XuZQ1cTPfI%253Fwidth=967&amp;height=273&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/MonsterPi</id>
		<title>MonsterPi</title>
		<updated>2016-10-08T00:00:00Z</updated>
		<content>
                                        


&lt;h2&gt;Preface&lt;/h2&gt;
&lt;p&gt;I've long loved the idea of home automation. From X10 and LightwaveRF through to modern Bluetooth and Wifi connected devices, I have played with dozens of technologies in search of home automation nirvana. But recently I have watched with growing bewilderment at the incredible number of "cloud-connected" home automation devices being released and the eagerness with which they're snapped up by naive consumers hungry to control everything from the carefree comfort of their iPhone.&lt;/p&gt;
&lt;p&gt;You see, while you can buy a myriad of IoT devices off the shelf nowadays, they nearly all come with some form of "cloud-service" that is necessary in order for the device to work as sold. As the more wily of reader will no doubt be aware, this exposes your home network to innumerable &lt;a href="https://it.slashdot.org/story/16/10/03/1359200/source-code-for-iot-botnet-mirai-which-took-down-krebs-on-security-website-with-ddos-attack-released"&gt;security concerns&lt;/a&gt;, &lt;a href="https://it.slashdot.org/story/16/08/08/1449221/hackers-make-the-first-ever-ransomware-for-smart-thermostats"&gt;potential abuses&lt;/a&gt; and an &lt;a href="https://tech.slashdot.org/story/16/01/14/1347243/nest-thermostat-bug-leaves-owners-without-heating"&gt;external point of failure&lt;/a&gt; that cannot be closed/fixed without sacrificing some or all of the functionality of the new fangled device.&lt;/p&gt;
&lt;p&gt;While I understand the ostensible benefits of this approach (ease of setup, remote use without manually opening firewall ports, centralised patching and upgrading, etc), sacrificing control of (potentially hazardous or invasive) devices within my home is not a value proposition I am comfortable with. I would very much like to see a new (or is that old?) breed of device that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;does not require an internet connection to operate with all features intact,&lt;/li&gt;
&lt;li&gt;with which the owner can proactively decide what control and data is available to servers outside of the home network and,&lt;/li&gt;
&lt;li&gt;which surface simple, open interfaces to the owner allowing them to completely control all aspects of the device.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In short, I'd like to drop the 'Inter' from IoT and expand the 'net' to become a 'Network of Things', or NoT.&lt;/p&gt;
&lt;p&gt;In terms of the consumer market, I am undoubtedly swimming against the tide here. Fortunately with the rise of hobbyist devices such as Arduino and RaspberryPi, IoT technologies have been democratised to the extent that anyone with just the smallest ability with a soldering iron and faculty with an IDE can create such devices for themselves.&lt;/p&gt;
&lt;p&gt;Ladies and gentlemen, I present my first (finished) NoT device, the...&lt;/p&gt;
&lt;h1&gt;MonsterPi&lt;/h1&gt;
&lt;p&gt;Years ago, while setting up my (living room) home cinema, I came across the &lt;a href="http://www.adverts.ie/home-audio/monster-hts-1600-home-theatre-powercenter-5-outlet-with-stage-2-clean-power-purge-protector-uk-version/7055360"&gt;Monster Power HTS 1600&lt;/a&gt; on &lt;a href="https://www.scan.co.uk/"&gt;Scan's website&lt;/a&gt;. It seems Monster Products were end-of-lining their power products in the UK (the above link was literally the only one I could find that still works!) and Scan were selling them off at £30 a piece. It was exactly what I was looking for at the time and, not being one to pass up a bargain, I bought two.&lt;/p&gt;
&lt;img src="https://0oiczq.dm2302.livefilestore.com/y3mwcGE45bQwRPaCXRNuB9tGejIT6aSpahgDN02u9ag661uCa_ZmYbNnaKz2aW81rjG8BTgsUhtZ0aDQ8ioIsagbcFP6LtM-IgV_rcPoCs8UI4dZNegv8JembGIuIr7ETkwTZwOTEUjsAAbQHy0jCyAGNkGu3NJZLkXjnGwgzUMlTI?width=700&amp;amp;height=466&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="One of the few remaining pictures online of the Monster Power HTS 1600 UK version"&gt;
&lt;p&gt;Both devices found homes powering and protected my front room and study AV equipment and, to this day, I am still very happy with them. However, I always felt that Monster had missed a trick with this product: the ability to individually and - ideally - remotely turn each of the sockets on the unit on and off as desired.&lt;/p&gt;
&lt;p&gt;When Microsoft announced that Windows IoT Core would run on a RaspberryPi the learning curve ahead of making this happen evaporated and I knew it was something I wanted to do. Unfortunately both Monster Power devices were in full time use and I didn't want to potentially sacrifice one on a project that might not work and could consign the device to the scrap yard. Given that you couldn't purchase the UK version of these devices any more and that, when they occasionally appeared on eBay, they'd invariably be priced at £100+ the project was indefinitely parked.&lt;/p&gt;
&lt;p&gt;Finally, a couple of months ago, a 'used' one appeared on eBay without a reserve and with bidding at thirty odd quid having just a few hours to go. I placed a bid without really hoping it would be successful and, to my surprise, ended up winning the auction for £40'ish including delivery. When it arrived I was delighted to find that it seemed to be brand new and unused (twisty wire on all the cables, supplementary cables still in sealed bags, etc). Plugging it in proved that everything worked as it should so everything was in place to build the MonsterPi.&lt;/p&gt;
&lt;h2&gt;Software&lt;/h2&gt;
&lt;p&gt;While waiting for the time and space required to start hacking up the hardware, I took a look into what was required to write a headless UWP app, self-hosting a HTTP REST endpoint that could be deployed to the RaspberryPi and set values on the GPIO pins necessary to control the &lt;a href="http://www.waveshare.com/rpi-relay-board.htm"&gt;Waveshare RaspberryPi Relay Board&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It didn't take long to find &lt;a href="https://github.com/tomkuijsten/restup"&gt;Restup&lt;/a&gt;, a beautifully simple if somewhat minimal 'Webserver for Universal Windows Apps'. The github repository provided ample samples for writing various types of 'controller' and in less than an hour, I had a working solution.&lt;/p&gt;
&lt;p&gt;Given the Waveshare relay board just required GPIO pins to be set in order to control the relay (low to close, high to open) this was achieved very simply using the classes available in the &lt;a href="https://msdn.microsoft.com/library/windows/apps/windows.devices.gpio.aspx"&gt;Windows.Devices.Gpio namespace&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Deployment was taken care of by Visual Studio and configuration performed using the Windows IoT Core Device Portal. The Device Portal allows you to configure deployed apps to run at start up thereby creating a "service-like" experience for headless apps.&lt;/p&gt;
&lt;img src="https://0oidzq.dm2302.livefilestore.com/y3myuJMpQJ0iee-DzmucnuUu2r69IZ2c_KNukHEjoPB0--qRcndLbk0EwUszv8MLYj207fNIWEelQn4TYtW40FVp_y77RW-aTL3AcxQWcowLMB_zsw9jYdH0SwepJ0l6_XC0z9erqkYt4k4TaUBdnqxPYUlSf786xKVx1zwTC4jEsg?width=1363&amp;amp;height=905&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Using the device portal to set Start-up apps"&gt;
&lt;p&gt;Full source code is available on my &lt;a href="https://github.com/ibebbs/MonsterPi"&gt;Github account&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Hardware&lt;/h2&gt;
&lt;p&gt;The hardware side of things proved to be both easier and more tricky than I expected.&lt;/p&gt;
&lt;p&gt;Initially I thought fitting the Pi was going to be child's-play when, upon opening the Monster Power chasis I found that the configuration of sockets providing isolation for RJ11 and RJ45 devices (phone and ethernet respectively) matched the layout of the ethernet and USB connectors of the Pi almost perfectly. Furthermore, these sockets were mounted on an easily removable daughter-board providing an obvious way to fix the pi in place.&lt;/p&gt;
&lt;img src="https://nhtcwg.dm2302.livefilestore.com/y3mKq_74GixCoND7XvyavcDTjnNPdW2xd58RqEk1KZtO4f8nqKhcwyGbMRJqYhtuIHOmJCrJo6O-pltKB1pW0DFAHNy2oi6CNuyOle6TUxrjb4UzQo5_uDIPhNAP1uF8llVVLds4J6Bcp5b2s0GRI_T1uLx__qES0eUimFSxaTWddk?width=1024&amp;amp;height=576&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="The sockets on the RaspberryPi aligned almost perfectly with the RJ11 isolator sockets"&gt;
&lt;p&gt;While alignment wasn't perfect, filing the holes in the chasis to provide access to all ports would be easy.&lt;/p&gt;
&lt;p&gt;Complexity came when I realised that, although the Monster Power included a micro-controller driven digital display, it was unlikely that the DC subsystem in place to power this would be adequate for the RaspberryPi. So here I had to get creative.&lt;/p&gt;
&lt;p&gt;I bought a small &lt;a href="https://www.amazon.co.uk/gp/product/B01H0OH3PI/ref=oh_aui_detailpage_o02_s01?ie=UTF8&amp;amp;psc=1"&gt;12v 80W switching power supply&lt;/a&gt; which would fit down one side of the Moster Power chasis and wired it to the 240v input of using the conveniently provided ring terminals. I used a &lt;a href="http://ian.bebbs.co.uk/posts/3DPrintingWithTheCelRobox"&gt;custom printed bracket&lt;/a&gt; to secure the PSU in place while providing a platform to mount the &lt;a href="http://www.waveshare.com/rpi-relay-board.htm"&gt;Waveshare RaspberryPi Relay Board&lt;/a&gt; above, in close proximity to the sockets I wanted to control with the relays.&lt;/p&gt;
&lt;p&gt;The live wire to the three sockets to be controlled by relays were daisy-chained together so one side of this wire was cut from each socket and connected to the normally-closed output of the relay (extending where necessary using crimp connectors).&lt;/p&gt;
&lt;p&gt;This is shown below:&lt;/p&gt;
&lt;img src="https://zphbnq.dm2302.livefilestore.com/y3mBGmj_-221eHr5ChhkWQfyEOjewU-6JEKOKlqHR-UqR0eMZdf2xPtI5qfP_K1rjguEplhOWObkMJ2fiGI4T4WSQOGh8GfodMLL2lPWD5QZFnBFPYwPUID3FZgVTYndwwL5jDybtRBC6JE_hhcTokWGrmppuLoHccNLsmFZyUsAvM?width=576&amp;amp;height=1024&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="12v switching PSU with relay board mounted in custom bracket"&gt;
&lt;p&gt;While the perspective in the picture makes it look like it hangs over the edge of the chasis, it does actually fit. It's tight, but it fits.&lt;/p&gt;
&lt;p&gt;I used a &lt;a href="https://www.amazon.co.uk/gp/product/B01CUA5Q74/ref=oh_aui_detailpage_o02_s00?ie=UTF8&amp;amp;psc=1"&gt;12V To 5V 3A 15W Power Converter Regulator with Micro USB Cable&lt;/a&gt; to power the RaspberryPi and - given I now had plenty of power to spare, decided to also fit the &lt;a href="https://www.amazon.co.uk/Step-Down-Step-down-Power-Module/dp/B00ENE55SQ/ref=pd_nav_hcs_bia_t_1?ie=UTF8&amp;amp;psc=1&amp;amp;refRID=J91844QA901NNMPP9XHJ"&gt;4-port USB power module&lt;/a&gt; I had bought, but not used, for our &lt;a href="http://ian.bebbs.co.uk/posts/WotNoBlogPosts"&gt;travels earlier in the year&lt;/a&gt;. Again, this aligned almost perfectly in the remaining holes in the Monster Power chasis.&lt;/p&gt;
&lt;img src="https://nhtcwg.dm2302.livefilestore.com/y3mKq_74GixCoND7XvyavcDTjnNPdW2xd58RqEk1KZtO4f8nqKhcwyGbMRJqYhtuIHOmJCrJo6O-pltKB1pW0DFAHNy2oi6CNuyOle6TUxrjb4UzQo5_uDIPhNAP1uF8llVVLds4J6Bcp5b2s0GRI_T1uLx__qES0eUimFSxaTWddk?width=1024&amp;amp;height=576&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="The sockets on the USB power module aligned almost perfectly with the RJ11 isolator sockets"&gt;
&lt;p&gt;Both these were mounted - upside down - on a custom printed bracket using the screw holes for the original daughter board to secure it in place. Terminal connectors were used to provide connection to the power supply just in case I needed to remove the components at a later date for some reason.&lt;/p&gt;
&lt;img src="https://zphcnq.dm2302.livefilestore.com/y3mMyQU1JCq5r9g0pnmuLGrrVm1-_D8Bq9UVm5uZgUD2lx9t3LVnjEIgWzqzwKeKbju29iHfBntmTX0FPZFKzWK6RAnFwWw-rxMfWyslJf52FN4XkFlglfGHc97-z24asPfR-NLEAd8nEE9e8X9V-tEP_wen7kF0zsAchvQJYwOjJk?width=576&amp;amp;height=1024&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Mounting the RaspberryPi and USB power module on a custom bracket"&gt;
&lt;p&gt;Finally, boards were fixed in place and a ribbon cable connected between the GPIO socket on the RaspberryPi and the relay board to allow control of the relays.&lt;/p&gt;
&lt;img src="https://nhtewg.dm2302.livefilestore.com/y3mYTQzOsTukjrHcb69XX-50V18rcvHJUP4R8u6hmsgR1yAm2DCpFzoK9UdUNyfxseH59qtuRbVeIVVX9AM1h8lde7IbZDOPRYz0le7cac0bFkoC4pzsyjVKNO3QapjDdlCK-awMaL_NOhYEw6rW4_7lMTobDNRqGrK17yE1SmeRHA?width=1024&amp;amp;height=576&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Brackets in place and RaspberryPi fitted"&gt;
&lt;p&gt;After a thorough check to make sure there were no shorts on any of the connections and that I had connected polarity correctly, I plugged it in and turned it on....&lt;/p&gt;
&lt;h2&gt;Testing&lt;/h2&gt;
&lt;p&gt;... and everything worked.&lt;/p&gt;
&lt;p&gt;The RaspberryPi booted but didn't switch the sockets on as - I think - not having a network connection meant it couldn't get an IP address which meant the software hadn't enabled to relays due to being configured to fail safe (leave the sockets off). The power indicator on the USB power module suggested it was working fine too.&lt;/p&gt;
&lt;p&gt;Next I relocated to another room where a network connection was available. I plugged it in, turned it on and saw the network connection LED's start blinking. After 15-20 seconds or so while the RaspberryPi booted, the relays tickets on and I was able to hit the REST endpoint from &lt;a href="https://www.getpostman.com/"&gt;Postman&lt;/a&gt;. I'd even managed to get the names of the sockets on the rest service to match the sockets the relays were controlling, although I admit this was more luck than judgement (I had completely expected to have to re-configure the software to match after the hardware was complete).&lt;/p&gt;
&lt;p&gt;I plugged in a small table lamp and recorded this:&lt;/p&gt;
&lt;iframe src="https://onedrive.live.com/embed?cid=03DF8A28BD9D0BC9&amp;amp;resid=3DF8A28BD9D0BC9%21266322&amp;amp;authkey=AI5IzCXupiYl-CU" width="600px" height="340px" frameborder="0" scrolling="no" allowfullscreen=""&gt;&lt;/iframe&gt;
&lt;p&gt;Boom! (Figuratively speaking of course... the MonsterPi didn't literally go boom... yet :0)&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;I've long loved the idea of home automation. From X10 and LightwaveRF through to modern Bluetooth and Wifi connected devices, I have played with dozens of technologies in search of home automation nirvana. But recently I have watched with growing bewilderment at the incredible number of "cloud-connected" home automation devices being released and the eagerness with which they're snapped up by naive consumers hungry to control everything from the carefree comfort of their iPhone.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/AcheivementUnlocked" />
		<id>http://ian.bebbs.co.uk/posts/AcheivementUnlocked</id>
		<title>Achievement Unlocked!</title>
		<updated>2016-08-11T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;So, I'm currently working on a project in which I've decided to employ the &lt;a href="http://martinfowler.com/bliki/CQRS.html"&gt;CQRS&lt;/a&gt;/&lt;a href="http://martinfowler.com/eaaDev/EventNarrative.html"&gt;ES&lt;/a&gt; architectural combo. Given the system is event sourced, I required read models built from the domain events and, conveniently, had blogged about doing this as one of my &lt;a href="http://ian.bebbs.co.uk/posts/ReactiveReadModels"&gt;first posts&lt;/a&gt; on this blog.&lt;/p&gt;
&lt;p&gt;It was very satisfying to be able to refer back to that blog post to re-familiarize with the pattern and I must say that so far everything is working beautifully. Stay tuned for a future post on using RX to implement a CQRS/ES application in a reactive manner.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;So, I'm currently working on a project in which I've decided to employ the &lt;a href="http://martinfowler.com/bliki/CQRS.html"&gt;CQRS&lt;/a&gt;/&lt;a href="http://martinfowler.com/eaaDev/EventNarrative.html"&gt;ES&lt;/a&gt; architectural combo. Given the system is event sourced, I required read models built from the domain events and, conveniently, had blogged about doing this as one of my &lt;a href="http://ian.bebbs.co.uk/posts/ReactiveReadModels"&gt;first posts&lt;/a&gt; on this blog.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ARipStoringTime" />
		<id>http://ian.bebbs.co.uk/posts/ARipStoringTime</id>
		<title>A Rip Storing Time</title>
		<updated>2016-12-07T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;From a youth of misspent money, I have a moderately large DVD collection. Some 600 movies in half a dozen DVD racks take a disproportionately large space in my dining room. This year, my partner and I  decided to host Xmas dinner for the family, meaning a dining table that could host a dozen was in order and... well, you can see where this is heading. The DVDs had to go.&lt;/p&gt;
&lt;p&gt;Now, even though I barely watch them anymore, there are still a couple of amazing films in my collection that aren't available from the (far too changeable) online streaming services and, as such, I was reluctant to simply banish them all to the attic. Instead, I decided to undertake the monumental task of ripping them all to HDD before boxing them all up.&lt;/p&gt;
&lt;h2&gt;Software&lt;/h2&gt;
&lt;p&gt;There are innumerable software solutions for ripping and transcoding DVD's... if you want to do one at a time. As you can probably appreciate, this wasn't a possibility for me or I'd still be ripping discs well into the New Year (not to mention through the Xmas dinner I'm actually doing this for). So a more, 'roll-your-own' solution was required.&lt;/p&gt;
&lt;p&gt;A bit of googling revealed &lt;a href="http://lifehacker.com/autorip-rips-dvds-and-blu-rays-as-soon-as-you-insert-th-477274988"&gt;this post&lt;/a&gt; which described a mechanism for ripping discs as soon as you put them into the drive. While it was still targetting people who wanted to rip discs one at a time, it did point me towards the two pieces of software I did ultimately use:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.makemkv.com/"&gt;MakeMKV&lt;/a&gt; - for ripping the entire contents of the DVD and,&lt;/li&gt;
&lt;li&gt;&lt;a href="https://handbrake.fr/"&gt;Handbrake&lt;/a&gt; - for transcoding source files into compressed H.264 format.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both these utilities come with CLI interfaces (details &lt;a href="http://www.makemkv.com/developers/"&gt;here&lt;/a&gt; and &lt;a href="https://handbrake.fr/docs/en/latest/cli/cli-options.html"&gt;here&lt;/a&gt; respectively) allowing them to be automated. Furthermore, MakeMKV can run multiple instances allowing you to do your drive ripping (the long slow process) in parallel from multiple drives.&lt;/p&gt;
&lt;h2&gt;Hardware&lt;/h2&gt;
&lt;p&gt;I'd been intending to buy a new server for my home to be used as a Docker host because my current server is so old it simply doesn't support the required virtualization instructions. I'd had my eye on the &lt;a href="http://www.ebuyer.com/714837-dell-poweredge-t20-3708-xeon-e3-1225v3-3-2-ghz-4gb-ram-1tb-hdd-tower-t20-3708"&gt;Dell T20 Xeon E3&lt;/a&gt; but was waiting for it to drop back below the £200 (after cashback) mark. However, realising I could (temporarily) use it as a DVD ripping machine, I decided to bite the bullet and bought the T20 with an additional 4Gb of RAM for £324 (less 2% Quidco and £80 cashback).&lt;/p&gt;
&lt;p&gt;It arrived a couple of days later and I must say I'm impressed. It's a lot of machine for the money, well built, has a copious number of USB sockets and is surprisingly fast. I installed Windows Server 2016 on this as it's the OS I intend to use for the Docker host and I thought it'd be a good practice run.&lt;/p&gt;
&lt;p&gt;To this I added the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;2 x 1Tb internal HDDs - configured as RAID-0 providing a fast destination for the drive rips.&lt;/li&gt;
&lt;li&gt;4 x USB DVD-ROM drives - drives for ripping from - a couple I already had plus a &lt;a href="https://www.amazon.co.uk/dp/B01B8U7JW2/ref=pe_385721_51767431_TE_dp_1"&gt;couple from Amazon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1 x 4Tb external USB HDD - destination for transcoded rips&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All in, it's quite a monster.&lt;/p&gt;
&lt;h2&gt;Putting it together&lt;/h2&gt;
&lt;p&gt;Unlike most of the out of the box software I'd found, I needed software that would do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Wait for a disc to be inserted in one of the drives&lt;/li&gt;
&lt;li&gt;Determine that the disc is actually a DVD video&lt;/li&gt;
&lt;li&gt;Rip the disc to a destination folder based on the volume label of the DVD&lt;/li&gt;
&lt;li&gt;Allow up to four concurrent rip operations&lt;/li&gt;
&lt;li&gt;Queue ripped folders for transcoding allowing only a single transcoding operation to run at a time.&lt;/li&gt;
&lt;li&gt;Save the transcoded movie to the external drive.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While there may be software out there that does this, a couple of evening's googling didn't reveal it so, I decided a DIY job was in order. Besides, I thought the multiple producer/single consumer nature of the multiple rips/single transcoding would be a great fit for playing with &lt;a href="https://msdn.microsoft.com/en-us/library/hh228603%28v=vs.110%29.aspx?f=255&amp;amp;MSPPError=-2147217396"&gt;Dataflow&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In relatively short order, I created &lt;a href="https://github.com/ibebbs/DriveRipper"&gt;DriveRipper&lt;/a&gt;... and it's worked pretty well. I've been happily ripping four DVD's at a time, averaging around 12-15 DVD's an hour, with only a few small problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Because Dataflow enforces order of tasks throughout the pipeline (one if it's biggest strengths!) a slow rip or drive can hold up transcoding such that a queue builds up. Not a massive problem as the encoding process on the Xeon is actually pretty rapid (averaging 450fps) so it catches up with the relatively slow ripping process (about 20 minutes per disc) with ease.&lt;/li&gt;
&lt;li&gt;Some DVD's - particularly the old ones - are single sided or low quality or lack additional material or all of the above. This means that the contents of the disc is less than the 4.2Gb cut off I used for determining that a particular disc is likely to be a DVD. This can be sorted with a simple code change but I dediced to put these discs to one side for now and come back to them.&lt;/li&gt;
&lt;li&gt;Some DVD's - again, particularly the olds ones - don't have a rational volume name; using terms like 'e19245' or, even worse, 'DVDVideo'. This has meant that, after the transcoding is complete, I need to rename the folders so that the contents don't get overwritten by a subsequent rip.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So far I'm 150 DVD's through and just been told that the new dining room furniture is being delivered Monday.&lt;/p&gt;
&lt;p&gt;Rip little machine, rip like wind!! Oh, wait...&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;From a youth of misspent money, I have a moderately large DVD collection. Some 600 movies in half a dozen DVD racks take a disproportionately large space in my dining room. This year, my partner and I  decided to host Xmas dinner for the family, meaning a dining table that could host a dozen was in order and... well, you can see where this is heading. The DVDs had to go.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/RxWebWithTypescript" />
		<id>http://ian.bebbs.co.uk/posts/RxWebWithTypescript</id>
		<title>WebRx and Typescript</title>
		<updated>2016-03-08T00:00:00Z</updated>
		<content>
                                        


&lt;h1&gt;Continuing with WebRx&lt;/h1&gt;
&lt;p&gt;In &lt;a href="./posts/RxWeb"&gt;part 1&lt;/a&gt; of this series I showed how to set up a project structure that allows you to start using WebRx from within Visual Studio. While fairly simple, the example provides a great illustration of you how WebRx allows you to separate your view and view model.&lt;/p&gt;
&lt;p&gt;In this article I further develop the structure to allow you to develop your application using Typescript.&lt;/p&gt;
&lt;h1&gt;From 'app.js' to 'app.ts'&lt;/h1&gt;
&lt;p&gt;Previously we copied a chunk of JavaScript from the WebRx &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;getting started guide&lt;/a&gt; into an &lt;code&gt;app.js&lt;/code&gt; script that was directly used from within the &lt;code&gt;index.html&lt;/code&gt; file. We now want to &lt;a href="https://en.wikipedia.org/wiki/Source-to-source_compiler"&gt;&lt;em&gt;transpile&lt;/em&gt;&lt;/a&gt; the &lt;code&gt;app.js&lt;/code&gt; script from a Typescript file so that we can further develop the application in a structured and type-safe manner.&lt;/p&gt;
&lt;p&gt;To do this simply follow the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Delete the existing &lt;code&gt;app.js&lt;/code&gt; file leaving the &lt;code&gt;js&lt;/code&gt; folder empty.&lt;/li&gt;
&lt;li&gt;Add and configure a &lt;code&gt;TypeScript JSON Configuration File&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Add a &lt;code&gt;TypeScript JSON Configuration File&lt;/code&gt; to the solution as shown below&lt;br&gt;
&lt;img src="/Content/RxWebWithTypescript/AddTypeScriptJsonConfigurationFile.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Add TypeScript Json Configuration File"&gt;&lt;/li&gt;
&lt;li&gt;Replace the &lt;code&gt;node_modules&lt;/code&gt; exclusion with &lt;code&gt;Scripts&lt;/code&gt;&lt;br&gt;
By default Visual Studio (or, more acurately, the TypeScript transpiler) with pick up all &lt;code&gt;ts&lt;/code&gt; files in the solution. As we don't want to attempt to re-transpile all the referenced typescript files we add &lt;code&gt;Scripts&lt;/code&gt; to the exclusion list. Further, as we added a reference to &lt;code&gt;WebRx&lt;/code&gt; via Nuget, our references are in the &lt;code&gt;Scripts&lt;/code&gt; folder, not &lt;code&gt;node_modules&lt;/code&gt;, so this exclusion can be removed.&lt;/li&gt;
&lt;li&gt;Add an &lt;code&gt;outDir&lt;/code&gt; setting to transpile to the &lt;code&gt;js&lt;/code&gt; folder&lt;br&gt;
This setting will force the TypeScript transpiler to output the transpiled JavaScript files to the &lt;code&gt;js&lt;/code&gt; folder where they can be used by the client browser.&lt;/li&gt;
&lt;li&gt;You should now have a &lt;code&gt;tsconfig.json&lt;/code&gt; file that looks like this:
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
  "compilerOptions": {
    "noImplicitAny": false,
    "noEmitOnError": true,
    "removeComments": false,
    "sourceMap": true,
    "target": "es5",
    "outDir": "js"
  },
  "exclude": [
    "Scripts",
    "wwwroot"
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Add a &lt;code&gt;ts&lt;/code&gt; folder to the solution.&lt;/li&gt;
&lt;li&gt;Add an &lt;code&gt;app.ts&lt;/code&gt; typescript file to the &lt;code&gt;ts&lt;/code&gt; folder.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Add references to Rx and WebRx to the &lt;code&gt;app.ts&lt;/code&gt; file.&lt;br&gt;
WebRx requires that you add an explicit reference to &lt;code&gt;rx.all.d.ts&lt;/code&gt; prior to the reference to &lt;code&gt;web.rx.d.ts&lt;/code&gt; in order for the Rx module to be brought into scope. The references should therefore be added like this:
&lt;pre class="prettyprint"&gt;&lt;code&gt;/// &amp;lt;reference path="../Scripts/rx.all.d.ts"/&amp;gt;
/// &amp;lt;reference path="../Scripts/typings/web.rx.d.ts" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Implement view / view model code&lt;br&gt;
You can now re-implement the code from &lt;code&gt;app.js&lt;/code&gt; as TypeScript virtually verbatim but do note how you get Intellisense for all the methods and properties of &lt;code&gt;wx&lt;/code&gt; module.&lt;/li&gt;
&lt;li&gt;Fix compilation error with call to &lt;code&gt;wx.applyBindings&lt;/code&gt;&lt;br&gt;
The &lt;code&gt;wx.applyBindings&lt;/code&gt; method &lt;em&gt;requires&lt;/em&gt; a &lt;code&gt;model&lt;/code&gt; parameter which, in JavaScript, is defaulted but in TypeScript causes a compilation error. To resolve this, simply pass an empty object to the method.&lt;/li&gt;
&lt;li&gt;Your &lt;code&gt;app.ts&lt;/code&gt; file should now look like this:
&lt;pre class="prettyprint"&gt;&lt;code&gt;/// &amp;lt;reference path="../Scripts/rx.all.d.ts"/&amp;gt;
/// &amp;lt;reference path="../Scripts/typings/web.rx.d.ts" /&amp;gt;

wx.app.component('hello', {
    viewModel: function () {
        this.firstName = 'Bart';
        this.lastName = 'Simpson';
    },
    template: 'The name is &amp;lt;span data-bind="text: firstName + \' \' + lastName"&amp;gt;&amp;lt;/span&amp;gt;'
});

wx.router.state({
    name: "$",
    views: { 'main': "hello" }
});

wx.router.reload();

wx.applyBindings({});
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="5"&gt;
&lt;li&gt;Compile the project and include the generated &lt;code&gt;js/app.js&lt;/code&gt; and &lt;code&gt;js/app.js.map&lt;/code&gt; files into the project.&lt;/li&gt;
&lt;li&gt;Hit F5 and you should again see the message 'The name is Bart Simpson' displayed in your default browser.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Congratulations, you're now ready to develop your application using full Intellisense and in the comfort of the knowledge that the compiler (well, transpiler) will pick up any syntactic bugs you may inadvertently create.&lt;/p&gt;
&lt;p&gt;As always, the completed &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/WebRxWithTypeScript"&gt;source code for this post&lt;/a&gt; can be found in the &lt;a href="https://github.com/ibebbs/BlogProjects"&gt;BlogProjects repository&lt;/a&gt; on &lt;a href="https://github.com/ibebbs"&gt;Github&lt;/a&gt;&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In &lt;a href="./posts/RxWeb"&gt;part 1&lt;/a&gt; of this series I showed how to set up a project structure that allows you to start using WebRx from within Visual Studio. While fairly simple, the example provides a great illustration of you how WebRx allows you to separate your view and view model.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ToddlerBoxTopsTenThousandUsers" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mVAxtKFjUEGk7Hdhzjl4UZ2INnFdBbw9K-tnYZ8DYoJ-VoKxpAN6w8Ng0DFTYdSxpHY6IvL5-VwJpLkQl6qWRmMQXSExLXopz5CFuSxIbyaMLrnL2Vy3yPZlISAAknXZdT4HwiZJ55zg2UtKwucBL88-xHh6rn5Mh97yzfRsCPjI%253Fwidth=1024&amp;height=574&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/ToddlerBoxTopsTenThousandUsers</id>
		<title>ToddlerBox Tops 10,000 Users!!</title>
		<updated>2016-12-20T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Really that got out of hand fast! I had no idea so many people would be interested in letting their toddler loose on their XBox controller. In fact, there have been many things that have surprised me about this app:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Acquisition rate has increased&lt;/p&gt;
&lt;p&gt;I kind of expected an initial burst of acquisitions then a slow tail off but this hasn't happened. As it's only been a little over a month since ToddlerBox was released to the store, I guess there's every possibility that it's still in the "burst" stage and theres just more interest in apps of this type. Well, here's hoping.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reviews have been extremely polarized&lt;/p&gt;
&lt;p&gt;Almost without exception, reviews have been 4-5 stars or 1 star. Also, while a couple of the 1 star ratings are to do with app functionality (it seems a couple of people have issues running even this basic UWP app) the overwhelming majority of 1 star ratings are due to peoples dislike of ads; because...&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ads are a very risky business&lt;/p&gt;
&lt;p&gt;As with most parents, I am extremely cautious about what my toddler is exposed to. Therefore I was extremely cautious about adding advertising as a means of revenue to ToddlerBox, regardless of how small or out of the way they were.
After completing the Ad-Mediation questions in the Windows Store and being assured that ads would be both age rated and not "tracking", I felt a lot better about the idea and decided a small banner ad on the instructions screen would be pretty harmless. Furthermore, throughout the process of adding the banner, I didn't see a single advert I would be concerned about putting in front of my child; most were simple flashing inbox icons or the like.
However, after discussing ToddlerBox with a friend, he decided to install it on his Xbox and I was very upset to see that the ads being displayed were both more intrusive and more "click-baity" than any I had seen previously. I am now investigating ways to generate some revenue from the app but without upsetting parents.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The reviews shown in the store are not "all reviews"&lt;/p&gt;
&lt;p&gt;As the publisher of ToddlerBox, I get to see all reviews left about the app on the store. Due to all the previous points, the app is currently averaging about a 2.6 star rating across 50 odd reviews. However, when viewing the app in the Store on my friend's XBox, it was shown as having a 4.5 star rating from just 2 reviews. Now, while some of the reviews I can see are translated from foreign languages, most are in English and I'm therefore at a loss to explain why they're not being displayed when an XBox in the English local browses the store.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It's not just toddlers using ToddlerBox&lt;/p&gt;
&lt;p&gt;I've had more than one review stating how good this game is to play after consuming various illicit substances ;0P&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Anyway, as described above, while acquisition rate has fluctuated on a daily basis, the overall trend in acquisition shows unexpected growth:&lt;/p&gt;
&lt;img src="https://bnljqq-dm2306.files.1drv.com/y3msqT1msmkJ_32Jewx8Ysuoys0lC35GCLY-aQPyJ9YhR75KMswOLcznSPGOOBGhhsMRb6qK3_xh_qr3h1Xh-vFwmSog1_HoOS-Isj1lMoFPpuV42oAwJi3A5JiY-ToAirVoZDnz2gQ7N6jUed82zW83IZ_qQcbqWGw1ekaNh4wjBU?width=660&amp;amp;height=252&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Acquisitions over App Lifetime"&gt;
&lt;p&gt;Daily usage also shows that a healthy number of acquisitions are being used regularly, with nearly 800 people using ToddlerBox nearly 1700 times just yesterday (19th December):&lt;/p&gt;
&lt;img src="https://bnlkqq-dm2306.files.1drv.com/y3mBC-i0nboWq0ibRyIcBhs1O2MnfOUx-OxTQZDUNHbh-eVRbfH0xP9-p9hLJqC82i1SBB5ZfpcfmTlvuZwMBD-Gt0BZZC-IvVCJOd1jzexDoiC-BV4LG7X2aOyOapkCKK6wM6WWffluiuD5MKKet6MfEIjTWNZMCpFx1FP13suiCY?width=660&amp;amp;height=249&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Daily usage"&gt;
&lt;p&gt;So, the Xmas break is almost upon us and I will be returning my attention to ToddlerBox (yes, despite the career break, I try to spend most of my time working on 'serious' projects or study). I have a number of new features in mind for it (including the #1 requested feature of "sound!!") and will be looking to try out a couple of more features of the awesome Win2D library. It's going to be a lot of fun (for me and my little girl) and will hopefully allow ToddlerBox to reach the next major (although admittedly arbitrary) milestone of 25,000 acquisitions!&lt;/p&gt;
&lt;p&gt;Watch this space...&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Really that got out of hand fast! I had no idea so many people would be interested in letting their toddler loose on their XBox controller. In fact, there have been many things that have surprised me about this app:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarf" />
		<id>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarf</id>
		<title>A sentiment(al) analysis of why Red Dwarf is no longer funny</title>
		<updated>2017-01-31T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Yesterday I had a lot of fun playing with &lt;a href="http://jupyter.org/"&gt;Project Jupyter&lt;/a&gt;. For those that aren't aware of this project, it's an effort to provide a workspace for performing repeatable experimentation with data. In short it mixes markdown editing capabilities with a &lt;a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;REPL&lt;/a&gt; environment for a large number of languages. From the website:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, machine learning and much more"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After having my interest tweaked by the &lt;a href="https://try.jupyter.org/"&gt;browser version&lt;/a&gt; I bit the bullet and spent ages downloading and installing the &lt;a href="http://jupyter.org/install.html"&gt;full version&lt;/a&gt; to a virtual machine. It's a Python based web-app so requires quite a bit of setup and unfortunately I found the documentation to be a bit sparse.&lt;/p&gt;
&lt;p&gt;And so it was that while trying to work out how to install the &lt;a href="https://github.com/fsprojects/IfSharp"&gt;FSharp module&lt;/a&gt; I came across &lt;a href="https://notebooks.azure.com/"&gt;Azure Notebooks&lt;/a&gt;. This is a free, Azure hosted version of Jupyter that has almost all the features of a local installation but with none of the faff. After quickly spinning up a new notebook here I didn't even look back at the local installation.&lt;/p&gt;
&lt;h2&gt;A Jupyter [Data] Mining Core Project&lt;/h2&gt;
&lt;p&gt;As per the title and lead of this post, I decided to use Jupyter to have a little fun.&lt;/p&gt;
&lt;p&gt;Back in September, while grinding my way through &lt;a href="http://www.imdb.com/title/tt0094535/episodes?season=11&amp;amp;ref_=tt_eps_sn_11"&gt;season 11 of Red Dwarf&lt;/a&gt;, I began to wonder why it wasn't as funny as it used to be. Had the writing deteriorated? Were the actors past it? Or were these elements still as great as they used to be and it was me who had changed?&lt;/p&gt;
&lt;p&gt;I started thinking about ways this could be investigated such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using IMDB rating as a measure of humour in each episode of Red Dwarf&lt;/li&gt;
&lt;li&gt;Performing semantic analysis of episode's transcript to see if the sentiment had changed&lt;/li&gt;
&lt;li&gt;Using word-count to determine whether there was a correlation between character participation and overall humour&lt;/li&gt;
&lt;li&gt;etc&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, it was a funny notion and provided a pleasant distraction from the &lt;a href="http://www.imdb.com/title/tt5218266"&gt;pretty awful episode&lt;/a&gt; of Red Dwarf I was watching at the time. I added it to my "ideas" list in &lt;a href="https://trello.com/b/KoTWuFUi/public-board"&gt;Trello&lt;/a&gt;, finished the episode and went to bed.&lt;/p&gt;
&lt;p&gt;Yesterday, when I came across Project Jupyter, I knew it'd be a great medium for performing this investigation so shifted the analysis from "Ideas" to "In progress" and got cracking.&lt;/p&gt;
&lt;h2&gt;Data Science using F#&lt;/h2&gt;
&lt;p&gt;Now, while in relation to this investigation I use the term "data science" to basically mean "munging a few numbers and drawing a few graphs", I do think F# makes a fantastic language for the discipline in general. It has some incredible mechanisms for &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/fsharp/tutorials/type-providers/"&gt;acquiring&lt;/a&gt; and &lt;a href="http://fsharpforfunandprofit.com/posts/the-option-type/"&gt;cleaning&lt;/a&gt; data as well as for &lt;a href="http://www.quanttec.com/fparsec/"&gt;parsing natural language&lt;/a&gt;. Couple this with it's concise, functional, elegant language and the ability to leverage components from the entire breadth of .NET ecosystem and you have quite a significant offering.&lt;/p&gt;
&lt;h2&gt;Azure Notebooks&lt;/h2&gt;
&lt;p&gt;The Azure implementation of Project Jupyter is first class and, for now at least, totally free. Getting started is as simple as logging in with Microsoft credentials and then clicking 'Add notebook'. Being an MS implementation, I used Edge to edit the notebook and found the experience extremely robust, especially given it's a "Preview" program.&lt;/p&gt;
&lt;p&gt;In fact I experience just two issues while authoring my notebook:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data Store - It's not currently possible to upload or store data within the Azure notebook library (despite having functionality to do this in the web-interface). Instead you need to host your data on one of a small number of whitelisted sites. Fortunately Github is one of these sites so this doesn't prove to be much of an issue.&lt;/li&gt;
&lt;li&gt;Packages - While Azure Notebooks provides access to a large number of packages "out-of-the-box" (i.e. FSharp.Data, XPlot.Plotly, etc) it can be tricky to add/use other packages. For example, I wanted to use the XPlot.GoogleCharts package (as it provided trendline capabilities) and ended up having to write a custom display printer for it to work (due to an &lt;a href="https://github.com/fsprojects/IfSharp/issues/118"&gt;open issue&lt;/a&gt; on Github).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Apart from these issues, authoring and scripting F# in an Azure Notebook was almost as fast as using &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/fsharp/tutorials/fsharp-interactive/"&gt;"F# Interactive"&lt;/a&gt;. It even provides Intellisense capabilities but, in practice, these are usually too slow to be of actual use.&lt;/p&gt;
&lt;h2&gt;Sharing Notebooks&lt;/h2&gt;
&lt;p&gt;From Azure Notebooks you're able to download your notebook as a native ".ipynb" file (in fact this is encouraged as MS reserves the right to remove unused notebooks after 60 days). You can then share this file to other people who have Jupyter installed or, preferably, commit it to a repository in Github which has excellent support for Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;You can find my notebook "A sentiment(al) analysis of why Red Dwarf is no longer funny (to me)" &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis/blob/master/Investigation.ipynb"&gt;here&lt;/a&gt;. As you will see when you click the link, Github not only shows you the static parts of the notebook but actually tries to spin up a kernel and execute the code parts too. This is a "limited rendering only" so Github also provides a link to open the notebook in 'nbviewer' &lt;a href="http://nbviewer.jupyter.org/github/ibebbs/RedDwarfAnalysis/blob/2712285e1f9c69fc347bdfe6404792101eaea5f1/Investigation.ipynb"&gt;web-app&lt;/a&gt;. This link is shown below:&lt;/p&gt;
&lt;img src="https://mvpfyw-dm2306.files.1drv.com/y3mppldGfaYEhvWkV7mdUw26-lP3SOzlMTGFbf8slchIfjBL57IH-GrJev6ai_rISiHBKrom7Abg9YFjfhZ1ArOFT7a7mh4gJuGq-CErv1dun48GQC_BdhMV08fh6hbw400d9nHSEXJ0jA2nPBIrpOPNrOz0I3lVY1tu_L656ylQKg?width=660&amp;amp;height=283&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660; margin-top: 6px; margin-bottom: 6px;" alt="Open external view with nbviewer"&gt;
&lt;h2&gt;The analysis&lt;/h2&gt;
&lt;p&gt;I had timeboxed my investigation into Project Jupyter and therefore didn't get round to performing an actual sentiment anaylsis of the content of each episode. However I did manage to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Programmatically download episode information from several sources in JSON format and use &lt;a href="http://fsharp.github.io/FSharp.Data/library/JsonValue.html"&gt;JsonValue&lt;/a&gt; to dynamically query these sources&lt;/li&gt;
&lt;li&gt;Scrape demographically categorized rating information from IMDB and use &lt;a href="http://fsharp.github.io/FSharp.Data/reference/fsharp-data-htmldocument.html"&gt;HtmlDocument&lt;/a&gt; to parse the data into strong types&lt;/li&gt;
&lt;li&gt;Resolve issue with rendering XPlot.GoogleCharts charts within the notebook and use these charts to provide an interactive visualisation of the decline in rating of Red Dwarf across time and demographic categories.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This provided a fair stab at correlating episode rating with the overall decline in Red Dwarf's humourousness but is a long way short of any form of "data science". It was both enlightening and a lot of fun doing this small project and I will certainly consider Azure Notebooks as a valuable tool in my toolbox.&lt;/p&gt;
&lt;p&gt;Should I find the time, I would certainly like to return to this project and use &lt;a href="http://www.quanttec.com/fparsec/"&gt;FParsec&lt;/a&gt; and &lt;a href="https://azure.microsoft.com/en-gb/services/cognitive-services/text-analytics/"&gt;Azure Text Analytics&lt;/a&gt; to perform an actual sentiment analysis. Hopefully it'll overturn, or at least help justify, my somewhat disturbing conclusion!&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Yesterday I had a lot of fun playing with &lt;a href="http://jupyter.org/"&gt;Project Jupyter&lt;/a&gt;. For those that aren't aware of this project, it's an effort to provide a workspace for performing repeatable experimentation with data. In short it mixes markdown editing capabilities with a &lt;a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;REPL&lt;/a&gt; environment for a large number of languages. From the website:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartIII" />
		<id>http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartIII</id>
		<title>Home Network Monitoring - Part III</title>
		<updated>2016-04-12T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;In the last post, I configured Logstash to extracted source and destination address information from the "Client Access Log" Syslog messages sent by my router and added a number of visualizations to my Kibana dashboard which allow me to explore which local devices are access which remote servers.&lt;/p&gt;
&lt;p&gt;While this is already very useful, it's almost impossible to remember which devices relate to which IP addresses on the local network, let alone the on the internet. As such, I really want the ability to translate the IP addresses (and, ideally, port numbers) into device, host or protocol names.&lt;/p&gt;
&lt;h1&gt;translating remote ip addresses to host names&lt;/h1&gt;
&lt;p&gt;When a local device accesses a remote server it will, ordinarily, do so by resolving an IP address for a host name, for example 'google.com' resolves to the address '216.58.213.110'. On my network, my router acts as a DNS server, resolving names it knows and forwarding unresolved names to Googles DNS servers. A the results of the host name to IP address lookup are cached in the DNS server (e.g. my router) I can perform a &lt;a href="https://en.wikipedia.org/wiki/Reverse_DNS_lookup"&gt;reverse DNS lookup&lt;/a&gt; at very little processing cost and without consuming any WAN bandwidth.&lt;/p&gt;
&lt;p&gt;As usual, Logstash comes with a filter that is able to perform this operation called, unsurprisingly, 'dns'. However, to provide a consistent set of fields to Kibana, it requires a couple of additional steps to ensure it functions consistently. Here is the amended &lt;code&gt;syslog.config&lt;/code&gt; with the reverse DNS lookup in place.&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;input {
  tcp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
  udp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
}

filter {
    grok {
        match =&amp;gt; [ "message", "&amp;lt;%{POSINT:syslog_pri}&amp;gt;%{SYSLOGTIMESTAMP:syslog_timestamp} Vigor\: Local User \(MAC=%{MAC:source_mac}\): %{IP:source_address}(?::%{POSINT:source_port})? -&amp;gt; %{IP:destination_address}(?::%{POSINT:destination_port})? \((?&amp;lt;protocol&amp;gt;TCP|UDP)\)" ]
        add_tag =&amp;gt; "access"
    }
    if "access" in [tags] {
        mutate {
            add_field =&amp;gt; {
              "destination_host" =&amp;gt; "%{[destination_address]}"
            }
        }
        dns {
            reverse =&amp;gt; [ "destination_host" ]
            action =&amp;gt; "replace"
            nameserver =&amp;gt; "192.168.1.1"
        }
    }
}

output {
  elasticsearch {
    hosts =&amp;gt; ["192.168.1.30:9200"]
    index =&amp;gt; "syslog-%{+YYYY.MM.dd}"
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that, when an 'access' message is successfully grokked, I add a tag to the tags array field of the message called "access". If another type of message has been received (i.e. a DNS lookup) then the grok pattern won't match and the 'access' tag will not be added to tags.&lt;/p&gt;
&lt;p&gt;After the &lt;code&gt;grok&lt;/code&gt; filter, I check to see if the tags field contains the 'access' tag and, if so, use the &lt;code&gt;mutate&lt;/code&gt; filter to copy the 'destination_address' field value into a 'destination_host' field. This is done as the &lt;code&gt;dns&lt;/code&gt; filter will replace the field value if a successful reverse DNS lookup is performed but will leave the original value (i.e. the IP address) if a reverse DNS could not be performed. This way we either get the host name or IP address in the 'destination_host' field and it's never empty.&lt;/p&gt;
&lt;p&gt;With the changes to configuration in place, I restart Logstash. Then, in Kibana, I refresh the field list for the 'syslog-*' index, add 'destination_host' to the 'Syslog Messages' saved search, load 'Access By Destination Address' visualization and modify it to use 'destination_host' rather than the 'destination_address' field; and get the following:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-AccessByDestinationHostAnalysedVisualization.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Access By Destination Host Analysed Visualization"&gt;
&lt;p&gt;While initially it looks promising, a quick look at the list of hosts being accessed shows something peculiar: the domain names have been split into their component parts.&lt;/p&gt;
&lt;h1&gt;analysis, mappings and templates&lt;/h1&gt;
&lt;p&gt;The reason for the host names being split is because, by default, ElasticSearch performs 'analysis' on text strings. This analysis involves splitting the strings into discrete words which can be indexed more efficiently. Some strings however, for example domain names, should be treated as a single word and as such we need to prevent ElasticSearch from performing the analysis.&lt;/p&gt;
&lt;p&gt;How ElasticSearch treats various fields within a message can be controlled by modifying the index mapping. The current mapping for the 'syslog' index can be retrieved by a REST call to the address 'http://[ElasticSearchHost]:9200/syslog-2016.04.12/_mapping'. This returns:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
    "syslog-2016.04.12": {
        "mappings": {
            "syslog": {
                "properties": {
                    "@@timestamp": {
                        "type": "date",
                        "format": "strict_date_optional_time||epoch_millis"
                    },
                    "@@version": {
                        "type": "string"
                    },
                    "destination_address": {
                        "type": "string"
                    },
                    "destination_host": {
                        "type": "string"
                    },
                    "destination_port": {
                        "type": "string"
                    },
                    "host": {
                        "type": "string"
                    },
                    "message": {
                        "type": "string"
                    },
                    "protocol": {
                        "type": "string"
                    },
                    "source_address": {
                        "type": "string"
                    },
                    "source_mac": {
                        "type": "string"
                    },
                    "source_port": {
                        "type": "string"
                    },
                    "syslog_pri": {
                        "type": "string"
                    },
                    "syslog_timestamp": {
                        "type": "string"
                    },
                    "tags": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    }
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to prevent ElasticSearch from analysing the 'destination_host' field, we need to add an 'index' key with the value 'not_analyzed'. Even though things have been mostly working correctly so far, I can save quite a bit of storage and processing time by marking almost all of the string fields as 'not_analyzed'. This is shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
    "syslog-2016.04.12": {
        "mappings": {
            "syslog": {
                "properties": {
                    "@@timestamp": {
                        "type": "date",
                        "format": "strict_date_optional_time||epoch_millis"
                    },
                    "@@version": {
                        "type": "string"
                    },
                    "destination_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_port": {
                        "type": "integer"
                    },
                    "host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "message": {
                        "type": "string"
                    },
                    "protocol": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_mac": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_port": {
                        "type": "integer"
                    },
                    "syslog_pri": {
                        "type": "integer"
                    },
                    "syslog_timestamp": {
                        "type": "string"
                    },
                    "tags": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    }
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, while I could write this mapping directly to the ElasticSearch index, as the index is date-based, I'd have to resend the mapping manually everyday. Instead, I am going to create a mapping template that will match an index name based on pattern and automatically apply the template. This is done by crafting a PUT call to the ElasticSearch '_template' endpoint with the specific template name. In short, the following mapping template is posted to &lt;code&gt;http://[ElasticSearch:9200]/_templates/syslog_template&lt;/code&gt;&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
        "template": "syslog-*",
        "mappings": {
            "syslog": {
                "properties": {
                    "@@timestamp": {
                        "type": "date",
                        "format": "strict_date_optional_time||epoch_millis"
                    },
                    "@@version": {
                        "type": "string"
                    },
                    "destination_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_port": {
                        "type": "integer"
                    },
                    "host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "message": {
                        "type": "string"
                    },
                    "protocol": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_mac": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_port": {
                        "type": "integer"
                    },
                    "syslog_pri": {
                        "type": "integer"
                    },
                    "syslog_timestamp": {
                        "type": "string"
                    },
                    "tags": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    }
                }
            }
        }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this in place I need to delete todays syslog index so that it is recreated, using the mapping above, when the first syslog message is received. Once this has been done, the visualization looks like this:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-AccessByDestinationHostNotAnalysedVisualization.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Access By Destination Host Not-Analysed Visualization"&gt;
&lt;p&gt;Nice!&lt;/p&gt;
&lt;h1&gt;summary&lt;/h1&gt;
&lt;p&gt;In this post, I showed how to display host names for accessed servers rather than IP addresses. I also covered how to update ElasticSearch mapping such that field 'analysis' can be prevented and host names kept together.&lt;/p&gt;
&lt;p&gt;In the next post, I'll show how to translate local device IP addresses in to device names.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In the last post, I configured Logstash to extracted source and destination address information from the "Client Access Log" Syslog messages sent by my router and added a number of visualizations to my Kibana dashboard which allow me to explore which local devices are access which remote servers.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/IContributedAndAllIGot" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mNzf5Sylp6SOZbv6t2Q_atZh0reZJW7RYL9EgdZ4V4aZSaf_8Sqe8UPzCEaq7t3RKQn5GX1DvkSWdsolooyOHZj9Ma389uQChI7uhzICOmFTm8aZaRBYS4jS0K8g07vYNjEJofO_Io8VnpaqgTRsLJwSIEMEzg1P1TOt9dbXzm6s%253Fwidth=2465&amp;height=1039&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/IContributedAndAllIGot</id>
		<title>I contributed and all I got...</title>
		<updated>2016-11-12T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;A while back, I contributed my &lt;a href="http://ian.bebbs.co.uk/posts/UsingHyperlinkInMVVM"&gt;HyperlinkExtensions&lt;/a&gt; to the &lt;a href="http://ian.bebbs.co.uk/posts/UWPCommunityToolkitv1_1"&gt;UWP Community Toolkit&lt;/a&gt;. This morning postman brought me a very pleasant surprise:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://orvy1q.dm2302.livefilestore.com/y3mcg6h9OGMl0tKB0ohOeyyBSVI-CwtcQF9XPWLXHBQI1inTRaPd9_k1jeoOpTIga1ZVnezoWRp34VnQuSmMduXhLro6OeJ4Unrgxe3PVOAh2kA3Pae1SN3wmxv3sxPDJlD1uTFxMKkKMk2lRjxKWZE1Ktqvs7k-mr6mCjq0UdKLh8?width=574&amp;amp;height=660&amp;amp;cropmode=none" alt="T-shirt front"&gt;&lt;img src="https://orvx1q.dm2302.livefilestore.com/y3mzcdee8-cKnRVTO-rrLFoC5rQMdorNPkUwiu49xlSHN6OeisdbwOFTzvPTLZzInaP0JBQLgOu9bkX8eZZZa4SuKd2ruJI80mI38NbMcTftpRMmE9zFx6DwWNGSctfhS6F2HRlKQ7Ve60D8Y6G94bbLVuFJ5hp4E9mYWQTG0QhxVk?width=594&amp;amp;height=660&amp;amp;cropmode=none" alt="T-shirt back"&gt;&lt;/p&gt;
&lt;p&gt;How cool is that?! Not too many open source projects provide such swag!&lt;/p&gt;
&lt;p&gt;Thanks to the &lt;a href="https://github.com/Microsoft/UWPCommunityToolkit"&gt;UWP Community Toolkit&lt;/a&gt; maintainers, keep up the good work!&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;A while back, I contributed my &lt;a href="http://ian.bebbs.co.uk/posts/UsingHyperlinkInMVVM"&gt;HyperlinkExtensions&lt;/a&gt; to the &lt;a href="http://ian.bebbs.co.uk/posts/UWPCommunityToolkitv1_1"&gt;UWP Community Toolkit&lt;/a&gt;. This morning postman brought me a very pleasant surprise:&lt;/p&gt;</summary>
	</entry>
</feed>sualization.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard Add Visualization"&gt;
&lt;p&gt;With the "Syslog Messages Over Time" visualization added, we make it a usable size by dragging the resize control (button right corner of the visualization) to extend the visualization across the width of the window as shown below:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardSizeVisualization.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard Size Visualization"&gt;
&lt;p&gt;Finally, to make it easier to see the messages the histogram refers to, we'll add a table of related Syslog messages onto our dashboard below the histogram. To do this, click the '+' button, selected 'Searches' and then our 'Syslog Messages' search. When the table is added to the dashboard, make it a similar size as the histogram as shown below:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardWithSearch.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard With Search"&gt;
&lt;p&gt;Once done, we need to save the dashboard so we can reload it any time we need it. Simply click the 'Save Dashboard' button as shown below:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardSaveSyslogMessages.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard Save Syslog Messages"&gt;
&lt;p&gt;Once saved you can bookmark the page and get back to your dashboard any time you like. Furthermore, once saved, you can monkey with the dashboard (explore the data by highlighting various areas of the chart, change time frames, set autorefresh etc) as much as you like knowing you can return to saved version any time.&lt;/p&gt;
&lt;h1&gt;summary&lt;/h1&gt;
&lt;p&gt;In this post, I have outlined how to use a Syslog capable router to send Syslog messages to Logstash and have Logstash store these messages in ElasticSearch for querying. Furthermore we then created a dashboard in which we can explore the number of Syslog messages we received over various timeframes.&lt;/p&gt;
&lt;p&gt;In the next post we'll increase the granularity of the messages we store so that we can start creating more interesting dashboard.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Home networks are becoming increasingly complex. It is no longer just geeks and techies who have pervasive WiFi through-out their home to which a myriad of devices connect and communicate. When things go wrong or, worse still, the network is compromised by rouge hardware or software it's extremely difficult to work out what has happened and where to start troubleshooting the issue.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/WotNoBlogPosts" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mKlqOBjK9u-QOTjr8e6t2pOev7BN2vWZHyEDf2l27_HhaNgR_aVCXi2-GJh_KZMQV-naegShjBydS0blOk2kSndI2eTXnRhuqA5Ry0VYn8a0HdOEj_RvSUJ8uVdzsiDmcn4XRkyaAn7kScarmtvlf5nua4L9lkP_bWrKG5Ai7JdQ%253Fwidth=660&amp;height=371&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/WotNoBlogPosts</id>
		<title>Wot No Blog Posts?</title>
		<updated>2016-07-26T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Yes, it's been over three months since my last blog post. "What have you been doing?" I hear you (the hypothetical reader) ask. Well... well I'll tell you.&lt;/p&gt;
&lt;p&gt;Having left my previous permanent position in January, I decided the time was right for a &lt;strong&gt;career break&lt;/strong&gt;. Having been &lt;a href="https://www.ted.com/talks/stefan_sagmeister_the_power_of_time_off?language=en"&gt;inspired to take a career break&lt;/a&gt; some six years ago, I knew how rejuvenating time off work can be and how reinvigorating it is when you finally have some time to pick and choose what it is you want to do and, more importantly, how. Indeed, last time I took a career break I ended up founding a company which - while not successful enough to prevent me having to return to employment - was massively educational, incredibly liberating and a whole lot of fun.&lt;/p&gt;
&lt;p&gt;However, my motivations for this career break are vastly different to those of six years ago. At that time I had just emerged from a somewhat turbulent relationship and was looking to - &lt;em&gt;sorry for the cliché&lt;/em&gt; - "re-find" myself; this time I am in a stable and happy relationship with my partner who last year gave birth to our little baby girl. And while, six years ago, I could - and was happy to - survive on very meagre savings, I am now lucky enough to be in a position where financial pressures are not an issue, at least in the short-term. Finally, while I had very little idea of what I was going to do during my last career break (which itself was extremely liberating in that you are suddenly open to being able to say "yes" to pretty much anything) this time I have a much more developed concept of how I want to use this opportunity.&lt;/p&gt;
&lt;p&gt;While my motivations and desires for the coming months will be the subject of future blog posts, I have started putting together a &lt;a href="https://trello.com/b/KoTWuFUi/public-board"&gt;public Trello board&lt;/a&gt; of ideas/projects I want to undertake. It's just a start and by no means comprehensive but I thought some transparency around my ideas and goals (not to mention progress!) would be good for me.&lt;/p&gt;
&lt;p&gt;For now though I want to share what I've been doing - and why there have been no blog posts - for the last three months. You see, a primary motivation for taking time out of my career now was to spend time with my young family and maximise the use of my partner's remaining maternity leave. To this end, shortly after leaving my previous job, my partner and I decided to &lt;strong&gt;take our baby on a road trip around Europe&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The timing really couldn't have been better; my partner still had a few months of maternity leave remaining, the baby was still happy to have long naps in the back of the car whenever we drove anywhere and I was still keen on buying a day-van (it's been a &lt;em&gt;thing&lt;/em&gt; with me for a while now). So in February we started planning and looking for a motor that could comfortably cart the three of us around Europe and by mid March we'd bought an imported Nissan Elgrand E51 Ryder Autech.&lt;/p&gt;
&lt;img src="https://zdfcta.dm2302.livefilestore.com/y3mRDVqstf6XsjN73biGoYnN5s-SzVcHx9pEdYl2S_wM803HpiosWK5Skxm-kskeHTMkahk_PIdejAp70x14KCaOwmZb6OvAvAig8uqI4bdBs2Pb_lAUsm-O_2lO8krW_18ReDVMLXqVkJWUGUSJ-d80bOIi8ciWIgyxDzL5fw4qF4?width=1796&amp;amp;height=1347&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="My other baby"&gt;
&lt;p&gt;Now the Elgrand is an MPV and not a campervan (a mostly pragmatic decision based on the fact we could use it on a daily basis after the trip and only a little bit due to "love at first drive") so there was a lot of work to do in order to prepare it for such a long journey. Therefore, between March and May, I researched, built and installed a bunch of modifications for the Elgrand to support us on our adventure. This included a custom built leisure battery / charging system enclosure, custom built frame to mount the electrical systems and luggage, routing of cabling around the Elgrand and several internal modifications for enhancing the navigation / ICE systems.&lt;/p&gt;
&lt;p&gt;I documented these modifications on the &lt;a href="http://elgrandoc.uk/"&gt;Elgrand Owners Club website&lt;/a&gt;. This site proved invaluable in terms of information about working on the Elgrand and I wanted to give something back to the active and very helpful community there. Due to limitations in the website's forum, the details had to be split across five posts which - if you're interested - can be found here: &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-i.3311/"&gt;Part I&lt;/a&gt;, &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-ii.3312/"&gt;Part II&lt;/a&gt;, &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-iii.3313/"&gt;Part III&lt;/a&gt;, &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-iv.3314/"&gt;Part IV&lt;/a&gt;, &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-v.3315/"&gt;Part V&lt;/a&gt;. After just a couple of days these posts have already garnered significant praise and numerous follow on questions so I feel pretty good about having spent the time writing these posts.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;As an aside, it occurred to me that this work could almost have been a case-study in Agile development. Not being a carpenter or mechanic and my work on cars to date having been pretty much limited to topping up the oil, I started this project from an absolute level of maximum ignorance. Fortunately as both a stake holder and engineer, it was easy to outline use-cases for the work which, while I didn't actually document them at the time, would have included some choice ones such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"As a driver I need a non-Japanese navigation system so I know where the smeg I'm supposed to be going!",&lt;/li&gt;
&lt;li&gt;"As a parent I need a fridge in the van so that we can keep food for the baby food fresh and - hopefully - the baby healthy" and,&lt;/li&gt;
&lt;li&gt;"As a caffeine junkie I need a means of making coffee in the van so that I don't murder everyone the morning after we spend a night in it!"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These could then be naturally prioritized and, where possible, undertaken concurrently by my partner and I. If something went well, we could close it off and move onto the next thing; if it didn't we could reevaluate it's value / priority in light of what we had. This way we managed to hit our deadline (the ferry departure - which we put off "committing" to until as late as possible) with as much high value work done as possible. More importantly, at departure (aka deployment) time, we had a significantly lower level of ignorance such that, should anything go wrong while we were "live", we'd actually stand a chance of fixing it without having to - possibly literally - "roll back" to England.&lt;/p&gt;
&lt;p&gt;Yes, yes, some of this terminology is undoubtedly tenuous but, having had hours and hours to reflect on this work while driving around Europe, it was rewarding to see how much more effective an iterative approach to problem solving can be. Who knows if we'd ever have got away if we'd tried to plan &lt;em&gt;everything&lt;/em&gt; up front.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Anyway, we departed England in mid-May and returned mid-July and had a truly fantastic adventure. In &lt;strong&gt;58 days&lt;/strong&gt; we travelled &lt;strong&gt;7912 miles&lt;/strong&gt; and visited &lt;strong&gt;20 countries&lt;/strong&gt;. Along the way we met a number of old friends, made a lot of new friends and saw some amazing sites and scenery. We learned a lot, not only about the various cultures / histories around Europe but also about ourselves and our daughter. And we laughed a lot, mostly about the quirks of the various cultures we were experiencing but also - in retrospect at least - about some of the challenges we faced along the way; like having to park up in a field at a border crossing in order to buy the vignette that would allow us to drive the car in the country we were about to cross in to, and getting visited by both a swarm of monstrously huge locust type insects and a heavily armed and somewhat suspicious (the Elgrand has very dark privacy glass) border guard.&lt;/p&gt;
&lt;p&gt;We really did experience so much that I frequently find myself remembering something from the trip that a) I had somehow already forgotten and b) seems like both a lifetime &lt;em&gt;and&lt;/em&gt; just a few days ago. Fortunately my partner kept a very detailed (and anonymised) blog of our journey in which she does an terrific job of capturing the fun and freedom we enjoyed while away. Should you be interested, you can read it &lt;a href="https://bigspune.wordpress.com/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And now we're home. The baby has started nursery and my partner is returning to work. While I'm still having to consciously work out where I am when I wake up in the night (seriously, after two months of staying somewhere different every night, this seems to be a thing at the moment) and we're still trying to get the house back into some semblance of order, life is returning to our own special approximation of normality.&lt;/p&gt;
&lt;p&gt;For four days a week and for the foreseeable future, I will have pretty much all day to do... well, pretty much anything I want. It's an exciting time in the world of .NET given the recent release of .NET Core and Microsoft's assimilation of Xamarin. Graph and document data stores (aka NoSQL) continue to make inroads on the traditional strong holds of legacy relational databases. And there are some profound changes in the broader world of software development such as the continuing move towards containerized deployment and cloud infrastructures. I'm very much looking forward to investigating / leveraging all these in the months to come.&lt;/p&gt;
&lt;p&gt;Who knows where it will lead. I will certainly be keeping my ear to the ground should an exciting job/contract come around. Ideally I'd want something remote / freelance which I could do on my terms and, should the right opportunity drop in my lap, I'd certainly be open to it. That said, what I'd really like to do is resurrect my company and see where I can take it. I have a couple of ideas with potential but will hold off on developing them until I've refamiliarised myself with the current trends in software development because, even though it's only been a few months, it feels like I've been out of the game for years.&lt;/p&gt;
&lt;p&gt;Well, game on.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Yes, it's been over three months since my last blog post. "What have you been doing?" I hear you (the hypothetical reader) ask. Well... well I'll tell you.&lt;/p&gt;</summary>
	</entry>
</feed>col": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_mac": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_port": {
                        "type": "integer"
                    },
                    "syslog_pri": {
                        "type": "integer"
                    },
                    "syslog_timestamp": {
                        "type": "string"
                    },
                    "tags": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    }
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, while I could write this mapping directly to the ElasticSearch index, as the index is date-based, I'd have to resend the mapping manually everyday. Instead, I am going to create a mapping template that will match an index name based on pattern and automatically apply the template. This is done by crafting a PUT call to the ElasticSearch '_template' endpoint with the specific template name. In short, the following mapping template is posted to &lt;code&gt;http://[ElasticSearch:9200]/_templates/syslog_template&lt;/code&gt;&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
        "template": "syslog-*",
        "mappings": {
            "syslog": {
                "properties": {
                    "@@timestamp": {
                        "type": "date",
                        "format": "strict_date_optional_time||epoch_millis"
                    },
                    "@@version": {
                        "type": "string"
                    },
                    "destination_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_port": {
                        "type": "integer"
                    },
                    "host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "message": {
                        "type": "string"
                    },
                    "protocol": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_mac": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_port": {
                        "type": "integer"
                    },
                    "syslog_pri": {
                        "type": "integer"
                    },
                    "syslog_timestamp": {
                        "type": "string"
                    },
                    "tags": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    }
                }
            }
        }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this in place I need to delete todays syslog index so that it is recreated, using the mapping above, when the first syslog message is received. Once this has been done, the visualization looks like this:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-AccessByDestinationHostNotAnalysedVisualization.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Access By Destination Host Not-Analysed Visualization"&gt;
&lt;p&gt;Nice!&lt;/p&gt;
&lt;h1&gt;summary&lt;/h1&gt;
&lt;p&gt;In this post, I showed how to display host names for accessed servers rather than IP addresses. I also covered how to update ElasticSearch mapping such that field 'analysis' can be prevented and host names kept together.&lt;/p&gt;
&lt;p&gt;In the next post, I'll show how to translate local device IP addresses in to device names.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In the last post, I configured Logstash to extracted source and destination address information from the "Client Access Log" Syslog messages sent by my router and added a number of visualizations to my Kibana dashboard which allow me to explore which local devices are access which remote servers.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ReactiveStateMachines" />
		<id>http://ian.bebbs.co.uk/posts/ReactiveStateMachines</id>
		<title>Reactive State Machines</title>
		<updated>2016-11-09T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Today I'd like to share an implementation I've recently been employing that leverages Rx to implement a &lt;a href="https://en.wikipedia.org/wiki/Finite-state_machine"&gt;state-machine&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.martinfowler.com/dslCatalog/stateMachine.html"&gt;State-machines are a terrific pattern&lt;/a&gt; that, when applied correctly, can greatly simplify the implementation, maintenance and extensibility of many types of functionality; from &lt;a href="https://msdn.microsoft.com/en-gb/windows/uwp/launch-resume/app-lifecycle"&gt;application lifecycle management&lt;/a&gt; to business process coordination. They're particularly helpful with long-running, asynchronous processes that need to behave differently at various stages of the process, especially when the process is message or event driven.&lt;/p&gt;
&lt;p&gt;Normally, state machines are defined by "a list of its states, its initial state, and the triggering condition for each transition". However, when looked at from the point of view of "&lt;a href="http://slides.com/robwormald/everything-is-a-stream#/" title="Everything is a stream - Rob Wormald"&gt;everything&lt;/a&gt; &lt;a href="https://gist.github.com/staltz/868e7e9bc2a7b8c1f754" title="The introduction to Reactive Programming you've been missing - andrestaltz"&gt;being&lt;/a&gt; &lt;a href="http://weareadaptive.com/blog/2014/05/05/everything-is-a-stream/" title="Reactive Trader 2: Everything is a Stream - Matt Barrett"&gt;a&lt;/a&gt; &lt;a href="http://colintheshots.com/blog/?p=85" title="Be Reactive - Colintheshots"&gt;stream&lt;/a&gt;", they can also be viewed as a stream of transitions with states existing as the rest period between those transitions.&lt;/p&gt;
&lt;p&gt;In this mindset, a state can simply be defined as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;public interface IState
{
    IObservable&amp;lt;ITransition&amp;gt; Enter();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In short, the result of entering a state is an observable of transitions away from the state.&lt;/p&gt;
&lt;p&gt;With this in hand, the state machine of, for example, a typical UWP app can be defined as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;public class StateMachine
{        
    private readonly IStateFactory _factory;
    private readonly Subject&amp;lt;IState&amp;gt; _state;

    public Machine(IStateFactory factory)
    {
        _factory = factory;

        _state = new Subject&amp;lt;IState&amp;gt;();
    }

    public IDisposable Initialize()
    {
        // First create a stream of transitions by ...
        IObservable&amp;lt;ITransition&amp;gt; transitions = _state
            // ... starting from the initializing state ...
            .StartWith(_factory.Initializing())
            // ... enter the current state ...
            .Select(state =&amp;gt; state.Enter())
            // ... subscribing to the transition observable ...
            .Switch()
            // ... and ensure only a single shared subscription is made to the transitions observable ...
            .Publish()
            // ... held until there are no more subscribers
            .RefCount();

        // Then, for each transition type, select the new state...
        IObservable&amp;lt;IState&amp;gt; states = Observable.Merge(
            states.OfType&amp;lt;Transition.ToStarting&amp;gt;().Select(transition =&amp;gt; _factory.Starting()),
            states.OfType&amp;lt;Transition.ToResuming&amp;gt;().Select(transition =&amp;gt; _factory.Resuming()),
            states.OfType&amp;lt;Transition.ToRunning&amp;gt;().Select(transition =&amp;gt; _factory.Running()),
            states.OfType&amp;lt;Transition.ToSuspending&amp;gt;().Select(transition =&amp;gt; _factory.Suspending())
        );

        // Finally, subscribe to the state observable ...
        return states
            // ... ensuring all transitions are serialized ...
            .ObserveOn(Scheduler.CurrentThread)
            // ... back onto the source state observable
            .Subscribe(_state);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are no constraints regarding which events/triggers each state uses to construct the observable of transitions returned when the Enter method is called, but they usually follow one of two patterns:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Wait for an event/trigger to be received and transition to a new state based on the type of event/trigger received.&lt;/li&gt;
&lt;li&gt;Perform an asynchronous / long-running process and transition to another state when it completes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To illustrate this, the Initializing and Starting state definitions below can be considered to be examples of the former and latter patterns respectively.&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;internal class Initializing : IState
{
    private readonly IEventAggregator _bus;

    public Initializing(IEventAggregator bus)
    {
        _bus = bus;
    }

    public IObservable&amp;lt;ITransition&amp;gt; Enter()
    {
        return Observable.Merge&amp;lt;ITransition&amp;gt;(
            _bus.GetEvent&amp;lt;Event.Start&amp;gt;().Select(_ =&amp;gt; new Transition.ToStarting()),
            _bus.GetEvent&amp;lt;Event.Resume&amp;gt;().Select(_ =&amp;gt; new Transition.ToResuming())
        );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;internal class Starting : IState
{
    private readonly DataStore.IContext _dataStoreContext;

    public Starting(DataStore.IContext dataStoreContext)
    {
        _dataStoreContext = dataStoreContext;
    }

    public IObservable&amp;lt;ITransition&amp;gt; Enter()
    {
        return Observable.Create&amp;lt;ITransition&amp;gt;(
            async observer =&amp;gt;
            {
                await _dataStoreContext.InitializeAsync();

                observer.OnNext(new Transition.ToRunning());
            }
        );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, states can (and should!) be very small and easily testable. All together a complete, strongly typed, 'async' friendly state machine can be implemented with just a handful of classes containing minimal code.&lt;/p&gt;
&lt;p&gt;I have used this pattern on numerous occasions and enjoy the simplicity and extensibility it affords me when defining long-running process flows.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Today I'd like to share an implementation I've recently been employing that leverages Rx to implement a &lt;a href="https://en.wikipedia.org/wiki/Finite-state_machine"&gt;state-machine&lt;/a&gt;.&lt;/p&gt;</summary>
	</entry>
</feed>es nor am I able to access them from my MCP dashboard. In short, the current beta exam process is extremely poor and much worse than it was five or six years ago when I took (and passed) around a dozen such beta exams.&lt;/p&gt;
&lt;p&gt;Regardless, time spent on this study was a huge win. I learned a lot about a platform which is becoming increasingly prevalent in the Windows ecosystem. UWP apps are able to run on everything from Raspberry Pi to Hololens, and I have since deployed/released UWP apps for Raspberry Pi, Mobile (phone/table), PC and XBox. Indeed, after completing the exam, I continued to develop my UWP study app over the next few months.&lt;/p&gt;
&lt;h3&gt;Holiday&lt;/h3&gt;
&lt;p&gt;Across the year, I allocated around 40 days (including bank-holidays and weekends) as non-work days (aka holiday). This included snowboarding with friends, trips abroad, visiting relatives and a long festive break over Xmas. Although more than the holiday allowance at most full time jobs (depending on how it's allocated), I feel this represents a fairly decent split between work and play.&lt;/p&gt;
&lt;h3&gt;OneCog.Solutions&lt;/h3&gt;
&lt;p&gt;Once life had returned to normal following our tour of Europe and taking the Microsoft beta exam, I decided to work on a few projects that were interesting to me.&lt;/p&gt;
&lt;p&gt;Firstly, this was continuing my investigation of UWP, initially to &lt;a href="http://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl"&gt;flesh out&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/store/p/littlelittle/9nblggh51b1b"&gt;release&lt;/a&gt; the UWP app I had written while studying for the UWP exam but then to also evaluate UWP as a &lt;a href="http://ian.bebbs.co.uk/posts/MonsterPi"&gt;platform for IoT devices&lt;/a&gt;. I then proceeded to broaden my area of investigation into &lt;a href="http://ian.bebbs.co.uk/posts/DockerAndKafka"&gt;non-Microsoft technologies&lt;/a&gt; and even into areas that, while still technical, were &lt;a href="http://ian.bebbs.co.uk/posts/3DPrintingWithTheCelRobox"&gt;not directly involved with software development&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;During this time I endeavored to keep an up-to-date public profile. Through a &lt;a href="https://trello.com/b/KoTWuFUi/public-board"&gt;public Trello board&lt;/a&gt;, products I had released (&lt;a href="https://www.microsoft.com/en-gb/store/p/littlelittle/9nblggh51b1b"&gt;LittleLittle&lt;/a&gt; &amp;amp; &lt;a href="https://www.microsoft.com/en-gb/store/p/toddlerbox/9nblggh3zr4l"&gt;ToddlerBox&lt;/a&gt;), posts to &lt;a href="http://ian.bebbs.co.uk/"&gt;my blog&lt;/a&gt; and contributions to both &lt;a href="https://github.com/ibebbs"&gt;Github&lt;/a&gt; and &lt;a href="http://stackoverflow.com/users/628821/ibebbs"&gt;StackOverflow&lt;/a&gt; I tried to make sure as much of my time as possible was surfaced publicly. Indeed, having become extremely delivery-oriented since first drinking the agile (&lt;a href="https://medium.com/swlh/agile-is-the-new-waterfall-f7baef5d026d#.jpmks6gi4"&gt;lower-case 'a'&lt;/a&gt;) kool-aid several years ago, I feel the public-facing nature of these interactions substituted as a form of delivery; or, in Agile parlance, became my &lt;a href="https://www.agilealliance.org/glossary/definition-of-done/"&gt;"definition of done"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While, in retrospect, I had hoped to have investigated many more technologies than I actually managed during this time, overall I would consider this time well spent. In addition to releasing two applications to the Windows Store and contributing to several public Github projects (more on this later) I managed to rack up over 1000 rep on StackOverflow in just a couple of months.&lt;/p&gt;
&lt;p&gt;Unfortunately, during this time, I didn't achieve my primary goal; namely finding a project that could potentially be grown into a marketable product and form the basis of a company. While there were no shortage of ideas and there still remain a couple of "coals in the fire", I don't think I've yet found the gap in the market I'm looking for. One slight positive note here is that I have, at the very least, determined a couple of markets I'm very keen on investigating further and in which I'd like to work in the future.&lt;/p&gt;
&lt;h2&gt;Health&lt;/h2&gt;
&lt;p&gt;For this visualization I have employed step count (vertical bars), weight (yellow line with dotted yellow representing ideal weight) and fat-mass (red line with dotted red representing ideal fat-mass) as a (very rough) approximation of health. While, in theory, I should have had more leisure time available to exercise over the course of the year, in real terms I found that I did far less than expected. This was due to a number of factors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My previous employer, being a company that revolves around football, had regular football matches/tournaments between company staff which were of a very high standard. I played in as many of these as possible and, once I left, I very much missed the exercise.&lt;/li&gt;
&lt;li&gt;My commute to work each day involved a (voluntary) walk from St Pancras station to Camden Lock - and back again - every day. This constituted 30 minutes/5000 steps of valuable exercise each day that was no longer necessary when I started working from home.&lt;/li&gt;
&lt;li&gt;I ran a football team for my village that played in the local Bedfordshire league. Unfortunately, due to lack of players this team folded at the end of last season leaving me entirely bereft of football for the majority of the year.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At punching-weight, I aim to be 11st and 15% fat-mass. This used to be a fairly common occurrence while playing football regularly but, as can be seen, I've not managed to get back into a similar condition this year. Fortunately, I &lt;em&gt;have&lt;/em&gt; managed to avoid devolving into a complete bucket of lard thanks to several things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Parenthood - As any parent will tell you, being a parent is both exhausting and relentless. While previously I would undertake very little exercise in the evening, nowadays I expend a significant amount of energy each evening running around after my daughter. While not often recognised, this constitutes a fairly high level of activity.&lt;/li&gt;
&lt;li&gt;Preparation for Touring Europe - During this time I did &lt;strong&gt;a lot&lt;/strong&gt; of very physical work. From lugging construction materials and tools around to disassembling and reassembling the van, the average day was extremely active, especially when compared to sitting in an office chair for eight hours.&lt;/li&gt;
&lt;li&gt;European Tour - as can be seen from the step count, although a great deal of time was spent driving, our time away involved a lot of other activity. This activity (particularly loading and unloading the van each day!) provided a lot of exercise and helped keep me fit over the summer.&lt;/li&gt;
&lt;li&gt;Swimming - In a desperate attempt to remain in some sort of shape, I have recently started swimming semi-regularly.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In retrospect, something that came as no surprise but for which I failed to anticipate the true impact, was the effect of not exercising on my state of mind and general happiness. Having always been an active and optimistic individual, I completely underestimated the tight correlation between these two characteristics. Mid-November saw me at my least active and, as I've come to realise, my least productive/focused (as evidenced by the sudden surge in StackOverflow rep!). Fortunately I try be somewhat self-reflective and, recognising that my diminished level of activity might be a possible cause for a perceived lack of progress, I decided to start swimming again as a means to address this.&lt;/p&gt;
&lt;p&gt;Now, while I'm still not exercise as much as I would like, I at least feel like my activity levels are sufficient to allow me to focus on projects and achieve my deliverables. Moving forward I very much hope to re-establish the village football team in time for next season or join another team such that I get at least a couple of games a month.&lt;/p&gt;
&lt;h2&gt;Finances&lt;/h2&gt;
&lt;p&gt;In counterpoint to the Health visualization described above, the Finances visualization shows a relative interpretation of my financial health across the year.&lt;/p&gt;
&lt;p&gt;At the beginning of the year, when considering a career-break, I tried to calculate a monthly "burn-rate" (i.e. total out-goings per month). Given I was not planning to change my lifestyle at all and my partner and I had already planned a number of holidays, I arrived at a rough estimate of £3k per month. This was affordable and, while it would put a dent in my savings, wouldn't leave me worrying about money at the end of the year.&lt;/p&gt;
&lt;p&gt;Through-out the year there were a number of factors that further affected my finances:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Touring Europe in the van cost significantly more than I estimated.&lt;/li&gt;
&lt;li&gt;My daughter's nursery care was cheaper than expected since moving her from four days a week to three (instead having an additional 'daddy-day-care' day).&lt;/li&gt;
&lt;li&gt;While I typically spend a significant amount on computer hardware, this year I required very little but for a relatively cheap new server.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, looking back across the year (and excluding large one-off payments like buying the van) it seems my burn-rate was closer to £2k, one third less than I had planned. This coupled with receiving returns on previous investments meant I actually ended the year significantly better off than I started it. While this definitely wouldn't be the case were I to continue the career-break for a second year, it is very reassuring to know that I could, should I decide to do so.&lt;/p&gt;
&lt;h2&gt;Github contributions&lt;/h2&gt;
&lt;p&gt;Across the year - although predominantly in the last few months - I made 368 commits to Github. These were spread across a couple of dozen repositories but mostly focused on the (private) repository for &lt;a href="https://www.microsoft.com/en-gb/store/p/littlelittle/9nblggh51b1b"&gt;LittleLittle&lt;/a&gt; and my (statically generated &amp;amp; github-pages hosted) &lt;a href="https://github.com/ibebbs/ibebbs.github.io"&gt;blog&lt;/a&gt;. Additionally, I contributed to several open source repositories, most notably the &lt;a href="https://github.com/Microsoft/UWPCommunityToolkit"&gt;UWP Community Toolkit&lt;/a&gt; (1000 stars) and &lt;a href="https://github.com/beto-rodriguez/Live-Charts"&gt;Live-Charts&lt;/a&gt; (875 stars).&lt;/p&gt;
&lt;p&gt;Given 2016 was a leap-year, 368 commits in 366 days averages (just!) over one a day. Overall I'm quite pleased with this level of commitment and the quantity of work it represents, especially considering the amount of time this year spent not working. Additionally, for the last three months of this year, my partner and I have both elected to work four-day weeks as we felt it represented a better balance between parental and nursery care for our daughter. For me this meant Thursdays became "daddy-day-care" so that I could take my daughter swimming - something we both really enjoy - but which adversely affected my productivity.&lt;/p&gt;
&lt;p&gt;Moving forward I intend to start publishing much more of my work to public repositories including regular updates to my &lt;a href="https://github.com/ibebbs/Spikes"&gt;"Spikes"&lt;/a&gt; repository which contains investigative projects and examples for solutions to various StackOverflow questions.&lt;/p&gt;
&lt;h2&gt;StackOverflow&lt;/h2&gt;
&lt;p&gt;Talking of StackOverflow questions, the next visualization shows StackOverflow Reputation accumulation across the year (light blue line) with gains shown day-by-day (dark blue boxes). While I predominantly consider it a distraction, I really enjoy answering questions on StackOverflow, probably due to the awesome &lt;a href="https://en.wikipedia.org/wiki/Gamification"&gt;gamification&lt;/a&gt; employed on the &lt;a href="http://stackexchange.com/"&gt;StackExchange&lt;/a&gt; sites.&lt;/p&gt;
&lt;p&gt;While there is a low level of fairly constant reputation gain, most of the gains came in short bursts. As discussed above, I attribute this losing focus on my main projects due to inactivity. Still, there are far worse forms of procrastination than helping people and I consider this a relatively good use of time.&lt;/p&gt;
&lt;p&gt;I am currently endeavoring to get the 'Fanatic' badge (visit StackOverflow for 100 days consecutively) but trying not to let it get in the way of other work. This usually means only answering questions when I can quickly point the asker in the right direction but I will occasionally field a more challenging question when it's &lt;a href="http://stackoverflow.com/questions/tagged/system.reactive"&gt;something I'm particularly interested in&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Blog posts&lt;/h2&gt;
&lt;p&gt;Over the course of the year I have written and published 22 blog posts - totaling nearly 24,000 words - across a range of subjects including:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;3D PRINTING (1) APACHE KAFKA (1) APACHE ZOOKEEPER (1) ATTACHED PROPERTY (1) BDD (1) BEHAVIORAL (1) BLOG (3) CAREER BREAK (1) CLIENT-SIDE FRAMEWORK (2) CQRS (1) DART (1) DATAFLOW (1) DOCKER (1) DVD RIPPING (1) EF (1) ELASTIC STACK (4) ELASTICSEARCH (4) EVENT SOURCING (1) EVENTS (1) EVENTSOURCING (1) FUTURE (1) GITHUB (2) GROWTH (1) HYPERLINK (1) IOT (1) JAVASCRIPT (2) JS (1) KIBANA (4) LITTLELITTLE (1) LOGSTASH (4) MAPLIN (1) MONITORING (4) MVVM (1) NANOSERVER (1) NETWORKING (4) PARENTHOOD (1) PATTERNS (1) PRODUCTIVITY (1) RASPBERRYPI (1) REACTIVE (7) REST (1) ROBOX (1) RX (7) SQL (1) STATE MACHINES (1) SVG (1) SYSLOG (4) TESTING (1) TODDLERBOX (3) TOOLKIT (2) TPL (2) TRAVEL (1) TYPESCRIPT (1) UWP (7) VISUAL STUDIO (2) VISUAL STUDIO CODE (1) WEBRX (2) WINDOWS SERVER 2016 (1) WYAM (1) XAML (2) XBOX (3)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This content garners an average of around 110 unique visitors and 400 page views every month.&lt;/p&gt;
&lt;p&gt;One of these posts - &lt;a href="https://blogs.msdn.microsoft.com/dotnet/2016/09/07/the-week-in-net-972016/"&gt;"The absolute easiest way to use SVG icons in UWP apps"&lt;/a&gt; was featured in &lt;a href="https://blogs.msdn.microsoft.com/dotnet/2016/09/07/the-week-in-net-972016/"&gt;"The week in .NET – 9/7/2016"&lt;/a&gt;. Furthermore, blog posts I have shared with people on other platforms (i.e. StackOverflow, MSDN, etc) have been understood and well received.&lt;/p&gt;
&lt;p&gt;All in, I think I've added some valuable content to my blog this last year but feel like I should have tried harder to increase it's reach. While writing these blog posts inevitably takes a considerably amount of time, I intend to continue making as many new posts as possible, hopefully across an increased range of subjects and - by submitting to various aggregation blogs - with increased readership.&lt;/p&gt;
&lt;h2&gt;Commitments&lt;/h2&gt;
&lt;p&gt;This timeline displays any days I had expected to work yet was unable to for a variety of reasons. Over the course of the year this accounted for 42 days, mostly the Thursdays that have become my "daddy-day-care" day and during which I take my daughter swimming. While these "commitments" would have been worked around had I been in full-time employment, the flexibility of working when I can as opposed to when I have to has undoubtedly led to a greater degree of motiviation and concentration when I am in front of the computer.&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;Given this fairly comprehensive look back across the year, it's time to perform the retrospective.&lt;/p&gt;
&lt;h3&gt;What went well?&lt;/h3&gt;
&lt;p&gt;There were numerous wins across the year including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Getting to spend the year with my partner and baby which included spending two months traveling Europe in a camper-van.&lt;/li&gt;
&lt;li&gt;Releasing applications to the Windows Store for phone, tablet, PC and XBox.&lt;/li&gt;
&lt;li&gt;Furthering the breadth of my technical knowledge of various platforms, technologies and methodologies.&lt;/li&gt;
&lt;li&gt;Adding a significant amount of content to my blog.&lt;/li&gt;
&lt;li&gt;Contributing to numerous repositories on Github including several for popular open-source projects.&lt;/li&gt;
&lt;li&gt;Increasing my StackOverflow Reputation level by answering questions on a variety of subjects.&lt;/li&gt;
&lt;li&gt;Fully realising the importance of exercise on productivity.&lt;/li&gt;
&lt;li&gt;Completing the year in better financial health than I had expected.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;What didn't go so well?&lt;/h3&gt;
&lt;p&gt;Given that, despite taking a career break, I continued to be productive in a variety of ways, I don't feel like too many things went badly this year. However there are a few things I would have liked to have achieved but didn't such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Not finding the "market gap" or having the "killer idea" I had hoped to translate into a start-up.&lt;/li&gt;
&lt;li&gt;Not investigating as many technologies as I had hoped across the course of the year.&lt;/li&gt;
&lt;li&gt;Lacking a significant amount of exercise and thereby loosing focus and momentum for ongoing projects.&lt;/li&gt;
&lt;li&gt;Shying away from increasing the exposure of my blog content via news aggregators, social media, etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;What needs to change moving forward&lt;/h3&gt;
&lt;p&gt;Well, I gave myself the year to come up with the "killer idea" but didn't manage it so now it's time to change tack. In the coming months I will be starting to look for contract work which, ideally, I can do remotely. Fortunately there is no pressure for me to return to work so I can be quite picky about the roles I take. The ideal contract would ideally feature one or all of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UWP/WPF&lt;/li&gt;
&lt;li&gt;Rx/Streaming technologies&lt;/li&gt;
&lt;li&gt;.NET Core&lt;/li&gt;
&lt;li&gt;IoT&lt;/li&gt;
&lt;li&gt;NoSQL datastores&lt;/li&gt;
&lt;li&gt;CQRS/ES&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ideally in the following markets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Baby/Toddler/Child care/entertainment&lt;/li&gt;
&lt;li&gt;Social Justice&lt;/li&gt;
&lt;li&gt;Automation&lt;/li&gt;
&lt;li&gt;Agriculture&lt;/li&gt;
&lt;li&gt;Renewable Energy&lt;/li&gt;
&lt;li&gt;Automotive&lt;/li&gt;
&lt;li&gt;Economics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That said, given the large number of &lt;a href="https://blog.rjmetrics.com/2014/04/30/the-big-opportunities-in-the-unknown-unknowns/"&gt;"unknown unknowns"&lt;/a&gt;, perhaps there are other technologies / markets I've not encountered yet that would be equally enthralling.&lt;/p&gt;
&lt;p&gt;In the mean time, I will continue to investigate other interesting technologies and release updates to my existing products as appropriate.&lt;/p&gt;
&lt;p&gt;Regarding family life, well, in this respect I hope to continue the extremely rewarding work/life balance my partner and I have achieved over the last year. This could be difficult once the demands of external deadlines become a reality again but it's something I would be extremely reluctant to change.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Saturday morning, having realized that we had no commitments or prior engagements until the following Tuesday, my partner and I decided to go on a trip. We rapidly packed bags for ourselves and our little girl, threw them in the van and set off with no set destination other than "the south-west". We ended up staying in a small farm on Exmoor and having a terrific time walking on the moor and visiting nearby sites.&lt;/p&gt;</summary>
	</entry>
</feed>s with Docker on Windows, or, more specifically, Docker on Windows using Nanoserver as the container OS.&lt;/p&gt;</summary>
	</entry>
</feed>  }
}

filter {
    grok {
        match =&amp;gt; [ "message", "&amp;lt;%{POSINT:syslog_pri}&amp;gt;%{SYSLOGTIMESTAMP:syslog_timestamp} Vigor\: Local User \(MAC=%{MAC:source_mac}\): %{IP:source_address}(?::%{POSINT:source_port})? -&amp;gt; %{IP:destination_address}(?::%{POSINT:destination_port})? \((?&amp;lt;protocol&amp;gt;TCP|UDP)\)" ]
        add_tag =&amp;gt; "access"
    }
    if "access" in [tags] {
        mutate {
            add_field =&amp;gt; {
              "source_host" =&amp;gt; "%{[source_address]}"
              "destination_host" =&amp;gt; "%{[destination_address]}"
            }
        }
        dns {
            reverse =&amp;gt; [ "destination_host" ]
            action =&amp;gt; "replace"
            nameserver =&amp;gt; "192.168.1.1"
        }
        translate {
            destination =&amp;gt; "source_host"
            dictionary_path =&amp;gt; "config\IPLookup.yaml"
            fallback =&amp;gt; "%{source_address}"
            field =&amp;gt; "source_address"      
            override =&amp;gt; true   
        }
    }
}

output {
  elasticsearch {
    hosts =&amp;gt; ["192.168.1.30:9200"]
    index =&amp;gt; "syslog-%{+YYYY.MM.dd}"
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the &lt;code&gt;translate&lt;/code&gt; filter where I lookup the &lt;code&gt;source_address&lt;/code&gt; field in the &lt;code&gt;IPLookup.yaml&lt;/code&gt; file and put the result in the &lt;code&gt;source_host&lt;/code&gt; field. If not found, the &lt;code&gt;fallback&lt;/code&gt; value instructs the filter to output the &lt;code&gt;source_address&lt;/code&gt; into the &lt;code&gt;source_host&lt;/code&gt; field. The &lt;code&gt;override&lt;/code&gt; value is set to true as the &lt;code&gt;source_host&lt;/code&gt; field is added in the &lt;code&gt;mutate&lt;/code&gt; filter above as a fail-safe.&lt;/p&gt;
&lt;p&gt;With the changes to configuration in place, I once again restart Logstash. Once a syslog message has been received, I get the mapping from ElasticSearch and update it to mark the &lt;code&gt;local_host&lt;/code&gt; field as &lt;code&gt;not_analyzed&lt;/code&gt;. Then, in Kibana, I refresh the field list for the 'syslog-*' index, add 'local_host' to the 'Syslog Messages' saved search, load 'Access By Local Address' visualization and modify it to use 'local_host' rather than the 'local_address' field and save it as 'Access By Local Host'. Finally, I replace this visualization on my dashboard and get the following:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardWithAccessByLocalHost.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard With Access By Local Host"&gt;
&lt;h1&gt;further mappings&lt;/h1&gt;
&lt;p&gt;Now I've got the translation of local IP addresses to names working, I'm going to add a few more translations for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IP Address to Operating System&lt;/li&gt;
&lt;li&gt;IP Address to Wired/WiFi connection&lt;/li&gt;
&lt;li&gt;TCP and UDP Port to Protocol (using a &lt;a href="http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml"&gt;CSV from IANA&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With these in place, the dashboard is starting to come together:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardWithLocalPortAndOsLookups.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard With Local Port And Os Lookups"&gt;
&lt;h1&gt;summary&lt;/h1&gt;
&lt;p&gt;In this post, I showed how to display local device names rather than IP addresses by using LogStash's &lt;code&gt;translate&lt;/code&gt; filter. I then used this filter to provide further information about local device and protocols.&lt;/p&gt;
&lt;p&gt;In the next post, I'll show how to add some variation to the dashboard by mapping destination locations.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In the last post, I used the Logstash &lt;code&gt;dns&lt;/code&gt; filter to translate remote server IP addresses into recognisable domain names. In this post, I will look to perform a similar operation for local IP addresses in order to translate them into recognisable device names.&lt;/p&gt;</summary>
	</entry>
</feed>

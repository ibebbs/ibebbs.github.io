<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<link rel="self" href="http://ian.bebbs.co.uk/" />
	<id>http://ian.bebbs.co.uk/</id>
	<title>Ian Bebbington</title>
	<rights>2018</rights>
	<updated>2018-02-06T17:03:36Z</updated>
	<logo>http://ian.bebbs.co.uk/y3mVYjKPwLNM4SpxZ-xLtIcMigGcxEzKTdUxFym5tI2hMna1NOz6e5axIvMYoGFlV1ftnmELd2YUX4QowbgtJ_iJkEHUEXpngrQ47dG5_hm88hO2ZJM1mRZLWwhDoB0KfKuu6WFFqmWoKb_2f18gkAqJQ20PkRodrAj4PzkSSgO9A4%253Fwidth=660&amp;height=371&amp;cropmode=none</logo>
	<subtitle>IObservable&lt;Opinion&gt;</subtitle>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/CombiningUwpSpeechSynthesizerWithAudioGraph" />
		<id>http://ian.bebbs.co.uk/posts/CombiningUwpSpeechSynthesizerWithAudioGraph</id>
		<title>Combining the UWP SpeechSynthesizer and AudioGraph APIs</title>
		<updated>2017-01-25T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Synchronicity is a wonderful thing.&lt;/p&gt;
&lt;p&gt;Just this morning I was considering using the new &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.speechsynthesis.speechsynthesizer.aspx"&gt;SpeechSynthesizer&lt;/a&gt; capabilities of the UWP platform to add spoken language to my &lt;a href="https://www.microsoft.com/en-gb/store/p/toddlerbox/9nblggh3zr4l"&gt;ToddlerBox app for Xbox&lt;/a&gt;. I had already started using the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiograph.aspx"&gt;AudioGraph&lt;/a&gt; classes to play sounds in the app so ideally wanted to continue using this API to emit speech.&lt;/p&gt;
&lt;p&gt;Then, during my morning... ahem... ablutions, I came across &lt;a href="https://mtaulty.com/2017/01/15/windows-10-uwp-iot-core-speechsynthesizer-raspberry-pi-and-audio-popping/"&gt;this post&lt;/a&gt; by Mike Taulty who was looking to do the same thing but for different reasons. It seems that the RaspberryPi has a firmware issue that causes a &lt;a href="https://social.msdn.microsoft.com/Forums/en-US/7c312972-6a09-4acd-8a3f-c59485a81d74/clicking-sound-during-start-and-stop-of-audio-playback?forum=WindowsIoT"&gt;popping noise&lt;/a&gt;  every time speech is emitted using the MediaPlayer and AudioGraph seems to be a way of resolving it.&lt;/p&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;Mike had implemented a means of emitting speech via AudioGraph by saving the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.speechsynthesis.speechsynthesisstream.aspx?f=255&amp;amp;MSPPError=-2147217396"&gt;SpeechSynthesisStream&lt;/a&gt; to a  temporary file and then using multiple &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiofileinputnode.aspx"&gt;AudioFileInputNode&lt;/a&gt; instances to render the speech to the AudioGraph.&lt;/p&gt;
&lt;p&gt;"Well", I thought, "there's got to be a better way. How hard can this be..."&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Turns out the answer is: "Not all that hard, but...".&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;My approach&lt;/h2&gt;
&lt;p&gt;I wanted to find a way to eliminate the need for the temporary files and render the speech stream directly to the graph.&lt;/p&gt;
&lt;p&gt;To do this, I first saved the SpeechSynthesisStream to a file so that I could examine the content. As expected, the file turned out to be a simple 32-bit, mono, ADPCM waveform in &lt;a href="http://soundfile.sapp.org/doc/WaveFormat/"&gt;WAV/RIFF format&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Having previously messed about with AudioGraph I knew there was a way of creating an in-memory waveform and that the &lt;a href="https://github.com/Microsoft/Windows-universal-samples"&gt;Windows-Universal-Samples github repository&lt;/a&gt; had an &lt;a href="https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/AudioCreation"&gt;AudioCreation sample&lt;/a&gt; that &lt;a href="https://github.com/Microsoft/Windows-universal-samples/blob/master/Samples/AudioCreation/cs/AudioCreation/Scenario3_FrameInputNode.xaml.cs"&gt;showed how to do this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fundamentally, this sample shows how to use the &lt;a href="https://msdn.microsoft.com/en-gb/library/windows/apps/windows.media.audio.audioframeinputnode.quantumstarted"&gt;QuantumStarted event&lt;/a&gt; of the &lt;a href="https://msdn.microsoft.com/library/windows/apps/dn914147"&gt;AudioFrameInputNode&lt;/a&gt; to dynamically add &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audioframe.aspx"&gt;AudioFrame&lt;/a&gt; to the AudioFrameInputNode which are then rendered to the &lt;a href="https://msdn.microsoft.com/en-gb/library/windows/apps/dn914151"&gt;output node&lt;/a&gt;. An extract from the sample is shown here:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;  unsafe private AudioFrame GenerateAudioData(uint samples)
  {
      // Buffer size is (number of samples) * (size of each sample)
      // We choose to generate single channel (mono) audio. For multi-channel, multiply by number of channels
      uint bufferSize = samples * sizeof(float);
      AudioFrame frame = new Windows.Media.AudioFrame(bufferSize);

      using (AudioBuffer buffer = frame.LockBuffer(AudioBufferAccessMode.Write))
      using (IMemoryBufferReference reference = buffer.CreateReference())
      {
          byte* dataInBytes;
          uint capacityInBytes;
          float* dataInFloat;

          // Get the buffer from the AudioFrame
          ((IMemoryBufferByteAccess)reference).GetBuffer(out dataInBytes, out capacityInBytes);

          // Cast to float since the data we are generating is float
          dataInFloat = (float*)dataInBytes;

          float freq = 1000; // choosing to generate frequency of 1kHz
          float amplitude = 0.3f;
          int sampleRate = (int)graph.EncodingProperties.SampleRate;
          double sampleIncrement = (freq * (Math.PI * 2)) / sampleRate;

          // Generate a 1kHz sine wave and populate the values in the memory buffer
          for (int i = 0; i &amp;lt; samples; i++)
          {
              double sinValue = amplitude * Math.Sin(theta);
              dataInFloat[i] = (float)sinValue;
              theta += sampleIncrement;
          }
      }

      return frame;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Imitation being the sincerest form of flattery, I then refactored this code to read the binary data from the SpeechSynthesisStream rather than generate a sine wave as shown above. This was greatly facilited by the &lt;a href="https://msdn.microsoft.com/en-us/library/hh582142.aspx"&gt;WindowsRuntimeStreamExtensions.AsStreamForRead&lt;/a&gt; method which allowed me to use basic &lt;a href="https://msdn.microsoft.com/en-us/library/system.io.stream.aspx"&gt;Stream&lt;/a&gt; methods  (specifically &lt;a href="https://msdn.microsoft.com/en-us/library/system.io.stream.readbyte.aspx"&gt;Stream.ReadByte()&lt;/a&gt;) instead of having to mess about with &lt;a href="https://msdn.microsoft.com/en-us/library/windows.media.speechsynthesis.speechsynthesisstream.readasync.aspx"&gt;IBuffer&lt;/a&gt; instances.&lt;/p&gt;
&lt;p&gt;In short order, I ended up with the code below (where &lt;code&gt;_stream&lt;/code&gt; is a member of the containing class pointing to the underlying SpeechSynthesisStream):&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;    private unsafe void QuantumStarted(AudioFrameInputNode sender, FrameInputNodeQuantumStartedEventArgs args)
    {
        uint numSamplesNeeded = (uint)args.RequiredSamples;

        if (numSamplesNeeded != 0 &amp;amp;&amp;amp; _stream.Position &amp;lt; _stream.Length)
        {
            uint bufferSize = numSamplesNeeded * sizeof(float);
            AudioFrame frame = new AudioFrame(bufferSize);

            using (AudioBuffer buffer = frame.LockBuffer(AudioBufferAccessMode.Write))
            {
                using (IMemoryBufferReference reference = buffer.CreateReference())
                {
                    byte* dataInBytes;
                    uint capacityInBytes;

                    // Get the buffer from the AudioFrame
                    ((IMemoryBufferByteAccess)reference).GetBuffer(out dataInBytes, out capacityInBytes);

                    for (int i = 0; i &amp;lt; bufferSize; i++)
                    {
                        if (_stream.Position &amp;lt; _stream.Length)
                        {
                            dataInBytes[i] = (byte)_stream.ReadByte();
                        }
                        else
                        {
                            dataInBytes[i] = 0;
                        }
                    }
                }
            }

            _frameInputNode.AddFrame(frame);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to my surprised, it worked!&lt;/p&gt;
&lt;p&gt;I encapsulated this code into a class named &lt;a href="https://github.com/ibebbs/BlogProjects/blob/master/UwpSpeechAudio/GraphExtensions.cs"&gt;AudioSpeechInputNode&lt;/a&gt; and made this class implement &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudioinputnode.aspx"&gt;IAudioInputNode&lt;/a&gt; so it could be treated like any other node in the AudioGraph. Finally I added an extension method to AudioGraph that created instance of this node in the same way that other nodes are created. This is shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;    AudioSpeechInputNode speechInputNode = await _graph.CreateSpeechInputNodeAsync(new SpeechSynthesizer(), "As input node");
    speechInputNode.AddOutgoingConnection(_outputNode); // device output node
    speechInputNode.Stop();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this node in hand you're then at liberty to call the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudionode.start.aspx"&gt;Start&lt;/a&gt;, &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudionode.stop.aspx"&gt;Stop&lt;/a&gt; and &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudionode.reset.aspx"&gt;Reset&lt;/a&gt; methods as you see fit.&lt;/p&gt;
&lt;p&gt;Et voila, a SpeechSynthesisStream rendered in an AudioGraph without the need for an intermediary file.&lt;/p&gt;
&lt;h2&gt;You said there was a 'but' ...&lt;/h2&gt;
&lt;p&gt;Well, yes. Three of them actually.&lt;/p&gt;
&lt;h3&gt;The big 'but'&lt;/h3&gt;
&lt;p&gt;While this approach certainly solves the issue with needing temporary files and a 'popping' sound each time speech is emitted, I'm afraid to say it does not resolve the 'popping' noise encountered when the application starts on a RaspberryPi.&lt;/p&gt;
&lt;p&gt;Being a good nerd, I had a spare RaspberryPi 3 hanging around with a recent version of Windows 10 IoT Core installed. It took just a few minutes to recompile my &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/UwpSpeechAudio"&gt;sample app&lt;/a&gt; to ARM and deploy it to the Pi whereupon I could confirm that there is no popping when emitting speech but there is when the application starts. In fact, I receive three distinct 'pops' during application start-up which, by studiously placing breakpoints, I isolated to &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiograph.createasync.aspx"&gt;AudioGraph.CreateAsync&lt;/a&gt; (two pops) and &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiograph.start.aspx"&gt;AudioGraph.Start&lt;/a&gt; (one pop).&lt;/p&gt;
&lt;p&gt;Microsoft would have us believe that this is an issue with the RaspberryPi firmware but, as it also occurs on &lt;a href="https://developer.qualcomm.com/hardware/dragonboard-410c"&gt;DragonBoard 410c&lt;/a&gt; I'm more inclined to believe it's an issue with the Windows drivers. On a hunch, I've just ordered a &lt;a href="https://www.amazon.co.uk/dp/B016CU2PEU"&gt;USB Sound Adapter from Amazon&lt;/a&gt;. This device is &lt;em&gt;meant&lt;/em&gt; to be Windows and RaspberryPi compatible (which doesn't necessarily mean it'll work with IoT Core on RPi) and, if it works, I'll be very interested to see if I still get the popping noises when the application starts. I'll update this post once I have an answer...&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Update: I'm pleased to say that, not only does &lt;a href="https://www.amazon.co.uk/dp/B016CU2PEU"&gt;this device&lt;/a&gt; work with Windows 10 IoT Core running on the RaspberryPi 3, but it also resolves the issue with popping noises when the application starts. Of course, this would probably also solve the issue with popping noises when rendering speech through MediaPlayer too making my solution above less necessary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;The intermediate 'but'&lt;/h3&gt;
&lt;p&gt;My code makes a number of assumptions about the format of the SpeechSynthesisStream and encapsulates these as constants. It would be much better to read the format from the WAVE 'fmt ' chunk of the underlying RIFF structures in the stream but, being a pragmatic, &lt;a href="https://martinfowler.com/bliki/Yagni.html"&gt;YAGNI principled&lt;/a&gt; developer... I skipped this for now.&lt;/p&gt;
&lt;h3&gt;The small 'but'&lt;/h3&gt;
&lt;p&gt;As is probably very obvious, the code above is in no way optimised. I'm sure there are &lt;em&gt;much&lt;/em&gt; better and faster ways of storing and copying the binary data from the SpeechSynthesisStream into the AudioBuffer (perhaps just using an intermediate byte array would help) but, for now, this code works fine.&lt;/p&gt;
&lt;h2&gt;Show me the code&lt;/h2&gt;
&lt;p&gt;All the code for the above can be found in a &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/UwpSpeechAudio"&gt;UWP sample app&lt;/a&gt; within the &lt;a href="https://github.com/ibebbs/BlogProjects"&gt;BlogProjects&lt;/a&gt; repository of my &lt;a href="https://github.com/ibebbs"&gt;Github&lt;/a&gt; account.&lt;/p&gt;
&lt;p&gt;Do &lt;a href="https://twitter.com/ibebbs"&gt;get in touch&lt;/a&gt; if you find this code helpful or have suggestions for improving it.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Synchronicity is a wonderful thing.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ASmartHome-Part2" />
		<id>http://ian.bebbs.co.uk/posts/ASmartHome-Part2</id>
		<title>A SmartHome... NoT - Part II</title>
		<updated>2018-02-06T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;In &lt;a href="http://ian.bebbs.co.uk/posts/ASmartHome-Part1"&gt;part I&lt;/a&gt; of this series I described how to use Xiaomi Mi Smart Home devices without compromising your home privacy or security.&lt;/p&gt;
&lt;p&gt;And lo, with the &lt;em&gt;sweet, sweet nut&lt;/em&gt; of privacy-friendly sensors laid before me, I raised the metaphorical &lt;em&gt;hammer of code&lt;/em&gt; like an allegorical Thor about to deliver righteous justice to... and then I stopped. What was I trying to deliver righteous justice to. In fact, what the smeg did I actually want to &lt;em&gt;do&lt;/em&gt; with all these things?&lt;/p&gt;
&lt;p&gt;So focused had I been on finding a 'how', I hadn't really considered the what or why? Monitoring, sure but there had to be useful things I could automate.&lt;/p&gt;
&lt;p&gt;At this point I decided to take a look around at what other people were doing and, almost inevitably, came upon the &lt;a href="https://community.openhab.org/"&gt;OpenHAB forums&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;OpenHABian&lt;/h1&gt;
&lt;p&gt;OpenHAB has been around for years and for much of this time has been the &lt;em&gt;go to&lt;/em&gt; software for home automation.  Nowadays there a numerous other offerings and OpenHAB has had to rapidly evolve to stay competitive. To this end OpenHAB recently released OpenHAB 2 which, as far as I can tell, is a full rewrite based on &lt;a href="https://www.eclipse.org/smarthome/"&gt;Eclipse SmartHome framework&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While &lt;a href="http://www.myopenhab.org/"&gt;'cloud based' versions of OpenHAB are available&lt;/a&gt; the normal use-case is to deploy a version of OpenHAB on the local network thereby keeping all processing locally too. To facilitate this, they now offer pre-built images of OpenHabian - a distribution for single board computes (i.e. the Raspberry Pi et al) that comes with OpenHAB pre-installed.&lt;/p&gt;
&lt;p&gt;Anyway, I was interested in how OpenHAB might have evolved and love trying out new images on the Raspberry Pi (seriously it's like Docker except on real hardware and... well... works) so downloaded &lt;a href="https://github.com/openhab/openhabian/releases"&gt;the latest version&lt;/a&gt; (somewhat confusing named 'version 1.4' even though it contains OpenHAB 2.2), &lt;a href="https://etcher.io/"&gt;etched it&lt;/a&gt; to an SD card, put the SD card in a spare RPi3 and booted.&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;Installation of OpenHABian is pretty straight forward, simply insert the newly prepared SD card and power on the Pi. One thing to note however is that the setup of OpenHABian requires internet access to download additional components / updates. As I had added the RPi3 running OpenHABian to my secured subnet, my first install of OpenHABian failed as there was no internet access available. A quick firewall exclusion and restart solved the problem.&lt;/p&gt;
&lt;h2&gt;Paper UI&lt;/h2&gt;
&lt;p&gt;One of the key enhancements in OpenHAB 2 is the introduction of 'Paper UI'. Paper UI is an HTML5 web application which allows a fully graphical setup and administration of &lt;a href="https://docs.openhab.org/configuration/things.html"&gt;Things&lt;/a&gt; and &lt;a href="https://docs.openhab.org/configuration/items.html"&gt;Items&lt;/a&gt;. Where previously you'd have to drop into textual configuration of components, Paper UI offers a simplified means of getting your home automation devices known to, and used by, OpenHAB.&lt;/p&gt;
&lt;p&gt;Indeed, getting Paper UI to recognise and use my Xiaomi Mi Smart Home devices was simple and can be done as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Install the &lt;a href="https://docs.openhab.org/addons/bindings/mihome/readme.html"&gt;'Xiaomi Mi Smart Home Binding'&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From the Paper UI, click the 'Add-ons' menu item on the left&lt;/li&gt;
&lt;li&gt;Click the 'Bindings' tab at the top of the page&lt;/li&gt;
&lt;li&gt;Search for 'Xiaomi'&lt;/li&gt;
&lt;li&gt;Click the 'INSTALL' button to the right of the 'Xiaomi Mi Smart Home Binding'&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add the Xiaomi Gateway(s)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Once the 'Xiaomi Mi Smart Home Binding' has been installed, any gateways on the current subnet that have 'local network functions' enabled should magically appear in the 'Inbox' and have a notification shown.&lt;/li&gt;
&lt;li&gt;For each gateway on the subnet, simply add it as a 'Thing' with a unique name and in an appropriate location. Also don't forget to add the 'developer key' (copied from the Xiami Mi Home app after enabling 'local network functions') so you can issue commands to the gateway.&lt;/li&gt;
&lt;li&gt;Each time you add a gateway, the binding will query sub-devices registered with the gateway which will also then be shown in the inbox. These sub-devices can then be added as 'Things' for which you should  remember to set the location so 'Items' linked to the 'Thing' (see below) are displayed correctly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add 'Items' to be displayed&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You should now see all your devices in 'Things'. Each one has several 'Channels' which can be 'linked' to an 'Item' by clicking the blue and white circular icon beside it. For most types of 'Channels', the default values displayed in the 'Link Channel' can be left as is.&lt;/li&gt;
&lt;li&gt;Each 'Item' linked to a channel is shown on the Control page with Locations seperated on to discrete tabs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once all your Xiaomi devices have been added as 'Things' and their respective 'Channels' linked to 'Items' you should end up with something like this in the 'Control' page:&lt;/p&gt;
&lt;img src="/Content/posts/OpenHAB - Paper UI - Configured.png" alt="OpenHAB - Paper UI - Configured" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;So far so good. Now what?&lt;/p&gt;
&lt;p&gt;Well, turns out not a lot. After getting your devices added to OpenHABian, you have to move into textual configuration if you want to actually perform any automation via interaction between devices.&lt;/p&gt;
&lt;p&gt;"Oh", I thought, "That was a waste of time then".&lt;/p&gt;
&lt;h2&gt;Node-RED&lt;/h2&gt;
&lt;p&gt;On a whim, I decided to SSH into OpenHABian and play with the &lt;a href="https://docs.openhab.org/installation/openhabian.html#openhabian-config"&gt;OpenHABian Configuration Tool&lt;/a&gt;. Most of the options were fairly straight forward and unexciting until I got to the &lt;a href="https://docs.openhab.org/installation/openhabian.html#optional-components"&gt;Optional Components&lt;/a&gt; menu. Here a couple of items caught my eye, particularly the option to install Node-RED along side OpenHAB.&lt;/p&gt;
&lt;p&gt;I'd heard of &lt;a href="https://nodered.org/"&gt;Node-RED&lt;/a&gt; previously but had never tried it. As I was about to junk the install of OpenHABian anyway, I decided I'd have a play... and this is where the magic happened.&lt;/p&gt;
&lt;p&gt;For others who have not used Node-RED, it is a Node.js app designed for "wiring together hardware devices, APIs and online services in new and interesting ways". It has an amazingly simple yet ludicrously brilliant UI which makes experimentation with it's various 'nodes' extremely quick and easy. Moreover, the installation on OpenHABian comes pre-installed with nodes to interact with 'Items' in OpenHAB.&lt;/p&gt;
&lt;p&gt;Despite, never having used Node-RED before, in just a few minutes I had the following flow deployed and running:&lt;/p&gt;
&lt;img src="/Content/posts/Node-RED - First Flow.png" alt="First Node-RED flow" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;Which does the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Uses an &lt;code&gt;openhab2-in&lt;/code&gt; node to listen to changes to the &lt;code&gt;OfficeDoorSensor_OpenStatus&lt;/code&gt; value.&lt;/li&gt;
&lt;li&gt;Uses a &lt;code&gt;switch&lt;/code&gt; node to compare the status value to 'OPEN' or 'CLOSED' and emit the message to the appropriate port.&lt;/li&gt;
&lt;li&gt;If the door has been opened:
&lt;ul&gt;
&lt;li&gt;Use a &lt;code&gt;openhab2-out&lt;/code&gt; node to issue a 'ON' &lt;code&gt;ItemCommand&lt;/code&gt; to the &lt;code&gt;OfficeGateway_Brightness&lt;/code&gt; channel (i.e. turn the light in the Xiami Mi Smart Gateway on).&lt;/li&gt;
&lt;li&gt;Wait five seconds then use a &lt;code&gt;openhab2-out&lt;/code&gt; node to issue a 'OFF' &lt;code&gt;ItemCommand&lt;/code&gt; to the &lt;code&gt;OfficeGateway_Brightness&lt;/code&gt; channel (i.e. turn the light in the Xiami Mi Smart Gateway off).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the door has been closed then use a &lt;code&gt;openhab2-out&lt;/code&gt; node to issue a 'OFF' &lt;code&gt;ItemCommand&lt;/code&gt; to the &lt;code&gt;OfficeGateway_Brightness&lt;/code&gt; channel (i.e. turn the light in the Xiami Mi Smart Gateway off).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ok, the use case is fairly simple but wow, what an incredibly level of integration between disparate sensors / lights with just five nodes, a few connections and no bespoke code what-so-ever.&lt;/p&gt;
&lt;p&gt;I was hooked.&lt;/p&gt;
&lt;p&gt;Playing with Node-RED inspired me to start brain-storming potential use-cases and they soon started coming thick and fast. Broadly the use-cases fell into three main categories:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Utility - mitigate small frustrations around the house&lt;/li&gt;
&lt;li&gt;Security - enhance home security&lt;/li&gt;
&lt;li&gt;Efficiency - reduce home power consumption&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;However, one use case I came up with fell into all three of these categories &lt;strong&gt;and&lt;/strong&gt; a logical progression from the above flow.&lt;/p&gt;
&lt;h1&gt;A use case at last!&lt;/h1&gt;
&lt;p&gt;Our new 'forever home' has a built in double garage. While the doors on the garage are in pretty good condition, the locks are nothing special and present an obvious security weak spot. Indeed, we use the garage doors every day as it's a very convenient way into the house which increases the likelihood we'll forget to close the doors properly.&lt;/p&gt;
&lt;p&gt;Furthermore, the flurescent lights in the garage are old and take an age to turn on. As we need to go through the garage to get to the utility room and can't see the way to the utility room until the light is on, we tended to simply turn them on at the beginning of the day and turn them off before going to bed each night, thereby consuming way more energy than necessary.&lt;/p&gt;
&lt;p&gt;Understanding this, I used an additional gateway in the garage, coupled with sensors on each of the doors (garage door, kitchen door, utility room door) and an easily controllable &lt;a href="https://www.amazon.co.uk/gp/product/B077HLQMBD"&gt;IP camera&lt;/a&gt; to put together the following flow:&lt;/p&gt;
&lt;img src="/Content/posts/Node-RED - Garage.png" alt="Node-RED garage flow" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;This does a couple of things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Turns on the light in the gateway whenever any of the doors open&lt;/p&gt;
&lt;p&gt;The light in the gateway is more than enough to light the way to the utility room which addresses the utility aspect of the use-case as we no longer need to wait for the garage light to come on. Furthermore, three minutes after the door was opened (regardless of whether it's been closed again), the light in the gateway is turned off. This is normally long enough for us to do whatever we needed in the garage and addresses the efficiency aspect of the use-case as we no longer leave a light on all day.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Turns the IP Camera to look at the opened door and takes a snapshot&lt;/p&gt;
&lt;p&gt;The IP camera I've used has a useful feature whereby it can record several Pan/Tilt positions which it can then return to using a single command. I use this feature to point the camera at the door which has just been opened and use a further command to take a snapshot image of what it sees. This addresses the security aspect of the use case by ensuring video surveilance coverage of activity within the garage.&lt;br&gt;
&lt;em&gt;Ultimately I intend to upload this image to a cloud storage provider and send a notification to my phone if this happens within certain time constraints but this has yet to be implemented.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Moving forward&lt;/h1&gt;
&lt;p&gt;As you can see, the combination of Xiaomi Mi Smart devices, OpenHAB[ian] and Node-RED is extremely potent. Without writing any code (compiled, intepreted or DSL), I'm able to orchestrate some very advanced interactions between sensors, actuators and other services.&lt;/p&gt;
&lt;p&gt;In the next post, I'll discuss how I've developed this platform even further into a full, voice activated, digital assistant while &lt;em&gt;still&lt;/em&gt; maintaining privacy and security.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In &lt;a href="http://ian.bebbs.co.uk/posts/ASmartHome-Part1"&gt;part I&lt;/a&gt; of this series I described how to use Xiaomi Mi Smart Home devices without compromising your home privacy or security.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/3DPrintingWithTheCelRobox" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mgQk7Eo-T13uKoaK88obO48Y6pzP0KHelfDJwLdORXiP6nnbplZzVSqbrBCBPh9bTpRgyynkyjS9mY53_ZE1f0NDpBcuKTDB7Jf6_a2me30twiv6CGRB6lQjK6Lu-DKkn6LTWVHSq463duCG-820-pQKTQ_q5ifVlXN40_86622Q%253Fwidth=965&amp;height=292&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/3DPrintingWithTheCelRobox</id>
		<title>3D Printing with the CEL Robox</title>
		<updated>2016-10-07T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;So, I've wanted a 3D printer for a while and recently a perfect storm of events meant I finally took the plunge.&lt;/p&gt;
&lt;p&gt;I had hit a wall in my MonsterPi project trying to mount a RaspberryPi in a constrained space (more on this in a subsequent post). Most of my usual hacks (you'd be amazed what you can do with a sheet of acrylic and a Meccano set) simply wouldn't cut it and I was considering abandoning the project. Without intentionally meaning to, I found myself looking at 3D printers on &lt;a href="http://www.maplin.co.uk/c/gadgets-toys-and-hobbies/3d-printers"&gt;Maplin's website&lt;/a&gt; and saw that they were selling 'used' 3D printers at quite a discount.&lt;/p&gt;
&lt;p&gt;After a quick look around for reviews I found that one of the models Maplin were selling - the &lt;a href="http://www.maplin.co.uk/p/cel-robox-3d-printer-used-b81qq"&gt;CEL Robox&lt;/a&gt; - was listed as one of the best "Plug 'n' play" printers on &lt;a href="https://www.3dhubs.com/best-3d-printer-guide#plugnplay-cel-robox"&gt;3D Hubs&lt;/a&gt;. Moreover, my local (well, 15 miles away) Maplin's store had one in stock. But there was that 'used' thing. From what I'd gathered, getting a 3D printer to print reliably is tricky at the best of times, and I was thinking of buying one that had already been used and returned or worse, didn't even work in the first place.&lt;/p&gt;
&lt;p&gt;Too intrigued not to dig a little deeper, I gave Maplin a call. Now experience has lead me not to expect too much from Maplin's employees - at best they're well meaning but witless, at worst they think you are -  but this time proved to be an exception. The guy who answered the phone was superb (note to self: must tweet Maplin about how great this guy is). Although he initially seemed confused about not having a used model of the 3D printer in store, he checked the website to confirm availability then the store stock levels to work out what was going on. Turns out the 'used' printer they had was actually the display model and after noting that he was unsure of the history of the printer he offered to make a couple of calls to other staff to find out the condition and how much it had been used then call me back; as I said, he was excellent. As promised, he called back in 15 minutes or so having confirmed that the printer had only been used to print a few example models and had otherwise sat idle for almost a year. Unfortunately in that time it had garnered a few scratches and lost it's box and support material but, having talked to his manager, he would be able to offer a further discount on the used price if I wanted to come in a take a look at it.&lt;/p&gt;
&lt;p&gt;At the store an hour later it turned out that the guy I had talked to was actually the store manager and was really going the extra mile. By the time I had turned up, he had collated replacement components (power lead, usb lead, brushes, etc) from store stock and had the printer out ready for me to inspect. Amusingly, he had his staff so well organised that, seeing a few components laying around, they had actually put them all back on the shelves so he had to go collect them all again - but I couldn't help but be impressed. Anyway, the scratches turned out to be superfluous, the offer of an additional discount very attractive and the store manager's assurances that should anything be wrong with the unit he'd ensure it was replaced no questions asked very persuasive.&lt;/p&gt;
&lt;p&gt;So I bought it, brought it home and, once the baby was safely ensconced at nursery the next day, set it up and set about calibrating it. The unit itself is a thing of beauty. Bold lines and colours with smooth, solid feeling mechanical components and a general air of quality; not at all what I've come to expect from a &lt;a href="https://www.kickstarter.com/projects/robox/robox-desktop-3d-printer-and-micro-manufacturing-p"&gt;Kickstarter funded project&lt;/a&gt;. While I was initially wary of buying a 3D printer that used a proprietary "chipped" spool for fear of a lock-in to an expensive source of filament, the integrated nature of the spool into the body of the unit and the intelligence it provides to the software - everything from how much spool is left to how much a particular model will cost to print - is fantastic. Far from other "hobbyist" 3D printers where filament projects precariously around the unit, the feed of filament to the head is completely hidden from view and loading of filament completely automated.&lt;/p&gt;
&lt;p&gt;Unfortunately calibration wasn't quite as smooth and it took a long time to get the printer ready to actually try printing a model. In fact, despite repeatedly trying and following all suggestions, one of the calibration tests - the needle valve opening calibration for the fill nozzle - stoically refused to run successfully. This may have been the result of the unit sitting idle for so long or simply me not setting it up right but the failure to pass this test was extremely worrisome. Even the 'purge' material test (used to completely empty the print heads when you're planning on changing material) failed to lay down material as it should but this was mostly resolved by vigorously cleaning the print bed with the isopropyl alcohol.&lt;/p&gt;
&lt;p&gt;Anyway, despite the needle valve opening calibration still failing, I decided to print a model to see how it would perform before deciding whether or not to return the unit. From CEL's downloadable samples, I decided to try printing the 'cargo-box' as it didn't seem to require too much filament and a small container is always useful for something. Actually loading and starting to print a model using CEL's &lt;a href="http://www.cel-robox.com/downloads/"&gt;AutoMaker&lt;/a&gt; software is ludicrously simple: start a new layout, load a model, choose the granularity of the print, go.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Watching a 3D model being printed is really something to behold. Despite it taking hours "like watching a 3D printer fabricate" should really become the metaphorical antonym to "like watching paint dry"; from the initial outline of the print being laid on the print bed, to seeing a solid object emerge, the process is fascinating. Taking a virtual object modelled on your computer and seeing that object take shape and become a physical object in the real world is thrilling, with innumerable possibilities opening up with every layer of filament laid down.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In short order (well, actually 'long order' but it certainly didn't feel that way) and with much amazement and relief, the print was finished perfectly. A 1.5" square, green plastic cargo-box sat inside the Robox; I had fabricated a solid object from - seemingly - nothing. Once the unit had cooled the heated print-bed and unlocked the door, I tried removing the box, entirely expecting to have to lever and peel the plastic off the bed. To my surprise it moved easily, seemingly held to the bed by nothing more than a static charge. I was further surprised by the strength of the box; given it was made from nothing more than melted strands of plastic, I absolutely expected the fabricated object to have the tensile strength of a faberge egg. Yet it was incredibly rigid and inflexible, only the tell-tale layering giving away the fact that it had been 3D printer rather than cast in an industrial manufacturing plant.&lt;/p&gt;
&lt;img src="https://0ohhnq.dm2302.livefilestore.com/y3mzj-a64dzTwhL7kVdtCG_OooHuVEnWyP5gynRF28lVCG247INMKuJpO8E2neQaekUtsZINVLDxnr5iwvoFRVqrOysfCj5ouJTt3e9oNYAOlrvaV2V7FquQultYnqicCjLCpdtiUF1NCeS5hfzgoXL5KhtZ2iBMvDpnslKBEX86FI?width=1024&amp;amp;height=576&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="My first 3D printed object"&gt;
&lt;p&gt;Now it was time to see if I could use the printer for the purpose I bought it: fabricating custom components for other projects. First up was a bracket to hold a RaspberryPi and other components in a very specific configuration. &lt;a href="http://www.sketchup.com/products/sketchup-pro/new-in-2016?gclid=CIK4ks2Cy88CFc0y0wodZmwHaQ"&gt;SketchUp&lt;/a&gt; has been my go-to 3D modelling software of choice since being bought and given away by Google. It is amazingly quick and easy to use for almost everything except extremely precise components with low tolerances; i.e. exactly the kind of thing I needed to do. So I went about looking for alternatives and quickly settled on the free version of &lt;a href="https://www.rs-online.com/designspark/mechanical-software"&gt;DesignSpark Mechanical from RS Components&lt;/a&gt;. Despite some quirkiness in it's UI, it provides most of the features and ease of use of SketchUp with several digits of precision for designed components. Indeed, instead of using a mouse to try to get the exact length of an edge, you can simply enter the length you want on the keyboard; precisely the functionality I thought was missing from SketchUp.&lt;/p&gt;
&lt;p&gt;It took several hours to complete the 3D model for the bracket I needed - somewhat due to DesignSpark's learning curve but mostly the precise measurements and imprecise iteration required to design a bracket that would hold all the components just so - but eventually it was ready to print. Again, friction from design software to print ready was minimal. DesignSpark is able to export in the standard STL format and AutoMaker loaded the model and positioned it on the print-bed automatically, promising to fabricate me a completely custom component for just £1.48's worth of material.&lt;/p&gt;
&lt;p&gt;I set the print going but was quickly dismayed that the first layer of the print wasn't being laid properly at the far corners of the bed, mostly due to the fact that the corners of the bed away from the tabs that hold it in place had risen slightly. Regardless, I decided to let the print continue and see if subsequent layers would adhere to the small smudge of material the print head had managed to deposit. This turned out to be the right choice as by layer three the base of the bracket was fully formed and the printer had started using the "fill" nozzle to quickly start filling out further layers.&lt;/p&gt;
&lt;p&gt;It took about three hours to design and an hour and forty minutes to fabricate, but the bracket fitted perfectly and was easily strong enough to hold all the components in the configuration I needed. I was a very happy boy and immediately starting to design a subsequent bracket I needed for the same project and plan for a load of other custom bits.&lt;/p&gt;
&lt;p&gt;In summary, if you're thinking of buying a 3D printer and can afford what is - regardless of the heavy discount - an expensive bit of technology, I would absolutely recommend going for it. The possibilities of what you can create are mind-boggling and the sensation of watching them come into existence exhilarating. Being able to fabricate components I previously had to hack together from off the shelf bits is tremendously empowering and I can unashamedly say that I am completely hooked on 3D printing.&lt;/p&gt;
&lt;p&gt;Furthermore, while I have no direct experience of other 3D printers, I wouldn't hesitate to recommend CEL's Robox printer as - despite still failing the nozzle calibration - it has yet to fail a print and the software is remarkably straight forward and easy to use.&lt;/p&gt;
&lt;p&gt;Watch this space for more adventures in 3D printing as I integrate my new found fabrication abilities into my innumerable ongoing projects. First up: MonsterPi.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;So, I've wanted a 3D printer for a while and recently a perfect storm of events meant I finally took the plunge.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/NewBlogUsingWyam" />
		<id>http://ian.bebbs.co.uk/posts/NewBlogUsingWyam</id>
		<title>Using Wyam</title>
		<updated>2015-11-09T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;I've been meaning to create a blog for a &lt;strong&gt;long&lt;/strong&gt; time but never found a system with the right combination of features (power vs flexibility vs learning curve, cost, technology stack, etc). CMSs (Wordpress, Drupal, etc) were always way too much faff and most static site generators required the installation of numerous languages / run-times / sdks, etc.&lt;/p&gt;
&lt;p&gt;Then I found &lt;a href="http://wyam.io/" title="Wyam Homepage"&gt;Wyam&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Being .NET based it could be used from my day-to-day development machine and, by cleverly leveraging the  Roslyn compiler platform, can be set up to be as simple or flexible as desired. A quick flick through the module and API pages and I knew I'd found a potential candidate for my statically generated blog.&lt;/p&gt;
&lt;p&gt;Being a... ahem... pragmatic developer with somewhat dated web skills I decided to take the path of least resistance and copy someone else's blog layout. Afterall, imitation is the sincerest form of flattery, right? As such, I contacted Dave Glick - the most-excellent author of Wyam - to see if he would mind me 'borrowing' the layout he used for &lt;a href="http://daveaglick.com/" title="Dave Glick's blog"&gt;his blog&lt;/a&gt;. He quickly replied to my cheeky request and said he didn't mind at all if used his layout, even refusing my offer of attribution (which I hope this blog post somewhat makes up for).&lt;/p&gt;
&lt;p&gt;With the all clear, I &lt;a href="https://github.com/Wyamio/Wyam/releases/tag/v0.10.0-beta" title="download page for Wyam version 0.10.0-beta"&gt;downloaded the latest version of Wyam&lt;/a&gt;, cloned the &lt;a href="https://github.com/Wyamio/Wyam" title="Github repository for Wyam "&gt;Wyam repository&lt;/a&gt;, invoked Wyam to generate an &lt;a href="https://github.com/Wyamio/Wyam/tree/develop/Examples" title="Wyam Example sites in Github repository"&gt;example site&lt;/a&gt;... and got an exception.&lt;/p&gt;
&lt;p&gt;Another quick chat with Mr. Glick revealed that the project is iterating quickly and currently in a "move fast and break things" mode. Fortunately the issue was already resolved in the development branch so, after local build of Wyam, I managed to successfully generate the example sites.&lt;/p&gt;
&lt;p&gt;"Now for some blatant plagiarism with his blog" I thought to myself but again, after cloning his (generously shared and CC licensed) &lt;a href="https://github.com/daveaglick/daveaglick" title="Github repository for Dave Glick's blog"&gt;blog&lt;/a&gt;, asking Wyam to generate the site threw an exception. This time, a &lt;a href="https://github.com/Wyamio/Wyam/issues/112#issuecomment-155165316" title="Wyam PostFile issue comment on Github"&gt;short bit of call-stack sleuthing&lt;/a&gt; revealed another breaking change which was easily resolved by examining the &lt;a href="http://wyam.io/modules/" title="Module documentation for Wyam"&gt;Wyam module documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once more with feeling and ét voila, a MVB (Minimal Viable Blog).&lt;/p&gt;
&lt;p&gt;All in all, not a bad experience with an early beta of a very clever project. Moving forward, I actually hope to do very little with Wyam other than post blog entries but will certainly endeavour to keep up to date with Wyam and share my experiences here.&lt;/p&gt;
&lt;p&gt;If you're looking for a flexible yet powerful .NET based static-site generator, go check out &lt;a href="http://wyam.io/" title="Wyam Homepage"&gt;Wyam&lt;/a&gt;. If you experience any problems with it I'd definitely recommend posting an issue on Github, Dave seems to be very on the ball responding to issues (and extremely friendly to boot).&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;I've been meaning to create a blog for a &lt;strong&gt;long&lt;/strong&gt; time but never found a system with the right combination of features (power vs flexibility vs learning curve, cost, technology stack, etc). CMSs (Wordpress, Drupal, etc) were always way too much faff and most static site generators required the installation of numerous languages / run-times / sdks, etc.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/OnTheImportanceOfDoingSomething" />
		<id>http://ian.bebbs.co.uk/posts/OnTheImportanceOfDoingSomething</id>
		<title>On The Importance of Doing Something</title>
		<updated>2015-11-16T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;I've just become a father. It's amazing and I'm loving every day, from waking up in the morning and being greeted by huge grin from my little girl to putting her to bed in the evening when she can barely keep her eyes open. My baby instantaneously became priority number one and has left little time for other passions like home programming projects.&lt;/p&gt;
&lt;p&gt;Yet, simultaneously, I have found the time since my baby was born to be some of the most productive time of my life. Since she her birth, I've spent every hour possible with her, worked regular hours - and been productive during those hours - at my day job, got an unexpectedly healthy amount of sleep and still managed to complete a significant amount of work on personal projects as well as creating and writing this blog.&lt;/p&gt;
&lt;p&gt;While reflecting on why this might be, I came up with one simple, inescapable conclusion: &lt;a href="https://github.com/ibebbs" title="ibebbs Github Profile"&gt;my Github profile&lt;/a&gt;. More specifically the "Current Streak" of contributions. You see, I am a sucker for gamification and seeing that "Current Streak" increase each day is remarkably rewarding. As such, I am finding time each day - no matter how little - to do &lt;em&gt;something&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Previously, I'd get home in the evening, think about the projects I had to work on, realise that there probably wouldn't be enough time to make significant progress and procrastinate about it until I had more time available to "get things done properly" - which was happening increasingly rarely. Now, instead of focusing on some distant goal, I simply think about finding &lt;em&gt;something&lt;/em&gt; I can do and publish to Github in whatever time I have available. It really doesn't matter what it is, as long as I get the &lt;a href="https://www.microsoft.com/surface/en-gb/devices/surface-pro-4" title="Microsoft Surface Pro 4"&gt;Surface&lt;/a&gt; out and start. Almost always, once I've started something, I get engrossed in it and am able to spend way more time than I thought might be available on it.&lt;/p&gt;
&lt;p&gt;For example, I'm writing this post from the sofa in my front room having spent a wonderful evening with my other half and little girl. Not having had time to make a commit today, I decided not to get an early night and instead tucked them into their respective beds before heading back down stairs to get a start on this post. Initially I had planned simply jot down a few ideas and possibly write a sentence or two before committing to Github and retiring for the evening. Yet here I am still writing after several paragraphs (and &lt;a href="https://music.microsoft.com/album/london-grammar/if-you-wait-deluxe-edition/bz.EE99E107-0100-11DB-89CA-0019B92A3933?action=play" title="London Grammar on Groove Music"&gt;one very enjoyable album&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;I probably won't finish tonight, and definitely won't publish this post until I've had time to re-read and edit it. But I've got my commit for the day and made an unexpected amount of progress on a blog post about making an unexpected amount of progress. In short, I got &lt;em&gt;something&lt;/em&gt; done and that feels good.&lt;/p&gt;
&lt;p&gt;Night!&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;I've just become a father. It's amazing and I'm loving every day, from waking up in the morning and being greeted by huge grin from my little girl to putting her to bed in the evening when she can barely keep her eyes open. My baby instantaneously became priority number one and has left little time for other passions like home programming projects.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/DartInVisualStudioCode" />
		<id>http://ian.bebbs.co.uk/posts/DartInVisualStudioCode</id>
		<title>Dart web development with Visual Studio Code</title>
		<updated>2017-01-17T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Visual Studio Code is rapidly becoming my go-to editor for anything not project-oriented C#/F#. I've switched from &lt;a href="https://atom.io/"&gt;Atom&lt;/a&gt; to &lt;a href="(https://code.visualstudio.com/)"&gt;VSC&lt;/a&gt; for editing my (&lt;a href="http://ian.bebbs.co.uk/posts/NewBlogUsingWyam"&gt;statically-generated, Markdown driven&lt;/a&gt;) blog and have used it for authoring powershell scripts, dockerfiles and much, much more. So, when I decided I wanted to write some &lt;a href="https://www.dartlang.org/"&gt;Dart&lt;/a&gt; code, it was the obvious choice.&lt;/p&gt;
&lt;h2&gt;Why Dart?&lt;/h2&gt;
&lt;p&gt;Why did I decide on Dart? Well, I had project I wanted to undertake that featured some... shock horror... dynamic web content. If that isn't enough to send chills down your spine, you've either &lt;a href="https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.fqoett4pt"&gt;never had to look at getting started with modern web development&lt;/a&gt; or &lt;a href="https://medium.com/@pistacchio/i-m-a-web-developer-and-i-ve-been-stuck-with-the-simplest-app-for-the-last-10-days-fb5c50917df#.glf30ovv1"&gt;you've already drunk the cool-aid&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Either way, most rational people in the industry will (in the moments of clarity between writing off the last framework as dated and evangelising the next) reluctantly admit that &lt;a href="https://medium.com/@wob/the-sad-state-of-web-development-1603a861d29f#.lqu2r4xup"&gt;modern web development is a mess&lt;/a&gt;. But this is the world we live in and the best one can do is dodge the analysis paralysis and mitigate the majority of the risks. For me, this was adopting a &lt;a href="https://www.dartlang.org/guides/language/language-tour"&gt;strongly-typed modern development language&lt;/a&gt; that has a &lt;a href="https://webdev.dartlang.org/"&gt;strong web pedegry&lt;/a&gt; and just get on with it.&lt;/p&gt;
&lt;h2&gt;But in Visual Studio Code?&lt;/h2&gt;
&lt;p&gt;Why not? It's a great editor and already has great support for Dart courtesy of Danny Tuppeny's &lt;a href="https://marketplace.visualstudio.com/items?itemName=DanTup.DartVS-VisualStudiosupportforGooglesDart"&gt;excellent Dart extension&lt;/a&gt;. Furthermore, I try to keep my development machine as lean and clean as possible so I didn't want to have to &lt;a href="https://www.jetbrains.com/webstorm/"&gt;install an IDE specifically for Dart development&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fortunately, as you'll see, getting set up for Dart development with Visual Studio Code is very easy, doesn't require any installation (everything is "xcopy" deployed) and you can start being productive almost right away.&lt;/p&gt;
&lt;h2&gt;Ingredients&lt;/h2&gt;
&lt;p&gt;You will need the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://code.visualstudio.com/Download"&gt;Visual Studio Code&lt;/a&gt; - obviously&lt;/li&gt;
&lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=DanTup.dart-code"&gt;DartVS&lt;/a&gt; - the Dart language extension for Visual Studio Code&lt;/li&gt;
&lt;li&gt;&lt;a href="https://storage.googleapis.com/dart-archive/channels/stable/release/1.21.0/sdk/dartsdk-windows-x64-release.zip"&gt;The Dart SDK&lt;/a&gt; - the code Dart binaries and tools needed for dart development&lt;/li&gt;
&lt;li&gt;&lt;a href="https://storage.googleapis.com/dart-archive/channels/stable/release/latest/dartium/dartium-windows-ia32-release.zip"&gt;Dartium&lt;/a&gt; - a version of Chrome (even called "Chrome.exe") with a built in Dart runtime&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Steps&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Download and extract the Dart SDK to a location on your HD (I use &lt;code&gt;C:\Apps&lt;/code&gt; for "manually" installed tools/applications so will be using the path &lt;code&gt;C:\Apps\dart-sdk&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Download and extract Dartium to a location on your HD (&lt;code&gt;C:\Apps\chromium&lt;/code&gt; for me).&lt;/li&gt;
&lt;li&gt;Create a new directory wherever you keep your source files and name it &lt;code&gt;GettingStartedWithDart&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;In this directory, create two further directories named &lt;code&gt;lib&lt;/code&gt; and &lt;code&gt;web&lt;/code&gt; (this structure follows the &lt;a href="https://www.dartlang.org/tools/pub/package-layout"&gt;Pub Package Layout Conventions&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Start Visual Studio Code and open the &lt;code&gt;GettingStartedWithDart&lt;/code&gt; folder. You should see something like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt6eg-dm2306.files.1drv.com/y3m_WQkZhj4Xo-vjZzyUVujyGYAM3lM7Gs84uuf59zCfPKJQzrT9d--PF8Ns9Gwm3qluxzW26f_H9OU5PZQEq37lEKy9aKY553bzGzZLNU_CBIRGUWA_9_QbE-a0WgQz284pvZY2-Voc83pjQc2h9iMUIzap8At--sCEdhJXyO6sXw?width=660&amp;amp;height=497&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Empty Project"&gt;
&lt;ol start="6"&gt;
&lt;li&gt;If you haven't already, install the DartVS extension by hitting &lt;code&gt;Ctrl-Shift-X&lt;/code&gt; (the keyboard shortcut for "View-&amp;gt;Extensions") and type Dart in the search box. This should show the "Dart Code" extension by "Danny Tuppeny". Click install and reload the window when complete.&lt;/li&gt;
&lt;li&gt;As we haven't elected to add the Dart SDK to the path, we need to tell the Dart extension where it can find the SDK. This is done by editing the User Settings (&lt;code&gt;File-&amp;gt;Preferences-&amp;gt;User Settings&lt;/code&gt;) and adding the following settings:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;    "dart.sdkPath": "C:\\Apps\\dart-sdk",
    "dart.debugSdkLibraries": false,
    "dart.debugExternalLibraries": false
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="8"&gt;
&lt;li&gt;Back in the Explorer view (&lt;code&gt;Ctrl-Shift-E&lt;/code&gt;) add a new file to the &lt;code&gt;web&lt;/code&gt; directory named &lt;code&gt;main.dart&lt;/code&gt;. We'll populate this file shortly but, for now, it's just so that VSC (and DartVS) realises that this is a Dart project.&lt;/li&gt;
&lt;li&gt;Add another new file named &lt;code&gt;pubspec.yaml&lt;/code&gt; to the root directory. This file tells the Dart compiler (named &lt;code&gt;Pub&lt;/code&gt;) how to build your Dart project and follows a very &lt;a href="https://www.dartlang.org/tools/pub/pubspec"&gt;simply format&lt;/a&gt;. In this file add &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;dependencies&lt;/code&gt; and &lt;code&gt;transformers&lt;/code&gt; as shown below:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;name: GettingStartedWithDart
dependencies:
transformers:
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="10"&gt;
&lt;li&gt;When you save this file, you should see the &lt;code&gt;Output&lt;/code&gt; panel appear showing the output of the &lt;code&gt;Pub&lt;/code&gt; command. This is a feature of the DartVS extension which runs a &lt;code&gt;pub get&lt;/code&gt; command whenever you save the &lt;code&gt;pubspec.yaml&lt;/code&gt; file. As you can probably guess from the output (shown below) the purpose of this command is to retrieve/update any dependencies you've declared in the &lt;code&gt;dependencies&lt;/code&gt; section. Also, once the &lt;code&gt;pub get&lt;/code&gt; command has run, you should see a new &lt;code&gt;pubspec.lock&lt;/code&gt; file appear in the root directory.&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt5eg-dm2306.files.1drv.com/y3mCavvhl_SorCHUuY_oZ01TMQ9jkjpMy_I48Eotp3TlC5s-TRU0JaznDIYoihtHpfFj6A3Aqwu9eEKDhOQaK7jnEO7g6UscYBqeBp5yLg_PnzxGgWQpVTwgrxkJeOw8EUet6KhgGEn2Lkm3IYfP4-K-SEXXvKT4G64DcweiAsnQ-k?width=660&amp;amp;height=497&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Get Dependencies"&gt;
&lt;ol start="11"&gt;
&lt;li&gt;As we're focusing on using Dart for web development, we'll also add an HTML document we'll manipulate using Dart. To do this, simply add new file named &lt;code&gt;index.html&lt;/code&gt; to the &lt;code&gt;web&lt;/code&gt; directory and populate it with the following:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;Getting Started With Dart&amp;lt;/title&amp;gt;
    &amp;lt;script type="application/dart" src="main.dart"&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;h1 id="header"&amp;gt;Hmm... what should I say?&amp;lt;/h1&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="12"&gt;
&lt;li&gt;At this point you should have the following layout in your project and we're ready start start writing some Dart.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;    [Source Directory]
    |-&amp;gt; [Project Name] (i.e. "GettingStartedWithDart")
    | | -&amp;gt; lib
    | | -&amp;gt; web
    | | | -&amp;gt; index.html
    | | | -&amp;gt; main.dart
    | | -&amp;gt; pubspec.lock
    | | -&amp;gt; pubspec.yaml
&lt;/pre&gt;
&lt;ol start="13"&gt;
&lt;li&gt;In the &lt;code&gt;main.dart&lt;/code&gt; file, add the following code. (Note, if you type this code rather than copy-pasting it, you'll notice the excellent intellisense features provided by VSC and implemented beautifully by Dart VS.)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;import 'dart:html';

void main() {
  querySelector('#header').text = 'Ah yes... Hello World!!!';
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="14"&gt;
&lt;li&gt;Right, now we have an HTML file and some Dart code and we're ready to run. While you could run this code manually from the command line, if you're intending on doing more than just this getting started guide, I'd very much recommend setting up some task runners in VSC. This is done by opening the command palette (&lt;code&gt;Ctrl-Shift-P&lt;/code&gt;) and typing &lt;code&gt;Configure Task Runner&lt;/code&gt;, which should show you the command &lt;code&gt;Tasks: Configure Task Runner&lt;/code&gt;. Select this and you will see a list of build systems VSC can automatically create a task runner for (shown below). As Dart isn't one of the predefined templates, select "Others" to create an empty Tasks file.&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt4eg-dm2306.files.1drv.com/y3mjQOmP0yb0-3KfLb34MamSLnq13qKN0jSNcEHLMIOn7u2kbunZuaN74mec-0mquSOr05it5RZC6Uov1rnpiweb1sL6a96iKFJYLWC_6hSlldbQjHriAKAa71-k_8Dop-6iLRxL38BNzOMqii4VNZVfIlFgV_Ow2hG1GtMwXjB7A4?width=660&amp;amp;height=497&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Configure Task Runner"&gt;
&lt;ol start="15"&gt;
&lt;li&gt;This command should create a new file called &lt;code&gt;tasks.json&lt;/code&gt; in a new &lt;code&gt;.vscode&lt;/code&gt; directory and will contain the following json.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
    // See https://go.microsoft.com/fwlink/?LinkId=733558
    // for the documentation about the tasks.json format
    "version": "0.1.0",
    "command": "echo",
    "isShellCommand": true,
    "args": ["Hello World"],
    "showOutput": "always"
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="16"&gt;
&lt;li&gt;If you're not familiar with configuring VSC task runners, I'd very much recommend clicking the link in this file to see what the task runner is able to do and how to configure it. However, for your convenience, I have provided my configuration below:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
    // See https://go.microsoft.com/fwlink/?LinkId=733558
    // for the documentation about the tasks.json format
    "version": "0.1.0",
    "command": "C:\\Apps\\dart-sdk\\bin\\pub.bat",
    "isShellCommand": true,
    "args": [],
    "showOutput": "always",
    "echoCommand": true,
    "tasks": [
        {
            "taskName": "build",
            "args": [],
            "isWatching": false
         },
        {
            "taskName": "serve",
            "args": [],
            "isWatching": true
         }
    ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="17"&gt;
&lt;li&gt;&lt;p&gt;As you will probably be able to determine, this file contains two tasks; one named &lt;code&gt;build&lt;/code&gt; and the other named &lt;code&gt;serve&lt;/code&gt;. The &lt;code&gt;build&lt;/code&gt; command compiles your code and checks for errors while the &lt;code&gt;serve&lt;/code&gt; command sets up a local web-server (by default bound to port 8080) capable of serving the content of the &lt;code&gt;web&lt;/code&gt; directory. Lets try both.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open the command palette (&lt;code&gt;Ctrl-Shift-P&lt;/code&gt;), delete the '&amp;gt;' prompt and then type &lt;code&gt;task&lt;/code&gt; followed by a space. You should see the two tasks defined above appear. Continue to &lt;code&gt;build&lt;/code&gt; and then hit return. At this point, the output pane should appear displaying the &lt;code&gt;Tasks&lt;/code&gt; output and your code should be compiled (and, transpiled into JS!). This is shown below:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt3eg-dm2306.files.1drv.com/y3ma_gmHNRQHH3HaNTz8ytRLamtMwlzmi0dRSYl1aqncp0Zy-RaUW_qLGOebg_PpgRdCoYLQYFcuRWZ3FC_Y6jJ0Qw6n5rWbGxvUMzi5_yqitbOf3DrJUVAkQi9Th0JvQmzLysrJGrnhrVe7Z2eYY6uUse_0o88veVTn8eYaIZsHnw?width=660&amp;amp;height=497&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Tasks and Build output"&gt;
&lt;ol start="19"&gt;
&lt;li&gt;&lt;p&gt;If everything is successful, you should see the message '&lt;code&gt;Built 2 files to "build"&lt;/code&gt;'. Now we can test our Dart code by serving it through &lt;code&gt;pub server&lt;/code&gt;. To do this, start the &lt;code&gt;task serve&lt;/code&gt; task in a similar manner to the &lt;code&gt;task build&lt;/code&gt; above. As this task is an &lt;code&gt;isWatching&lt;/code&gt; command, the task won't complete when run but will emit messages to the output pane when changes occur. This is shown below:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;With a local web-server serving out HTML file and Dart code, we can finally start to use Dartium to run the code. Note that, we're using Dartium because we'll be executing the Dart code directly (rather than the transpiled JavaScript) and Dartium has a built-in Dart runtime which allows for advanced debugging of our Dart code. Start Dartium but executing it from either command line or GUI (exists at &lt;code&gt;C:\Apps\chromium\chrome.exe&lt;/code&gt; for me) and, once started, navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; and you should see the following:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://nbtqeg-dm2306.files.1drv.com/y3m2wj9PACazah5vdBUyW8AOGu__v3AbjHyzU66QtsvCuHVA4Ya710e4bjVJv4GdNiXlige7q8waQcphwiH8FtLZG8eu-z7cOiBPi-vqx8KfgkYPvwVrtPIpJoCmdIDR8LmO8DIqkHSvNe6Kz5q65IoWi1DRivqqpX5YUET_9zEmS4?width=660&amp;amp;height=542&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Success!!"&gt;
&lt;p&gt;Congratulations, you've just run your first Dart code.&lt;/p&gt;
&lt;p&gt;If something went wrong and you don't see the header text change from 'Hmm... what should I say?' to 'Ah yes... Hello World!!!' then you can use Dartium's Developer Tools (&lt;code&gt;Ctrl-Shift-I&lt;/code&gt;) to view errors and add breakpoints so you can work out what has gone wrong. The developer tools are shown here:&lt;/p&gt;
&lt;img src="https://nbtpeg-dm2306.files.1drv.com/y3my4JbT3bsQcqBOB3NANuaB-FMf_vBHNlAc1qm5QaXuFVEWxIV1YuoIj7gu-QJZtFOgS_gHJBknLl8J_LY9shZ_YtYf8Jf0BL9T0r4NMf3dv5XXvZt0x_J0IqZ7lurmX5MJP7oyA9FMO8oMkm29BAxoQI2jV-s6dyO2APv8dvXRTM?width=660&amp;amp;height=542&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Dartium Developer Tools"&gt;
&lt;p&gt;You can find loads more information online about the &lt;a href="https://www.dartlang.org/"&gt;Dart Language&lt;/a&gt; and &lt;a href="https://webdev.dartlang.org/"&gt;Dart Web Development&lt;/a&gt;. Versions of Dart are changing rapidly (there was a minor update while writing this post!) and a thriving &lt;a href="https://www.dartlang.org/community"&gt;support community&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As a (mainly) C# developer I found Dart super easy to get up to speed with and the Visual Studio Code/Dartium combo to be extremely productive. Hopefully you will too.&lt;/p&gt;
&lt;p&gt;Have fun.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Visual Studio Code is rapidly becoming my go-to editor for anything not project-oriented C#/F#. I've switched from &lt;a href="https://atom.io/"&gt;Atom&lt;/a&gt; to &lt;a href="(https://code.visualstudio.com/)"&gt;VSC&lt;/a&gt; for editing my (&lt;a href="http://ian.bebbs.co.uk/posts/NewBlogUsingWyam"&gt;statically-generated, Markdown driven&lt;/a&gt;) blog and have used it for authoring powershell scripts, dockerfiles and much, much more. So, when I decided I wanted to write some &lt;a href="https://www.dartlang.org/"&gt;Dart&lt;/a&gt; code, it was the obvious choice.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/Nano2Docker" />
		<id>http://ian.bebbs.co.uk/posts/Nano2Docker</id>
		<title>Nano2Docker</title>
		<updated>2017-07-10T00:00:00Z</updated>
		<content>
                                        


&lt;h1&gt;Deployment at last&lt;/h1&gt;
&lt;p&gt;While my current contract doesn't leave much time for personal projects, I have made some progress on my current project (details on exactly what this is to follow). In fact, some of the smaller, peripheral services have their primary use-cases functionally complete and are ready for deployment and I am now faced with the question: Deployment to where?&lt;/p&gt;
&lt;h1&gt;Fabric or Container&lt;/h1&gt;
&lt;p&gt;Given this project constitutes multiple micro-services using message based, asynchronous communication with the potential to scale services horizontally, I required some form of elastic service fabric. Furthermore, I wanted a local development environment which would simulate a cluster of machines but with which I could monkey about as much as I liked without fear of accidentally incurring massive hosting fees in the cloud.&lt;/p&gt;
&lt;p&gt;As I had just upgraded my home server with plenty of memory, I decided to use one of more virtual machines running on this server to host the environment during development, but which technology to use?&lt;/p&gt;
&lt;p&gt;Initially I had intended to use a &lt;a href="https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-get-started-with-a-local-cluster"&gt;local Service Fabric cluster&lt;/a&gt;. However, upon further investigation I found that the SDK and API introduced significant friction to the development process (needing additional projects for supplying manifest / configuration data for services, overly complex deployment scripts, etc). Even the 'guest executable' approach seemed overly complex and I quickly went off this approach.&lt;/p&gt;
&lt;p&gt;My second thought was &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;; specifically the creation of a local &lt;a href="https://docs.docker.com/engine/swarm/"&gt;Docker Swarm&lt;/a&gt; which I could deploy servies to with &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;. &lt;a href="https://docs.docker.com/machine/"&gt;Docker Machine&lt;/a&gt; made short work of provisioning Docker hosts in Hyper-V but with one caveat: it's &lt;a href="http://boot2docker.io/"&gt;boot2docker&lt;/a&gt; image would only run Linux based containers and, while many of the services I have written / will write run quite happily on .NET Core, some require packages that do not yet provide support for .NET Core / Standard.&lt;/p&gt;
&lt;p&gt;Given that a recent update made &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;Swarm mode available to Windows Server 2016&lt;/a&gt; host operating systems, I decided I would look into provisioning a series of Windows Server VM's with container support and configure Docker on these VM's to operate in swarm mode.&lt;/p&gt;
&lt;h1&gt;Using Nano Server as a Docker host&lt;/h1&gt;
&lt;p&gt;While I had previously used Microsoft Nano Server as a &lt;a href="http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII"&gt;guest OS&lt;/a&gt; for &lt;a href="http://ian.bebbs.co.uk/posts/DockerAndKafka"&gt;containerized apps&lt;/a&gt;, I hadn't realised that it was possible to use it as a host OS for Docker until I came across &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/deploy-containers-on-nano"&gt;this article&lt;/a&gt;. For those not familiar with Nano Server it is an extremely slimmed down (the OS image is less than 170Mb) and fast booting (5-10 seconds), headless version of Windows Server 2016 which, given it is capable of acting as a Docker host, effectively makes it 'boot2docker' but for Windows containers.&lt;/p&gt;
&lt;p&gt;Nano Server is shipped with Windows Server 2016 and is accompanied by a Powershell module which provides some terrific facilities for working with Nano Server images. &lt;a href="https://docs.microsoft.com/en-us/windows-server/get-started/deploy-nano-server"&gt;This document&lt;/a&gt; shows how to use this Powershell module to create customised Nano Server images as either &lt;a href="https://en.wikipedia.org/wiki/Windows_Imaging_Format"&gt;'.wim'&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ISO_image"&gt;'.iso'&lt;/a&gt; or - most interestingly for me -  &lt;a href="https://technet.microsoft.com/en-us/library/hh831446(v=ws.11).aspx"&gt;'.vhdx'&lt;/a&gt;. In short, the following powershell command will create a virtual HD that can be attached to a virtual machine and which will boot directly into Nano Server with support for - but no utilites to provide - containerization services:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;New-NanoServerImage -Edition Standard -DeploymentType Guest -MediaPath &amp;lt;path to root of media&amp;gt; -BasePath &amp;lt;path in which to build the image&amp;gt; -TargetPath &amp;lt;destination path&amp;gt;\NanoServer.vhdx -ComputerName &amp;lt;computer name&amp;gt; -Containers -EnableRemoteManagementPort
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will also open &lt;a href="https://msdn.microsoft.com/en-us/library/aa384426(v=vs.85).aspx"&gt;WinRM&lt;/a&gt; ports on the Nano Server which allows you to use &lt;a href="https://technet.microsoft.com/en-us/library/ff700227.aspx"&gt;PS Remoting&lt;/a&gt; to remote into the virtual machine and examine it's state; indispensable for debugging purposes.&lt;/p&gt;
&lt;h1&gt;Updating Nano Server&lt;/h1&gt;
&lt;p&gt;Referring back to the &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;'Getting Started with Swarm Mode'&lt;/a&gt; article, it states that a &lt;a href="https://support.microsoft.com/en-us/help/4015217/windows-10-update-kb4015217"&gt;relatively recent update&lt;/a&gt; is required to run Docker Swarms on Windows Server 2016 based OS's. It is therefore necessary to ensure this update is applied to any NanoServer image we create for the purpose of running Docker, ideally during the creation of the image not a subsequent setup script.&lt;/p&gt;
&lt;p&gt;Well, those clever people at Microsoft thought of this too and provided a &lt;code&gt;-ServicingPackagePath&lt;/code&gt; argument for the &lt;code&gt;New-NanoServerImage&lt;/code&gt; command which takes a path to a cab update file and applies the update to the NanoServer OS during image creation. A mechanism for getting an update from Microsoft (as an *.msu) and extracting it into a (series of) cab-files for use in the &lt;code&gt;New-NanoServerImage&lt;/code&gt; is provided by Thomas Maurer in &lt;a href="http://www.thomasmaurer.ch/2016/10/how-to-install-updates-on-nano-server/"&gt;an excellent blog post here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Installing Docker as part of a Nano Server image&lt;/h1&gt;
&lt;p&gt;Now, just like 'boot2docker' we want our Nano Server to be ready to host Windows Containers as soon as it's booted and without further manual configuration. To this end, I needed to find a way to install Docker as part of the deployment process. Fortunately the 'New-NanoServer' command provides a &lt;code&gt;-SetupCompleteCommand&lt;/code&gt; argument which allows you to 'run custom commands as part of setupcomplete.cmd' (i.e. on first boot). Great, so now to prepare a script to deploy Docker which we can call via the &lt;code&gt;-SetupCompleteCommand&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;Conveniently, Docker's &lt;a href="https://docs.docker.com/docker-ee-for-windows/install/#using-a-script-to-install-docker-ee"&gt;documentation for installing Docker EE&lt;/a&gt; (the version supported by Windows) provides exactly the script required, copied below with some additional configuration copied from the 'Prepare Container Host' section of &lt;a href=""&gt;'Deploy Containers on Nano'&lt;/a&gt; article:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;# On an online machine, download the zip file
Invoke-Webrequest -UseBasicparsing -Outfile docker.zip https://download.docker.com/components/engine/windows-server/17.03/docker-17.03.0-ee.zip

# Extract the archive.
Expand-Archive docker.zip -DestinationPath $Env:ProgramFiles

# Clean up the zip file.
Remove-Item -Force docker.zip

# Install Docker. This will require rebooting.
# This is not required as we have already prepared out image with container support
# $null = Install-WindowsFeature containers

# Add Docker to the path for the current session.
$env:path += ";$env:ProgramFiles\docker"

# Modify PATH to persist across sessions.
# Note: Nano Server's SetEnvironmentVariable method does not take a scope parameter 
[Environment]::SetEnvironmentVariable("PATH", $env:path)

# Open an inbound port for the docker daemon  
netsh advfirewall firewall add rule name="Docker daemon " dir=in action=allow protocol=TCP localport=2375

# Create and populate docker daemon's configuration file
New-Item -Type File 'C:\ProgramData\docker\config\daemon.json' -Force
Add-Content 'C:\programdata\docker\config\daemon.json' '{ "hosts": ["tcp://0.0.0.0:2375", "npipe://"] }'

# Register the Docker daemon as a service.
dockerd --register-service

# Start the daemon.
Start-Service docker
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this script requires that the Nano Server be online when the script is run so that it can download the Docker binaries. Unfortunately, given that this script will run as part of the deployment process, this is unlikely to be the case. Instead, we'll need to lean on another feature of the &lt;code&gt;New-NanoServerImage&lt;/code&gt;, &lt;code&gt;-CopyPath&lt;/code&gt;. This argument allows you to specify one or more files to copy to the Nano Server image as part of it's creation and we'll use it to copy a pre-downloaded copy of the docker binaries (along with a copy of the deployment script) to the root of the images C:\ drive, as shown here:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;New-NanoServerImage -Edition Standard -DeploymentType Guest -MediaPath &amp;lt;path to root of media&amp;gt; -BasePath &amp;lt;path in which to build the image&amp;gt; -TargetPath &amp;lt;destination path&amp;gt;\NanoServer.vhdx -ComputerName &amp;lt;computer name&amp;gt; -Containers -EnableRemoteManagementPort -CopyPath @('&amp;lt;path to deployment script&amp;gt;\DeployDocker.ps1', '&amp;lt;path in which docker is downloaded&amp;gt;\docker.zip') -SetupCompleteCommand @('Powershell.exe -Command .\DeployDocker.ps1') 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, now we can comment out the first line of the script above and it'll run fine, right? Unfortunately not. It seems that, at the stage of the boot process at which this script runs, powershell isn't quite ready to run powershell. Fortunately, others have encountered this issue before and Sergey Babkin provides &lt;a href="https://blogs.msdn.microsoft.com/sergey_babkins_blog/2017/01/05/how-to-run-powershell-from-setupcomplete-cmd/"&gt;this solution&lt;/a&gt;; copied below with customisation for our requirements:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;set LOCALAPPDATA=%USERPROFILE%\AppData\Local
set PSExecutionPolicyPreference=Unrestricted
Powershell -Command C:\DeployDocker.ps1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so we'll add and deploy this batch file as 'DeployDocker.bat' and then execute this instead of the powershell script as the &lt;code&gt;-SetupCompleteCommand&lt;/code&gt;, as shown here:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;New-NanoServerImage -Edition Standard -DeploymentType Guest -MediaPath &amp;lt;path to root of media&amp;gt; -BasePath &amp;lt;path in which to build the image&amp;gt; -TargetPath &amp;lt;destination path&amp;gt;\NanoServer.vhdx -ComputerName &amp;lt;computer name&amp;gt; -Containers -EnableRemoteManagementPort -CopyPath @('&amp;lt;path to deployment batch file'\DeployDocker.bat', '&amp;lt;path to deployment script&amp;gt;\DeployDocker.ps1', '&amp;lt;path in which docker is downloaded&amp;gt;\docker.zip') -SetupCompleteCommand 'C:\DeployDocker.bat' 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And thats it. If you now create a virtual machine with the new 'NanoServer.vhdx' image as it's boot drive, you should find that, once it's booted you're able to communicate with the Docker daemon on the VM. For example:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;docker -H &amp;lt;IP Address of VM&amp;gt; ps
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Should return a (empty) list of containers present on the Nano Server host.&lt;/p&gt;
&lt;h1&gt;Scripting the creation of a VM&lt;/h1&gt;
&lt;p&gt;Now, jumping through all the hoops above each time we want to make a new VM to host docker would be arduous to say the least. As such, I put together a powershell module which is able to directly create VM's ready to host Docker containers in just a few steps. From a powershell command prompr, this can be done as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Get the Nano2Docker powershell module&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This module is available in my Docker repository on Github and can be downloaded directly using the following command:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;Invoke-WebRequest -OutFile Nano2Docker.psm1 https://raw.githubusercontent.com/ibebbs/Docker/master/Nano2Docker/Nano2Docker.psm1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then installed using:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;Import-Module Nano2Docker.psm1
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Prepare a base NanoServer image&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The process of downloading docker and applying updates can be extremely slow. Therefore we first create a reusable base NanoServer image that has docker installed and updates applied. This is done using the command:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;Initialize-Nano2DockerImage -MediaPath &amp;lt;Drive letter for Windows Server 2016&amp;gt; -BuildPath &amp;lt;Path to a build location&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, if your Windows Server 2016 media is mounted in the 'G' drive and you want to build the new Nano2Docker image in the 'C:\Nano2Docker' folder, you'd use the command:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;Initialize-Nano2DockerImage -MediaPath G: -BuildPath "C:\Nano2Docker"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The command provides defaults download locations for docker and required updates but these can be overriden using the &lt;code&gt;-DockerUrl&lt;/code&gt; and &lt;code&gt;-UpdateUrl&lt;/code&gt; parameters repsectively. Furthermore, if you already have an '.msu' file downloaded you can save a lot of time by providing this to the command using the &lt;code&gt;-UpdateFile&lt;/code&gt; parameter.&lt;/p&gt;
&lt;p&gt;When you run this command, you will be prompted for Administrator credentials for the new Nano2Docker image. Either enter them when prompted or supply a &lt;code&gt;SecureString&lt;/code&gt; value to the &lt;code&gt;-Password&lt;/code&gt; argument (which is usually done using the &lt;code&gt;Get-Credentials&lt;/code&gt; commandlet).&lt;/p&gt;
&lt;p&gt;When this command completes - which can take a while - you will find a 'Nano2Docker.vhdx' file in the BuildPath directory.&lt;/p&gt;
&lt;p&gt;3. Create a VM using the new NanoServer image&lt;/p&gt;
&lt;p&gt;You can now use the &lt;code&gt;New-Nano2Docker&lt;/code&gt; commandlet to quickly create new VM docker hosts. The command is used as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;New-Nano2Docker -MediaPath &amp;lt;Drive letter for Windows Server 2016&amp;gt; -ImagePath &amp;lt;Path to a previously created Nano2Docker.vhdx&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using our previous example, the command would be:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;New-Nano2Docker -MediaPath G: -ImagePath "C:\Nano2Docker\Nano2Docker.vhdx"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will copy the base image to the VM path (defaults to 'C:\Users\Public\Documents\Hyper-V\Virtual Hard Disks'), provision a new, local, Hyper-V VM named 'Nano2Docker' with reasonable resources (4 cores / 2Gb of dynamic ram) and attached to the first available virtual switch.
Obviously, each of these characteristics can be changed using the appropriate arguments - use &lt;code&gt;Get-Help New-Nano2Docker&lt;/code&gt; to list the available arguments. You will again be asked to an Administrator password for the new VM which can be entered during creation or specified as a parameter to the commandlet.&lt;/p&gt;
&lt;p&gt;Once the new VM has been created, it will be started and the script will wait for NanoServer to start correctly. Once started, the IP address of the new VM is displayed and it should be immediately possible to use docker to communicate with the docker daemon on the VM.&lt;/p&gt;
&lt;h1&gt;Scripting the deployment of a Docker Swarm&lt;/h1&gt;
&lt;p&gt;Given it was now trivial to create docker hosts, I wrote a final commandlet which leverages previous commandlets to provision an entire docker swarm. This is done using the &lt;code&gt;New-Nano2DockerSwarm&lt;/code&gt; commandlet as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;New-Nano2DockerSwarm -MediaPath &amp;lt;Drive letter for Windows Server 2016&amp;gt; -ImagePath &amp;lt;Path to a previously created Nano2Docker.vhdx&amp;gt; -VMPath &amp;lt;Path to a location to store swarm host VMs&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, using our previous example and wanting to store new VM images in the 'C:\Nano2Docker\VMs' directory, the command would be:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;New-Nano2DockerSwarm -MediaPath G: -ImagePath "C:\Nano2Docker\Nano2Docker.vhdx" -VMPath "C:\Nano2Docker\VMs"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command defaults to creating a single manager node and three worker nodes named 'n2d-mngr-0' and 'n2d-wrkr-0/1/2' respectively. All nodes will have already been joined to the swarm in the appropriate capacity and ready for services to be deployed using docker or docker-compose.
Again, the number of manager and worked nodes as well as the name prefix for each node can be changed via the appropriate arguments (use &lt;code&gt;Get-Help New-Nano2DockerSwarm&lt;/code&gt; to list the arguments).&lt;/p&gt;
&lt;h1&gt;Roundup&lt;/h1&gt;
&lt;p&gt;I've successfully used this script to provision multiple docker hosts and docker swarms but it's worthwhile noting that it can be a bit finickity with directories. If you can an error saying it couldn't find a directory then simply create it first. I really ought to fix up the script (improvements via PR gratefully accepted) but I'm now a bit busy deploying services to my swarm :0)&lt;/p&gt;
&lt;p&gt;Furthermore I've successfully used nodes created by this script to provision a hybrid swarm (see the 'Mixed OS clusters section &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;here&lt;/a&gt;) of boot2docker and nano2docker images. With the appropriate labels on the nodes, it is possible to use &lt;code&gt;docker-compose&lt;/code&gt; to automatically deploy images to the correct hosts while retaining all the benefits of overlay networking.&lt;/p&gt;
&lt;p&gt;It's a lot of docking fun!&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;While my current contract doesn't leave much time for personal projects, I have made some progress on my current project (details on exactly what this is to follow). In fact, some of the smaller, peripheral services have their primary use-cases functionally complete and are ready for deployment and I am now faced with the question: Deployment to where?&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/UsingSVGInUWP" />
		<id>http://ian.bebbs.co.uk/posts/UsingSVGInUWP</id>
		<title>The absolute easiest way to use SVG icons in UWP apps</title>
		<updated>2016-09-01T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;There are &lt;a href="http://stackoverflow.com/a/3528493/628821"&gt;many&lt;/a&gt; (&lt;a href="http://stackoverflow.com/a/22107360/628821"&gt;many&lt;/a&gt;, &lt;a href="http://blogs.u2u.be/diederik/post/2012/07/26/Transforming-SVG-graphics-to-XAML-Metro-Icons.aspx"&gt;many&lt;/a&gt;) ways to use SVG assets as icons in UWP / XAML apps, most requiring some form of DataTemplate or UserControl. While these approaches work &lt;em&gt;ok&lt;/em&gt; they're normally a pain to author and use, often requiring custom converters to be written if the asset is to be used via any form of data binding. Here I present an extremely flexible way of using these assets that requires nothing more than drag-and-drop.&lt;/p&gt;
&lt;p&gt;This approach uses &lt;a href="https://glyphter.com/"&gt;Glyphter&lt;/a&gt; - a free, online tool for converting SVG icons to fonts - to produce a custom font containing your SVG assets; similar to fonts like &lt;a href="http://modernicons.io/segoe-mdl2/cheatsheet/"&gt;Segoe MDL2&lt;/a&gt; and &lt;a href="http://fontawesome.io/"&gt;FontAwesome&lt;/a&gt;. Glypter's free tier allows you to craft a single font, containing just basic alpha-numerics. Should you need more than this, you can upgrade to a premium tier which allows you to work on multiple fonts of a much greater size.&lt;/p&gt;
&lt;p&gt;Once you've built your font, it can be embedded in the app package and icons displayed by simply using a TextBlock element with the Text property set to the alpha-numeric code of the icon to display and the FontFamily set to the custom font. Furthermore, you're easily able to present the required icons in the desired colour - by changing the TextBlock's Foreground brush - and size - by changing FontSize or embedding within the TextBlock within a ViewBox.&lt;/p&gt;
&lt;p&gt;To get started, simply locating the SVG asset you'd like to use. &lt;a href="https://thenounproject.com/"&gt;The Noun Project&lt;/a&gt; is a good resource containing an incredible number of high quality icons that can be used in commercial products for a small fee or via attribution. Once you've found the icon you want to use - lets use &lt;a href="https://thenounproject.com/localdomain/collection/memes/?oq=meme&amp;amp;cidx=0&amp;amp;i=105269"&gt;this one&lt;/a&gt; by &lt;a href="https://thenounproject.com/localdomain/"&gt;Gareth&lt;/a&gt; - simply download the icon as an SVG. Once it's downloaded, locate the file and drag it onto the Glypter grid in the desired location. After a short pause while the file is uploaded to Glypter and processed, it'll appear in the grid slot you selected; here I've added the icon to the 'A':&lt;/p&gt;
&lt;img src="/Content/UsingSVGInUWP/DraggedIntoGlyphter.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Glyphter custom font"&gt;
&lt;p&gt;Repeat this for all the icons you want to use - I'll just stick with the one icon for now - then download the font by clicking the font download button (the 'down arrow' in the 'FONT' button). This will compile all your assets into a zip file containing the font (in &lt;a href="https://en.wikipedia.org/wiki/TrueType"&gt;'.ttf'&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Web_Open_Font_Format"&gt;'.woff'&lt;/a&gt; formats), svg and css assets. We're only interested in the '.ttf' file so extract it from the zip file and copy it to the 'Assets' folder of your UWP app.&lt;/p&gt;
&lt;p&gt;From within VisualStudio - or better yet, Blend - add the '.ttf' file to the project, ensuring it's 'Build Action' is set to 'Content' and 'Copy to Output Directory' set to 'Do not copy' as shown below:&lt;/p&gt;
&lt;img src="/Content/UsingSVGInUWP/BlendWithGlyphterFont.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Custom font added to project in Blend"&gt;
&lt;p&gt;With this in place, when you drop a TextBlock on a page, you should be able to select your embedded font from the Font combobox as shown below:&lt;/p&gt;
&lt;img src="/Content/UsingSVGInUWP/SelectFont.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Custom font selection in Blend"&gt;
&lt;p&gt;The rest, as they say, is history. In a few minutes you too can use the following XAML:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;&amp;lt;Grid&amp;gt;
    &amp;lt;StackPanel HorizontalAlignment="Center" VerticalAlignment="Center"&amp;gt;
        &amp;lt;TextBlock Text="SVG in UWP EZ!" HorizontalAlignment="Center" FontFamily="Impact" Margin="10"/&amp;gt;
        &amp;lt;TextBlock Text="A" FontFamily="ms-appx:/Assets/Glyphter.ttf#Glyphter" FontSize="96" HorizontalAlignment="Center"/&amp;gt;
        &amp;lt;TextBlock Text="Y U NO USE!" HorizontalAlignment="Center" FontFamily="Impact"/&amp;gt;
    &amp;lt;/StackPanel&amp;gt;
&amp;lt;/Grid&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: There seems to be an issue/inconsistency with the FontFamily value created when using the XAML designer to select your custom font. Sometimes, but not always, the designer will fail to add the "ms-appx" protocol to the FontFamily property value which, while it has no effect at design time, will prevent the app from locating the custom font at runtime. You should there ensure this value is present before deploying your app.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To create this amazing UI:&lt;/p&gt;
&lt;img src="/Content/UsingSVGInUWP/SVGInUWPEZ.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="SVG in UWP EZ! Y U NO USE!"&gt;
&lt;p&gt;Enjoy.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;There are &lt;a href="http://stackoverflow.com/a/3528493/628821"&gt;many&lt;/a&gt; (&lt;a href="http://stackoverflow.com/a/22107360/628821"&gt;many&lt;/a&gt;, &lt;a href="http://blogs.u2u.be/diederik/post/2012/07/26/Transforming-SVG-graphics-to-XAML-Metro-Icons.aspx"&gt;many&lt;/a&gt;) ways to use SVG assets as icons in UWP / XAML apps, most requiring some form of DataTemplate or UserControl. While these approaches work &lt;em&gt;ok&lt;/em&gt; they're normally a pain to author and use, often requiring custom converters to be written if the asset is to be used via any form of data binding. Here I present an extremely flexible way of using these assets that requires nothing more than drag-and-drop.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/DockerAndKafka" />
		<id>http://ian.bebbs.co.uk/posts/DockerAndKafka</id>
		<title>Getting started with Docker and Apache Kafka</title>
		<updated>2017-01-04T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;For my first blog post of the new year (Happy New Year everyone!!!), I'd like to share some of my recent adventures with Docker on Windows, or, more specifically, Docker on Windows using Nanoserver as the container OS.&lt;/p&gt;
&lt;p&gt;I've been meaning to get up to speed with Docker for a while and, having &lt;a href="http://ian.bebbs.co.uk/posts/ARipStoringTime"&gt;recently acquired a decent new server for the purpose&lt;/a&gt;, decided that a festive period break from some of my &lt;a href="http://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl"&gt;longer term projects&lt;/a&gt;, would be an ideal time to finally dive in. In typical Bebbs style, "diving in" invariably involves the "deep end" and, as such, it seemed that a great initiation into the containerization waters would be to take &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; - a service typically run on Linux - and deploy it within a Windows &lt;a href="https://blogs.technet.microsoft.com/windowsserver/2015/04/08/microsoft-announces-nano-server-for-modern-apps-and-cloud/"&gt;Nanoserver&lt;/a&gt; container - a recent release from Microsoft and still a very-much bleeding-edge OS.&lt;/p&gt;
&lt;p&gt;I've been interested in Apache Kafka for quite a while. Described as a "distributed streaming platform" it very much resonates with my "everything is a stream" philosophy. Furthermore, some of &lt;a href="https://www.confluent.io/product/connectors/"&gt;it's connectors&lt;/a&gt; to various traditional RDBMS's offer an intriguing means of moving between 'state store' and 'event store' methodologies.&lt;/p&gt;
&lt;h2&gt;Getting started&lt;/h2&gt;
&lt;p&gt;For the host system, I started with a fresh install of Windows Server 2016 (Desktop Experience for convenience) on a &lt;a href="http://www.dell.com/uk/business/p/poweredge-t20/pd"&gt;Dell T20 Xeon&lt;/a&gt;. Following &lt;a href="https://msdn.microsoft.com/en-gb/virtualization/windowscontainers/quick_start/quick_start_windows_server"&gt;this quick start guide&lt;/a&gt; quickly led to an issue whereby the Docker package couldn't be verified by it's SHA256 hash and therefore refused to install. Fortunately I found a report of the issue and a work around &lt;a href="https://github.com/OneGet/MicrosoftDockerProvider/issues/15"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I have since reinstalled docker on Windows Server 2016 and did not experience the issue again so it must have been resolved.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With Docker installed and the &lt;a href="https://hub.docker.com/r/microsoft/dotnet-samples/"&gt;dotnet-samples&lt;/a&gt; example container running, my attention turned to Nanoserver.&lt;/p&gt;
&lt;p&gt;A quick pull and run of the &lt;a href="https://hub.docker.com/r/microsoft/nanoserver/"&gt;Nanoserver image&lt;/a&gt; and I found myself at an interactive command prompt of a deployed container running Nanoserver. This can be done as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;docker pull microsoft/nanoserver:latest
docker run -it --rm microsoft/nanoserver:latest cmd
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Kafka &amp;amp; Zookeeper&lt;/h2&gt;
&lt;p&gt;While looking for a pre-built image of Kafka running on Nanoserver, it quickly became apparent that in order to get an instance of &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; running, you first need a running instance of &lt;a href="https://zookeeper.apache.org/"&gt;Apache Zookeeper&lt;/a&gt;. While you could technically run both services from within a single container (indeed, Kafka is pre-configured to look for a Zookeeper instance on localhost) I wanted to utilize the core value propositions of containers vs VM instances; namely minimal overhead and composability.&lt;/p&gt;
&lt;p&gt;This meant that I would therefore be building two container images, one for Zookeeper and one for Kafka, both of which would be running on Nanoserver.&lt;/p&gt;
&lt;h2&gt;Building the Zookeeper image&lt;/h2&gt;
&lt;h3&gt;Take 1&lt;/h3&gt;
&lt;img src="https://mbt4mw-dm2306.files.1drv.com/y3m4bDPZgQ871xh0PU_QAcxaL1v9QKVFYFi8Q2uAb82woT97il9OZ_njULBYVK8aNohSJIgAAawJaj-tNunCWe4oXs5LpggjuVv41JGAQ2TFPco7IB1Xx57j6y2X0TUAtNfOQvoJWLxFFHjL5eSgzVeooe_OjURV4VJ8q_QDhN7coA?width=660&amp;amp;height=363&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="I built this container up from nothing. When I started here, all there was was nanoserver. Other developers said it was daft to build Zookeeper on nanoserver, but I did it all the same. Just to show'em."&gt;
&lt;blockquote&gt;
&lt;p&gt;I built this [container] up from nothing. When I started here, all there was was [nanoserver]. Other [developers] said it was daft to build [Zookeeper] on [nanoserver], but I did it all the same. Just to show'em.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, from most of everything I have read about building docker images, it seemed the thing to do was use a &lt;a href="https://docs.docker.com/engine/reference/builder/"&gt;Dockerfile&lt;/a&gt; to start an intermediate container based on the source image (Microsoft/Nanoserver in this instance) then run a script within the intermediate container (as part of the dockerfile) to download, install and configure all the required components. The output of this docker build process would be a new image with the appropriate services running on startup.&lt;/p&gt;
&lt;p&gt;I therefore started by preparing a powershell script that would do just that. Following &lt;a href="http://stackoverflow.com/a/38895811"&gt;this post on StackOverflow&lt;/a&gt; I developed and tested a script on a Windows Server 2016 (Desktop Experience) Virtual Machine. This was done so that I could use &lt;a href="https://technet.microsoft.com/en-us/library/dn818483(v=ws.11).aspx"&gt;snapshotting&lt;/a&gt; in order to roll-back to a clean image anytime a issue with the script was encountered.&lt;/p&gt;
&lt;p&gt;Unfortunately, when it came time to try running Zookeeper I hit the following error at start-up:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;log4j:WARN No appenders could be found for logger (org.apache.zookeeper.server.quorum.QuorumPeerConfig).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
Invalid config, exiting abnormally
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some quick googling turned up &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c5"&gt;this issue&lt;/a&gt; but every subsequent comment seemed to suggest that the issue had been resolved. I tried a &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c8"&gt;frustrating&lt;/a&gt; &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c9"&gt;number&lt;/a&gt; of &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c4"&gt;unsuccessful&lt;/a&gt; &lt;a href="http://tech.donghao.org/tag/zookeeper/"&gt;workarounds&lt;/a&gt; until I realized that it was a &lt;a href="https://en.wiktionary.org/wiki/PICNIC"&gt;PICNIC error&lt;/a&gt;. Specifically, while following the StackOverflow post above, I had failed to realize that the version of Zookeeper they specified wasn't actually the latest version and that the issue really had been resolved in a later version. This took a frustratingly and embarrassingly long time but hey, &lt;a href="http://www.goodreads.com/quotes/7678-when-people-say-it-s-always-the-last-place-you-look"&gt;it's always the last place you look&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, a morning of trial and error resulted in a thing of beauty; a script that would - completely automatically - download, extract, configure, install (as a service!) and run a Zookeeper instance. This is shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;## Download sources
$zipUri = "http://homeserver/download/7z1604-x64.exe" # http://www.7-zip.org/a/7z1604-x64.exe";
$nssmUri = "http://homeserver/download/nssm-2.24.zip" # "https://nssm.cc/release/nssm-2.24.zip"
$javaUri = "http://homeserver/download/jre-8u111-windows-x64.exe" # "http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jre-8u111-windows-x64.exe"
$zookeeperUri = "http://homeserver/download/zookeeper-3.4.9.tar.gz" # "http://apache.mirrors.nublue.co.uk/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz"
$kafkaUri = "http://homeserver/download/kafka_2.11-0.10.1.0.tgz" # "http://apache.mirror.anlx.net/kafka/0.10.1.0/kafka_2.11-0.10.1.0.tgz"

## Application locations
$appDir = "c:\Apps"
$zipDir = $appDir + "\7zip"
$nssmDir = $appDir + "\nssm"
$zookeeperDir = $appDir + "\Zookeeper"

## Data locations
$zookeeperDataDir = $zookeeperDir + "\Data"

## Application executables
$zip = $zipDir + "\7z.exe"
$nssm = $nssmDir + "\nssm.exe"
$zookeeper = $zookeeperDir + "\bin\zkServer.cmd"

function New-TempPath()
{
    if (!(Test-Path -Path C:\Temp))
    {
        New-Item c:\Temp -ItemType Directory
    }
}

function Expand-File($zipFile, $targetPath)
{
    $args = @("e", $zipFile, "-o$targetPath", '-y')
    &amp;amp;$zip $args
}

function Expand-Directory($zipFile, $targetPath)
{
    $args = @("x", $zipFile, "-o$targetPath", '-aoa')
    &amp;amp;$zip $args
}

function Install-7zip()
{
    New-Item "c:\Temp\7zip" -ItemType Directory -Force
    Invoke-WebRequest -Uri $zipUri -OutFile c:\Temp\7zip\7zip.exe
    &amp;amp;"C:\Temp\7zip\7zip.exe" /S /D=$zipDir | Out-Null
    Remove-Item -Path "c:\Temp\7zip\7zip.exe"
}

function Install-NSSM()
{
    New-Item "c:\Temp\NSSM" -ItemType Directory -Force
    Invoke-WebRequest -Uri $nssmUri -OutFile c:\Temp\NSSM\NSSM.zip

    Expand-Directory c:\Temp\NSSM\NSSM.zip c:\Temp\NSSM

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path c:\Temp\NSSM -Filter "nssm-*"
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination c:\Temp\NSSM -Force

    New-Item $nssmDir -ItemType Directory -Force
    Copy-Item -Path "c:\Temp\NSSM\win64\nssm.exe" $nssm -Force
}

function Install-Java()
{
    New-Item c:\Temp\Java -ItemType Directory -Force
    Invoke-WebRequest -Uri $javaUri -OutFile c:\temp\Java\Java.exe

    Start-Process "C:\Temp\Java\Java.exe" -ArgumentList "INSTALL_SILENT=Enable INSTALLDIR=C:\Java\Jre AUTO_UPDATE=Disable WEB_JAVA=Disable WEB_ANALYTICS=Disable EULA=Disable REBOOT=Disable NOSTARTMENU=Enable SPONSORS=Disable REMOVEOUTOFDATEJRES=0" -NoNewWindow -Wait

    [Environment]::SetEnvironmentVariable("JAVA_HOME", "C:\Java\Jre", "Machine")

    Remove-Item -Path "C:\Temp\Java\Java.exe"
}

function Get-Zookeeper()
{
    New-Item c:\Temp\Zookeeper -ItemType Directory -Force
    Invoke-WebRequest -Uri $zookeeperUri -OutFile c:\temp\Zookeeper\Zookeeper.tar.gz
    Expand-File c:\temp\Zookeeper\Zookeeper.tar.gz c:\temp\Zookeeper
    Expand-Directory c:\temp\Zookeeper\Zookeeper.tar $zookeeperDir

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path $zookeeperDir -Filter "zookeeper-*"
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination $zookeeperDir -Force

    Remove-Item -Path $folder.FullName
    Remove-Item -Path "c:\temp\Zookeeper" -Recurse
}

function Initialize-Zookeeper()
{
    New-Item -Path $zookeeperDataDir -ItemType Directory -Force
    $zookeeperDataLinuxDir = $zookeeperDataDir.Replace('\', '/')

    Copy-Item -Path ($zookeeperDir + '\conf\zoo_sample.cfg') -Destination ($zookeeperDir + '\conf\zoo.cfg') -Force

    $configFile = $zookeeperDir + '\conf\zoo.cfg'
    $logFile = $zookeeperDir + '\conf\log4j.properties'

    $config = [IO.File]::ReadAllText($configFile) -replace "dataDir=[\/\w]*", ("dataDir=" + $zookeeperDataLinuxDir)
    [IO.File]::WriteAllText($configFile, $config)

    $logProperties = [IO.File]::ReadAllText($logFile) -replace "#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE", "log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE"
    [IO.File]::WriteAllText($logFile, $logProperties)
}

function Install-Zookeeper()
{
    &amp;amp;$nssm install Zookeeper $zookeeper | Out-Null
    &amp;amp;$nssm set Zookeeper AppDirectory $zookeeperDir | Out-Null

    &amp;amp;$nssm set Zookeeper DisplayName "Zookeeper" | Out-Null
    &amp;amp;$nssm set Zookeeper Description "Apache Zookeeper. Running from $zookeeperDir" | Out-Null
    &amp;amp;$nssm set Zookeeper Start SERVICE_AUTO_START | Out-Null
    &amp;amp;$nssm set Zookeeper ObjectName LocalSystem | Out-Null
    &amp;amp;$nssm set Zookeeper Type SERVICE_WIN32_OWN_PROCESS | Out-Null
}

function Start-Zookeeper()
{
    &amp;amp;$nssm start Zookeeper | Out-Null
}

function Stop-Zookeeper()
{
    &amp;amp;$nssm stop Zookeeper | Out-Null
}

New-TempPath

Install-7zip
Install-NSSM
Install-Java

Get-Zookeeper
Initialize-Zookeeper
Install-Zookeeper
Start-Zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this mighty script in hand I prepared the following dockerfile:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;FROM microsoft/nanoserver
MAINTAINER Ian Bebbington &amp;lt;docker@bebbs.co.uk&amp;gt;
LABEL Description="Zookeeper running on Microsoft Nanoserver" Version="0.1"
ADD Install-Zookeeper.ps1 /
RUN [ "powershell.exe", "C:/Install-Zookeeper.ps1" ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And watched in dismay as it completely failed to build a container.&lt;/p&gt;
&lt;p&gt;You see, while the script ran perfectly on Windows Server 2016, Nanoserver is a far more constrained environment. It has neither support for 32-bit assemblies nor any graphic stack to speak of so, in short-order, the 7zip utility, Java installer and &lt;a href="https://nssm.cc/"&gt;Non-Sucking Service Manager&lt;/a&gt; executables all failed.&lt;/p&gt;
&lt;p&gt;Well, crap.&lt;/p&gt;
&lt;h3&gt;Take 2&lt;/h3&gt;
&lt;img src="https://mbt5mw-dm2306.files.1drv.com/y3mDYUaDMt02GzcHWl0DE1ASfBA6QbYzEwY-koD_MSkQGr3oRavQLf5jyRBH5TVFEBASZyRxAL00cuoRKuNNJ6lvSfEJD42p0QkZNzUQAFV-TKzdglya78e_ON8lHg7vQBS96aSQL-Hz0AobNgzQ83uHZN1T3nyDQKlumWgM50OZBc?width=660&amp;amp;height=440&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="So! I built a second one!"&gt;
&lt;blockquote&gt;
&lt;p&gt;So! I built a second one!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My next thought was to try salvaging as much of the script as possible by using &lt;a href="https://technet.microsoft.com/en-us/library/ff700227.aspx"&gt;Powershell Remoting&lt;/a&gt; to interactively install the required components and then &lt;a href="https://docs.docker.com/engine/reference/commandline/commit/"&gt;committing&lt;/a&gt; the changes to a new image.&lt;/p&gt;
&lt;p&gt;While, in retrospect, this was undoubtedly the wrong way forward, I was simultaneously fortunate and frustrated by the fact that it simply doesn't seem possible to use powershell remoting with Nanoserver when running within a container. Indeed, after learning more about &lt;a href="https://msdn.microsoft.com/en-us/library/aa384426(v=vs.85).aspx"&gt;WinRM&lt;/a&gt; than I thought possible, posting on &lt;a href="https://social.msdn.microsoft.com/Forums/en-US/e0652324-30e4-4ebb-8689-55205e6d8bc9/enterpssession-to-nanoserver-container-in-docker-access-is-denied?forum=windowscontainers"&gt;Microsoft's Windows Container forums&lt;/a&gt; and even offering my &lt;a href="http://stackoverflow.com/questions/39195068/powershell-remote-access-to-nanoserver-on-docker"&gt;first bounty on StackOverflow&lt;/a&gt; I simply could not find an answer to why it wasn't possible to establish a remote session.&lt;/p&gt;
&lt;p&gt;In the mean time...&lt;/p&gt;
&lt;h3&gt;Take 3&lt;/h3&gt;
&lt;img src="https://mbt3mw-dm2306.files.1drv.com/y3m5x6G99So08jPRwR0n1Msb-8SrSKNaOsB6aLd-CYAk8kSo9xRsa6i9Kd44QzRHin_EKMOpsNMZpacjCkoeGaMsODu6S7zI3NavsVz89vKF4Ot3b9pLEwaHxmg2mxXzvG8rQqCyf7C769ScaTkbPQ5WG2RwwcTHOyRqm0A-4RDNuQ?width=660&amp;amp;height=441&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="So, I built a third one..."&gt;
&lt;blockquote&gt;
&lt;p&gt;I built a third one...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Powershell remoting works beautifully with Nanoserver when running in a Hyper-V virtual machine but Hyper-V networking and Docker networking configurations don't seem to play well together. Indeed, after creating a new virtual-router so that I could access the Nanoserver virtual machine from the host PC, the Docker NAT network became inaccessible. Now, I'm sure it would be possible to dig into the virtual networking configuration and find a way to resolve this but, having spent an incredibly frustrating few hours reconfiguring WinRM, I decided it would be quicker to simply re-install the host OS and start from scratch.&lt;/p&gt;
&lt;h3&gt;Take 4&lt;/h3&gt;
&lt;img src="https://oltxmw-dm2306.files.1drv.com/y3mGaNRc9vDgPZnXfcJZfjYwIEFL32s3nCdk_kA84gB5NGOAoC3SLqP5D7ZffgKPO1VHXQEaRXvVuGCwFjoLKyo7o-gaUXFvGRcZPRPQrifhGNlBmU8RfqR5ZTgKIhxRvzJIMPoXydQ_N5UROZmaUXtKHH3jKtxIobDubPEdWsp-GM?width=660&amp;amp;height=495&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="But the fourth one stayed up!"&gt;
&lt;blockquote&gt;
&lt;p&gt;But the fourth one stayed up!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To accompany the fresh host environment, I decided to employ a fresh approach to building the container image. Namely, use a script to build the container's file system structure on the host PC and then simply copy it wholesale to the container from within the dockerfile. This meant deploying the Java Runtime Environment from a compressed archive rather than silent executable and using the &lt;a href="https://docs.docker.com/engine/reference/builder/#/entrypoint"&gt;dockerfile entrypoint&lt;/a&gt; instruction to run Zookeeper rather than installing it as a service.&lt;/p&gt;
&lt;p&gt;After all the faff and frustration of the previous two attempts (not to mention reinstallation of OS on host PC), this approach was remarkably smooth. Again, in retrospect this was undoubtedly the correct approach but this approach almost certainly benefited from all the knowledge I had accrued from the previous failed attempts. As always, &lt;a href="http://www.goodreads.com/quotes/390439-we-learn-wisdom-from-failure-much-more-than-from-success"&gt;you can learn more from failure than success&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, in relatively short order, I had a script that prepared and configured the container's file system structure on the host PC and a dockerfile that copied this structure to a new image and set the Zookeeper service as the entrypoint for the image. These are shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;## Download sources
$zipUri = "http://homeserver/download/7z1604-x64.exe" # http://www.7-zip.org/a/7z1604-x64.exe";
$javaUri = "http://homeserver/download/jre-8u111-windows-x64.tar.gz" # "http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jre-8u111-windows-x64.tar.gz"
$zookeeperUri = "http://homeserver/download/zookeeper-3.4.9.tar.gz" # "http://apache.mirrors.nublue.co.uk/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz"
$dockerModuleUri = "http://homeserver/download/Docker.0.1.0.zip" # "https://github.com/Microsoft/Docker-PowerShell/releases/download/v0.1.0/Docker.0.1.0.zip"

## Build location
$buildDir = Get-Location
$tmpDir = $buildDir.Path + "\Temp"
$rootDir = $buildDir.Path + "\Root"
$biuldAppDir = $rootDir + "\Apps"
$buildDataDir = $rootDir + "\Data"
$buildDockerZip = $tmpDir + "\Docker.zip"
$buildDockerModule = $tmpDir + "\Docker"
$buildZipDir = $tmpDir + "\7zip"
$buildJreDir = $biuldAppDir + "\Jre"
$buildZookeeperDir = $biuldAppDir + "\Zookeeper"
$buildZookeeperDataDir = $buildDataDir + "\Zookeeper"

## Temp files
$zipInstaller = $tmpDir + "\7zInstaller.exe"
$jreGzip = $tmpDir + "\Jre.tar.gz"
$jreTar = $tmpDir + "\Jre.tar"
$zooKeeperGzip = $tmpDir + "\Zookeeper.tar.gz"
$zooKeeperTar = $tmpDir + "\Zookeeper.tar"

## Target locations
$targetDir = "C:\"
$appDir = $targetDir + "\Apps"
$dataDir = $targetDir + "\Data"
$jreDir = $appDir + "\Jre"
$zookeeperDir = $appDir + "\Zookeeper"
$zookeeperDataDir = $dataDir + "\Zookeeper"

## Executables
$zip = $buildZipDir + "\7z.exe"
$zookeeper = $zookeeperDir + "\bin\zkServer.cmd"
$docker = "docker"

function New-TempPath()
{
    if (!(Test-Path -Path $tmpDir))
    {
        New-Item $tmpDir -ItemType Directory
    }
}

function Remove-TempPath()
{
    Remove-Item $tmpDir -Recurse -Force
}

function New-RootPath()
{
    Remove-Item $rootDir -Recurse -Force
    New-Item $rootDir -ItemType Directory
}

function Remove-RootPath()
{
    Remove-Item $rootDir -Recurse -Force
}

function Expand-File($zipFile, $targetPath)
{
    $args = @("e", $zipFile, "-o$targetPath", '-y')
    &amp;amp;$zip $args | Out-Host
}

function Expand-Directory($zipFile, $targetPath)
{
    $args = @("x", $zipFile, "-o$targetPath", '-aoa')
    &amp;amp;$zip $args | Out-Host
}

function Install-DockerModule()
{
    Invoke-WebRequest -Uri $dockerModuleUri -OutFile $buildDockerZip
    Expand-Archive -Path $buildDockerZip -DestinationPath $buildDockerModule -Force

    Import-Module $buildDockerModule
}

function Remove-DockerModule()
{
    Remove-Module $buildDockerModule
}

function Install-7zip()
{
    $folder = New-Item $buildZipDir -ItemType Directory -Force
    Invoke-WebRequest -Uri $zipUri -OutFile $zipInstaller
    &amp;amp;$zipInstaller /S /D=$folder | Out-Null
    Remove-Item -Path $zipInstaller
}

function Remove-7zip()
{
    Remove-Item $buildZipDir -Recurse -Force
}

function Get-Java()
{
    Invoke-WebRequest -Uri $javaUri -OutFile $jreGzip
    Expand-File $jreGzip $tmpDir
    Expand-Directory $jreTar $buildJreDir

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path $buildJreDir -Filter "jre*"
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination $buildJreDir -Force

    Remove-Item -Path $folder.FullName -Force
    Remove-Item -Path $jreGzip -Force
    Remove-Item -Path $jreTar -Force
}

function Get-Zookeeper()
{
    Invoke-WebRequest -Uri $zookeeperUri -OutFile $zooKeeperGzip
    Expand-File $zooKeeperGzip $tmpDir
    Expand-Directory $zooKeeperTar $buildZookeeperDir

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path $buildZookeeperDir -Filter "zookeeper-*"
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination $buildZookeeperDir -Force

    Remove-Item -Path $folder.FullName -Force
    Remove-Item -Path $zooKeeperTar -Force
    Remove-Item -Path $zooKeeperGzip -Force
}

function Initialize-Zookeeper()
{
    New-Item -Path $buildDataDir -ItemType Directory -Force
    New-Item -Path $buildZookeeperDataDir -ItemType Directory -Force

    $zookeeperDataLinuxDir = $zookeeperDataDir.Replace('\', '/')

    Copy-Item -Path ($buildZookeeperDir + '\conf\zoo_sample.cfg') -Destination ($buildZookeeperDir + '\conf\zoo.cfg') -Force

    $configFile = $buildZookeeperDir + '\conf\zoo.cfg'
    $logFile = $buildZookeeperDir + '\conf\log4j.properties'

    $config = [IO.File]::ReadAllText($configFile) -replace "dataDir=[\/\w]*", ("dataDir=" + $zookeeperDataLinuxDir)
    [IO.File]::WriteAllText($configFile, $config)

    $logProperties = [IO.File]::ReadAllText($logFile) -replace "#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE", "log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE"
    [IO.File]::WriteAllText($logFile, $logProperties)
}

function New-DockerImage()
{
    Build-ContainerImage -Path $buildDir -Repository "ibebbs/nanozoo:latest"
}


# Setup directory structure
New-TempPath
New-RootPath

# Install required tools
Install-DockerModule
Install-7zip

# Get components
Get-Java
Get-Zookeeper
Initialize-Zookeeper

# Build docker image
New-DockerImage

# Cleanup
Remove-DockerModule
Remove-7zip
Remove-TempPath
Remove-RootPath
&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;FROM microsoft/nanoserver
MAINTAINER Ian Bebbington &amp;lt;docker@bebbs.co.uk&amp;gt;
LABEL Description="Zookeeper running on Microsoft Nanoserver" Version="0.1"
ADD Root /
ADD Start-Zookeeper.ps1 /
RUN setx /M JAVA_HOME C:\Apps\Jre
EXPOSE 2181
ENTRYPOINT [ "powershell.exe", "C:/Start-Zookeeper.ps1" ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And this one worked. This one started. This one stayed up!&lt;/p&gt;
&lt;h2&gt;Building the Kafka image&lt;/h2&gt;
&lt;p&gt;With the Zookeeper scripts as a pattern, it was ludicrously easy to script up another image for Kafka. Just a few changes to file names and configuration parameters and Kafka started almost first time.&lt;/p&gt;
&lt;p&gt;I won't copy the script or dockerfile here as they're extremely similar to the Zookeeper versions. Instead, all scripts and files used above can be found in my &lt;a href="https://github.com/ibebbs/Docker"&gt;Docker repository on Github&lt;/a&gt; and the resultant images can be found on &lt;a href="https://hub.docker.com/r/ibebbs/"&gt;Docker hub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Moving forward&lt;/h2&gt;
&lt;img src="https://oltymw-dm2306.files.1drv.com/y3mIddKC619ngQYu9mwpyXXi9YgUp-MVwZ9_lR8JRla2AKvMm91LwnW2p0G3GkOZj5X_TXQUap_XULDAaiCWMC5Hx0ZvjKdAjeW7YWqacnwEAgCSZgmgBF1DCH83Zcywki6qKmOXbKkZO_SWmvQHpajyOQRHO1pJNB3ak2YpT6DmX8?width=660&amp;amp;height=371&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="But I don't want any of that!"&gt;
&lt;blockquote&gt;
&lt;p&gt;But I don't want any of that!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Moving forward, I need to address a couple of short-comings in the Kafka script (specifically the hard-coded IP address for the Zookeeper container) and then look to use Docker Compose to automatically bring up Zookeeper and Kafka on demand.&lt;/p&gt;
&lt;p&gt;It's been an interesting journey so far and I've not even begun to actually use the deployed services yet! Still, it is truly magical to run a docker container and see it boot an entire Windows server and service in just 10-20 seconds and a few hundred Mb.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;For my first blog post of the new year (Happy New Year everyone!!!), I'd like to share some of my recent adventures with Docker on Windows, or, more specifically, Docker on Windows using Nanoserver as the container OS.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/RxVsTpl" />
		<id>http://ian.bebbs.co.uk/posts/RxVsTpl</id>
		<title>On the perils of traversing parallel universes</title>
		<updated>2016-02-01T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Despite taking some poetic license with the title of this post, the dramatics are not without merit. I have spent a significant portion of the last three days trying to write a series of tests around some asynchronous code to prove it managed - or, more specifically, limited - concurrency as intended. This code, while mainly Rx based, made calls to TPL methods and needed to wait, without blocking, for a result to be returned prior to allowing subsequent calls to be made. In short it mixed Rx and TPL to implement a multi-procuder / single consumer concurrency pattern, and this mix proved to be the source of much (much, much!) frustration.&lt;/p&gt;
&lt;p&gt;While I don't necessarily believe that &lt;a href="https://code.google.com/archive/p/fakeiteasy/issues/31"&gt;threading should be avoided in unit tests&lt;/a&gt; I do, as much as possible, endeavour to keep tests synchronous. Obviously this can be tricky when you're &lt;a href="http://stackoverflow.com/questions/20861305/should-i-unit-test-concurrency"&gt;specifically&lt;/a&gt; &lt;a href="http://stackoverflow.com/questions/12159/how-should-i-unit-test-threaded-code"&gt;testing&lt;/a&gt;  &lt;a href="http://stackoverflow.com/questions/1226779/how-to-run-concurrency-unit-test"&gt;concurrency&lt;/a&gt; but, fortunately, this has become immeasurably easier since Rx introduced testing in &lt;a href="http://blogs.msdn.com/b/rxteam/archive/2012/06/14/testing-rx-queries-using-virtual-time-scheduling.aspx"&gt;virtual time&lt;/a&gt; via the &lt;a href="http://www.introtorx.com/content/v1.0.10621.0/16_TestingRx.html"&gt;TestScheduler&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So, with this magical mechanism for manipulating the motion of time in my mitts, I proceeded to write the test &lt;code&gt;ShouldOnlySendASingleCommandAtATime&lt;/code&gt;... which promptly failed. And I'm not talking the good, red-green kinda failure. Nooo, this was an old school &lt;em&gt;"I've written the code, better make sure it works... oh, that's weird!"&lt;/em&gt; kinda failure.&lt;/p&gt;
&lt;p&gt;Assertions on calls to faked objects were failing and, after a lot of digging I finally found out why: Despite diligently injecting and using a &lt;code&gt;TestScheduler&lt;/code&gt; through my Rx code and mocking calls to TPL code such that they returned &lt;code&gt;TaskCompletionSource&amp;lt;T&amp;gt;&lt;/code&gt; instances, I was still seeing my unit tests start a &lt;strong&gt;second worker thread&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;Weird indeed.&lt;/p&gt;
&lt;p&gt;After a lot of hacking around with my code and other &lt;a href="http://www.theallium.com/engineering/computer-programming-to-be-officially-renamed-googling-stackoverflow/"&gt;"computer programming"&lt;/a&gt; type activities, I finally happened upon this &lt;a href="http://stackoverflow.com/questions/28183473/executing-tpl-code-in-a-reactive-pipeline-and-controlling-execution-via-test-sch/28236216#28236216"&gt;curiously titled question&lt;/a&gt;. The question very closely reflected what I was trying to achieve and was fortunately followed by an incredibly detailed answer by &lt;a href="http://stackoverflow.com/users/87427/james-world"&gt;James World&lt;/a&gt;. Of particular note was this paragraph:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One particular pain point of Rx that leaves many testers scratching their heads, is the fact that the TPL -&amp;gt; Rx family of conversions introduce concurrency. e.g. ToObservable, SelectMany's overload accepting Task&lt;t&gt; etc. don't provide overloads with a scheduler and insidiously force you off the TestScheduler thread, even if mocking with TCS&lt;/t&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Bingo! Exactly the issue I was experiencing. James also provided a link to the following &lt;a href="https://github.com/Reactive-Extensions/Rx.NET/issues/21"&gt;bug report for Rx&lt;/a&gt; validating his answer and vindicating my confusion. This epiphany lead me to rewrite the interfaces to my dependencies such that they were Rx rather than TPL based. After which, lo and behold, my unit tests started passing.&lt;/p&gt;
&lt;p&gt;Phew!&lt;/p&gt;
&lt;p&gt;In conclusion, I guess the physicists are right: &lt;a href="https://www.newscientist.com/article/dn11745-could-black-holes-be-portals-to-other-universes/"&gt;If you want to move between parallel universes, be prepared to fall into a black hole!&lt;/a&gt;&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Despite taking some poetic license with the title of this post, the dramatics are not without merit. I have spent a significant portion of the last three days trying to write a series of tests around some asynchronous code to prove it managed - or, more specifically, limited - concurrency as intended. This code, while mainly Rx based, made calls to TPL methods and needed to wait, without blocking, for a result to be returned prior to allowing subsequent calls to be made. In short it mixed Rx and TPL to implement a multi-procuder / single consumer concurrency pattern, and this mix proved to be the source of much (much, much!) frustration.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII" />
		<id>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII</id>
		<title>A sentiment(al) analysis of why Red Dwarf is no longer funny</title>
		<updated>2017-04-12T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;I've recently been working on a project that required some natural language processing. After a surprisingly brief search I came upon the &lt;a href="https://stanfordnlp.github.io/CoreNLP/"&gt;Stanford CoreNLP&lt;/a&gt; suite of tools and after playing with their &lt;a href="http://corenlp.run/"&gt;online demo&lt;/a&gt; was astounded at the capabilities it provided. Furthermore, it was free, could be run such that it provided a basic HTTP API and came packaged with everything it needed save a copy of the JRE.&lt;/p&gt;
&lt;p&gt;Having recently &lt;a href="http://ian.bebbs.co.uk/posts/DockerAndKafka"&gt;enjoyed a lot of success&lt;/a&gt; running &lt;a href="https://zookeeper.apache.org/"&gt;various&lt;/a&gt; &lt;a href="https://kafka.apache.org/"&gt;JAVA&lt;/a&gt; &lt;a href="https://neo4j.com/product/"&gt;services&lt;/a&gt; inside a &lt;a href="https://www.docker.com/"&gt;Docker container&lt;/a&gt; running &lt;a href="https://technet.microsoft.com/en-us/windows-server-docs/get-started/getting-started-with-nano-server"&gt;Windows Nano Server&lt;/a&gt;, I decided to see if CoreNLP could be run like this too. Copying my previous &lt;a href="https://github.com/ibebbs/Docker/blob/master/Nanoserver-Zookeeper/Build.ps1"&gt;build script&lt;/a&gt; and &lt;a href="https://github.com/ibebbs/Docker/blob/master/Nanoserver-CoreNLP/Build.ps1"&gt;amending it&lt;/a&gt; to build a &lt;a href="https://hub.docker.com/r/ibebbs/nanonlp/"&gt;container running CoreNLP&lt;/a&gt; was ludicrously easy and in no time I had a local API I could hit to perform all the natural language processing I needed.&lt;/p&gt;
&lt;p&gt;Now, while the project I was working on mainly required the &lt;a href="https://stanfordnlp.github.io/CoreNLP/ner.html"&gt;"Named Entity Recognition"&lt;/a&gt; and &lt;a href="https://stanfordnlp.github.io/CoreNLP/openie.html"&gt;"Open IE"&lt;/a&gt; annotators, I was intrigued to see that CoreNLP also included a basic &lt;a href="https://stanfordnlp.github.io/CoreNLP/sentiment.html"&gt;Sentiment&lt;/a&gt; annotator. Given that I had written part one of this post back in January, had noted at the time how much I'd like to do sentiment analysis on the transcripts of Red Dwarf, and that I hadn't written a blog post since, I decided to take some time out and perform the sentiment analysis so that I could write this post.&lt;/p&gt;
&lt;p&gt;Again employing &lt;a href="https://jupyter.org/"&gt;Project Jupyter&lt;/a&gt; hosted on &lt;a href="https://notebooks.azure.com/"&gt;Azure Notebooks&lt;/a&gt; and using &lt;a href="http://fsharp.org/"&gt;F#&lt;/a&gt; coupled with &lt;a href="https://fslab.org/"&gt;FsLab&lt;/a&gt; as my primary language and toolkit, I had a lot of fun performing the analysis. Like last time, you can find the &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis/blob/master/SentimentAnalysisWithCoreNLP.ipynb"&gt;full notebook&lt;/a&gt; and source material in my &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis"&gt;Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note: As before, Github provides a "limited rendering only" so, to see all the charts running correctly you need to use the 'nbviewer' link shown below to see a full rendering of the notepad.&lt;/p&gt;
&lt;img src="https://mvpfyw-dm2306.files.1drv.com/y3mppldGfaYEhvWkV7mdUw26-lP3SOzlMTGFbf8slchIfjBL57IH-GrJev6ai_rISiHBKrom7Abg9YFjfhZ1ArOFT7a7mh4gJuGq-CErv1dun48GQC_BdhMV08fh6hbw400d9nHSEXJ0jA2nPBIrpOPNrOz0I3lVY1tu_L656ylQKg?width=660&amp;amp;height=283&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660; margin-top: 6px; margin-bottom: 6px;" alt="Open external view with nbviewer"&gt;
&lt;p&gt;The best bit of all (note: spoilers ahead!) is that it seems my original conclusion may indeed have been wrong... or at least mis-attributed.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;I've recently been working on a project that required some natural language processing. After a surprisingly brief search I came upon the &lt;a href="https://stanfordnlp.github.io/CoreNLP/"&gt;Stanford CoreNLP&lt;/a&gt; suite of tools and after playing with their &lt;a href="http://corenlp.run/"&gt;online demo&lt;/a&gt; was astounded at the capabilities it provided. Furthermore, it was free, could be run such that it provided a basic HTTP API and came packaged with everything it needed save a copy of the JRE.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartIV" />
		<id>http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartIV</id>
		<title>Home Network Monitoring - Part IV</title>
		<updated>2016-04-16T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;In the last post, I used the Logstash &lt;code&gt;dns&lt;/code&gt; filter to translate remote server IP addresses into recognisable domain names. In this post, I will look to perform a similar operation for local IP addresses in order to translate them into recognisable device names.&lt;/p&gt;
&lt;h1&gt;translating local ip addresses to device names&lt;/h1&gt;
&lt;p&gt;While in the last post we could use the &lt;code&gt;dns&lt;/code&gt; filter to perform a reverse dns lookup to resolve a remote domain name for an IP address, this is not possible with local IP addresses. Fortunately, I have two key tools that I can use to perform a similar operation:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;While my router behaves as a DHCP server, it has a feature that allows it to always allocate the same IP address to a given MAC address. Therefore I know a given device will always have a specific IP address.&lt;/li&gt;
&lt;li&gt;Logstash provides the &lt;code&gt;translate&lt;/code&gt; filter which allows you to map from one value to another via a dictionary lookup.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With my routers "Bind IP to MAC" function set up, I will author a new &lt;code&gt;yaml&lt;/code&gt; file that meets the specifications outlined in the &lt;code&gt;translate&lt;/code&gt; filter &lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-translate.html#plugins-filters-translate-destination"&gt;documentation&lt;/a&gt;. It looks like this:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;192.168.1.3: TPLink Range Extender
192.168.1.9: Ricoh Printer
192.168.1.10: Server A
192.168.1.21: PC A
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I'll name this file &lt;code&gt;IPLookup.yaml&lt;/code&gt; and save it besides the &lt;code&gt;syslog.config&lt;/code&gt; file. Next I need to add additional filters to &lt;code&gt;syslog.config&lt;/code&gt; which now looks as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;input {
  tcp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
  udp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
}

filter {
    grok {
        match =&amp;gt; [ "message", "&amp;lt;%{POSINT:syslog_pri}&amp;gt;%{SYSLOGTIMESTAMP:syslog_timestamp} Vigor\: Local User \(MAC=%{MAC:source_mac}\): %{IP:source_address}(?::%{POSINT:source_port})? -&amp;gt; %{IP:destination_address}(?::%{POSINT:destination_port})? \((?&amp;lt;protocol&amp;gt;TCP|UDP)\)" ]
        add_tag =&amp;gt; "access"
    }
    if "access" in [tags] {
        mutate {
            add_field =&amp;gt; {
              "source_host" =&amp;gt; "%{[source_address]}"
              "destination_host" =&amp;gt; "%{[destination_address]}"
            }
        }
        dns {
            reverse =&amp;gt; [ "destination_host" ]
            action =&amp;gt; "replace"
            nameserver =&amp;gt; "192.168.1.1"
        }
        translate {
            destination =&amp;gt; "source_host"
            dictionary_path =&amp;gt; "config\IPLookup.yaml"
            fallback =&amp;gt; "%{source_address}"
            field =&amp;gt; "source_address"      
            override =&amp;gt; true   
        }
    }
}

output {
  elasticsearch {
    hosts =&amp;gt; ["192.168.1.30:9200"]
    index =&amp;gt; "syslog-%{+YYYY.MM.dd}"
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the &lt;code&gt;translate&lt;/code&gt; filter where I lookup the &lt;code&gt;source_address&lt;/code&gt; field in the &lt;code&gt;IPLookup.yaml&lt;/code&gt; file and put the result in the &lt;code&gt;source_host&lt;/code&gt; field. If not found, the &lt;code&gt;fallback&lt;/code&gt; value instructs the filter to output the &lt;code&gt;source_address&lt;/code&gt; into the &lt;code&gt;source_host&lt;/code&gt; field. The &lt;code&gt;override&lt;/code&gt; value is set to true as the &lt;code&gt;source_host&lt;/code&gt; field is added in the &lt;code&gt;mutate&lt;/code&gt; filter above as a fail-safe.&lt;/p&gt;
&lt;p&gt;With the changes to configuration in place, I once again restart Logstash. Once a syslog message has been received, I get the mapping from ElasticSearch and update it to mark the &lt;code&gt;local_host&lt;/code&gt; field as &lt;code&gt;not_analyzed&lt;/code&gt;. Then, in Kibana, I refresh the field list for the 'syslog-*' index, add 'local_host' to the 'Syslog Messages' saved search, load 'Access By Local Address' visualization and modify it to use 'local_host' rather than the 'local_address' field and save it as 'Access By Local Host'. Finally, I replace this visualization on my dashboard and get the following:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardWithAccessByLocalHost.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard With Access By Local Host"&gt;
&lt;h1&gt;further mappings&lt;/h1&gt;
&lt;p&gt;Now I've got the translation of local IP addresses to names working, I'm going to add a few more translations for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IP Address to Operating System&lt;/li&gt;
&lt;li&gt;IP Address to Wired/WiFi connection&lt;/li&gt;
&lt;li&gt;TCP and UDP Port to Protocol (using a &lt;a href="http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml"&gt;CSV from IANA&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With these in place, the dashboard is starting to come together:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardWithLocalPortAndOsLookups.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard With Local Port And Os Lookups"&gt;
&lt;h1&gt;summary&lt;/h1&gt;
&lt;p&gt;In this post, I showed how to display local device names rather than IP addresses by using LogStash's &lt;code&gt;translate&lt;/code&gt; filter. I then used this filter to provide further information about local device and protocols.&lt;/p&gt;
&lt;p&gt;In the next post, I'll show how to add some variation to the dashboard by mapping destination locations.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In the last post, I used the Logstash &lt;code&gt;dns&lt;/code&gt; filter to translate remote server IP addresses into recognisable domain names. In this post, I will look to perform a similar operation for local IP addresses in order to translate them into recognisable device names.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ReactiveStateMachines" />
		<id>http://ian.bebbs.co.uk/posts/ReactiveStateMachines</id>
		<title>Reactive State Machines</title>
		<updated>2016-11-09T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Today I'd like to share an implementation I've recently been employing that leverages Rx to implement a &lt;a href="https://en.wikipedia.org/wiki/Finite-state_machine"&gt;state-machine&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.martinfowler.com/dslCatalog/stateMachine.html"&gt;State-machines are a terrific pattern&lt;/a&gt; that, when applied correctly, can greatly simplify the implementation, maintenance and extensibility of many types of functionality; from &lt;a href="https://msdn.microsoft.com/en-gb/windows/uwp/launch-resume/app-lifecycle"&gt;application lifecycle management&lt;/a&gt; to business process coordination. They're particularly helpful with long-running, asynchronous processes that need to behave differently at various stages of the process, especially when the process is message or event driven.&lt;/p&gt;
&lt;p&gt;Normally, state machines are defined by "a list of its states, its initial state, and the triggering condition for each transition". However, when looked at from the point of view of "&lt;a href="http://slides.com/robwormald/everything-is-a-stream#/" title="Everything is a stream - Rob Wormald"&gt;everything&lt;/a&gt; &lt;a href="https://gist.github.com/staltz/868e7e9bc2a7b8c1f754" title="The introduction to Reactive Programming you've been missing - andrestaltz"&gt;being&lt;/a&gt; &lt;a href="http://weareadaptive.com/blog/2014/05/05/everything-is-a-stream/" title="Reactive Trader 2: Everything is a Stream - Matt Barrett"&gt;a&lt;/a&gt; &lt;a href="http://colintheshots.com/blog/?p=85" title="Be Reactive - Colintheshots"&gt;stream&lt;/a&gt;", they can also be viewed as a stream of transitions with states existing as the rest period between those transitions.&lt;/p&gt;
&lt;p&gt;In this mindset, a state can simply be defined as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;public interface IState
{
    IObservable&amp;lt;ITransition&amp;gt; Enter();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In short, the result of entering a state is an observable of transitions away from the state.&lt;/p&gt;
&lt;p&gt;With this in hand, the state machine of, for example, a typical UWP app can be defined as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;public class StateMachine
{        
    private readonly IStateFactory _factory;
    private readonly Subject&amp;lt;IState&amp;gt; _state;

    public Machine(IStateFactory factory)
    {
        _factory = factory;

        _state = new Subject&amp;lt;IState&amp;gt;();
    }

    public IDisposable Initialize()
    {
        // First create a stream of transitions by ...
        IObservable&amp;lt;ITransition&amp;gt; transitions = _state
            // ... starting from the initializing state ...
            .StartWith(_factory.Initializing())
            // ... enter the current state ...
            .Select(state =&amp;gt; state.Enter())
            // ... subscribing to the transition observable ...
            .Switch()
            // ... and ensure only a single shared subscription is made to the transitions observable ...
            .Publish()
            // ... held until there are no more subscribers
            .RefCount();

        // Then, for each transition type, select the new state...
        IObservable&amp;lt;IState&amp;gt; states = Observable.Merge(
            states.OfType&amp;lt;Transition.ToStarting&amp;gt;().Select(transition =&amp;gt; _factory.Starting()),
            states.OfType&amp;lt;Transition.ToResuming&amp;gt;().Select(transition =&amp;gt; _factory.Resuming()),
            states.OfType&amp;lt;Transition.ToRunning&amp;gt;().Select(transition =&amp;gt; _factory.Running()),
            states.OfType&amp;lt;Transition.ToSuspending&amp;gt;().Select(transition =&amp;gt; _factory.Suspending())
        );

        // Finally, subscribe to the state observable ...
        return states
            // ... ensuring all transitions are serialized ...
            .ObserveOn(Scheduler.CurrentThread)
            // ... back onto the source state observable
            .Subscribe(_state);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are no constraints regarding which events/triggers each state uses to construct the observable of transitions returned when the Enter method is called, but they usually follow one of two patterns:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Wait for an event/trigger to be received and transition to a new state based on the type of event/trigger received.&lt;/li&gt;
&lt;li&gt;Perform an asynchronous / long-running process and transition to another state when it completes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To illustrate this, the Initializing and Starting state definitions below can be considered to be examples of the former and latter patterns respectively.&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;internal class Initializing : IState
{
    private readonly IEventAggregator _bus;

    public Initializing(IEventAggregator bus)
    {
        _bus = bus;
    }

    public IObservable&amp;lt;ITransition&amp;gt; Enter()
    {
        return Observable.Merge&amp;lt;ITransition&amp;gt;(
            _bus.GetEvent&amp;lt;Event.Start&amp;gt;().Select(_ =&amp;gt; new Transition.ToStarting()),
            _bus.GetEvent&amp;lt;Event.Resume&amp;gt;().Select(_ =&amp;gt; new Transition.ToResuming())
        );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;internal class Starting : IState
{
    private readonly DataStore.IContext _dataStoreContext;

    public Starting(DataStore.IContext dataStoreContext)
    {
        _dataStoreContext = dataStoreContext;
    }

    public IObservable&amp;lt;ITransition&amp;gt; Enter()
    {
        return Observable.Create&amp;lt;ITransition&amp;gt;(
            async observer =&amp;gt;
            {
                await _dataStoreContext.InitializeAsync();

                observer.OnNext(new Transition.ToRunning());
            }
        );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, states can (and should!) be very small and easily testable. All together a complete, strongly typed, 'async' friendly state machine can be implemented with just a handful of classes containing minimal code.&lt;/p&gt;
&lt;p&gt;I have used this pattern on numerous occasions and enjoy the simplicity and extensibility it affords me when defining long-running process flows.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Today I'd like to share an implementation I've recently been employing that leverages Rx to implement a &lt;a href="https://en.wikipedia.org/wiki/Finite-state_machine"&gt;state-machine&lt;/a&gt;.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl" />
		<id>http://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl</id>
		<title>CQRS/ES &amp; MVVM using RX, EF &amp; SQL in UWP &amp; PCL …</title>
		<updated>2016-12-22T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;So, while ToddlerBox is riding high, I'd like to share some thoughts about another app I have in the store; &lt;a href="https://www.microsoft.com/en-gb/store/p/littlelittle/9nblggh51b1b"&gt;LittleLittle&lt;/a&gt;. This app has been the subject of most of my efforts over the last few months and is significantly more complex (and, frustratingly, less successful!) than ToddlerBox.&lt;/p&gt;
&lt;p&gt;LittleLittle was started shortly after my baby girl started weaning and became constipated - apparently a very common occurrence. When we visited a paediatrician about it, they asked that we keep a record of her bowel movements so that we could track the condition to see if it was getting better or worse.&lt;/p&gt;
&lt;p&gt;"I wonder if there's an app for that", I thought. And, of course, there was.&lt;/p&gt;
&lt;h2&gt;Opportunity and Methodology&lt;/h2&gt;
&lt;p&gt;However, while there are plenty of other baby tracking apps out there, very few work across platform (I use Windows Mobile while my partner uses Android) and even fewer work as I feel they should.&lt;/p&gt;
&lt;p&gt;Given the requirement to work across a variety of platforms, maximising code re-use was extremely desirable. As such, I decided that all of the core-logic for the app needed to be written in a PCL. Furthermore, particular care would be taken to observe a pure MVVM methodology so that ViewModels (an embodiment of the app's UX) could also be shared across platform.&lt;/p&gt;
&lt;p&gt;Finally, following some work in the CQRS/ES space at my previous employer, I wanted to write an app that used this methodology end-to-end. LittleLittle seemed a perfect opportunity to do so.&lt;/p&gt;
&lt;h2&gt;Technology and Platform&lt;/h2&gt;
&lt;p&gt;To partner the &lt;a href="http://martinfowler.com/bliki/CQRS.html"&gt;CQRS&lt;/a&gt;/&lt;a href="http://martinfowler.com/eaaDev/EventSourcing.html"&gt;ES&lt;/a&gt; methodology, I was keen to use &lt;a href="https://msdn.microsoft.com/en-us/library/hh242985.aspx"&gt;Rx&lt;/a&gt; as the driving technology for implementation. As readers of my blog will know, I am very much of the opinion that "&lt;a href="http://slides.com/robwormald/everything-is-a-stream#/" title="Everything is a stream - Rob Wormald"&gt;everything&lt;/a&gt; &lt;a href="https://gist.github.com/staltz/868e7e9bc2a7b8c1f754" title="The introduction to Reactive Programming you've been missing - andrestaltz"&gt;is&lt;/a&gt; &lt;a href="http://weareadaptive.com/blog/2014/05/05/everything-is-a-stream/" title="Reactive Trader 2: Everything is a Stream - Matt Barrett"&gt;a&lt;/a&gt; &lt;a href="http://colintheshots.com/blog/?p=85" title="Be Reactive - Colintheshots"&gt;stream&lt;/a&gt;" and event sourcing from "a stream of events" seemed a perfect fit for Rx.&lt;/p&gt;
&lt;p&gt;Given that the Event Sourcing methodology - not to mention the nature of the app itself - required a persistence layer, I decided to use a recently new technology; &lt;a href="https://docs.microsoft.com/en-us/ef/core/"&gt;Entity Framework Core&lt;/a&gt;. I decided on EFCore simply because the tooling for the UWP platform was pretty good and I liked the 'code-first' approach to schema and migration generation. Coupled with this, I decided to use a &lt;a href="https://docs.microsoft.com/en-us/ef/core/providers/sqlite/"&gt;SQLite&lt;/a&gt; database as it was a proven data store for use with EFCore and across a variety of underlying platforms.&lt;/p&gt;
&lt;p&gt;Finally, when I started LittleLittle I was studying for the &lt;a href="https://www.microsoft.com/en-us/learning/exam-70-357.aspx"&gt;Microsoft Beta Exam "Developing Mobile Apps"&lt;/a&gt;. As such, while I was keen for the app to be cross-platform, the initial platform I wanted to support was UWP. I was - and still am - amazed by how, if you craft your code and views carefully, an application can run on an amazing number for platforms including RaspberryPi, Phone, Tablet, PC, Xbox and Hololens.&lt;/p&gt;
&lt;h2&gt;And here's one I made earlier…&lt;/h2&gt;
&lt;p&gt;After many weeks of work, innumerable iterations and much refactoring, I ended up with this:&lt;/p&gt;
  &lt;div class="horizontal_list"&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zuimew-dm2306.files.1drv.com/y3mcsjpC-olqYg0zbsOtSdJ1adHni1Apkeklf-2gzDpiB9ph_25HlwE5jeyMxex_1ryS-zVZxkMw0vtNsDCMrnzser84bs_zq9S75PZqddHWrRfMGfo3YbQhc-3ZwJGzjHMRuX_Ml0UQ_81MQnW4oOqva8Ap2jw2DIbULXOgc9ER7E?width=144&amp;amp;height=256&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="Splashscreen"&gt;
    &lt;/div&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zuilew-dm2306.files.1drv.com/y3muwswRbqzTW9QY2Ms8LyW2AAl8vIDTt8DKl-lsB_0uqQvGZJDkqFRF1Jg151-YQzqyUxourRpTXaaHttLPaXkE3hXmavIZKYyI7isdayp_PLbXDVOKCX_u83bEdzFmsfPRAikqWEVteWkTaFnX1SH8YgEd4UABUffd5dVZ4QAkvM?width=144&amp;amp;height=256&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="Available actions"&gt;
    &lt;/div&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zuikew-dm2306.files.1drv.com/y3mCHoxbDYsMkbkH-RQlFyxK5Y6zVhP_TU7JYj_MLCQrEfQsClKqlWoVqSsEt-ae7tYBvH89lvstPnIfhrA6MKPXNyjAp7O9EMy28Cof7nnc22DTFYs5FUECbQUEV_P8HxaVwWSFUyEN1MGAuWfY1x-36ZHviTEjqBOZM9m6pYm80Q?width=144&amp;amp;height=256&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="History"&gt;
    &lt;/div&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zuiiew-dm2306.files.1drv.com/y3mz7gADh3Y09Fb6QuQ2CY35gjWD2T9KEY_oWWbcijxNl2URePlVW0IjLhEBWeIoPOR1a-gAhRyoYNTdtefVfe8vd6d-Lnq5Cq_rcXEt4HZ5kt-jxOsCPLkJCaJtnfi5P-dTVNtJhMBYNbOtfiHXiPd9HsZODdjUwX-LphBvBAl_98?width=144&amp;amp;height=256&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="Height and weight charts"&gt;
    &lt;/div&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zeirew-dm2306.files.1drv.com/y3miUjsB3mUDyGdRCPudsd1I42ad9-MAI5JRV15z821gQAc7H_mqIgEeEDr1YWCvZh5AZOT6BAuAVSdMwz-Qnr6mG53KzP8xbeo2hinEJyplWnHoVs4FG7sbga6HMgLP6qd_x_mxRx2uqEVTfVAgXSOLMmHnQSpMxbV7DzQzPT1LXY?width=144&amp;amp;height=256&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="Sleep and excretion charts"&gt;
    &lt;/div&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zeiqew-dm2306.files.1drv.com/y3m2ZYqI7vBDCM_Ptv8Xvgo-UeDhvqtKIh5cxNy40KinoCzXem7V_-gIOsrkYvWyOtI6dod-HgNweHuue9DUB9r2yvgPNNXVvkPkIJKshYS4z-M1Qts9DPdqobqwnfHpIjewlWDj_Z6sFFVgbRlvsySton_n_nQrk4buXjebRss5JQ?width=144&amp;amp;height=256&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="Sleep and excretion charts"&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;p&gt;And I'm extremely happy with the result. CQRS/ES and Rx are a perfect match and the technology stack in general has been extremely productive.&lt;/p&gt;
&lt;p&gt;This morning I drew up a (retrospective) architecture to illustrate how much of the application is portable and how simple yet extensible it is.&lt;/p&gt;
&lt;img src="https://bdliqq-dm2306.files.1drv.com/y3mdSQ-fHhXJWrDI-4wfqFoaso56RU_vCH51ognfdTMYlml6nEgxQHUJWgTgHg5fw4cAEwpaJM1GVookE2ok4HscXXmd-a6WAcU7Xd509Rdmb35JaS2-5Zzx5G_YiNpAoxLekZifHRzDQittyVv6rybVIp33YiqopFatHZVcND-lhY?width=1024&amp;amp;height=626&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Architecture diagram"&gt;
&lt;h2&gt;"The proof is in the dog-fooding"&lt;/h2&gt;
&lt;p&gt;Apologies for the mixed metaphors but, suffice to say, while the technology choices may be deemed to be a success, the app can only be consider to be so if it is fit for purpose. As such, I have been using LittleLittle everyday for the past several weeks - across a number of iterations and versions - and I'm very, very pleased with the result. The UI is fast and efficient to use and the app has yet to crash or lose any data (either at runtime or between versions).&lt;/p&gt;
&lt;p&gt;Indeed, a little while ago my other half took our baby to stay with her grandparents for a several days and agreed to keep LittleLittle up to date while she was away. She came back with a couple of small suggestions but overall very impressed by how fast and easy to use it was.&lt;/p&gt;
&lt;p&gt;While it has yet to see a significant number of Windows Store acquisitions, Store Analytics shows there are a few people actively using the app and, so far, I have yet to see any crashes or failures. I intend to leverage the success of ToddlerBox to promote LittleLittle in the near future so, fingers crossed, it'll start getting some serious use and useful feedback.&lt;/p&gt;
&lt;h2&gt;Moving forward&lt;/h2&gt;
&lt;p&gt;While I intend to put LittleLittle on hold for a little while in order to work on some other projects I've been meaning to look at, I very much intend to return to the project early in the new year. I have a backlog full of features I'd like to implement not to mention the need to write a version which runs on Android/iOS (which will probably be in Xamarin).&lt;/p&gt;
&lt;p&gt;In the mean time, I will be blogging about a few of the components in the architecture diagram above and sharing some of the approaches I have taken and successes (or problems!) I encountered.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;So, while ToddlerBox is riding high, I'd like to share some thoughts about another app I have in the store; &lt;a href="https://www.microsoft.com/en-gb/store/p/littlelittle/9nblggh51b1b"&gt;LittleLittle&lt;/a&gt;. This app has been the subject of most of my efforts over the last few months and is significantly more complex (and, frustratingly, less successful!) than ToddlerBox.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/RxWeb" />
		<id>http://ian.bebbs.co.uk/posts/RxWeb</id>
		<title>Using Rx on the Web</title>
		<updated>2016-03-04T00:00:00Z</updated>
		<content>
                                        


&lt;h2&gt;Finding a framework&lt;/h2&gt;
&lt;p&gt;So, I have recently found myself with a need to dive into the depths of modern web-development and, as I am currently looking to write a highly interactive single-page web application, the first thing to decide on was a client side framework to use. You won't have to read too many of my blog posts to realise that I'm a big fan of &lt;a href="https://msdn.microsoft.com/en-us/data/gg577609.aspx?f=255&amp;amp;MSPPError=-2147217396"&gt;Rx&lt;/a&gt;. I am also keen on the MVVM approach to separating concerns when writing user interfaces. Therefore, during my research of modern web UI frameworks, I was extremely interested when I came across &lt;a href="http://webrxjs.org/"&gt;WebRx&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;Billed as "a browser-based MVVM-Framework that combines functional-reactive programming with declarative Data-Binding, Templating and Client-Side Routing" it struck a chord with my UI development style. In fact, it elevates &lt;a href="http://reactivex.io/documentation/observable.html"&gt;Observables&lt;/a&gt; to a first class concept in a manner eerily similar to the ObservableProperty/ObservableCommand classes I wrote for my &lt;a href="https://github.com/ibebbs/Caliburn.Micro.Reactive.Extensions"&gt;Caliburn.Micro.Reactive.Extensions&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;Unfortunately, as a framework, WebRx seems to be struggling to achieve critical mass and therefore there was very limited information available when I decided to attempt to implement the &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;WebRx "Hello World"&lt;/a&gt; example using Visual Studio. As is almost par for the course when using a new framework, I fell at a frustratingly early hurdle and, given the lack of info (seriously, only one tagged post on &lt;a href="https://stackoverflow.com/questions/tagged/webrx"&gt;stackoverflow&lt;/a&gt;!), I had to work through the problem 'old-skool'... ya'know, by actually finding and solving the problem rather than just googling a solution.&lt;/p&gt;
&lt;p&gt;Anyway, I thought I'd put together a post outlining how to get started with this framework in Visual Studio in an attempt to start addressing the lack of info regarding this promising framework.&lt;/p&gt;
&lt;h2&gt;The name is Bart Simpson&lt;/h2&gt;
&lt;p&gt;Rather than the traditional 'Hello World' app, WebRx's 'Getting Started' guide displays a page stating 'The name is Bart Simpson'. This is done in order to demonstrates the MVVM separation of concerns through the use of a view bound to an underlying view model which provides the name 'Bart Simpson'.&lt;/p&gt;
&lt;p&gt;I don't intend to cover the entirety of the getting started guide here, merely the additional/different steps needed to get the project work from Visual Studio. As such, I suggest &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;opening the guide&lt;/a&gt; in a browser and leaving it open while working through the steps below as I will be referring to it extensively.&lt;/p&gt;
&lt;p&gt;First up, open Visual Studio. Pretty much any modern version is fine, I am using Visual Studio 2015 Professional. Start a new project and select 'ASP.NET Web Application'&lt;/p&gt;
&lt;img src="/Content/RxWeb/NewAspWebApplication.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="New ASP.NET Web Application"&gt;
&lt;p&gt;In the following dialog, select an empty ASP.NET Template and click ok.&lt;/p&gt;
&lt;img src="/Content/RxWeb/EmptyAsp452Project.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Empty ASP.NET Template"&gt;
&lt;p&gt;Now we have a web project, lets add a reference to WebRx. This can be done using either the Package Manager Console using the command &lt;code&gt;Install-Package WebRx&lt;/code&gt; or via the visual Nuget package manager as shown below:&lt;/p&gt;
&lt;img src="/Content/RxWeb/InstallWebRxPackage.png" class="img-responsive" style="margin: auto; width:66%; margin-top: 6px; margin-bottom: 6px;" alt="Install WebRx Package"&gt;
&lt;p&gt;Regardless of how you add the reference to WebRx, you will be asked whether you wish to 'Search for TypeScript Typings' as shown below. Just click 'Yes'.&lt;/p&gt;
&lt;img src="/Content/RxWeb/AddTypeScriptTypings.png" class="img-responsive" style="margin: auto; width:300px; margin-top: 6px; margin-bottom: 6px;" alt="Add TypeScript Typings"&gt;
&lt;p&gt;You will also be prompted to accept the license aggrement for a number of RxJs packages which WebRx depends upon; you should accept these too.&lt;/p&gt;
&lt;p&gt;One the reference is added, you should find that a Scripts directory has been added to your solution and which contains a number of 'ts' and 'js' files for both WebRx and RxJs. With this in place, we can then continue with the getting started guide by adding an 'index.html' file to the project and copy pasting the sample 'index.html' file from the WebRx &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;getting started guide&lt;/a&gt;. It should look something like this:&lt;/p&gt;
&lt;img src="/Content/RxWeb/CopyPasteIndexFromGettingStarted.png" class="img-responsive" style="margin: auto; width:400px; margin-top: 6px; margin-bottom: 6px;" alt="Copy Paste Index From Getting Started"&gt;
&lt;p&gt;At this point the eagle-eyed amongst you will notice three things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Our scripts are now in a 'bower_modules' directory&lt;br&gt;
As we used Nuget and not bower to install our WebRx dependencies, the script references should be changed to refer to the Scripts directory&lt;/li&gt;
&lt;li&gt;Our scripts directory does not contain a rx.all.js file.&lt;br&gt;
For some reason, WebRx depends on a version of RxJs that does not include an rx.all.js file. To resolve this, simply upgrade to the latest version of RxJs-All, as shown below:
&lt;img src="/Content/RxWeb/UpgradeRxJsAll.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Upgrade RxJs All"&gt;&lt;/li&gt;
&lt;li&gt;We don't have a 'js' folder containing an 'app.js' file.&lt;br&gt;
Because we've not got to that bit yet.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now add a 'js' folder to the solution and add a 'app.js' to it. In this file copy the full 'app.js' sample from the WebRx  &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;getting started guide&lt;/a&gt; as shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;wx.app.component('hello', {
  viewModel: function() {
    this.firstName = 'Bart';
    this.lastName = 'Simpson';
  },
  template: 'The name is &amp;lt;span data-bind="text: firstName + \' \' + lastName"&amp;gt;&amp;lt;/span&amp;gt;'
});

wx.router.state({
  name: "$",
  views: { 'main': "hello" }
});

wx.router.reload();

wx.applyBindings();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save all, set 'index.html' as the start page and hit F5. If everything went as planned you should now see 'The name is Bart Simpson' displayed in your default browser:&lt;/p&gt;
&lt;img src="/Content/RxWeb/TheNameIsBartSimpson.png" class="img-responsive" style="margin: auto; width:400px; margin-top: 6px; margin-bottom: 6px;" alt="The Name Is Bart Simpson"&gt;
&lt;p&gt;And that's it. While the getting started example doesn't seem very complex, it does show a separation of view and view model. I'm very much looking forward to digging into the details of this very promising framework.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/WebRxWithAsp4"&gt;completed project&lt;/a&gt; for this post can be found in my &lt;a href="https://github.com/ibebbs/BlogProjects"&gt;BlogProjects repository&lt;/a&gt; on &lt;a href="https://github.com/ibebbs"&gt;Github&lt;/a&gt;&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;So, I have recently found myself with a need to dive into the depths of modern web-development and, as I am currently looking to write a highly interactive single-page web application, the first thing to decide on was a client side framework to use. You won't have to read too many of my blog posts to realise that I'm a big fan of &lt;a href="https://msdn.microsoft.com/en-us/data/gg577609.aspx?f=255&amp;amp;MSPPError=-2147217396"&gt;Rx&lt;/a&gt;. I am also keen on the MVVM approach to separating concerns when writing user interfaces. Therefore, during my research of modern web UI frameworks, I was extremely interested when I came across &lt;a href="http://webrxjs.org/"&gt;WebRx&lt;/a&gt; .&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarf" />
		<id>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarf</id>
		<title>A sentiment(al) analysis of why Red Dwarf is no longer funny</title>
		<updated>2017-01-31T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Yesterday I had a lot of fun playing with &lt;a href="http://jupyter.org/"&gt;Project Jupyter&lt;/a&gt;. For those that aren't aware of this project, it's an effort to provide a workspace for performing repeatable experimentation with data. In short it mixes markdown editing capabilities with a &lt;a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;REPL&lt;/a&gt; environment for a large number of languages. From the website:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, machine learning and much more"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After having my interest tweaked by the &lt;a href="https://try.jupyter.org/"&gt;browser version&lt;/a&gt; I bit the bullet and spent ages downloading and installing the &lt;a href="http://jupyter.org/install.html"&gt;full version&lt;/a&gt; to a virtual machine. It's a Python based web-app so requires quite a bit of setup and unfortunately I found the documentation to be a bit sparse.&lt;/p&gt;
&lt;p&gt;And so it was that while trying to work out how to install the &lt;a href="https://github.com/fsprojects/IfSharp"&gt;FSharp module&lt;/a&gt; I came across &lt;a href="https://notebooks.azure.com/"&gt;Azure Notebooks&lt;/a&gt;. This is a free, Azure hosted version of Jupyter that has almost all the features of a local installation but with none of the faff. After quickly spinning up a new notebook here I didn't even look back at the local installation.&lt;/p&gt;
&lt;h2&gt;A Jupyter [Data] Mining Core Project&lt;/h2&gt;
&lt;p&gt;As per the title and lead of this post, I decided to use Jupyter to have a little fun.&lt;/p&gt;
&lt;p&gt;Back in September, while grinding my way through &lt;a href="http://www.imdb.com/title/tt0094535/episodes?season=11&amp;amp;ref_=tt_eps_sn_11"&gt;season 11 of Red Dwarf&lt;/a&gt;, I began to wonder why it wasn't as funny as it used to be. Had the writing deteriorated? Were the actors past it? Or were these elements still as great as they used to be and it was me who had changed?&lt;/p&gt;
&lt;p&gt;I started thinking about ways this could be investigated such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using IMDB rating as a measure of humour in each episode of Red Dwarf&lt;/li&gt;
&lt;li&gt;Performing semantic analysis of episode's transcript to see if the sentiment had changed&lt;/li&gt;
&lt;li&gt;Using word-count to determine whether there was a correlation between character participation and overall humour&lt;/li&gt;
&lt;li&gt;etc&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, it was a funny notion and provided a pleasant distraction from the &lt;a href="http://www.imdb.com/title/tt5218266"&gt;pretty awful episode&lt;/a&gt; of Red Dwarf I was watching at the time. I added it to my "ideas" list in &lt;a href="https://trello.com/b/KoTWuFUi/public-board"&gt;Trello&lt;/a&gt;, finished the episode and went to bed.&lt;/p&gt;
&lt;p&gt;Yesterday, when I came across Project Jupyter, I knew it'd be a great medium for performing this investigation so shifted the analysis from "Ideas" to "In progress" and got cracking.&lt;/p&gt;
&lt;h2&gt;Data Science using F#&lt;/h2&gt;
&lt;p&gt;Now, while in relation to this investigation I use the term "data science" to basically mean "munging a few numbers and drawing a few graphs", I do think F# makes a fantastic language for the discipline in general. It has some incredible mechanisms for &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/fsharp/tutorials/type-providers/"&gt;acquiring&lt;/a&gt; and &lt;a href="http://fsharpforfunandprofit.com/posts/the-option-type/"&gt;cleaning&lt;/a&gt; data as well as for &lt;a href="http://www.quanttec.com/fparsec/"&gt;parsing natural language&lt;/a&gt;. Couple this with it's concise, functional, elegant language and the ability to leverage components from the entire breadth of .NET ecosystem and you have quite a significant offering.&lt;/p&gt;
&lt;h2&gt;Azure Notebooks&lt;/h2&gt;
&lt;p&gt;The Azure implementation of Project Jupyter is first class and, for now at least, totally free. Getting started is as simple as logging in with Microsoft credentials and then clicking 'Add notebook'. Being an MS implementation, I used Edge to edit the notebook and found the experience extremely robust, especially given it's a "Preview" program.&lt;/p&gt;
&lt;p&gt;In fact I experience just two issues while authoring my notebook:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data Store - It's not currently possible to upload or store data within the Azure notebook library (despite having functionality to do this in the web-interface). Instead you need to host your data on one of a small number of whitelisted sites. Fortunately Github is one of these sites so this doesn't prove to be much of an issue.&lt;/li&gt;
&lt;li&gt;Packages - While Azure Notebooks provides access to a large number of packages "out-of-the-box" (i.e. FSharp.Data, XPlot.Plotly, etc) it can be tricky to add/use other packages. For example, I wanted to use the XPlot.GoogleCharts package (as it provided trendline capabilities) and ended up having to write a custom display printer for it to work (due to an &lt;a href="https://github.com/fsprojects/IfSharp/issues/118"&gt;open issue&lt;/a&gt; on Github).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Apart from these issues, authoring and scripting F# in an Azure Notebook was almost as fast as using &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/fsharp/tutorials/fsharp-interactive/"&gt;"F# Interactive"&lt;/a&gt;. It even provides Intellisense capabilities but, in practice, these are usually too slow to be of actual use.&lt;/p&gt;
&lt;h2&gt;Sharing Notebooks&lt;/h2&gt;
&lt;p&gt;From Azure Notebooks you're able to download your notebook as a native ".ipynb" file (in fact this is encouraged as MS reserves the right to remove unused notebooks after 60 days). You can then share this file to other people who have Jupyter installed or, preferably, commit it to a repository in Github which has excellent support for Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;You can find my notebook "A sentiment(al) analysis of why Red Dwarf is no longer funny (to me)" &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis/blob/master/Investigation.ipynb"&gt;here&lt;/a&gt;. As you will see when you click the link, Github not only shows you the static parts of the notebook but actually tries to spin up a kernel and execute the code parts too. This is a "limited rendering only" so Github also provides a link to open the notebook in 'nbviewer' &lt;a href="http://nbviewer.jupyter.org/github/ibebbs/RedDwarfAnalysis/blob/2712285e1f9c69fc347bdfe6404792101eaea5f1/Investigation.ipynb"&gt;web-app&lt;/a&gt;. This link is shown below:&lt;/p&gt;
&lt;img src="https://mvpfyw-dm2306.files.1drv.com/y3mppldGfaYEhvWkV7mdUw26-lP3SOzlMTGFbf8slchIfjBL57IH-GrJev6ai_rISiHBKrom7Abg9YFjfhZ1ArOFT7a7mh4gJuGq-CErv1dun48GQC_BdhMV08fh6hbw400d9nHSEXJ0jA2nPBIrpOPNrOz0I3lVY1tu_L656ylQKg?width=660&amp;amp;height=283&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660; margin-top: 6px; margin-bottom: 6px;" alt="Open external view with nbviewer"&gt;
&lt;h2&gt;The analysis&lt;/h2&gt;
&lt;p&gt;I had timeboxed my investigation into Project Jupyter and therefore didn't get round to performing an actual sentiment anaylsis of the content of each episode. However I did manage to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Programmatically download episode information from several sources in JSON format and use &lt;a href="http://fsharp.github.io/FSharp.Data/library/JsonValue.html"&gt;JsonValue&lt;/a&gt; to dynamically query these sources&lt;/li&gt;
&lt;li&gt;Scrape demographically categorized rating information from IMDB and use &lt;a href="http://fsharp.github.io/FSharp.Data/reference/fsharp-data-htmldocument.html"&gt;HtmlDocument&lt;/a&gt; to parse the data into strong types&lt;/li&gt;
&lt;li&gt;Resolve issue with rendering XPlot.GoogleCharts charts within the notebook and use these charts to provide an interactive visualisation of the decline in rating of Red Dwarf across time and demographic categories.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This provided a fair stab at correlating episode rating with the overall decline in Red Dwarf's humourousness but is a long way short of any form of "data science". It was both enlightening and a lot of fun doing this small project and I will certainly consider Azure Notebooks as a valuable tool in my toolbox.&lt;/p&gt;
&lt;p&gt;Should I find the time, I would certainly like to return to this project and use &lt;a href="http://www.quanttec.com/fparsec/"&gt;FParsec&lt;/a&gt; and &lt;a href="https://azure.microsoft.com/en-gb/services/cognitive-services/text-analytics/"&gt;Azure Text Analytics&lt;/a&gt; to perform an actual sentiment analysis. Hopefully it'll overturn, or at least help justify, my somewhat disturbing conclusion!&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Yesterday I had a lot of fun playing with &lt;a href="http://jupyter.org/"&gt;Project Jupyter&lt;/a&gt;. For those that aren't aware of this project, it's an effort to provide a workspace for performing repeatable experimentation with data. In short it mixes markdown editing capabilities with a &lt;a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;REPL&lt;/a&gt; environment for a large number of languages. From the website:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartIII" />
		<id>http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartIII</id>
		<title>Home Network Monitoring - Part III</title>
		<updated>2016-04-12T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;In the last post, I configured Logstash to extracted source and destination address information from the "Client Access Log" Syslog messages sent by my router and added a number of visualizations to my Kibana dashboard which allow me to explore which local devices are access which remote servers.&lt;/p&gt;
&lt;p&gt;While this is already very useful, it's almost impossible to remember which devices relate to which IP addresses on the local network, let alone the on the internet. As such, I really want the ability to translate the IP addresses (and, ideally, port numbers) into device, host or protocol names.&lt;/p&gt;
&lt;h1&gt;translating remote ip addresses to host names&lt;/h1&gt;
&lt;p&gt;When a local device accesses a remote server it will, ordinarily, do so by resolving an IP address for a host name, for example 'google.com' resolves to the address '216.58.213.110'. On my network, my router acts as a DNS server, resolving names it knows and forwarding unresolved names to Googles DNS servers. A the results of the host name to IP address lookup are cached in the DNS server (e.g. my router) I can perform a &lt;a href="https://en.wikipedia.org/wiki/Reverse_DNS_lookup"&gt;reverse DNS lookup&lt;/a&gt; at very little processing cost and without consuming any WAN bandwidth.&lt;/p&gt;
&lt;p&gt;As usual, Logstash comes with a filter that is able to perform this operation called, unsurprisingly, 'dns'. However, to provide a consistent set of fields to Kibana, it requires a couple of additional steps to ensure it functions consistently. Here is the amended &lt;code&gt;syslog.config&lt;/code&gt; with the reverse DNS lookup in place.&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;input {
  tcp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
  udp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
}

filter {
    grok {
        match =&amp;gt; [ "message", "&amp;lt;%{POSINT:syslog_pri}&amp;gt;%{SYSLOGTIMESTAMP:syslog_timestamp} Vigor\: Local User \(MAC=%{MAC:source_mac}\): %{IP:source_address}(?::%{POSINT:source_port})? -&amp;gt; %{IP:destination_address}(?::%{POSINT:destination_port})? \((?&amp;lt;protocol&amp;gt;TCP|UDP)\)" ]
        add_tag =&amp;gt; "access"
    }
    if "access" in [tags] {
        mutate {
            add_field =&amp;gt; {
              "destination_host" =&amp;gt; "%{[destination_address]}"
            }
        }
        dns {
            reverse =&amp;gt; [ "destination_host" ]
            action =&amp;gt; "replace"
            nameserver =&amp;gt; "192.168.1.1"
        }
    }
}

output {
  elasticsearch {
    hosts =&amp;gt; ["192.168.1.30:9200"]
    index =&amp;gt; "syslog-%{+YYYY.MM.dd}"
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that, when an 'access' message is successfully grokked, I add a tag to the tags array field of the message called "access". If another type of message has been received (i.e. a DNS lookup) then the grok pattern won't match and the 'access' tag will not be added to tags.&lt;/p&gt;
&lt;p&gt;After the &lt;code&gt;grok&lt;/code&gt; filter, I check to see if the tags field contains the 'access' tag and, if so, use the &lt;code&gt;mutate&lt;/code&gt; filter to copy the 'destination_address' field value into a 'destination_host' field. This is done as the &lt;code&gt;dns&lt;/code&gt; filter will replace the field value if a successful reverse DNS lookup is performed but will leave the original value (i.e. the IP address) if a reverse DNS could not be performed. This way we either get the host name or IP address in the 'destination_host' field and it's never empty.&lt;/p&gt;
&lt;p&gt;With the changes to configuration in place, I restart Logstash. Then, in Kibana, I refresh the field list for the 'syslog-*' index, add 'destination_host' to the 'Syslog Messages' saved search, load 'Access By Destination Address' visualization and modify it to use 'destination_host' rather than the 'destination_address' field; and get the following:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-AccessByDestinationHostAnalysedVisualization.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Access By Destination Host Analysed Visualization"&gt;
&lt;p&gt;While initially it looks promising, a quick look at the list of hosts being accessed shows something peculiar: the domain names have been split into their component parts.&lt;/p&gt;
&lt;h1&gt;analysis, mappings and templates&lt;/h1&gt;
&lt;p&gt;The reason for the host names being split is because, by default, ElasticSearch performs 'analysis' on text strings. This analysis involves splitting the strings into discrete words which can be indexed more efficiently. Some strings however, for example domain names, should be treated as a single word and as such we need to prevent ElasticSearch from performing the analysis.&lt;/p&gt;
&lt;p&gt;How ElasticSearch treats various fields within a message can be controlled by modifying the index mapping. The current mapping for the 'syslog' index can be retrieved by a REST call to the address 'http://[ElasticSearchHost]:9200/syslog-2016.04.12/_mapping'. This returns:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
    "syslog-2016.04.12": {
        "mappings": {
            "syslog": {
                "properties": {
                    "@@timestamp": {
                        "type": "date",
                        "format": "strict_date_optional_time||epoch_millis"
                    },
                    "@@version": {
                        "type": "string"
                    },
                    "destination_address": {
                        "type": "string"
                    },
                    "destination_host": {
                        "type": "string"
                    },
                    "destination_port": {
                        "type": "string"
                    },
                    "host": {
                        "type": "string"
                    },
                    "message": {
                        "type": "string"
                    },
                    "protocol": {
                        "type": "string"
                    },
                    "source_address": {
                        "type": "string"
                    },
                    "source_mac": {
                        "type": "string"
                    },
                    "source_port": {
                        "type": "string"
                    },
                    "syslog_pri": {
                        "type": "string"
                    },
                    "syslog_timestamp": {
                        "type": "string"
                    },
                    "tags": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    }
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to prevent ElasticSearch from analysing the 'destination_host' field, we need to add an 'index' key with the value 'not_analyzed'. Even though things have been mostly working correctly so far, I can save quite a bit of storage and processing time by marking almost all of the string fields as 'not_analyzed'. This is shown below:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
    "syslog-2016.04.12": {
        "mappings": {
            "syslog": {
                "properties": {
                    "@@timestamp": {
                        "type": "date",
                        "format": "strict_date_optional_time||epoch_millis"
                    },
                    "@@version": {
                        "type": "string"
                    },
                    "destination_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_port": {
                        "type": "integer"
                    },
                    "host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "message": {
                        "type": "string"
                    },
                    "protocol": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_mac": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_port": {
                        "type": "integer"
                    },
                    "syslog_pri": {
                        "type": "integer"
                    },
                    "syslog_timestamp": {
                        "type": "string"
                    },
                    "tags": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    }
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, while I could write this mapping directly to the ElasticSearch index, as the index is date-based, I'd have to resend the mapping manually everyday. Instead, I am going to create a mapping template that will match an index name based on pattern and automatically apply the template. This is done by crafting a PUT call to the ElasticSearch '_template' endpoint with the specific template name. In short, the following mapping template is posted to &lt;code&gt;http://[ElasticSearch:9200]/_templates/syslog_template&lt;/code&gt;&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
        "template": "syslog-*",
        "mappings": {
            "syslog": {
                "properties": {
                    "@@timestamp": {
                        "type": "date",
                        "format": "strict_date_optional_time||epoch_millis"
                    },
                    "@@version": {
                        "type": "string"
                    },
                    "destination_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "destination_port": {
                        "type": "integer"
                    },
                    "host": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "message": {
                        "type": "string"
                    },
                    "protocol": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_address": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_mac": {
                        "type": "string",
                        "index" : "not_analyzed"
                    },
                    "source_port": {
                        "type": "integer"
                    },
                    "syslog_pri": {
                        "type": "integer"
                    },
                    "syslog_timestamp": {
                        "type": "string"
                    },
                    "tags": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    }
                }
            }
        }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this in place I need to delete todays syslog index so that it is recreated, using the mapping above, when the first syslog message is received. Once this has been done, the visualization looks like this:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-AccessByDestinationHostNotAnalysedVisualization.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Access By Destination Host Not-Analysed Visualization"&gt;
&lt;p&gt;Nice!&lt;/p&gt;
&lt;h1&gt;summary&lt;/h1&gt;
&lt;p&gt;In this post, I showed how to display host names for accessed servers rather than IP addresses. I also covered how to update ElasticSearch mapping such that field 'analysis' can be prevented and host names kept together.&lt;/p&gt;
&lt;p&gt;In the next post, I'll show how to translate local device IP addresses in to device names.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In the last post, I configured Logstash to extracted source and destination address information from the "Client Access Log" Syslog messages sent by my router and added a number of visualizations to my Kibana dashboard which allow me to explore which local devices are access which remote servers.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/UWPCommunityToolkitv1_1" />
		<id>http://ian.bebbs.co.uk/posts/UWPCommunityToolkitv1_1</id>
		<title>UWP Community Toolkit v1.1 Released</title>
		<updated>2016-10-10T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Shortly after my blog post about &lt;a href="http://ian.bebbs.co.uk/posts/UsingHyperlinkInMVVM"&gt;Using a Hyperlink in MVVM&lt;/a&gt; a group of developers at Microsoft collated and released the &lt;a href="https://blogs.windows.com/buildingapps/2016/08/17/introducing-the-uwp-community-toolkit/#pRVgJbZbTBMHPyGG.97"&gt;UWP Community Toolkit&lt;/a&gt;. They were actively asking for contributions and, given the self contained nature of the Hyperlink extension, it seemed like a natural fit for the toolkit so I decided to try contributing it via pull request.&lt;/p&gt;
&lt;p&gt;The toolkit's contribution guidelines and conventions closely matched my own coding style so I had to change very little of the code in my article but did have to add XML summary blocks to each public class and members. With that done I could add the class to the &lt;a href="https://github.com/ibebbs/UWPCommunityToolkit/tree/dev/Microsoft.Toolkit.Uwp/Helpers"&gt;Helpers folder on the dev branch of my fork of the toolkit&lt;/a&gt; and &lt;a href="https://github.com/Microsoft/UWPCommunityToolkit/pull/226"&gt;issue a pull request&lt;/a&gt;. I was also asked to produce some documentation and a sample for the class which was then pulled into the document repo.&lt;/p&gt;
&lt;p&gt;The rest, as they say, is history. &lt;a href="https://blogs.windows.com/buildingapps/2016/10/05/announcing-uwp-community-toolkit-1-1/#1QBL3lQjtLbY537i.97"&gt;Version 1.1 of the toolkit released&lt;/a&gt; with yours truly in the &lt;a href="https://github.com/Microsoft/UWPCommunityToolkit/releases/"&gt;list of contributors&lt;/a&gt;. It's a small contribution but I really think the toolkit is a promising project and absolutely intend to contribute further in the near future.&lt;/p&gt;
&lt;p&gt;In the mean time, well done to all the maintainers of, and contributors to, the toolkit on this important milestone.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Shortly after my blog post about &lt;a href="http://ian.bebbs.co.uk/posts/UsingHyperlinkInMVVM"&gt;Using a Hyperlink in MVVM&lt;/a&gt; a group of developers at Microsoft collated and released the &lt;a href="https://blogs.windows.com/buildingapps/2016/08/17/introducing-the-uwp-community-toolkit/#pRVgJbZbTBMHPyGG.97"&gt;UWP Community Toolkit&lt;/a&gt;. They were actively asking for contributions and, given the self contained nature of the Hyperlink extension, it seemed like a natural fit for the toolkit so I decided to try contributing it via pull request.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ToddlerBoxTopsTenThousandUsers" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mVAxtKFjUEGk7Hdhzjl4UZ2INnFdBbw9K-tnYZ8DYoJ-VoKxpAN6w8Ng0DFTYdSxpHY6IvL5-VwJpLkQl6qWRmMQXSExLXopz5CFuSxIbyaMLrnL2Vy3yPZlISAAknXZdT4HwiZJ55zg2UtKwucBL88-xHh6rn5Mh97yzfRsCPjI%253Fwidth=1024&amp;height=574&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/ToddlerBoxTopsTenThousandUsers</id>
		<title>ToddlerBox Tops 10,000 Users!!</title>
		<updated>2016-12-20T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Really that got out of hand fast! I had no idea so many people would be interested in letting their toddler loose on their XBox controller. In fact, there have been many things that have surprised me about this app:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Acquisition rate has increased&lt;/p&gt;
&lt;p&gt;I kind of expected an initial burst of acquisitions then a slow tail off but this hasn't happened. As it's only been a little over a month since ToddlerBox was released to the store, I guess there's every possibility that it's still in the "burst" stage and theres just more interest in apps of this type. Well, here's hoping.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reviews have been extremely polarized&lt;/p&gt;
&lt;p&gt;Almost without exception, reviews have been 4-5 stars or 1 star. Also, while a couple of the 1 star ratings are to do with app functionality (it seems a couple of people have issues running even this basic UWP app) the overwhelming majority of 1 star ratings are due to peoples dislike of ads; because...&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ads are a very risky business&lt;/p&gt;
&lt;p&gt;As with most parents, I am extremely cautious about what my toddler is exposed to. Therefore I was extremely cautious about adding advertising as a means of revenue to ToddlerBox, regardless of how small or out of the way they were.
After completing the Ad-Mediation questions in the Windows Store and being assured that ads would be both age rated and not "tracking", I felt a lot better about the idea and decided a small banner ad on the instructions screen would be pretty harmless. Furthermore, throughout the process of adding the banner, I didn't see a single advert I would be concerned about putting in front of my child; most were simple flashing inbox icons or the like.
However, after discussing ToddlerBox with a friend, he decided to install it on his Xbox and I was very upset to see that the ads being displayed were both more intrusive and more "click-baity" than any I had seen previously. I am now investigating ways to generate some revenue from the app but without upsetting parents.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The reviews shown in the store are not "all reviews"&lt;/p&gt;
&lt;p&gt;As the publisher of ToddlerBox, I get to see all reviews left about the app on the store. Due to all the previous points, the app is currently averaging about a 2.6 star rating across 50 odd reviews. However, when viewing the app in the Store on my friend's XBox, it was shown as having a 4.5 star rating from just 2 reviews. Now, while some of the reviews I can see are translated from foreign languages, most are in English and I'm therefore at a loss to explain why they're not being displayed when an XBox in the English local browses the store.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It's not just toddlers using ToddlerBox&lt;/p&gt;
&lt;p&gt;I've had more than one review stating how good this game is to play after consuming various illicit substances ;0P&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Anyway, as described above, while acquisition rate has fluctuated on a daily basis, the overall trend in acquisition shows unexpected growth:&lt;/p&gt;
&lt;img src="https://bnljqq-dm2306.files.1drv.com/y3msqT1msmkJ_32Jewx8Ysuoys0lC35GCLY-aQPyJ9YhR75KMswOLcznSPGOOBGhhsMRb6qK3_xh_qr3h1Xh-vFwmSog1_HoOS-Isj1lMoFPpuV42oAwJi3A5JiY-ToAirVoZDnz2gQ7N6jUed82zW83IZ_qQcbqWGw1ekaNh4wjBU?width=660&amp;amp;height=252&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Acquisitions over App Lifetime"&gt;
&lt;p&gt;Daily usage also shows that a healthy number of acquisitions are being used regularly, with nearly 800 people using ToddlerBox nearly 1700 times just yesterday (19th December):&lt;/p&gt;
&lt;img src="https://bnlkqq-dm2306.files.1drv.com/y3mBC-i0nboWq0ibRyIcBhs1O2MnfOUx-OxTQZDUNHbh-eVRbfH0xP9-p9hLJqC82i1SBB5ZfpcfmTlvuZwMBD-Gt0BZZC-IvVCJOd1jzexDoiC-BV4LG7X2aOyOapkCKK6wM6WWffluiuD5MKKet6MfEIjTWNZMCpFx1FP13suiCY?width=660&amp;amp;height=249&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Daily usage"&gt;
&lt;p&gt;So, the Xmas break is almost upon us and I will be returning my attention to ToddlerBox (yes, despite the career break, I try to spend most of my time working on 'serious' projects or study). I have a number of new features in mind for it (including the #1 requested feature of "sound!!") and will be looking to try out a couple of more features of the awesome Win2D library. It's going to be a lot of fun (for me and my little girl) and will hopefully allow ToddlerBox to reach the next major (although admittedly arbitrary) milestone of 25,000 acquisitions!&lt;/p&gt;
&lt;p&gt;Watch this space...&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Really that got out of hand fast! I had no idea so many people would be interested in letting their toddler loose on their XBox controller. In fact, there have been many things that have surprised me about this app:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/RxWebWithTypescript" />
		<id>http://ian.bebbs.co.uk/posts/RxWebWithTypescript</id>
		<title>WebRx and Typescript</title>
		<updated>2016-03-08T00:00:00Z</updated>
		<content>
                                        


&lt;h1&gt;Continuing with WebRx&lt;/h1&gt;
&lt;p&gt;In &lt;a href="./posts/RxWeb"&gt;part 1&lt;/a&gt; of this series I showed how to set up a project structure that allows you to start using WebRx from within Visual Studio. While fairly simple, the example provides a great illustration of you how WebRx allows you to separate your view and view model.&lt;/p&gt;
&lt;p&gt;In this article I further develop the structure to allow you to develop your application using Typescript.&lt;/p&gt;
&lt;h1&gt;From 'app.js' to 'app.ts'&lt;/h1&gt;
&lt;p&gt;Previously we copied a chunk of JavaScript from the WebRx &lt;a href="http://webrxjs.org/docs/getting-started.html"&gt;getting started guide&lt;/a&gt; into an &lt;code&gt;app.js&lt;/code&gt; script that was directly used from within the &lt;code&gt;index.html&lt;/code&gt; file. We now want to &lt;a href="https://en.wikipedia.org/wiki/Source-to-source_compiler"&gt;&lt;em&gt;transpile&lt;/em&gt;&lt;/a&gt; the &lt;code&gt;app.js&lt;/code&gt; script from a Typescript file so that we can further develop the application in a structured and type-safe manner.&lt;/p&gt;
&lt;p&gt;To do this simply follow the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Delete the existing &lt;code&gt;app.js&lt;/code&gt; file leaving the &lt;code&gt;js&lt;/code&gt; folder empty.&lt;/li&gt;
&lt;li&gt;Add and configure a &lt;code&gt;TypeScript JSON Configuration File&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Add a &lt;code&gt;TypeScript JSON Configuration File&lt;/code&gt; to the solution as shown below&lt;br&gt;
&lt;img src="/Content/RxWebWithTypescript/AddTypeScriptJsonConfigurationFile.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Add TypeScript Json Configuration File"&gt;&lt;/li&gt;
&lt;li&gt;Replace the &lt;code&gt;node_modules&lt;/code&gt; exclusion with &lt;code&gt;Scripts&lt;/code&gt;&lt;br&gt;
By default Visual Studio (or, more acurately, the TypeScript transpiler) with pick up all &lt;code&gt;ts&lt;/code&gt; files in the solution. As we don't want to attempt to re-transpile all the referenced typescript files we add &lt;code&gt;Scripts&lt;/code&gt; to the exclusion list. Further, as we added a reference to &lt;code&gt;WebRx&lt;/code&gt; via Nuget, our references are in the &lt;code&gt;Scripts&lt;/code&gt; folder, not &lt;code&gt;node_modules&lt;/code&gt;, so this exclusion can be removed.&lt;/li&gt;
&lt;li&gt;Add an &lt;code&gt;outDir&lt;/code&gt; setting to transpile to the &lt;code&gt;js&lt;/code&gt; folder&lt;br&gt;
This setting will force the TypeScript transpiler to output the transpiled JavaScript files to the &lt;code&gt;js&lt;/code&gt; folder where they can be used by the client browser.&lt;/li&gt;
&lt;li&gt;You should now have a &lt;code&gt;tsconfig.json&lt;/code&gt; file that looks like this:
&lt;pre class="prettyprint"&gt;&lt;code&gt;{
  "compilerOptions": {
    "noImplicitAny": false,
    "noEmitOnError": true,
    "removeComments": false,
    "sourceMap": true,
    "target": "es5",
    "outDir": "js"
  },
  "exclude": [
    "Scripts",
    "wwwroot"
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Add a &lt;code&gt;ts&lt;/code&gt; folder to the solution.&lt;/li&gt;
&lt;li&gt;Add an &lt;code&gt;app.ts&lt;/code&gt; typescript file to the &lt;code&gt;ts&lt;/code&gt; folder.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Add references to Rx and WebRx to the &lt;code&gt;app.ts&lt;/code&gt; file.&lt;br&gt;
WebRx requires that you add an explicit reference to &lt;code&gt;rx.all.d.ts&lt;/code&gt; prior to the reference to &lt;code&gt;web.rx.d.ts&lt;/code&gt; in order for the Rx module to be brought into scope. The references should therefore be added like this:
&lt;pre class="prettyprint"&gt;&lt;code&gt;/// &amp;lt;reference path="../Scripts/rx.all.d.ts"/&amp;gt;
/// &amp;lt;reference path="../Scripts/typings/web.rx.d.ts" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Implement view / view model code&lt;br&gt;
You can now re-implement the code from &lt;code&gt;app.js&lt;/code&gt; as TypeScript virtually verbatim but do note how you get Intellisense for all the methods and properties of &lt;code&gt;wx&lt;/code&gt; module.&lt;/li&gt;
&lt;li&gt;Fix compilation error with call to &lt;code&gt;wx.applyBindings&lt;/code&gt;&lt;br&gt;
The &lt;code&gt;wx.applyBindings&lt;/code&gt; method &lt;em&gt;requires&lt;/em&gt; a &lt;code&gt;model&lt;/code&gt; parameter which, in JavaScript, is defaulted but in TypeScript causes a compilation error. To resolve this, simply pass an empty object to the method.&lt;/li&gt;
&lt;li&gt;Your &lt;code&gt;app.ts&lt;/code&gt; file should now look like this:
&lt;pre class="prettyprint"&gt;&lt;code&gt;/// &amp;lt;reference path="../Scripts/rx.all.d.ts"/&amp;gt;
/// &amp;lt;reference path="../Scripts/typings/web.rx.d.ts" /&amp;gt;

wx.app.component('hello', {
    viewModel: function () {
        this.firstName = 'Bart';
        this.lastName = 'Simpson';
    },
    template: 'The name is &amp;lt;span data-bind="text: firstName + \' \' + lastName"&amp;gt;&amp;lt;/span&amp;gt;'
});

wx.router.state({
    name: "$",
    views: { 'main': "hello" }
});

wx.router.reload();

wx.applyBindings({});
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="5"&gt;
&lt;li&gt;Compile the project and include the generated &lt;code&gt;js/app.js&lt;/code&gt; and &lt;code&gt;js/app.js.map&lt;/code&gt; files into the project.&lt;/li&gt;
&lt;li&gt;Hit F5 and you should again see the message 'The name is Bart Simpson' displayed in your default browser.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Congratulations, you're now ready to develop your application using full Intellisense and in the comfort of the knowledge that the compiler (well, transpiler) will pick up any syntactic bugs you may inadvertently create.&lt;/p&gt;
&lt;p&gt;As always, the completed &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/WebRxWithTypeScript"&gt;source code for this post&lt;/a&gt; can be found in the &lt;a href="https://github.com/ibebbs/BlogProjects"&gt;BlogProjects repository&lt;/a&gt; on &lt;a href="https://github.com/ibebbs"&gt;Github&lt;/a&gt;&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In &lt;a href="./posts/RxWeb"&gt;part 1&lt;/a&gt; of this series I showed how to set up a project structure that allows you to start using WebRx from within Visual Studio. While fairly simple, the example provides a great illustration of you how WebRx allows you to separate your view and view model.&lt;/p&gt;</summary>
	</entry>
</feed> types. For example, the method for &lt;code&gt;Event.AccountNameChanged&lt;/code&gt; is implemented as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;public static Func&amp;lt;ReadModel, ReadModel&amp;gt; Apply(Event.AccountNameChanged @@event)
{
    return readModel =&amp;gt; readModel.WithAccountName(@@event.AccountName);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This method takes the event to be processed as a parameter and returns a function in the form &lt;code&gt;Func&amp;lt;ReadModel,ReadModel&amp;gt;&lt;/code&gt; that closes over the parameter and calls the &lt;code&gt;WithAccountName&lt;/code&gt; extension method when executed. A similar pattern is followed for all the other event types.&lt;/p&gt;
&lt;p&gt;Once we have projected and merged all the event streams into a single &lt;code&gt;IObservable&amp;lt;Func&amp;lt;ReadModel, ReadModel&amp;gt;&amp;gt;&lt;/code&gt; we can use the scan function to iteratively apply each function to the cumulative read model instance and emit the result after each event.&lt;/p&gt;
&lt;p&gt;Pretty neat huh!&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;If you're starting out with &lt;a href="http://docs.geteventstore.com/introduction/event-sourcing-basics/" title="Event Sourcing Basics at GetEventStore"&gt;Event Sourcing&lt;/a&gt; you're probably looking for the ability to project events into &lt;a href="http://cqrs.nu/tutorial/cs/03-read-models" title="CQRS tutorial - Read Models"&gt;read models&lt;/a&gt; that can be used by the views in your application. Today I'd like to share a neat little mechanism I've established for building read model in C# by employing a strongly typed yet functional approach.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/MonsterPi" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mJgriVgVEFWAdldfy7Bj9MEJznwpJtJ4NFHotqnwZ0rWbC2h8ewxTr9MSxr6LCGyQBB-TvmYCV9j4YVZbu2EtVHagPnyc6O_LIZV2NqAiPfrfNkZ8P-XBV6SI0GiL7zx0iuOTniKjZ-Gq9_lN6SLkkIMHMx14EE3l2XuZQ1cTPfI%253Fwidth=967&amp;height=273&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/MonsterPi</id>
		<title>MonsterPi</title>
		<updated>2016-10-08T00:00:00Z</updated>
		<content>
                                        


&lt;h2&gt;Preface&lt;/h2&gt;
&lt;p&gt;I've long loved the idea of home automation. From X10 and LightwaveRF through to modern Bluetooth and Wifi connected devices, I have played with dozens of technologies in search of home automation nirvana. But recently I have watched with growing bewilderment at the incredible number of "cloud-connected" home automation devices being released and the eagerness with which they're snapped up by naive consumers hungry to control everything from the carefree comfort of their iPhone.&lt;/p&gt;
&lt;p&gt;You see, while you can buy a myriad of IoT devices off the shelf nowadays, they nearly all come with some form of "cloud-service" that is necessary in order for the device to work as sold. As the more wily of reader will no doubt be aware, this exposes your home network to innumerable &lt;a href="https://it.slashdot.org/story/16/10/03/1359200/source-code-for-iot-botnet-mirai-which-took-down-krebs-on-security-website-with-ddos-attack-released"&gt;security concerns&lt;/a&gt;, &lt;a href="https://it.slashdot.org/story/16/08/08/1449221/hackers-make-the-first-ever-ransomware-for-smart-thermostats"&gt;potential abuses&lt;/a&gt; and an &lt;a href="https://tech.slashdot.org/story/16/01/14/1347243/nest-thermostat-bug-leaves-owners-without-heating"&gt;external point of failure&lt;/a&gt; that cannot be closed/fixed without sacrificing some or all of the functionality of the new fangled device.&lt;/p&gt;
&lt;p&gt;While I understand the ostensible benefits of this approach (ease of setup, remote use without manually opening firewall ports, centralised patching and upgrading, etc), sacrificing control of (potentially hazardous or invasive) devices within my home is not a value proposition I am comfortable with. I would very much like to see a new (or is that old?) breed of device that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;does not require an internet connection to operate with all features intact,&lt;/li&gt;
&lt;li&gt;with which the owner can proactively decide what control and data is available to servers outside of the home network and,&lt;/li&gt;
&lt;li&gt;which surface simple, open interfaces to the owner allowing them to completely control all aspects of the device.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In short, I'd like to drop the 'Inter' from IoT and expand the 'net' to become a 'Network of Things', or NoT.&lt;/p&gt;
&lt;p&gt;In terms of the consumer market, I am undoubtedly swimming against the tide here. Fortunately with the rise of hobbyist devices such as Arduino and RaspberryPi, IoT technologies have been democratised to the extent that anyone with just the smallest ability with a soldering iron and faculty with an IDE can create such devices for themselves.&lt;/p&gt;
&lt;p&gt;Ladies and gentlemen, I present my first (finished) NoT device, the...&lt;/p&gt;
&lt;h1&gt;MonsterPi&lt;/h1&gt;
&lt;p&gt;Years ago, while setting up my (living room) home cinema, I came across the &lt;a href="http://www.adverts.ie/home-audio/monster-hts-1600-home-theatre-powercenter-5-outlet-with-stage-2-clean-power-purge-protector-uk-version/7055360"&gt;Monster Power HTS 1600&lt;/a&gt; on &lt;a href="https://www.scan.co.uk/"&gt;Scan's website&lt;/a&gt;. It seems Monster Products were end-of-lining their power products in the UK (the above link was literally the only one I could find that still works!) and Scan were selling them off at £30 a piece. It was exactly what I was looking for at the time and, not being one to pass up a bargain, I bought two.&lt;/p&gt;
&lt;img src="https://0oiczq.dm2302.livefilestore.com/y3mwcGE45bQwRPaCXRNuB9tGejIT6aSpahgDN02u9ag661uCa_ZmYbNnaKz2aW81rjG8BTgsUhtZ0aDQ8ioIsagbcFP6LtM-IgV_rcPoCs8UI4dZNegv8JembGIuIr7ETkwTZwOTEUjsAAbQHy0jCyAGNkGu3NJZLkXjnGwgzUMlTI?width=700&amp;amp;height=466&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="One of the few remaining pictures online of the Monster Power HTS 1600 UK version"&gt;
&lt;p&gt;Both devices found homes powering and protected my front room and study AV equipment and, to this day, I am still very happy with them. However, I always felt that Monster had missed a trick with this product: the ability to individually and - ideally - remotely turn each of the sockets on the unit on and off as desired.&lt;/p&gt;
&lt;p&gt;When Microsoft announced that Windows IoT Core would run on a RaspberryPi the learning curve ahead of making this happen evaporated and I knew it was something I wanted to do. Unfortunately both Monster Power devices were in full time use and I didn't want to potentially sacrifice one on a project that might not work and could consign the device to the scrap yard. Given that you couldn't purchase the UK version of these devices any more and that, when they occasionally appeared on eBay, they'd invariably be priced at £100+ the project was indefinitely parked.&lt;/p&gt;
&lt;p&gt;Finally, a couple of months ago, a 'used' one appeared on eBay without a reserve and with bidding at thirty odd quid having just a few hours to go. I placed a bid without really hoping it would be successful and, to my surprise, ended up winning the auction for £40'ish including delivery. When it arrived I was delighted to find that it seemed to be brand new and unused (twisty wire on all the cables, supplementary cables still in sealed bags, etc). Plugging it in proved that everything worked as it should so everything was in place to build the MonsterPi.&lt;/p&gt;
&lt;h2&gt;Software&lt;/h2&gt;
&lt;p&gt;While waiting for the time and space required to start hacking up the hardware, I took a look into what was required to write a headless UWP app, self-hosting a HTTP REST endpoint that could be deployed to the RaspberryPi and set values on the GPIO pins necessary to control the &lt;a href="http://www.waveshare.com/rpi-relay-board.htm"&gt;Waveshare RaspberryPi Relay Board&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It didn't take long to find &lt;a href="https://github.com/tomkuijsten/restup"&gt;Restup&lt;/a&gt;, a beautifully simple if somewhat minimal 'Webserver for Universal Windows Apps'. The github repository provided ample samples for writing various types of 'controller' and in less than an hour, I had a working solution.&lt;/p&gt;
&lt;p&gt;Given the Waveshare relay board just required GPIO pins to be set in order to control the relay (low to close, high to open) this was achieved very simply using the classes available in the &lt;a href="https://msdn.microsoft.com/library/windows/apps/windows.devices.gpio.aspx"&gt;Windows.Devices.Gpio namespace&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Deployment was taken care of by Visual Studio and configuration performed using the Windows IoT Core Device Portal. The Device Portal allows you to configure deployed apps to run at start up thereby creating a "service-like" experience for headless apps.&lt;/p&gt;
&lt;img src="https://0oidzq.dm2302.livefilestore.com/y3myuJMpQJ0iee-DzmucnuUu2r69IZ2c_KNukHEjoPB0--qRcndLbk0EwUszv8MLYj207fNIWEelQn4TYtW40FVp_y77RW-aTL3AcxQWcowLMB_zsw9jYdH0SwepJ0l6_XC0z9erqkYt4k4TaUBdnqxPYUlSf786xKVx1zwTC4jEsg?width=1363&amp;amp;height=905&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Using the device portal to set Start-up apps"&gt;
&lt;p&gt;Full source code is available on my &lt;a href="https://github.com/ibebbs/MonsterPi"&gt;Github account&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Hardware&lt;/h2&gt;
&lt;p&gt;The hardware side of things proved to be both easier and more tricky than I expected.&lt;/p&gt;
&lt;p&gt;Initially I thought fitting the Pi was going to be child's-play when, upon opening the Monster Power chasis I found that the configuration of sockets providing isolation for RJ11 and RJ45 devices (phone and ethernet respectively) matched the layout of the ethernet and USB connectors of the Pi almost perfectly. Furthermore, these sockets were mounted on an easily removable daughter-board providing an obvious way to fix the pi in place.&lt;/p&gt;
&lt;img src="https://nhtcwg.dm2302.livefilestore.com/y3mKq_74GixCoND7XvyavcDTjnNPdW2xd58RqEk1KZtO4f8nqKhcwyGbMRJqYhtuIHOmJCrJo6O-pltKB1pW0DFAHNy2oi6CNuyOle6TUxrjb4UzQo5_uDIPhNAP1uF8llVVLds4J6Bcp5b2s0GRI_T1uLx__qES0eUimFSxaTWddk?width=1024&amp;amp;height=576&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="The sockets on the RaspberryPi aligned almost perfectly with the RJ11 isolator sockets"&gt;
&lt;p&gt;While alignment wasn't perfect, filing the holes in the chasis to provide access to all ports would be easy.&lt;/p&gt;
&lt;p&gt;Complexity came when I realised that, although the Monster Power included a micro-controller driven digital display, it was unlikely that the DC subsystem in place to power this would be adequate for the RaspberryPi. So here I had to get creative.&lt;/p&gt;
&lt;p&gt;I bought a small &lt;a href="https://www.amazon.co.uk/gp/product/B01H0OH3PI/ref=oh_aui_detailpage_o02_s01?ie=UTF8&amp;amp;psc=1"&gt;12v 80W switching power supply&lt;/a&gt; which would fit down one side of the Moster Power chasis and wired it to the 240v input of using the conveniently provided ring terminals. I used a &lt;a href="http://ian.bebbs.co.uk/posts/3DPrintingWithTheCelRobox"&gt;custom printed bracket&lt;/a&gt; to secure the PSU in place while providing a platform to mount the &lt;a href="http://www.waveshare.com/rpi-relay-board.htm"&gt;Waveshare RaspberryPi Relay Board&lt;/a&gt; above, in close proximity to the sockets I wanted to control with the relays.&lt;/p&gt;
&lt;p&gt;The live wire to the three sockets to be controlled by relays were daisy-chained together so one side of this wire was cut from each socket and connected to the normally-closed output of the relay (extending where necessary using crimp connectors).&lt;/p&gt;
&lt;p&gt;This is shown below:&lt;/p&gt;
&lt;img src="https://zphbnq.dm2302.livefilestore.com/y3mBGmj_-221eHr5ChhkWQfyEOjewU-6JEKOKlqHR-UqR0eMZdf2xPtI5qfP_K1rjguEplhOWObkMJ2fiGI4T4WSQOGh8GfodMLL2lPWD5QZFnBFPYwPUID3FZgVTYndwwL5jDybtRBC6JE_hhcTokWGrmppuLoHccNLsmFZyUsAvM?width=576&amp;amp;height=1024&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="12v switching PSU with relay board mounted in custom bracket"&gt;
&lt;p&gt;While the perspective in the picture makes it look like it hangs over the edge of the chasis, it does actually fit. It's tight, but it fits.&lt;/p&gt;
&lt;p&gt;I used a &lt;a href="https://www.amazon.co.uk/gp/product/B01CUA5Q74/ref=oh_aui_detailpage_o02_s00?ie=UTF8&amp;amp;psc=1"&gt;12V To 5V 3A 15W Power Converter Regulator with Micro USB Cable&lt;/a&gt; to power the RaspberryPi and - given I now had plenty of power to spare, decided to also fit the &lt;a href="https://www.amazon.co.uk/Step-Down-Step-down-Power-Module/dp/B00ENE55SQ/ref=pd_nav_hcs_bia_t_1?ie=UTF8&amp;amp;psc=1&amp;amp;refRID=J91844QA901NNMPP9XHJ"&gt;4-port USB power module&lt;/a&gt; I had bought, but not used, for our &lt;a href="http://ian.bebbs.co.uk/posts/WotNoBlogPosts"&gt;travels earlier in the year&lt;/a&gt;. Again, this aligned almost perfectly in the remaining holes in the Monster Power chasis.&lt;/p&gt;
&lt;img src="https://nhtcwg.dm2302.livefilestore.com/y3mKq_74GixCoND7XvyavcDTjnNPdW2xd58RqEk1KZtO4f8nqKhcwyGbMRJqYhtuIHOmJCrJo6O-pltKB1pW0DFAHNy2oi6CNuyOle6TUxrjb4UzQo5_uDIPhNAP1uF8llVVLds4J6Bcp5b2s0GRI_T1uLx__qES0eUimFSxaTWddk?width=1024&amp;amp;height=576&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="The sockets on the USB power module aligned almost perfectly with the RJ11 isolator sockets"&gt;
&lt;p&gt;Both these were mounted - upside down - on a custom printed bracket using the screw holes for the original daughter board to secure it in place. Terminal connectors were used to provide connection to the power supply just in case I needed to remove the components at a later date for some reason.&lt;/p&gt;
&lt;img src="https://zphcnq.dm2302.livefilestore.com/y3mMyQU1JCq5r9g0pnmuLGrrVm1-_D8Bq9UVm5uZgUD2lx9t3LVnjEIgWzqzwKeKbju29iHfBntmTX0FPZFKzWK6RAnFwWw-rxMfWyslJf52FN4XkFlglfGHc97-z24asPfR-NLEAd8nEE9e8X9V-tEP_wen7kF0zsAchvQJYwOjJk?width=576&amp;amp;height=1024&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Mounting the RaspberryPi and USB power module on a custom bracket"&gt;
&lt;p&gt;Finally, boards were fixed in place and a ribbon cable connected between the GPIO socket on the RaspberryPi and the relay board to allow control of the relays.&lt;/p&gt;
&lt;img src="https://nhtewg.dm2302.livefilestore.com/y3mYTQzOsTukjrHcb69XX-50V18rcvHJUP4R8u6hmsgR1yAm2DCpFzoK9UdUNyfxseH59qtuRbVeIVVX9AM1h8lde7IbZDOPRYz0le7cac0bFkoC4pzsyjVKNO3QapjDdlCK-awMaL_NOhYEw6rW4_7lMTobDNRqGrK17yE1SmeRHA?width=1024&amp;amp;height=576&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Brackets in place and RaspberryPi fitted"&gt;
&lt;p&gt;After a thorough check to make sure there were no shorts on any of the connections and that I had connected polarity correctly, I plugged it in and turned it on....&lt;/p&gt;
&lt;h2&gt;Testing&lt;/h2&gt;
&lt;p&gt;... and everything worked.&lt;/p&gt;
&lt;p&gt;The RaspberryPi booted but didn't switch the sockets on as - I think - not having a network connection meant it couldn't get an IP address which meant the software hadn't enabled to relays due to being configured to fail safe (leave the sockets off). The power indicator on the USB power module suggested it was working fine too.&lt;/p&gt;
&lt;p&gt;Next I relocated to another room where a network connection was available. I plugged it in, turned it on and saw the network connection LED's start blinking. After 15-20 seconds or so while the RaspberryPi booted, the relays tickets on and I was able to hit the REST endpoint from &lt;a href="https://www.getpostman.com/"&gt;Postman&lt;/a&gt;. I'd even managed to get the names of the sockets on the rest service to match the sockets the relays were controlling, although I admit this was more luck than judgement (I had completely expected to have to re-configure the software to match after the hardware was complete).&lt;/p&gt;
&lt;p&gt;I plugged in a small table lamp and recorded this:&lt;/p&gt;
&lt;iframe src="https://onedrive.live.com/embed?cid=03DF8A28BD9D0BC9&amp;amp;resid=3DF8A28BD9D0BC9%21266322&amp;amp;authkey=AI5IzCXupiYl-CU" width="600px" height="340px" frameborder="0" scrolling="no" allowfullscreen=""&gt;&lt;/iframe&gt;
&lt;p&gt;Boom! (Figuratively speaking of course... the MonsterPi didn't literally go boom... yet :0)&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;I've long loved the idea of home automation. From X10 and LightwaveRF through to modern Bluetooth and Wifi connected devices, I have played with dozens of technologies in search of home automation nirvana. But recently I have watched with growing bewilderment at the incredible number of "cloud-connected" home automation devices being released and the eagerness with which they're snapped up by naive consumers hungry to control everything from the carefree comfort of their iPhone.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartIV" />
		<id>http://ian.bebbs.co.uk/posts/HomeNetworkMonitoring-PartIV</id>
		<title>Home Network Monitoring - Part IV</title>
		<updated>2016-04-16T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;In the last post, I used the Logstash &lt;code&gt;dns&lt;/code&gt; filter to translate remote server IP addresses into recognisable domain names. In this post, I will look to perform a similar operation for local IP addresses in order to translate them into recognisable device names.&lt;/p&gt;
&lt;h1&gt;translating local ip addresses to device names&lt;/h1&gt;
&lt;p&gt;While in the last post we could use the &lt;code&gt;dns&lt;/code&gt; filter to perform a reverse dns lookup to resolve a remote domain name for an IP address, this is not possible with local IP addresses. Fortunately, I have two key tools that I can use to perform a similar operation:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;While my router behaves as a DHCP server, it has a feature that allows it to always allocate the same IP address to a given MAC address. Therefore I know a given device will always have a specific IP address.&lt;/li&gt;
&lt;li&gt;Logstash provides the &lt;code&gt;translate&lt;/code&gt; filter which allows you to map from one value to another via a dictionary lookup.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With my routers "Bind IP to MAC" function set up, I will author a new &lt;code&gt;yaml&lt;/code&gt; file that meets the specifications outlined in the &lt;code&gt;translate&lt;/code&gt; filter &lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-translate.html#plugins-filters-translate-destination"&gt;documentation&lt;/a&gt;. It looks like this:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;192.168.1.3: TPLink Range Extender
192.168.1.9: Ricoh Printer
192.168.1.10: Server A
192.168.1.21: PC A
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I'll name this file &lt;code&gt;IPLookup.yaml&lt;/code&gt; and save it besides the &lt;code&gt;syslog.config&lt;/code&gt; file. Next I need to add additional filters to &lt;code&gt;syslog.config&lt;/code&gt; which now looks as follows:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;input {
  tcp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
  udp {
    port =&amp;gt; 5000
    type =&amp;gt; syslog
  }
}

filter {
    grok {
        match =&amp;gt; [ "message", "&amp;lt;%{POSINT:syslog_pri}&amp;gt;%{SYSLOGTIMESTAMP:syslog_timestamp} Vigor\: Local User \(MAC=%{MAC:source_mac}\): %{IP:source_address}(?::%{POSINT:source_port})? -&amp;gt; %{IP:destination_address}(?::%{POSINT:destination_port})? \((?&amp;lt;protocol&amp;gt;TCP|UDP)\)" ]
        add_tag =&amp;gt; "access"
    }
    if "access" in [tags] {
        mutate {
            add_field =&amp;gt; {
              "source_host" =&amp;gt; "%{[source_address]}"
              "destination_host" =&amp;gt; "%{[destination_address]}"
            }
        }
        dns {
            reverse =&amp;gt; [ "destination_host" ]
            action =&amp;gt; "replace"
            nameserver =&amp;gt; "192.168.1.1"
        }
        translate {
            destination =&amp;gt; "source_host"
            dictionary_path =&amp;gt; "config\IPLookup.yaml"
            fallback =&amp;gt; "%{source_address}"
            field =&amp;gt; "source_address"      
            override =&amp;gt; true   
        }
    }
}

output {
  elasticsearch {
    hosts =&amp;gt; ["192.168.1.30:9200"]
    index =&amp;gt; "syslog-%{+YYYY.MM.dd}"
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the &lt;code&gt;translate&lt;/code&gt; filter where I lookup the &lt;code&gt;source_address&lt;/code&gt; field in the &lt;code&gt;IPLookup.yaml&lt;/code&gt; file and put the result in the &lt;code&gt;source_host&lt;/code&gt; field. If not found, the &lt;code&gt;fallback&lt;/code&gt; value instructs the filter to output the &lt;code&gt;source_address&lt;/code&gt; into the &lt;code&gt;source_host&lt;/code&gt; field. The &lt;code&gt;override&lt;/code&gt; value is set to true as the &lt;code&gt;source_host&lt;/code&gt; field is added in the &lt;code&gt;mutate&lt;/code&gt; filter above as a fail-safe.&lt;/p&gt;
&lt;p&gt;With the changes to configuration in place, I once again restart Logstash. Once a syslog message has been received, I get the mapping from ElasticSearch and update it to mark the &lt;code&gt;local_host&lt;/code&gt; field as &lt;code&gt;not_analyzed&lt;/code&gt;. Then, in Kibana, I refresh the field list for the 'syslog-*' index, add 'local_host' to the 'Syslog Messages' saved search, load 'Access By Local Address' visualization and modify it to use 'local_host' rather than the 'local_address' field and save it as 'Access By Local Host'. Finally, I replace this visualization on my dashboard and get the following:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardWithAccessByLocalHost.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard With Access By Local Host"&gt;
&lt;h1&gt;further mappings&lt;/h1&gt;
&lt;p&gt;Now I've got the translation of local IP addresses to names working, I'm going to add a few more translations for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IP Address to Operating System&lt;/li&gt;
&lt;li&gt;IP Address to Wired/WiFi connection&lt;/li&gt;
&lt;li&gt;TCP and UDP Port to Protocol (using a &lt;a href="http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml"&gt;CSV from IANA&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With these in place, the dashboard is starting to come together:&lt;/p&gt;
&lt;img src="/Content/HomeNetworkMonitoring/Kibana-DashboardWithLocalPortAndOsLookups.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Kibana Dashboard With Local Port And Os Lookups"&gt;
&lt;h1&gt;summary&lt;/h1&gt;
&lt;p&gt;In this post, I showed how to display local device names rather than IP addresses by using LogStash's &lt;code&gt;translate&lt;/code&gt; filter. I then used this filter to provide further information about local device and protocols.&lt;/p&gt;
&lt;p&gt;In the next post, I'll show how to add some variation to the dashboard by mapping destination locations.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;In the last post, I used the Logstash &lt;code&gt;dns&lt;/code&gt; filter to translate remote server IP addresses into recognisable domain names. In this post, I will look to perform a similar operation for local IP addresses in order to translate them into recognisable device names.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ToddlerBoxReleasedToStore" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mVAxtKFjUEGk7Hdhzjl4UZ2INnFdBbw9K-tnYZ8DYoJ-VoKxpAN6w8Ng0DFTYdSxpHY6IvL5-VwJpLkQl6qWRmMQXSExLXopz5CFuSxIbyaMLrnL2Vy3yPZlISAAknXZdT4HwiZJ55zg2UtKwucBL88-xHh6rn5Mh97yzfRsCPjI%253Fwidth=1919&amp;height=1075&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/ToddlerBoxReleasedToStore</id>
		<title>ToddlerBox Released to the XBox Store</title>
		<updated>2016-11-16T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;My little girl loves playing with the XBox controller. In fact, she'll make a beeline for it as soon as she sees it and sit for ages twiddling the thumb-sticks and mashing the buttons. So I thought it'd be great to provide some visual accompaniment to the tactile experience of playing with the controller. Furthermore, I'd been looking for an excuse to play with Win2D as part of a UWP app and this felt like a perfect opportunity.&lt;/p&gt;
&lt;p&gt;To this end, I cracked open Visual Studio, started a blank UWP app, added a nuget reference to Win2D and started coding. Using a &lt;a href="https://microsoft.github.io/Win2D/html/T_Microsoft_Graphics_Canvas_UI_Xaml_CanvasAnimatedControl.htm"&gt;CanvasAnimatedControl&lt;/a&gt; it was simple to use the &lt;a href="https://microsoft.github.io/Win2D/html/E_Microsoft_Graphics_Canvas_UI_Xaml_CanvasAnimatedControl_Update.htm"&gt;Update&lt;/a&gt; callback to read the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.gaming.input.gamepad"&gt;Gamepad&lt;/a&gt; input and then use the &lt;a href="https://microsoft.github.io/Win2D/html/E_Microsoft_Graphics_Canvas_UI_Xaml_CanvasAnimatedControl_Draw.htm"&gt;Draw&lt;/a&gt; callback to draw a series of sprites based on the values read.&lt;/p&gt;
&lt;p&gt;All in, from not having used Win2D before, it took just a few hours to get a minimal app working with a variety of sprites and manipulation mechanisms. Flipping my &lt;a href="https://msdn.microsoft.com/en-gb/windows/uwp/xbox-apps/devkit-activation"&gt;XBox into developer mode&lt;/a&gt; allowed me to deploy the app directly to the Xbox and have a play. And I must say, I was very pleased with the result:&lt;/p&gt;
&lt;img src="https://zphxkg.dm2302.livefilestore.com/y3mynwGeO7sZByGMtgH7TP5ykDeabNNlbyLCFHZfLu2Ml9QbQft2wq6-MeIxMukEXnVpiqZfLa_lh7h15xlStRf8Eo81_y5J-zSplYIIDh5dKAkS-j2q2wS4-GUHpOpwW5eltQ8_CLhSQNoRRJwdZWs_AhjvxhhOMdCS5PB-stLlTE?width=1024&amp;amp;height=575&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="Lots of animals"&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;Lots of animals&lt;/h6&gt;
&lt;img src="https://zphykg.dm2302.livefilestore.com/y3mVAxtKFjUEGk7Hdhzjl4UZ2INnFdBbw9K-tnYZ8DYoJ-VoKxpAN6w8Ng0DFTYdSxpHY6IvL5-VwJpLkQl6qWRmMQXSExLXopz5CFuSxIbyaMLrnL2Vy3yPZlISAAknXZdT4HwiZJ55zg2UtKwucBL88-xHh6rn5Mh97yzfRsCPjI?width=1024&amp;amp;height=574&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="Lots of colours"&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;Lots of colours&lt;/h6&gt;
&lt;img src="https://zphwkg.dm2302.livefilestore.com/y3m8XFQkqAgfzj1Yt9EqXW14XVybPwILZ0Hn_yGK2sbayqyeGZVqwSOGpT_xAJS3WwzYFeyQ4Gw66Fa-QyRpM71WpPUktEfgvgteIKAXfp9qCSW_my9s-7kb4Ys7Qz1JYRHv-k8fl1Y8xTTDpLhfY5xG2m56hT_ObFWrKxFhV-N-lw?width=1024&amp;amp;height=575&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="Big..."&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;Big...&lt;/h6&gt;
&lt;img src="https://zphvkg.dm2302.livefilestore.com/y3mN4YESAkR1YSr8YbSDJtqi2DGD20bBa_w5RR2cYyAm9aXKXxib1A65RnVBxraAGCEXRELh0QMYDSASbm7F8ADzvh7EizJXlz-odd9Vhvq0ccfd0yNyL4v1f2qex5ol96GP6qvxE35Fo1L-hdlu9cfo08lDWZielw6ffr-vZ92aYE?width=1024&amp;amp;height=575&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="...or small"&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;...or small&lt;/h6&gt;
&lt;img src="https://zphukg.dm2302.livefilestore.com/y3mcH_fRNs467C1gL7rApW6mWiFYB-eCoUexIuW3CwX4Cb0seAy8IxNhjyiGFQx3jDrcB8ToLQJgekRDInIwMkMHQvVZ05vWCPrptx2vxkcu-KG40ldNAqOZu2ulyL7OPSGt7uuFNnZLOdtycCFVs3Tl5IWJltKR6uhEgxNW_j-4tI?width=1024&amp;amp;height=575&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:320px; margin-top: 6px; margin-bottom: 6px;" alt="And monkeys!!!"&gt;
&lt;h6 style="text-align: center;" markdown="1"&gt;And monkeys!!!!&lt;/h6&gt;
&lt;p&gt;The real test came when I handed to the controller to my 14 month old baby girl. It took a few seconds for her to realise that what she did on the controller affected what was displayed on screen but then there was no stopping her. For three or four minutes (a record for her!!!) she sat still, mashing away on the controller and staring at the screen while I sat mesmerized by how quickly she picked it all up.&lt;/p&gt;
&lt;p&gt;I'd call that a win!&lt;/p&gt;
&lt;p&gt;Given this success, I made some final touches and submitted it to the store; specifically for XBox. To my amazement, it passed certification first time, within 24 hours of submission despite submitting it on a Sunday. And here it is:&lt;/p&gt;
&lt;img src="https://1y8kkg.dm2302.livefilestore.com/y3mRbMDxeVB6f5ArIwJ6FjYCPRmwpPTp6LL2IGiIFOrFVgHzox_2HUl9lPNSq09KxXP5M3LD1E3nwgFi1a8HUCT-0dTH_VmemTLCQwHggxqy8u04C85i51eLPBj1op_n2ppnjK2zkhGDHcWWAyYvkncmNy4bqw58vumGP8BY4f9nZU?width=1024&amp;amp;height=576&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:800px; margin-top: 6px; margin-bottom: 6px;" alt="ToddlerBox in the store"&gt;
&lt;p&gt;Installing from the store and ready to entertain my little one whenever I need a break.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;My little girl loves playing with the XBox controller. In fact, she'll make a beeline for it as soon as she sees it and sit for ages twiddling the thumb-sticks and mashing the buttons. So I thought it'd be great to provide some visual accompaniment to the tactile experience of playing with the controller. Furthermore, I'd been looking for an excuse to play with Win2D as part of a UWP app and this felt like a perfect opportunity.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ARipStoringTime" />
		<id>http://ian.bebbs.co.uk/posts/ARipStoringTime</id>
		<title>A Rip Storing Time</title>
		<updated>2016-12-07T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;From a youth of misspent money, I have a moderately large DVD collection. Some 600 movies in half a dozen DVD racks take a disproportionately large space in my dining room. This year, my partner and I  decided to host Xmas dinner for the family, meaning a dining table that could host a dozen was in order and... well, you can see where this is heading. The DVDs had to go.&lt;/p&gt;
&lt;p&gt;Now, even though I barely watch them anymore, there are still a couple of amazing films in my collection that aren't available from the (far too changeable) online streaming services and, as such, I was reluctant to simply banish them all to the attic. Instead, I decided to undertake the monumental task of ripping them all to HDD before boxing them all up.&lt;/p&gt;
&lt;h2&gt;Software&lt;/h2&gt;
&lt;p&gt;There are innumerable software solutions for ripping and transcoding DVD's... if you want to do one at a time. As you can probably appreciate, this wasn't a possibility for me or I'd still be ripping discs well into the New Year (not to mention through the Xmas dinner I'm actually doing this for). So a more, 'roll-your-own' solution was required.&lt;/p&gt;
&lt;p&gt;A bit of googling revealed &lt;a href="http://lifehacker.com/autorip-rips-dvds-and-blu-rays-as-soon-as-you-insert-th-477274988"&gt;this post&lt;/a&gt; which described a mechanism for ripping discs as soon as you put them into the drive. While it was still targetting people who wanted to rip discs one at a time, it did point me towards the two pieces of software I did ultimately use:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.makemkv.com/"&gt;MakeMKV&lt;/a&gt; - for ripping the entire contents of the DVD and,&lt;/li&gt;
&lt;li&gt;&lt;a href="https://handbrake.fr/"&gt;Handbrake&lt;/a&gt; - for transcoding source files into compressed H.264 format.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both these utilities come with CLI interfaces (details &lt;a href="http://www.makemkv.com/developers/"&gt;here&lt;/a&gt; and &lt;a href="https://handbrake.fr/docs/en/latest/cli/cli-options.html"&gt;here&lt;/a&gt; respectively) allowing them to be automated. Furthermore, MakeMKV can run multiple instances allowing you to do your drive ripping (the long slow process) in parallel from multiple drives.&lt;/p&gt;
&lt;h2&gt;Hardware&lt;/h2&gt;
&lt;p&gt;I'd been intending to buy a new server for my home to be used as a Docker host because my current server is so old it simply doesn't support the required virtualization instructions. I'd had my eye on the &lt;a href="http://www.ebuyer.com/714837-dell-poweredge-t20-3708-xeon-e3-1225v3-3-2-ghz-4gb-ram-1tb-hdd-tower-t20-3708"&gt;Dell T20 Xeon E3&lt;/a&gt; but was waiting for it to drop back below the £200 (after cashback) mark. However, realising I could (temporarily) use it as a DVD ripping machine, I decided to bite the bullet and bought the T20 with an additional 4Gb of RAM for £324 (less 2% Quidco and £80 cashback).&lt;/p&gt;
&lt;p&gt;It arrived a couple of days later and I must say I'm impressed. It's a lot of machine for the money, well built, has a copious number of USB sockets and is surprisingly fast. I installed Windows Server 2016 on this as it's the OS I intend to use for the Docker host and I thought it'd be a good practice run.&lt;/p&gt;
&lt;p&gt;To this I added the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;2 x 1Tb internal HDDs - configured as RAID-0 providing a fast destination for the drive rips.&lt;/li&gt;
&lt;li&gt;4 x USB DVD-ROM drives - drives for ripping from - a couple I already had plus a &lt;a href="https://www.amazon.co.uk/dp/B01B8U7JW2/ref=pe_385721_51767431_TE_dp_1"&gt;couple from Amazon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1 x 4Tb external USB HDD - destination for transcoded rips&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All in, it's quite a monster.&lt;/p&gt;
&lt;h2&gt;Putting it together&lt;/h2&gt;
&lt;p&gt;Unlike most of the out of the box software I'd found, I needed software that would do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Wait for a disc to be inserted in one of the drives&lt;/li&gt;
&lt;li&gt;Determine that the disc is actually a DVD video&lt;/li&gt;
&lt;li&gt;Rip the disc to a destination folder based on the volume label of the DVD&lt;/li&gt;
&lt;li&gt;Allow up to four concurrent rip operations&lt;/li&gt;
&lt;li&gt;Queue ripped folders for transcoding allowing only a single transcoding operation to run at a time.&lt;/li&gt;
&lt;li&gt;Save the transcoded movie to the external drive.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While there may be software out there that does this, a couple of evening's googling didn't reveal it so, I decided a DIY job was in order. Besides, I thought the multiple producer/single consumer nature of the multiple rips/single transcoding would be a great fit for playing with &lt;a href="https://msdn.microsoft.com/en-us/library/hh228603%28v=vs.110%29.aspx?f=255&amp;amp;MSPPError=-2147217396"&gt;Dataflow&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In relatively short order, I created &lt;a href="https://github.com/ibebbs/DriveRipper"&gt;DriveRipper&lt;/a&gt;... and it's worked pretty well. I've been happily ripping four DVD's at a time, averaging around 12-15 DVD's an hour, with only a few small problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Because Dataflow enforces order of tasks throughout the pipeline (one if it's biggest strengths!) a slow rip or drive can hold up transcoding such that a queue builds up. Not a massive problem as the encoding process on the Xeon is actually pretty rapid (averaging 450fps) so it catches up with the relatively slow ripping process (about 20 minutes per disc) with ease.&lt;/li&gt;
&lt;li&gt;Some DVD's - particularly the old ones - are single sided or low quality or lack additional material or all of the above. This means that the contents of the disc is less than the 4.2Gb cut off I used for determining that a particular disc is likely to be a DVD. This can be sorted with a simple code change but I dediced to put these discs to one side for now and come back to them.&lt;/li&gt;
&lt;li&gt;Some DVD's - again, particularly the olds ones - don't have a rational volume name; using terms like 'e19245' or, even worse, 'DVDVideo'. This has meant that, after the transcoding is complete, I need to rename the folders so that the contents don't get overwritten by a subsequent rip.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So far I'm 150 DVD's through and just been told that the new dining room furniture is being delivered Monday.&lt;/p&gt;
&lt;p&gt;Rip little machine, rip like wind!! Oh, wait...&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;From a youth of misspent money, I have a moderately large DVD collection. Some 600 movies in half a dozen DVD racks take a disproportionately large space in my dining room. This year, my partner and I  decided to host Xmas dinner for the family, meaning a dining table that could host a dozen was in order and... well, you can see where this is heading. The DVDs had to go.&lt;/p&gt;</summary>
	</entry>
</feed>th:&lt;/p&gt;
&lt;img src="https://bnljqq-dm2306.files.1drv.com/y3msqT1msmkJ_32Jewx8Ysuoys0lC35GCLY-aQPyJ9YhR75KMswOLcznSPGOOBGhhsMRb6qK3_xh_qr3h1Xh-vFwmSog1_HoOS-Isj1lMoFPpuV42oAwJi3A5JiY-ToAirVoZDnz2gQ7N6jUed82zW83IZ_qQcbqWGw1ekaNh4wjBU?width=660&amp;amp;height=252&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Acquisitions over App Lifetime"&gt;
&lt;p&gt;Daily usage also shows that a healthy number of acquisitions are being used regularly, with nearly 800 people using ToddlerBox nearly 1700 times just yesterday (19th December):&lt;/p&gt;
&lt;img src="https://bnlkqq-dm2306.files.1drv.com/y3mBC-i0nboWq0ibRyIcBhs1O2MnfOUx-OxTQZDUNHbh-eVRbfH0xP9-p9hLJqC82i1SBB5ZfpcfmTlvuZwMBD-Gt0BZZC-IvVCJOd1jzexDoiC-BV4LG7X2aOyOapkCKK6wM6WWffluiuD5MKKet6MfEIjTWNZMCpFx1FP13suiCY?width=660&amp;amp;height=249&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Daily usage"&gt;
&lt;p&gt;So, the Xmas break is almost upon us and I will be returning my attention to ToddlerBox (yes, despite the career break, I try to spend most of my time working on 'serious' projects or study). I have a number of new features in mind for it (including the #1 requested feature of "sound!!") and will be looking to try out a couple of more features of the awesome Win2D library. It's going to be a lot of fun (for me and my little girl) and will hopefully allow ToddlerBox to reach the next major (although admittedly arbitrary) milestone of 25,000 acquisitions!&lt;/p&gt;
&lt;p&gt;Watch this space...&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Really that got out of hand fast! I had no idea so many people would be interested in letting their toddler loose on their XBox controller. In fact, there have been many things that have surprised me about this app:&lt;/p&gt;</summary>
	</entry>
</feed>//stackoverflow.com/questions/27341064/how-do-i-fix-importerror-cannot-import-name-incompleteread"&gt;'pip' error&lt;/a&gt;), accounts set up and code mashed together in order to get a functional app up and running. Not bad considering this was my first stab at writing Python on a Pi.&lt;/p&gt;
&lt;p&gt;I pushed the code to a &lt;a href="https://github.com/ibebbs/UnicornPiBot"&gt;Github repository&lt;/a&gt; but have included it below simply because I am impressed with how concise the it is:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;import sys
import random

from UHScroll import *
from twython import TwythonStreamer
from auth import (
    consumer_key,
    consumer_secret,
    access_token,
    access_token_secret
)

colours = ['red','white','pink','blue','green','cyan']

non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)

class UnicornPiBotStreamer(TwythonStreamer):
    def on_success(self, data):
        if 'text' in data:
            text = data['text'].translate(non_bmp_map)
            colour = random.choice(colours)
            print(text)
            unicorn_scroll(text, colour, 200, 0.05)

stream = UnicornPiBotStreamer(
    consumer_key,
    consumer_secret,
    access_token,
    access_token_secret
)

stream.statuses.filter(track='#INWED17')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I'm now beginning to see why Python has gained such traction in non-enterprise markets and will definitely consider using it for future projects. Skipping the edit-compile-run loop and simply interpretting the code via a command line call certainly makes for fast iterations but I don't think I'd appreciate it so much if I was trying to develop anything of any size/complexity.&lt;/p&gt;
&lt;p&gt;Anyway, having an exhibit visitors can interact with (albeit indirectly) will make a good addition to the &lt;a href="http://ian.bebbs.co.uk/posts/MonsterPi"&gt;other&lt;/a&gt; &lt;a href="https://www.raspberrypi.org/magpi/issues/40/"&gt;Pi&lt;/a&gt; &lt;a href="https://aiyprojects.withgoogle.com/voice"&gt;devices&lt;/a&gt; we'll be taking along and discussing.&lt;/p&gt;
&lt;p&gt;Really quite looking forward to it now...&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;So, my partner and I - being &lt;a href="https://www.stem.org.uk/stem-ambassadors/ambassadors"&gt;STEM Ambassadors&lt;/a&gt; - were asked to prepare and present a talk about Raspberry Pis for a local university on &lt;a href="http://www.inwed.org.uk/"&gt;International Women In Engineering Day&lt;/a&gt;. Unfortunately, this invitation came rather late as a previous presenter had dropped out and this left very little time to prepare.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/ToddlerBoxTopsTenThousandUsers" />
		<link rel="enclosure" type="image" href="http://ian.bebbs.co.uk/y3mVAxtKFjUEGk7Hdhzjl4UZ2INnFdBbw9K-tnYZ8DYoJ-VoKxpAN6w8Ng0DFTYdSxpHY6IvL5-VwJpLkQl6qWRmMQXSExLXopz5CFuSxIbyaMLrnL2Vy3yPZlISAAknXZdT4HwiZJ55zg2UtKwucBL88-xHh6rn5Mh97yzfRsCPjI%253Fwidth=1024&amp;height=574&amp;cropmode=none" />
		<id>http://ian.bebbs.co.uk/posts/ToddlerBoxTopsTenThousandUsers</id>
		<title>ToddlerBox Tops 10,000 Users!!</title>
		<updated>2016-12-20T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;Really that got out of hand fast! I had no idea so many people would be interested in letting their toddler loose on their XBox controller. In fact, there have been many things that have surprised me about this app:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Acquisition rate has increased&lt;/p&gt;
&lt;p&gt;I kind of expected an initial burst of acquisitions then a slow tail off but this hasn't happened. As it's only been a little over a month since ToddlerBox was released to the store, I guess there's every possibility that it's still in the "burst" stage and theres just more interest in apps of this type. Well, here's hoping.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reviews have been extremely polarized&lt;/p&gt;
&lt;p&gt;Almost without exception, reviews have been 4-5 stars or 1 star. Also, while a couple of the 1 star ratings are to do with app functionality (it seems a couple of people have issues running even this basic UWP app) the overwhelming majority of 1 star ratings are due to peoples dislike of ads; because...&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ads are a very risky business&lt;/p&gt;
&lt;p&gt;As with most parents, I am extremely cautious about what my toddler is exposed to. Therefore I was extremely cautious about adding advertising as a means of revenue to ToddlerBox, regardless of how small or out of the way they were.
After completing the Ad-Mediation questions in the Windows Store and being assured that ads would be both age rated and not "tracking", I felt a lot better about the idea and decided a small banner ad on the instructions screen would be pretty harmless. Furthermore, throughout the process of adding the banner, I didn't see a single advert I would be concerned about putting in front of my child; most were simple flashing inbox icons or the like.
However, after discussing ToddlerBox with a friend, he decided to install it on his Xbox and I was very upset to see that the ads being displayed were both more intrusive and more "click-baity" than any I had seen previously. I am now investigating ways to generate some revenue from the app but without upsetting parents.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The reviews shown in the store are not "all reviews"&lt;/p&gt;
&lt;p&gt;As the publisher of ToddlerBox, I get to see all reviews left about the app on the store. Due to all the previous points, the app is currently averaging about a 2.6 star rating across 50 odd reviews. However, when viewing the app in the Store on my friend's XBox, it was shown as having a 4.5 star rating from just 2 reviews. Now, while some of the reviews I can see are translated from foreign languages, most are in English and I'm therefore at a loss to explain why they're not being displayed when an XBox in the English local browses the store.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It's not just toddlers using ToddlerBox&lt;/p&gt;
&lt;p&gt;I've had more than one review stating how good this game is to play after consuming various illicit substances ;0P&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Anyway, as described above, while acquisition rate has fluctuated on a daily basis, the overall trend in acquisition shows unexpected growth:&lt;/p&gt;
&lt;img src="https://bnljqq-dm2306.files.1drv.com/y3msqT1msmkJ_32Jewx8Ysuoys0lC35GCLY-aQPyJ9YhR75KMswOLcznSPGOOBGhhsMRb6qK3_xh_qr3h1Xh-vFwmSog1_HoOS-Isj1lMoFPpuV42oAwJi3A5JiY-ToAirVoZDnz2gQ7N6jUed82zW83IZ_qQcbqWGw1ekaNh4wjBU?width=660&amp;amp;height=252&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Acquisitions over App Lifetime"&gt;
&lt;p&gt;Daily usage also shows that a healthy number of acquisitions are being used regularly, with nearly 800 people using ToddlerBox nearly 1700 times just yesterday (19th December):&lt;/p&gt;
&lt;img src="https://bnlkqq-dm2306.files.1drv.com/y3mBC-i0nboWq0ibRyIcBhs1O2MnfOUx-OxTQZDUNHbh-eVRbfH0xP9-p9hLJqC82i1SBB5ZfpcfmTlvuZwMBD-Gt0BZZC-IvVCJOd1jzexDoiC-BV4LG7X2aOyOapkCKK6wM6WWffluiuD5MKKet6MfEIjTWNZMCpFx1FP13suiCY?width=660&amp;amp;height=249&amp;amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Daily usage"&gt;
&lt;p&gt;So, the Xmas break is almost upon us and I will be returning my attention to ToddlerBox (yes, despite the career break, I try to spend most of my time working on 'serious' projects or study). I have a number of new features in mind for it (including the #1 requested feature of "sound!!") and will be looking to try out a couple of more features of the awesome Win2D library. It's going to be a lot of fun (for me and my little girl) and will hopefully allow ToddlerBox to reach the next major (although admittedly arbitrary) milestone of 25,000 acquisitions!&lt;/p&gt;
&lt;p&gt;Watch this space...&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;Really that got out of hand fast! I had no idea so many people would be interested in letting their toddler loose on their XBox controller. In fact, there have been many things that have surprised me about this app:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://ian.bebbs.co.uk/posts/NewBlogUsingWyam" />
		<id>http://ian.bebbs.co.uk/posts/NewBlogUsingWyam</id>
		<title>Using Wyam</title>
		<updated>2015-11-09T00:00:00Z</updated>
		<content>
                                        


&lt;p&gt;I've been meaning to create a blog for a &lt;strong&gt;long&lt;/strong&gt; time but never found a system with the right combination of features (power vs flexibility vs learning curve, cost, technology stack, etc). CMSs (Wordpress, Drupal, etc) were always way too much faff and most static site generators required the installation of numerous languages / run-times / sdks, etc.&lt;/p&gt;
&lt;p&gt;Then I found &lt;a href="http://wyam.io/" title="Wyam Homepage"&gt;Wyam&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Being .NET based it could be used from my day-to-day development machine and, by cleverly leveraging the  Roslyn compiler platform, can be set up to be as simple or flexible as desired. A quick flick through the module and API pages and I knew I'd found a potential candidate for my statically generated blog.&lt;/p&gt;
&lt;p&gt;Being a... ahem... pragmatic developer with somewhat dated web skills I decided to take the path of least resistance and copy someone else's blog layout. Afterall, imitation is the sincerest form of flattery, right? As such, I contacted Dave Glick - the most-excellent author of Wyam - to see if he would mind me 'borrowing' the layout he used for &lt;a href="http://daveaglick.com/" title="Dave Glick's blog"&gt;his blog&lt;/a&gt;. He quickly replied to my cheeky request and said he didn't mind at all if used his layout, even refusing my offer of attribution (which I hope this blog post somewhat makes up for).&lt;/p&gt;
&lt;p&gt;With the all clear, I &lt;a href="https://github.com/Wyamio/Wyam/releases/tag/v0.10.0-beta" title="download page for Wyam version 0.10.0-beta"&gt;downloaded the latest version of Wyam&lt;/a&gt;, cloned the &lt;a href="https://github.com/Wyamio/Wyam" title="Github repository for Wyam "&gt;Wyam repository&lt;/a&gt;, invoked Wyam to generate an &lt;a href="https://github.com/Wyamio/Wyam/tree/develop/Examples" title="Wyam Example sites in Github repository"&gt;example site&lt;/a&gt;... and got an exception.&lt;/p&gt;
&lt;p&gt;Another quick chat with Mr. Glick revealed that the project is iterating quickly and currently in a "move fast and break things" mode. Fortunately the issue was already resolved in the development branch so, after local build of Wyam, I managed to successfully generate the example sites.&lt;/p&gt;
&lt;p&gt;"Now for some blatant plagiarism with his blog" I thought to myself but again, after cloning his (generously shared and CC licensed) &lt;a href="https://github.com/daveaglick/daveaglick" title="Github repository for Dave Glick's blog"&gt;blog&lt;/a&gt;, asking Wyam to generate the site threw an exception. This time, a &lt;a href="https://github.com/Wyamio/Wyam/issues/112#issuecomment-155165316" title="Wyam PostFile issue comment on Github"&gt;short bit of call-stack sleuthing&lt;/a&gt; revealed another breaking change which was easily resolved by examining the &lt;a href="http://wyam.io/modules/" title="Module documentation for Wyam"&gt;Wyam module documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once more with feeling and ét voila, a MVB (Minimal Viable Blog).&lt;/p&gt;
&lt;p&gt;All in all, not a bad experience with an early beta of a very clever project. Moving forward, I actually hope to do very little with Wyam other than post blog entries but will certainly endeavour to keep up to date with Wyam and share my experiences here.&lt;/p&gt;
&lt;p&gt;If you're looking for a flexible yet powerful .NET based static-site generator, go check out &lt;a href="http://wyam.io/" title="Wyam Homepage"&gt;Wyam&lt;/a&gt;. If you experience any problems with it I'd definitely recommend posting an issue on Github, Dave seems to be very on the ball responding to issues (and extremely friendly to boot).&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;I've been meaning to create a blog for a &lt;strong&gt;long&lt;/strong&gt; time but never found a system with the right combination of features (power vs flexibility vs learning curve, cost, technology stack, etc). CMSs (Wordpress, Drupal, etc) were always way too much faff and most static site generators required the installation of numerous languages / run-times / sdks, etc.&lt;/p&gt;</summary>
	</entry>
</feed>th &amp;lt;Path to a previously created Nano2Docker.vhdx&amp;gt; -VMPath &amp;lt;Path to a location to store swarm host VMs&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, using our previous example and wanting to store new VM images in the 'C:\Nano2Docker\VMs' directory, the command would be:&lt;/p&gt;
&lt;pre class="prettyprint"&gt;&lt;code&gt;New-Nano2DockerSwarm -MediaPath G: -ImagePath "C:\Nano2Docker\Nano2Docker.vhdx" -VMPath "C:\Nano2Docker\VMs"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command defaults to creating a single manager node and three worker nodes named 'n2d-mngr-0' and 'n2d-wrkr-0/1/2' respectively. All nodes will have already been joined to the swarm in the appropriate capacity and ready for services to be deployed using docker or docker-compose.
Again, the number of manager and worked nodes as well as the name prefix for each node can be changed via the appropriate arguments (use &lt;code&gt;Get-Help New-Nano2DockerSwarm&lt;/code&gt; to list the arguments).&lt;/p&gt;
&lt;h1&gt;Roundup&lt;/h1&gt;
&lt;p&gt;I've successfully used this script to provision multiple docker hosts and docker swarms but it's worthwhile noting that it can be a bit finickity with directories. If you can an error saying it couldn't find a directory then simply create it first. I really ought to fix up the script (improvements via PR gratefully accepted) but I'm now a bit busy deploying services to my swarm :0)&lt;/p&gt;
&lt;p&gt;Furthermore I've successfully used nodes created by this script to provision a hybrid swarm (see the 'Mixed OS clusters section &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;here&lt;/a&gt;) of boot2docker and nano2docker images. With the appropriate labels on the nodes, it is possible to use docker-compose to automatically deploy images to the correct hosts while retaining all the benefits of overlay networking.&lt;/p&gt;



                                </content>
		<summary>&lt;p&gt;While my current contract doesn't leave much time for personal projects, I have made some progress on my current project (details on exactly what this is to follow). In fact, some of the smaller, peripheral services have their primary use-cases functionally complete and are ready for deployment and I am now faced with the question: Deployment to where?&lt;/p&gt;</summary>
	</entry>
</feed>
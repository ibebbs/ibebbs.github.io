<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
	<channel>
		<title>Ian Bebbington</title>
		<link>http://ian.bebbs.co.uk/</link>
		<description>IObservable&lt;Opinion&gt;</description>
		<copyright>2020</copyright>
		<pubDate>Thu, 23 Apr 2020 19:41:45 GMT</pubDate>
		<lastBuildDate>Thu, 23 Apr 2020 19:41:45 GMT</lastBuildDate>
		<item>
			<title>Many platforms, one world - Part 2</title>
			<link>http://ian.bebbs.co.uk/posts/COduo-Part2</link>
			<description>&lt;p&gt;This is part 2 of my series on using the Uno Platform to write a cross-platform app, able to target both single and dual-screen devices. In this post I cover the infrastructure used to collate and aggregate the data used by CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; as a prelude to a deeper dive into the implementation of the app itself which I will cover in later posts.&lt;/p&gt;</description>
			<enclosure url="http://ian.bebbs.co.uk/Content/CODuo/Header.png" length="0" type="image" />
			<guid>http://ian.bebbs.co.uk/posts/COduo-Part2</guid>
			<pubDate>Thu, 23 Apr 2020 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;This is part 2 of my series on using the Uno Platform to write a cross-platform app, able to target both single and dual-screen devices. In this post I cover the infrastructure used to collate and aggregate the data used by CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; as a prelude to a deeper dive into the implementation of the app itself which I will cover in later posts.&lt;/p&gt;
&lt;p&gt;Here are links to all the posts I have written - or intend to write - for this series:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="./COduo-Part1"&gt;Part 1 - Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="./COduo-Part2"&gt;Part 2 - Infrastructure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Part 3 - Client Architecture&lt;/li&gt;
&lt;li&gt;Part 4 - Using the TwoPaneView&lt;/li&gt;
&lt;li&gt;Part 5 - Implementing the interactive UK Map&lt;/li&gt;
&lt;li&gt;Part 6 - Charts on the Uno Platform&lt;/li&gt;
&lt;li&gt;Part 7 - Windows, Win10X and releasing to the Microsoft Store&lt;/li&gt;
&lt;li&gt;Part 8 - Android and releasing to the Google Play Store&lt;/li&gt;
&lt;li&gt;Part 9 - iOS and releasing to the Apple App Store&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="infrastructure"&gt;Infrastructure&lt;/h2&gt;
&lt;p&gt;While considering how to implement CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt;, I needed to ensure the app could retrieve all the data it required quickly, efficiently, securely and - most importantly - cheaply. As such, I decided to introduce service infrastructure that would perform all the required data collation, aggregation and serialization such that the app merely had to retrieve a single file from a know URI.&lt;/p&gt;
&lt;p&gt;Here is a mile-high view of the infrastructure used to operate CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; and the architecture of the app's various components:&lt;/p&gt;
&lt;img src="/Content/CODuo/Infrastructure.png" class="img-responsive" style="margin: auto; width:60%; margin-top: 6px; margin-bottom: 6px;" alt="Infrastructure.png"/&gt;
&lt;p&gt;As the primary focus of this series of posts is the Uno Platform I won't be digging into the service-side components too deeply but I feel it's important to show how the infrastructure delivers on the requirements above in order to understand how this simplifies the app's implementation.&lt;/p&gt;
&lt;h2 id="serverless"&gt;Server[less]&lt;/h2&gt;
&lt;p&gt;Fundamentally, the infrastructure is provided by two, timer-triggered &lt;a href="https://azure.microsoft.com/en-us/services/functions/"&gt;Azure Functions&lt;/a&gt;: &amp;quot;Weather Collection&amp;quot; and &amp;quot;Energy Aggregation&amp;quot;. These 'serverless' functions collate, process and store all the data required by the app, greatly simplifying client data access.&lt;/p&gt;
&lt;p&gt;Here's the (&lt;a href="https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-map?tabs=net"&gt;Application Insights&lt;/a&gt; generated) application map:&lt;/p&gt;
&lt;img src="/Content/CODuo/AzureFunctionsApplicationMap.png" class="img-responsive" style="margin: auto; width:60%; margin-top: 6px; margin-bottom: 6px;" alt="Azure Functions Application Map"/&gt;
&lt;h3 id="weather-collection"&gt;Weather Collection&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;[FunctionName(&amp;quot;WeatherV1&amp;quot;)]
public static async Task Weather(
    [TimerTrigger(WeatherNormal)] TimerInfo timer, 
    [CosmosDB(databaseName: CosmosDatabase, collectionName: WeatherCollection, ConnectionStringSetting = CosmosConnectionStringKey)] IAsyncCollector&amp;lt;Weather.Common.Document&amp;gt; documentsOut, 
    ILogger log)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Weather Collection function is triggered every hour and retrieves data from the &lt;a href="https://metoffice.apiconnect.ibmcloud.com/metoffice/production/"&gt;Met Office Weather Data Hub&lt;/a&gt;. It collects 48 hours worth of forecast data for each of 14 locations around the UK (one city in each of the 14 &lt;a href="https://www.ovoenergy.com/guides/energy-guides/dno.html"&gt;Distributed Network Operator regions&lt;/a&gt;) then transposes this to generate weather data for each hour containing the forecast in each region.&lt;/p&gt;
&lt;p&gt;This was done for many reasons but mostly to provide numerous small, easily indexed documents that can be cheaply written to, read from and updated within Cosmos DB. This has worked well and each hour documents are saved to a &lt;a href="https://azure.microsoft.com/en-us/updates/azure-cosmos-db-free-tier-is-now-available/"&gt;free tier CosmosDB container&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Persisting these documents does occasionally exceed the free tier's 400ru/s quota which means writes to Cosmos need to be retried until they succeed. While all the retries are transparently handled by the SDK, the retries cause the function to run longer than it otherwise would and, as such, I will probably modify the function to only persist 24 hours worth of forecast data in the next version.&lt;/p&gt;
&lt;h3 id="energy-aggregator"&gt;Energy Aggregator&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;[FunctionName(&amp;quot;EnergyV1&amp;quot;)]
public static async Task Energy(
    [TimerTrigger(EnergyNormal)]TimerInfo timer,
    [CosmosDB(
        databaseName: CosmosDatabase,
        collectionName: WeatherCollection,
        ConnectionStringSetting = CosmosConnectionStringKey)] DocumentClient client,
    [Blob(EnergyOutputFile, FileAccess.Write, Connection = EnergyStorage)] Stream blob, 
    ILogger log)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Energy Aggregation function runs every 15 minutes and requests electricity generation and composition information from a few different API's, most notably Elexon's &lt;a href="https://www.elexon.co.uk/knowledgebase/what-is-bmreports-com/"&gt;Balancing Mechanism Reporting Service&lt;/a&gt;. This is collated with weather data generated by the Weather Collection function then aggregated and serialized into a JSON document easily consumed by the CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; client application.&lt;/p&gt;
&lt;p&gt;The serialized document is then persisted in a publicly accessible &lt;a href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers?tabs=azure-portal"&gt;'Hot' Azure Blob&lt;/a&gt; meaning the client application can retrieve it with a single, unauthenticated HTTPS request.&lt;/p&gt;
&lt;h3 id="conclusion"&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;At current levels (and using the CosmosDB free-tier) it is currently costing less than £1 per month to run this infrastructure with only small increases (due to bandwidth costs) as application usage scales. As such, I feel it satisfies CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt;'s requirements very neatly. Furthermore, Visual Studio's impressive tooling for developing and testing Azure Functions locally (including local emulators of all storage) streamlines the delivery of features and regression testing of changes such that I've been able to iterate on this project extremely quickly.&lt;/p&gt;
&lt;h3 id="more-information"&gt;More information&lt;/h3&gt;
&lt;p&gt;I've deliberately kept this post at a &amp;quot;mile-high&amp;quot; level as the series is focused on the use of the Uno Platform to deliver a cross platform application. However, if you're keen to understand more of how these service-side components operate then drop me a line (contact links at the bottom of the page) and, if enough people are interested, I'll write a blog post detailing these approaches further.&lt;/p&gt;
&lt;h2 id="part-3"&gt;Part 3&lt;/h2&gt;
&lt;p&gt;&lt;a href="./COduo-Part3"&gt;Part 3&lt;/a&gt; will examine the architecture of CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; with an aim to providing an understanding of how it's primary components interoperate to provide a robust and testable experience across multiple platforms and dual-screens.&lt;/p&gt;
&lt;h2 id="finally"&gt;Finally&lt;/h2&gt;
&lt;p&gt;I hope you enjoy this series and that it goes some way to demonstrating the massive potential presented by the Uno Platform for delivering cross-platform experiences without having to invest in additional staff training nor bifurcating your development efforts.&lt;/p&gt;
&lt;p&gt;If you or your company are interested in building apps that can leverage the dual screen capabilities of new devices such as the Surface Duo and Surface Neo, or are keen to understand how a single code-base can deliver apps to &lt;em&gt;every platform from mobile phones to web sites&lt;/em&gt;, then please feel free to drop me a line using any of the links below or from my &lt;a href="https://ian.bebbs.co.uk/about"&gt;about page&lt;/a&gt;. I am actively seeking new clients in this space and would be happy to discuss any ideas you have or projects you're planning.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Many platforms, one world - Part 1</title>
			<link>http://ian.bebbs.co.uk/posts/COduo-Part1</link>
			<description>&lt;p&gt;This is part 1 of a series of posts in which I chronical how the Uno Platform was used to write an app which runs natively on all major platforms and naturally on modern dual-screen devices (such as the forthcoming Surface Neo and Surface Duo). I will endeavour to detail how the Uno Platform makes it possible to achieve "99% shared code" across operating system and form-factor, all without having to leave the comfort of basic C# nor needing to learn a new dialect of XAML. And finally, through the app, I hope to provide the means to better understand - and help mitigate - the impact our energy usage is having on the environment.&lt;/p&gt;</description>
			<enclosure url="http://ian.bebbs.co.uk/Content/CODuo/Header.png" length="0" type="image" />
			<guid>http://ian.bebbs.co.uk/posts/COduo-Part1</guid>
			<pubDate>Sun, 19 Apr 2020 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="tldr"&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;This is part 1 of a series of posts in which I chronical how the Uno Platform was used to write an app which runs natively on all major platforms and naturally on modern dual-screen devices (such as the forthcoming Surface Neo and Surface Duo). I will endeavour to detail how the Uno Platform makes it possible to achieve &amp;quot;99% shared code&amp;quot; across operating system and form-factor, all without having to leave the comfort of basic C# nor needing to learn a new dialect of XAML. And finally, through the app, I hope to provide the means to better understand - and help mitigate - the impact our energy usage is having on the environment.&lt;/p&gt;
&lt;h2 id="part-1"&gt;Part 1&lt;/h2&gt;
&lt;p&gt;In this post I cover the app's conceptualization, why I chose to implement it using the Uno Platform, how you can get the app for your device and where you can examine it's source code. Later posts detail the various conundra of designing, implementing and deploying an app targeting multiple platforms using the Uno Platform.&lt;/p&gt;
&lt;p&gt;Below is a (preliminary) list of posts I intend to write. It will be updated as each post is completed and published:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="./COduo-Part1"&gt;Part 1 - Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="./COduo-Part2"&gt;Part 2 - Infrastructure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Part 3 - Client Architecture&lt;/li&gt;
&lt;li&gt;Part 4 - Using the TwoPaneView&lt;/li&gt;
&lt;li&gt;Part 5 - Implementing the interactive UK Map&lt;/li&gt;
&lt;li&gt;Part 6 - Charts on the Uno Platform&lt;/li&gt;
&lt;li&gt;Part 7 - Windows, Win10X and releasing to the Microsoft Store&lt;/li&gt;
&lt;li&gt;Part 8 - Android and releasing to the Google Play Store&lt;/li&gt;
&lt;li&gt;Part 9 - iOS and releasing to the Apple App Store&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;Back in January I wrote a &lt;a href="https://ian.bebbs.co.uk/posts/UnoDuoHey"&gt;blog post&lt;/a&gt; showing how the &lt;a href="https://platform.uno/"&gt;Uno Platform&lt;/a&gt; could be used to write native, cross-platform apps that can leverage the unique UX opportunities afforded by dual and multi-screen devices such as the forthcoming Surface Duo and Surface Neo. This article was received well and the Uno Platform team dropped me a line after reading it suggesting that, if I could develop the PoC into a &amp;quot;real app&amp;quot;, they'd feature it on their &lt;a href="https://platform.uno/showcases/"&gt;showcases page&lt;/a&gt;. This seemed like a great idea but, as I was in the middle of a project at the time and couldn't immediately think of an app I wanted to write, I thanked them and left it there...&lt;/p&gt;
&lt;p&gt;Until, that is, I read that &lt;a href="https://blogs.microsoft.com/blog/2020/01/16/microsoft-will-be-carbon-negative-by-2030/"&gt;Microsoft had committed to going carbon negative by 2030&lt;/a&gt;. As regular readers of my blog will know, I have a penchant for &lt;a href="https://ian.bebbs.co.uk/posts/TechAdventuresInSustainability-PartI"&gt;using technology to help promote sustainable living&lt;/a&gt; and thought an app combining this with Microsoft's current focus on dual-screen devices could be the showcase app the Uno Platform team  were looking for.&lt;/p&gt;
&lt;p&gt;And so it was that CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; came to be:&lt;/p&gt;
&lt;img src="/Content/CODuo/RunningOnSurface.png" class="img-responsive" style="margin: auto; width:80%; margin-top: 6px; margin-bottom: 6px;" alt="Running On Surface.png"/&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;An early version of CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; running on Surface Pro (Windows 10), Surface Duo (Android 10) and Surface Neo (Windows 10X)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="so-what-is-coduo"&gt;So what is CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt;?&lt;/h2&gt;
&lt;p&gt;CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; is an app which presents data about electricity generation and carbon emissions across the UK in a user-friendly way.&lt;/p&gt;
&lt;p&gt;With CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; I wanted to not only increase people's awareness of the impact their energy usage was having on the environment - particularly the CO&lt;sub&gt;2&lt;/sub&gt; emissions - but also empower them to change their energy usage in ways which might help mitigate this impact. In short, my design goals could be summarised with the following two user stories:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;&amp;quot;As a domestic user of electricity, I need to understand the impact my energy usage has on the environment so that I am incentivized to change this usage&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;&amp;quot;As a domestic user of electricity, I need to understand how I can change my energy usage so that it's impact on the environment is minimized&amp;quot;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I started this project by searching for appropriate sources of data and was pleased to find that, for the UK at least, there were numerous free - and extremely detailed - public APIs available. I then spent some time prototyping a data visualisation that could show the carbon intensity of current and forecast energy generation and illustrate when might be best to use energy-intensive appliances (i.e. washing machines, dish washers, tumble dryers, etc).&lt;/p&gt;
&lt;p&gt;Using Syncfusion's Essential Studio I got the below working in a UWP app in single evening:&lt;/p&gt;
&lt;img src="/Content/CODuo/Prototype.png" class="img-responsive" style="margin: auto; width:80%; margin-top: 6px; margin-bottom: 6px;" alt="Prototype of COduo"/&gt;
&lt;p&gt;&amp;quot;Great&amp;quot;, I thought, &amp;quot;Now to make it run across every platform, on every screen and in every configuration. How difficult can it be?&amp;quot;.&lt;/p&gt;
&lt;p&gt;Well, lets find out.&lt;/p&gt;
&lt;h2 id="why-the-uno-platform"&gt;Why the Uno Platform?&lt;/h2&gt;
&lt;p&gt;This is my third blog post about the Uno Platform. The first two - &lt;a href="https://ian.bebbs.co.uk/posts/Uno"&gt;The Seven GUIs of Christmas&lt;/a&gt; about Uno's cross-platform capabilities &amp;amp; &lt;a href="https://ian.bebbs.co.uk/posts/UnoDuoHey"&gt;Uno, Duo, Hey!&lt;/a&gt; about Uno's dual-screen capabilities - showed a platform that had incredible potential and which was rapidly maturing to the point where it could deliver on this potential for &amp;quot;real world&amp;quot; apps.&lt;/p&gt;
&lt;p&gt;Given I wanted to write an app that would work natively on both the Surface Duo - which runs Android - and Surface Neo - which runs Windows 10X - the Uno Platform was an obvious choice as it would reduce my technology stack from this:
&lt;img src="/Content/CODuo/MultipleApps.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Multiple Apps"/&gt;&lt;/p&gt;
&lt;p&gt;To this:
&lt;img src="/Content/CODuo/UnoAllTheThings.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Uno All The Things!"/&gt;&lt;/p&gt;
&lt;p&gt;As we will see in the following series, this choice really has paid dividends. In fact, it has been so successful that I feel I must issue a correction:&lt;/p&gt;
&lt;p&gt;My first blog post about the Uno Platform - &lt;a href="https://ian.bebbs.co.uk/posts/Uno"&gt;The Seven GUIs of Christmas&lt;/a&gt; - contained the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The Uno platform is, somewhat amazingly, able to display (almost) the exact same XAML page across multiple platforms (or 'heads' to use Uno parlance) with a very high degree of fidelity. This is quite an achievement and the team at nventive are rightly proud of this capability.

However, from the perspective of someone looking to write large applications on this platform, I don't believe this facility is particularly important nor - to a certain extent - even desirable. You see, in my experience, it is often the case that each platform and/or form-factor requires such different UI and/or UX that trying to shoe-horn everything into a single XAML page results in a page that is difficult, if not impossible, to maintain.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In contrast to this statement, CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; has been written with a single code-base - from infrastructure through to view-models &lt;em&gt;and&lt;/em&gt; views - shared across all devices. This has led to neither code bloat nor maintainability issues due, in most part, to the Uno Platform's faithful reproduction of a few key UWP tenets.&lt;/p&gt;
&lt;p&gt;To explain: Whereas previously I had been used to writing cross-platform apps using multiple different display technologies, the Uno Platform is just UWP and UWP was designed to be... well... universal. Out of the gate, UWP ran on everything from desktop PCs and tablets through to mobile phones and IoT devices. It successfully abstracted away many technical difficulties of designing for multiple platforms ensuring the developer was able to write a single &amp;quot;adaptive&amp;quot; UI which would then be able to capitalize on the display surface(s) available.&lt;/p&gt;
&lt;p&gt;Uno have very successfully reproduced this capability across multiple disparate platforms and while not quite pixel-perfect - as we will see in future posts - it is close enough that any differences can be smoothed over with a little creative design.&lt;/p&gt;
&lt;h2 id="which-platforms-does-coduo-run-on"&gt;Which platforms does CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; run on?&lt;/h2&gt;
&lt;p&gt;CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; currently runs on the following platforms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Via UWP
&lt;ul&gt;
&lt;li&gt;Windows 10 PC&lt;/li&gt;
&lt;li&gt;Windows 10 Tablet&lt;/li&gt;
&lt;li&gt;Windows 10 Mobile/Phone&lt;/li&gt;
&lt;li&gt;Windows 10 IoT&lt;/li&gt;
&lt;li&gt;XBox One&lt;/li&gt;
&lt;li&gt;Hololens&lt;/li&gt;
&lt;li&gt;Surface Hub&lt;/li&gt;
&lt;li&gt;Windows 10X PC/Tablet (i.e. Surface Neo)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Via Android (Oreo - version 8 - or above)
&lt;ul&gt;
&lt;li&gt;Android Phone&lt;/li&gt;
&lt;li&gt;Android Tablet&lt;/li&gt;
&lt;li&gt;Android TV&lt;/li&gt;
&lt;li&gt;Dual-Screen Android Devices (i.e. Surface Duo)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Furthermore, CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; will be updated to run on the following platforms when time and resources allow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Via iOS
&lt;ul&gt;
&lt;li&gt;iPhone&lt;/li&gt;
&lt;li&gt;iPad&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Via WebAssembly
&lt;ul&gt;
&lt;li&gt;Any &lt;a href="https://en.wikipedia.org/wiki/WebAssembly"&gt;WebAssembly compatible browser&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="where-can-i-get-coduo"&gt;Where can I get CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt;?&lt;/h2&gt;
&lt;p&gt;Beta versions of CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; are currently available in the following apps stores:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.microsoft.com/en-gb/p/coduo/9php2cf3z997"&gt;Microsoft Store&lt;/a&gt; - for PC, Tablet, XBox, Hololens and Surface Hub&lt;/li&gt;
&lt;li&gt;&lt;a href="https://play.google.com/store/apps/details?id=solutions.onecog.coduo"&gt;Google Play&lt;/a&gt; - for Android Phone, Table, and TV.&lt;/li&gt;
&lt;li&gt;Apple App Store - Coming soon&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As promised, the Uno Platform Team have also featured CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; on their &lt;a href="https://platform.uno/showcases/"&gt;showcases page&lt;/a&gt; and as part of their introduction to using the &lt;a href="https://platform.uno/surface-duo-neo/"&gt;Uno Platform for Surface Duo and Surface Neo&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="will-you-be-open-sourcing-coduo"&gt;Will you be open-sourcing CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt;?&lt;/h2&gt;
&lt;p&gt;Yes, &lt;em&gt;mostly&lt;/em&gt;. In addition to detailing lots of the design and implementation considerations that went into writing CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; in various posts for this series, the code for CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; has been published under a &amp;quot;shared source&amp;quot; license; specifically &lt;a href="https://www.gnu.org/licenses/gpl-3.0.en.html"&gt;GPLv3&lt;/a&gt; with the &lt;a href="https://commonsclause.com/"&gt;&amp;quot;Commons Clause&amp;quot;&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;The Commons Clause is a license condition drafted by Heather Meeker that applies a narrow, minimal-form commercial restriction on top of an existing open source license to transition the project to a source-availability licensing scheme. The combined text replaces the existing license, allowing all permissions of the original license to remain except the ability to &amp;quot;Sell&amp;quot; the software as defined in the text.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is my hope that transitioning the CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; project to a &amp;quot;source-available&amp;quot; license scheme will allow others to understand how to use the Uno Platform to develop a cross-platform app without me having to worry about numerous clones of the app appearing in various app stores laden with ads.&lt;/p&gt;
&lt;p&gt;The source code for CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; can be found in my &lt;a href="https://github.com/ibebbs/CODuo"&gt;COduo repository on Github&lt;/a&gt;. If you like or use the source-code, please take the time to &amp;quot;star&amp;quot; the repository; it's a small gesture which really fuels developers's enthusiasm for projects such as these.&lt;/p&gt;
&lt;h2 id="when-will-new-posts-about-coduo-be-made-available"&gt;When will new posts about CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; be made available?&lt;/h2&gt;
&lt;p&gt;I intend to write/release a new post in the series every few days.&lt;/p&gt;
&lt;p&gt;My plan is for parts 2 and 3 to provide a high level overview of the service-side infrastructure and client app architecture respectively. These posts won't specifically discuss the Uno Platform but will instead provide insight into how the project was designed and how this design simplifies the development of a cross-platform app such as CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt;.&lt;/p&gt;
&lt;p&gt;After parts 2 and 3 I will be diving into the various considerations of using the Uno Platform to deliver a cross-platform app. Part 4 will detail how to use the TwoPaneView to develop an app that runs natively on dual-screen devices and part 5 onwards will discuss how other UI components were implemented.&lt;/p&gt;
&lt;p&gt;I will round out the series by highlighting platform differences you need to be aware of while using the Uno Platform and my experience of deploying CO&lt;sub&gt;&lt;em&gt;duo&lt;/em&gt;&lt;/sub&gt; to each of the various apps stores.&lt;/p&gt;
&lt;h2 id="finally"&gt;Finally&lt;/h2&gt;
&lt;p&gt;I hope you enjoy this series and that it goes some way to demonstrating the massive potential presented by the Uno Platform for delivering cross-platform experiences without having to invest in additional staff training nor bifurcating your development efforts.&lt;/p&gt;
&lt;p&gt;If you or your company are interested in building apps that can leverage the dual screen capabilities of new devices such as the Surface Duo and Surface Neo, or are keen to understand how a single code-base can deliver apps to &lt;em&gt;every platform from mobile phones to web sites&lt;/em&gt;, then please feel free to drop me a line using any of the links below or from my &lt;a href="https://ian.bebbs.co.uk/about"&gt;about page&lt;/a&gt;. I am actively seeking new clients in this space and would be happy to discuss any ideas you have or projects you're planning.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Uno, Duo, Hey!</title>
			<link>http://ian.bebbs.co.uk/posts/UnoDuoHey</link>
			<description>&lt;p&gt;Last December I wrote &lt;a href="https://ian.bebbs.co.uk/posts/Uno"&gt;a blog post&lt;/a&gt; called "The Seven GUIs of Christmas" as part of the &lt;a href="https://crosscuttingconcerns.com/The-Third-Annual-csharp-Advent"&gt;Third Annual C# Advent&lt;/a&gt; series. This post showed the use of the &lt;a href="https://platform.uno/"&gt;Uno Platform&lt;/a&gt; to write cross-platform apps in UWP. One of the major drivers behind this blog post a desire to write apps for Microsoft's &lt;a href="https://news.microsoft.com/october-2-2019/"&gt;recently announced Surface Neo and Surface Duo devices&lt;/a&gt; which run Windows 10X and Android respectively. Well, a couple of days ago, Microsoft finally released a &lt;a href="https://blogs.windows.com/windowsdeveloper/2020/01/22/announcing-dual-screen-preview-sdks-and-microsoft-365-developer-day/"&gt;preview SDK for the Surface Duo&lt;/a&gt; which included an Android Emulator with a preview Surface Duo image. Today I finally got a chance to see whether the Uno Platform really could deliver on these new form-factors.&lt;/p&gt;</description>
			<enclosure url="http://ian.bebbs.co.uk/Content/UnoDuoHey/SurfaceDuo-Title.jpg" length="0" type="image" />
			<guid>http://ian.bebbs.co.uk/posts/UnoDuoHey</guid>
			<pubDate>Fri, 24 Jan 2020 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;Last December I wrote &lt;a href="https://ian.bebbs.co.uk/posts/Uno"&gt;a blog post&lt;/a&gt; called &amp;quot;The Seven GUIs of Christmas&amp;quot; as part of the &lt;a href="https://crosscuttingconcerns.com/The-Third-Annual-csharp-Advent"&gt;Third Annual C# Advent&lt;/a&gt; series. This post showed the use of the &lt;a href="https://platform.uno/"&gt;Uno Platform&lt;/a&gt; to write cross-platform apps in UWP. One of the major drivers behind this blog post a desire to write apps for Microsoft's &lt;a href="https://news.microsoft.com/october-2-2019/"&gt;recently announced Surface Neo and Surface Duo devices&lt;/a&gt; which run Windows 10X and Android respectively. Well, a couple of days ago, Microsoft finally released a &lt;a href="https://blogs.windows.com/windowsdeveloper/2020/01/22/announcing-dual-screen-preview-sdks-and-microsoft-365-developer-day/"&gt;preview SDK for the Surface Duo&lt;/a&gt; which included an Android Emulator with a preview Surface Duo image. Today I finally got a chance to see whether the Uno Platform really could deliver on these new form-factors.&lt;/p&gt;
&lt;h2 id="installing-the-emulator"&gt;Installing the Emulator&lt;/h2&gt;
&lt;p&gt;If, like me, you don't have Android Studio installed and/or you want to install the Surface Duo SDK in a non-standard location (my super-speedy Intel Optane 900P C:\ drive is getting a little crowded!), you're going to face issues running the emulator. This is mostly due to the &lt;code&gt;run.bat&lt;/code&gt; file used to launch the emulator not looking in the correct location for the Android SDK and not supporting installation of the Surface Duo SDK in a path that contains spaces.&lt;/p&gt;
&lt;p&gt;If you're encountering issues launching the emulator, navigate to the &lt;code&gt;artifacts&lt;/code&gt; directory within the Surface Duo SDK installation directory and edit the &lt;code&gt;run.bat&lt;/code&gt; file to the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;&amp;#64;echo off

rem ##### ENSURE THE SDK LOCATION BELOW IS CORRECT: #######
set ANDROID_SDK_LOCATION=C:\Program Files (x86)\Android\android-sdk

rem ############ DO NOT Modify below this line ############

set DIRNAME=%~dp0
if &amp;quot;%DIRNAME%&amp;quot; == &amp;quot;&amp;quot; set DIRNAME=.\

echo %DIRNAME%

rem Check if emulator is installed
set EMULATOR=%ANDROID_SDK_LOCATION%\emulator\emulator.exe
echo &amp;quot;%EMULATOR%&amp;quot;
if exist %EMULATOR% (
    set ANDROID_PRODUCT_OUT=%DIRNAME%
    &amp;quot;%EMULATOR%&amp;quot; -verbose -accel auto %* -sysdir &amp;quot;%DIRNAME%\bin&amp;quot; -kernel &amp;quot;%DIRNAME%\bin\kernel-ranchu&amp;quot; -datadir &amp;quot;%DIRNAME%\bin\data&amp;quot; -initdata &amp;quot;%DIRNAME%\bin\userdata.img&amp;quot; -vendor &amp;quot;%DIRNAME%\bin\vendor-qemu.img&amp;quot; -system &amp;quot;%DIRNAME%\bin\system-qemu.img&amp;quot; -initdata &amp;quot;%DIRNAME%\bin\userdata.img&amp;quot; -data &amp;quot;%DIRNAME%\bin\userdata.img&amp;quot;
) else (
    echo &amp;quot;Can't find emulator executable, make sure its installed&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;TBH, the changes are mostly just encapsulating paths within quotes but hopefully this'll save you a little time.&lt;/p&gt;
&lt;p&gt;Hopefully now, when you launch the emulator, you'll be greeted by this:&lt;/p&gt;
&lt;img src="/Content/UnoDuoHey/DuoEmulator.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Android Duo Emulator"/&gt;
&lt;p&gt;Hmm... dual screens!&lt;/p&gt;
&lt;h2 id="getting-started"&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;Microsoft have done a great job of helping developers get started on this platform by supplying some great &lt;a href="https://docs.microsoft.com/en-gb/dual-screen/android/"&gt;code-snippets and samples&lt;/a&gt; in both &lt;a href="https://github.com/microsoft/surface-duo-sdk-samples"&gt;Java&lt;/a&gt; and &lt;a href="https://github.com/microsoft/surface-duo-sdk-xamarin-samples"&gt;C# (using the Xamarin platform)&lt;/a&gt;. Furthermore, the emulator &amp;quot;just works&amp;quot; with the Visual Studio IDE such that, once running, it appears as a standard deployment target allowing you to quickly get apps running within the Surface Duo image.&lt;/p&gt;
&lt;img src="/Content/UnoDuoHey/VisualStudioTargettingDuoEmulator.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="VisualStudio Targetting The Duo Emulator"/&gt;
&lt;h2 id="cross-platform-dual-screen"&gt;Cross-Platform Dual-Screen&lt;/h2&gt;
&lt;p&gt;My first priority with Uno was to make sure I could correctly interpret when the app was running on a single screen or across both screens. To do this, I took a look at the Xamarin samples and quickly saw that they used a &lt;code&gt;ScreenHelper&lt;/code&gt; class to collate information on the current state of the app. This class is provided as part of the (very new - just two days old at time of writing!) &lt;a href="https://www.nuget.org/packages/Xamarin.DuoSdk/0.0.3.2"&gt;Xamarin.DuoSdk nuget package&lt;/a&gt;. Fortunately, when running on Android (or iOS), Uno runs on top of Xamarin meaning I could just add a reference to this package from the &lt;code&gt;Droid&lt;/code&gt; head project of my Uno solution and start using this class right away.&lt;/p&gt;
&lt;p&gt;The main functions of the &lt;code&gt;ScreenHelper&lt;/code&gt; class were abstracted behind an &lt;code&gt;IDeviceHelper&lt;/code&gt; interface so that each head project could provide a platform specific implementation and a small shim written around the &lt;code&gt;ScreenHelper&lt;/code&gt; class to satisfy this interface. Finally, to provide responsiveness to changes, I again used my &lt;a href="https://www.nuget.org/packages/MVx.Observable/"&gt;MVx.Observable nuget package&lt;/a&gt; to dynamically call &lt;code&gt;IDeviceHelper&lt;/code&gt; members and update properties on a view model whenever the application changed modes.&lt;/p&gt;
&lt;p&gt;In very short order, I had this working:&lt;/p&gt;
&lt;iframe width="560" height="315" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" src="https://www.youtube.com/embed/MBPo9GvnX-Q" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Just to highlight: this is completely standard UWP / C# code, running &lt;em&gt;unchanged&lt;/em&gt; on a dual-screen Android device.&lt;/p&gt;
&lt;p&gt;A few comments / caveats:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The loading time of the Uno app in the emulator was due to the app being run, as debug, directly from the Visual Studio IDE and is not indicative of Uno Platform app start times.&lt;/li&gt;
&lt;li&gt;The app disappearing when switching between screens or between single and dual screen modes is not due to the Uno Platform; this happen with apps that come as part of the Duo image.&lt;/li&gt;
&lt;li&gt;Occasionally, when switching between single and dual screen modes, the app will just disappear. Again, this is nothing to do with the Uno Platform and happens with apps that come as part of the Duo image.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;h3 id="surface-duo"&gt;Surface Duo&lt;/h3&gt;
&lt;p&gt;While the Surface Duo Android Emulator image is undoubtedly rough around the edges (it is, after all, a preview) it manages to provide a tantalising taste of what using dual-screen devices could be like. Indeed, just running the Contacts and Calendar apps side-by-side boggles the mind with possible interactions between the two. Furthermore Microsoft have, in relatively short order, delivered a preview SDK from which it is possible to start developing new dual-screen apps or enhance existing apps to take advantage of a second screen. Exciting times!&lt;/p&gt;
&lt;h3 id="uno-platform"&gt;Uno Platform&lt;/h3&gt;
&lt;p&gt;Per my experience while writing &amp;quot;The Seven GUIs of Christmas&amp;quot; post, the Uno Platform has continued to preform admirably and shows great promise for writing apps that will run natively across platforms &lt;strong&gt;and&lt;/strong&gt; on dual screens. The only issue I had with Uno while writing the app above was the use of a &amp;quot;Shared Project&amp;quot; to share the Xaml/ViewModel between the various head projects. This approach (which &lt;a href="https://ian.bebbs.co.uk/posts/Uno#six-points-opining"&gt;I recommended against&lt;/a&gt; in my previous post) resulted in Visual Studio stubbornly refusing to show the Xaml editor and countless errors being shown in the error window despite everything compiling and running fine.&lt;/p&gt;
&lt;h3 id="code"&gt;Code&lt;/h3&gt;
&lt;p&gt;All code for this post can be found in my &lt;a href="https://github.com/ibebbs/UnoDuoHey"&gt;UnoDuoHey repository&lt;/a&gt; on Github.&lt;/p&gt;
&lt;h2 id="lastly"&gt;Lastly...&lt;/h2&gt;
&lt;p&gt;I am currently eager to find potential new clients interested in using the Uno Platform to deliver cross-platform apps and those looking to capitalise on the amazing potential of dual-screen devices in particular. If this sounds like you or your company, please feel free to drop me a line to discuss your project/ideas using any of the links below or from my &lt;a href="https://ian.bebbs.co.uk/about"&gt;about page&lt;/a&gt;.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Less ReST, more Hot Chocolate</title>
			<link>http://ian.bebbs.co.uk/posts/LessReSTMoreHotChocolate</link>
			<description>&lt;p&gt;A project I'm working on requires a microservice like evaluation environment. A brief google revealed very little that would suffice so I decided to quickly knock up my own. At the same time, I thought it would be a great opportunity to evaluate &lt;a href="https://hotchocolate.io/"&gt;Hot Chocolate&lt;/a&gt; by &lt;a href="https://chillicream.com/"&gt;Chilli Cream&lt;/a&gt;; a relative newcomer to the (very sparse) GraphQL for .NET scene. In this post I'll also be using &lt;a href="https://github.com/RicoSuter/NSwag"&gt;NSwag&lt;/a&gt; to generate &lt;a href="https://www.openapis.org/"&gt;OpenAPI documents&lt;/a&gt; and &lt;a href="https://docs.microsoft.com/en-us/dotnet/architecture/microservices/implement-resilient-applications/use-httpclientfactory-to-implement-resilient-http-requests#how-to-use-typed-clients-with-httpclientfactory"&gt;Typed Clients&lt;/a&gt; for downstream services and, finally, I will be containerizing the microservices using &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; and employing &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt; to run and test them.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/LessReSTMoreHotChocolate</guid>
			<pubDate>Wed, 08 Jan 2020 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;A project I'm working on requires a microservice like evaluation environment. A brief google revealed very little that would suffice so I decided to quickly knock up my own. At the same time, I thought it would be a great opportunity to evaluate &lt;a href="https://hotchocolate.io/"&gt;Hot Chocolate&lt;/a&gt; by &lt;a href="https://chillicream.com/"&gt;Chilli Cream&lt;/a&gt;; a relative newcomer to the (very sparse) GraphQL for .NET scene. In this post I'll also be using &lt;a href="https://github.com/RicoSuter/NSwag"&gt;NSwag&lt;/a&gt; to generate &lt;a href="https://www.openapis.org/"&gt;OpenAPI documents&lt;/a&gt; and &lt;a href="https://docs.microsoft.com/en-us/dotnet/architecture/microservices/implement-resilient-applications/use-httpclientfactory-to-implement-resilient-http-requests#how-to-use-typed-clients-with-httpclientfactory"&gt;Typed Clients&lt;/a&gt; for downstream services and, finally, I will be containerizing the microservices using &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; and employing &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt; to run and test them.&lt;/p&gt;
&lt;h2 id="contents"&gt;Contents&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#requirements"&gt;Requirements&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#solution"&gt;Solution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#environment"&gt;Environment&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#about-hot-chocolate"&gt;About Hot Chocolate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#solution-structure"&gt;Solution Structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rest-services"&gt;ReST Services&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#cheeze.store"&gt;Cheeze.Store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cheeze.inventory"&gt;Cheeze.Inventory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#providing-swagger-endpoints"&gt;Providing Swagger Endpoints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#generating-typed-clients"&gt;Generating Typed Clients&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#graphql-service"&gt;GraphQL Service&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#object-model"&gt;Object Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#schema-resolvers"&gt;Schema &amp;amp; Resolvers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#service-binding-configuration"&gt;Service Binding &amp;amp; Configuration&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#containerization"&gt;Containerization&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#docker-support"&gt;Docker Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#container-orchestration-support"&gt;Container Orchestration Support&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#testing"&gt;Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="requirements"&gt;Requirements&lt;/h2&gt;
&lt;h3 id="solution"&gt;Solution&lt;/h3&gt;
&lt;p&gt;The requirements for the test environment were pretty simple:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A .net core web service which, when called, fetched and collated data from two other .net core web services. As (conditionally) aggregating data from multiple sources is one of GraphQL's primary use cases I decided a GraphQL endpoint would make for a great entry point into this flow.&lt;/li&gt;
&lt;li&gt;Avoid any tight coupling between the GraphQL endpoint and the underlying web-services yet provide strong compile-time guarantees of cohesion with these services.&lt;/li&gt;
&lt;li&gt;A simple build/deployment/debug loop.&lt;/li&gt;
&lt;li&gt;Embrace 'modern' methodologies; for example asynchronous controller actions and &lt;a href="https://docs.microsoft.com/en-us/dotnet/csharp/nullable-references"&gt;Nullable Reference Types&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="environment"&gt;Environment&lt;/h3&gt;
&lt;p&gt;To follow the following steps you will need:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://dotnet.microsoft.com/download/dotnet-core/3.1"&gt;.Net Core 3.1 SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Powershell (I'd recommend the new &lt;a href="https://www.microsoft.com/en-us/p/windows-terminal-preview/9n0dx20hk701?activetab=pivot:overviewtab"&gt;Windows Terminal&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;A text editor (&lt;a href="https://code.visualstudio.com/Download"&gt;VSCode&lt;/a&gt; perhaps?)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/docker-for-windows/"&gt;Docker for Windows&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="about-hot-chocolate"&gt;About Hot Chocolate&lt;/h2&gt;
&lt;p&gt;I have only just started using Hot Chocolate but really like it. It allows code-first schema modelling using basic POCO classes leaving all the GraphQL magic to be implemented using a neat fluent syntax rooted from a &lt;a href="https://hotchocolate.io/docs/schema"&gt;&lt;code&gt;SchemaBuilder&lt;/code&gt;&lt;/a&gt; class. While this post is most certainly aimed at GraphQL beginners you may glean some additional information about Hot Chocolate from their &lt;a href="https://hotchocolate.io/docs/introduction.html"&gt;&amp;quot;Quick Start&amp;quot;&lt;/a&gt; or by watching &lt;a href="https://www.youtube.com/watch?v=Lr6qyoAT8k4"&gt;any&lt;/a&gt; &lt;a href="https://www.youtube.com/watch?v=2QLhcqFYRpg"&gt;one&lt;/a&gt; of the &lt;a href="https://www.youtube.com/watch?v=q-5MUqLAEFs"&gt;many talks&lt;/a&gt; by Michael Steib on it's use.&lt;/p&gt;
&lt;p&gt;Now, if you do watch/have seen any of the videos here, you will notice that &lt;a href="https://hotchocolate.io/docs/stitching"&gt;Schema Stitching&lt;/a&gt; is mentioned numerous times. In fact, in a couple of videos it is discussed specifically in relation to &amp;quot;stitching&amp;quot; ReST services into a GraphQL schema (along with other GraphQL schemas). This sounded fantastic and was certainly a desired use case when I started using Hot Chocolate. Unfortunately, there is zero documentation or guidance on how this can be achieved at the current time so the project that follows uses basic &lt;a href="https://hotchocolate.io/docs/resolvers"&gt;resolvers&lt;/a&gt; to fetch data from ReST services and AutoMapper to map between schemas.&lt;/p&gt;
&lt;p&gt;Before getting set up, be sure to install Hot Chocolate's template into the dotnet CLI as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;dotnet new -i HotChocolate.Templates.Server
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="solution-structure"&gt;Solution Structure&lt;/h2&gt;
&lt;p&gt;Here's how I set up my solution:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;# Create directories and initialize git
mkdir Cheeze
cd Cheeze
git init
mkdir src
cd src
# Create projects and remove superfluous files
dotnet new graphql -n Cheeze.Graph
dotnet new webapi -n Cheeze.Store
dotnet new classlib -n Cheeze.Store.Client
rm .\Cheeze.Store.Client\Class1.cs
dotnet new webapi -n Cheeze.Inventory
dotnet new classlib -n Cheeze.Inventory.Client
rm .\Cheeze.Inventory.Client\Class1.cs
# Create solution for easy of use from VS
dotnet new sln -n Cheeze
dotnet sln add .\Cheeze.Graph\Cheeze.Graph.csproj
dotnet sln add .\Cheeze.Store\Cheeze.Store.csproj
dotnet sln add .\Cheeze.Store.Client\Cheeze.Store.Client.csproj
dotnet sln add .\Cheeze.Inventory\Cheeze.Inventory.csproj
dotnet sln add .\Cheeze.Inventory.Client\Cheeze.Inventory.Client.csproj
# Add project references
dotnet add .\Cheeze.Graph\Cheeze.Graph.csproj reference .\Cheeze.Store.Client\Cheeze.Store.Client.csproj
dotnet add .\Cheeze.Graph\Cheeze.Graph.csproj reference .\Cheeze.Inventory.Client\Cheeze.Inventory.Client.csproj
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, if we do a &lt;code&gt;dotnet build&lt;/code&gt; now we'll see a couple of errors due to &lt;a href="https://github.com/ChilliCream/hotchocolate/issues/1329"&gt;a bug&lt;/a&gt; in the Hot Chocolate server template which fails to add the HotChocolate namespace to the list of using statements in &lt;code&gt;Startup.cs&lt;/code&gt;. This can be resolved with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&amp;#64;(Get-Content .\Cheeze.Graph\Startup.cs)[0..2] + &amp;quot;using HotChocolate;&amp;quot; + &amp;#64;(Get-Content .\Cheeze.Graph\Startup.cs)[3..44] | Set-Content .\Cheeze.Graph\Startup.cs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Everything should now build correctly.&lt;/p&gt;
&lt;h2 id="rest-services"&gt;ReST Services&lt;/h2&gt;
&lt;p&gt;We'll start by building out our ReST services.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Note: These ReST services simply return static (and somewhat bare) data as that's all the need to be for my test environment. As such there is no persistence layer implemented and much of the schema for each type is unused.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The two services are as follows:&lt;/p&gt;
&lt;h3 id="cheeze.store"&gt;Cheeze.Store&lt;/h3&gt;
&lt;p&gt;This web api will provide a full list of all cheeses available through the store along with descriptions and image URLs. It will (for simplicity) have a single endpoint which allows a consumer to retrieve all available cheeses.&lt;/p&gt;
&lt;p&gt;To set this up, do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Delete the &lt;code&gt;Controllers&lt;/code&gt; folder - We're a microservice and will be providing a single endpoint so there's no need for plurality here.&lt;/li&gt;
&lt;li&gt;Delete &lt;code&gt;WeatherForecast.cs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Add the following files:
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Controller.cs&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using System;
using System.Collections.Generic;
using System.Net;
using System.Threading.Tasks;
using Microsoft.AspNetCore.Mvc;

namespace Cheeze.Store
{
    [Route(&amp;quot;api/store&amp;quot;)]
    public class Controller : Microsoft.AspNetCore.Mvc.Controller
    {
        [HttpGet]
        [ProducesResponseType(typeof(IEnumerable&amp;lt;Cheese&amp;gt;), (int)HttpStatusCode.OK)]
        public Task&amp;lt;ActionResult&amp;lt;IEnumerable&amp;lt;Cheese&amp;gt;&amp;gt;&amp;gt; Get()
        {
            var result = new[]
            {
                new Cheese
                {
                    Id = Guid.Parse(&amp;quot;1468841a-5fbe-41c5-83b3-ab136b7ae70c&amp;quot;),
                    Name = &amp;quot;API Cheese&amp;quot;
                }
            };

            return Task.FromResult&amp;lt;ActionResult&amp;lt;IEnumerable&amp;lt;Cheese&amp;gt;&amp;gt;&amp;gt;(Ok(result));
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Cheese.cs&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using System;
using System.ComponentModel.DataAnnotations;

namespace Cheeze.Store
{
    public class Cheese
    {
        public Guid Id { get; set; }

        public Uri? Uri { get; set; }

        [Required]
        public string Name { get; set; } = string.Empty;

        public string Description { get; set; } = string.Empty;

        public decimal Price { get; set; }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="cheeze.inventory"&gt;Cheeze.Inventory&lt;/h3&gt;
&lt;p&gt;This web api provides up to date inventory information for cheeses available through the store. It will have two endpoints which allow a consumer to get the availability of a specific cheese or a list of cheeses by id.&lt;/p&gt;
&lt;p&gt;To set this up, do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Delete the &lt;code&gt;Controllers&lt;/code&gt; folder - same as above&lt;/li&gt;
&lt;li&gt;Delete &lt;code&gt;WeatherForecast.cs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Add the following files:
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Controller.cs&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using Microsoft.AspNetCore.Mvc;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Net;
using System.Threading.Tasks;

namespace Cheeze.Inventory
{
    [Route(&amp;quot;api/inventory&amp;quot;)]
    public class Controller : Microsoft.AspNetCore.Mvc.Controller
    {
        private static readonly Random Random = new Random();

        [HttpGet(&amp;quot;{id}&amp;quot;)]
        [ProducesResponseType(typeof(uint), (int)HttpStatusCode.OK)]
        public Task&amp;lt;ActionResult&amp;lt;uint&amp;gt;&amp;gt; Get(Guid id)
        {
            return Task.FromResult&amp;lt;ActionResult&amp;lt;uint&amp;gt;&amp;gt;(Ok((uint)Random.Next(10)));
        }

        [HttpPost]
        [ProducesResponseType(typeof(IEnumerable&amp;lt;Available&amp;gt;), (int)HttpStatusCode.OK)]
        public Task&amp;lt;ActionResult&amp;lt;IEnumerable&amp;lt;Available&amp;gt;&amp;gt;&amp;gt; Post([FromBody] Request request)
        {
            var available = request.Ids
                .Select(id =&amp;gt; new Available { Id = id, Quantity = (uint)Random.Next(10) }) 
                .ToArray();

            return Task.FromResult&amp;lt;ActionResult&amp;lt;IEnumerable&amp;lt;Available&amp;gt;&amp;gt;&amp;gt;(Ok(available));
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Request.cs&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using System;
using System.Collections.Generic;
using System.Linq;

namespace Cheeze.Inventory
{
    public class Request
    {
        public IEnumerable&amp;lt;Guid&amp;gt; Ids { get; set; } = Enumerable.Empty&amp;lt;Guid&amp;gt;();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Available.cs&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using System;

namespace Cheeze.Inventory
{
    public class Available
    {
        public Guid Id { get; set; }

        public uint Quantity { get; set; }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="providing-swagger-endpoints"&gt;Providing Swagger Endpoints&lt;/h3&gt;
&lt;p&gt;Both ReST services will provide a swagger endpoints to facilitate their use. We're using &lt;a href="https://github.com/RicoSuter/NSwag"&gt;'NSwag'&lt;/a&gt; to generate these endpoints for each project as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add the required packages to each project:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;dotnet add .\Cheeze.Store\Cheeze.Store.csproj package NSwag.AspNetCore
dotnet add .\Cheeze.Inventory\Cheeze.Inventory.csproj package NSwag.AspNetCore
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;In the &lt;code&gt;Startup.ConfigureServices&lt;/code&gt; method, register the required Swagger services:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;public void ConfigureServices(IServiceCollection services)
{
    services.AddControllers();

    // Register the Swagger services
    services.AddOpenApiDocument();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the &lt;code&gt;Startup.Configure&lt;/code&gt; method, enable the middleware for serving the generated Swagger specification and the Swagger UI:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;public void Configure(IApplicationBuilder app)
{
    if (env.IsDevelopment())
    {
        app.UseDeveloperExceptionPage();
    }

    // Remove HTTP-&amp;gt;HTTPS redirection for simplified hosting in Docker
    //app.UseHttpsRedirection();

    app.UseRouting();

    // Register the Swagger generator and the Swagger UI middlewares
    app.UseOpenApi();
    app.UseSwaggerUi3();

    app.UseAuthorization();

    app.UseEndpoints(endpoints =&amp;gt;
    {
        endpoints.MapControllers();
    });
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Build the solution to restore all dependencies:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;dotnet build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you now build and run either project you should now be able to navigate to the swagger endpoint UI. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;dotnet run --project .\Cheeze.Store\Cheeze.Store.csproj
start &amp;quot;microsoft-edge:http://localhost:5000/swagger&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="generating-typed-clients"&gt;Generating Typed Clients&lt;/h3&gt;
&lt;p&gt;We're now going to use NSwag`s MSBuild package to generate a &lt;a href="https://docs.microsoft.com/en-us/dotnet/architecture/microservices/implement-resilient-applications/use-httpclientfactory-to-implement-resilient-http-requests#how-to-use-typed-clients-with-httpclientfactory"&gt;Typed Client&lt;/a&gt; for each project at build time. To do this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Install the required packages&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;dotnet add .\Cheeze.Store\Cheeze.Store.csproj package NSwag.MSBuild
dotnet add .\Cheeze.Inventory\Cheeze.Inventory.csproj package NSwag.MSBuild
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Build project to restore packages&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Edit the project file to enable Nullable Reference Types and include all assemblies on build:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csproj"&gt;&amp;lt;Project Sdk=&amp;quot;Microsoft.NET.Sdk.Web&amp;quot;&amp;gt;
    &amp;lt;PropertyGroup&amp;gt;
        &amp;lt;TargetFramework&amp;gt;netcoreapp3.1&amp;lt;/TargetFramework&amp;gt;
        &amp;lt;Nullable&amp;gt;enable&amp;lt;/Nullable&amp;gt; &amp;lt;!-- Add this line --&amp;gt;
        &amp;lt;CopyLocalLockFileAssemblies&amp;gt;true&amp;lt;/CopyLocalLockFileAssemblies&amp;gt; &amp;lt;!-- And this line --&amp;gt;
    &amp;lt;/PropertyGroup&amp;gt;
    ...
&amp;lt;/Project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Generate an NSwag configuration file&lt;/p&gt;
&lt;p&gt;Building the solution after adding the &lt;code&gt;NSwag.MSBuild&lt;/code&gt; package should have added the NSwag tools to your nuget package cache (usually in the following directory: &lt;code&gt;%userprofile%\.nuget\packages\nswag.msbuild\13.2.0\tools\NetCore31&lt;/code&gt;). Using these build tools we can generate the required configuration file for each project with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;cd .\Cheeze.Inventory
~\.nuget\packages\nswag.msbuild\13.2.0\tools\NetCore31\dotnet-nswag.exe new
cd ..\Cheeze.Store
~\.nuget\packages\nswag.msbuild\13.2.0\tools\NetCore31\dotnet-nswag.exe new
cd ..
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we need to replace sections the generated configuration file with populated values. In each of files do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Set the &lt;code&gt;runtime&lt;/code&gt; version:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-json"&gt;{
    &amp;quot;runtime&amp;quot;: &amp;quot;NetCore31&amp;quot;,
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Modify the &lt;code&gt;documentGenerator&lt;/code&gt; section to generate an OpenAPI document from the generated web assembly. Do this by replacing the &lt;code&gt;documentGenerator&lt;/code&gt; section with the following (ensuring to replace the &lt;code&gt;controllerNames&lt;/code&gt;, &lt;code&gt;defaultUrlTemplate&lt;/code&gt; and &lt;code&gt;assemblyPaths&lt;/code&gt; to the correct values for each project):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-json"&gt;{
    ...
    &amp;quot;documentGenerator&amp;quot;: {
        &amp;quot;webApiToOpenApi&amp;quot;: {
            &amp;quot;controllerNames&amp;quot;: [
                &amp;quot;Cheeze.Store.Controller&amp;quot;
            ],
            &amp;quot;isAspNetCore&amp;quot;: true,
            &amp;quot;resolveJsonOptions&amp;quot;: false,
            &amp;quot;defaultUrlTemplate&amp;quot;: &amp;quot;api/store&amp;quot;,
            &amp;quot;addMissingPathParameters&amp;quot;: false,
            &amp;quot;includedVersions&amp;quot;: null,
            &amp;quot;defaultPropertyNameHandling&amp;quot;: &amp;quot;Default&amp;quot;,
            &amp;quot;defaultReferenceTypeNullHandling&amp;quot;: &amp;quot;Null&amp;quot;,
            &amp;quot;defaultDictionaryValueReferenceTypeNullHandling&amp;quot;: &amp;quot;NotNull&amp;quot;,
            &amp;quot;defaultResponseReferenceTypeNullHandling&amp;quot;: &amp;quot;NotNull&amp;quot;,
            &amp;quot;defaultEnumHandling&amp;quot;: &amp;quot;Integer&amp;quot;,
            &amp;quot;flattenInheritanceHierarchy&amp;quot;: false,
            &amp;quot;generateKnownTypes&amp;quot;: true,
            &amp;quot;generateEnumMappingDescription&amp;quot;: false,
            &amp;quot;generateXmlObjects&amp;quot;: false,
            &amp;quot;generateAbstractProperties&amp;quot;: false,
            &amp;quot;generateAbstractSchemas&amp;quot;: true,
            &amp;quot;ignoreObsoleteProperties&amp;quot;: false,
            &amp;quot;allowReferencesWithProperties&amp;quot;: false,
            &amp;quot;excludedTypeNames&amp;quot;: [],
            &amp;quot;serviceHost&amp;quot;: null,
            &amp;quot;serviceBasePath&amp;quot;: null,
            &amp;quot;serviceSchemes&amp;quot;: [],
            &amp;quot;infoTitle&amp;quot;: &amp;quot;My Title&amp;quot;,
            &amp;quot;infoDescription&amp;quot;: null,
            &amp;quot;infoVersion&amp;quot;: &amp;quot;1.0.0&amp;quot;,
            &amp;quot;documentTemplate&amp;quot;: null,
            &amp;quot;documentProcessorTypes&amp;quot;: [],
            &amp;quot;operationProcessorTypes&amp;quot;: [],
            &amp;quot;typeNameGeneratorType&amp;quot;: null,
            &amp;quot;schemaNameGeneratorType&amp;quot;: null,
            &amp;quot;contractResolverType&amp;quot;: null,
            &amp;quot;serializerSettingsType&amp;quot;: null,
            &amp;quot;useDocumentProvider&amp;quot;: true,
            &amp;quot;documentName&amp;quot;: &amp;quot;v1&amp;quot;,
            &amp;quot;aspNetCoreEnvironment&amp;quot;: null,
            &amp;quot;createWebHostBuilderMethod&amp;quot;: null,
            &amp;quot;startupType&amp;quot;: null,
            &amp;quot;allowNullableBodyParameters&amp;quot;: true,
            &amp;quot;output&amp;quot;: null,
            &amp;quot;outputType&amp;quot;: &amp;quot;Swagger2&amp;quot;,
            &amp;quot;assemblyPaths&amp;quot;: [
                &amp;quot;bin/$(Configuration)/netcoreapp3.1/Cheeze.Store.dll&amp;quot;
            ],
            &amp;quot;assemblyConfig&amp;quot;: null,
            &amp;quot;referencePaths&amp;quot;: [],
            &amp;quot;useNuGetCache&amp;quot;: true
        }
    },
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Remove the &lt;code&gt;openApiToTypeScriptClient&lt;/code&gt; and &lt;code&gt;openApiToCSharpController&lt;/code&gt; sections from within the &lt;code&gt;codeGenerators&lt;/code&gt; section of each file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Modify the &lt;code&gt;openApiToCSharpClient&lt;/code&gt; section to generate C# typed clients from the OpenAPI document. Do this by replacing the &lt;code&gt;openApiToCSharpClient&lt;/code&gt; section with the following (ensuring to replace the &lt;code&gt;className&lt;/code&gt;, &lt;code&gt;namespace&lt;/code&gt; and &lt;code&gt;output&lt;/code&gt; to the correct values for each project):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-json"&gt;{
    ...
    &amp;quot;codeGenerators&amp;quot;: {
        &amp;quot;openApiToCSharpClient&amp;quot;: {
            &amp;quot;clientBaseClass&amp;quot;: null,
            &amp;quot;configurationClass&amp;quot;: null,
            &amp;quot;generateClientClasses&amp;quot;: true,
            &amp;quot;generateClientInterfaces&amp;quot;: true,
            &amp;quot;injectHttpClient&amp;quot;: true,
            &amp;quot;disposeHttpClient&amp;quot;: true,
            &amp;quot;protectedMethods&amp;quot;: [],
            &amp;quot;generateExceptionClasses&amp;quot;: true,
            &amp;quot;exceptionClass&amp;quot;: &amp;quot;ApiException&amp;quot;,
            &amp;quot;wrapDtoExceptions&amp;quot;: true,
            &amp;quot;useHttpClientCreationMethod&amp;quot;: false,
            &amp;quot;httpClientType&amp;quot;: &amp;quot;System.Net.Http.HttpClient&amp;quot;,
            &amp;quot;useHttpRequestMessageCreationMethod&amp;quot;: false,
            &amp;quot;useBaseUrl&amp;quot;: false,
            &amp;quot;generateBaseUrlProperty&amp;quot;: false,
            &amp;quot;generateSyncMethods&amp;quot;: false,
            &amp;quot;exposeJsonSerializerSettings&amp;quot;: false,
            &amp;quot;clientClassAccessModifier&amp;quot;: &amp;quot;public&amp;quot;,
            &amp;quot;typeAccessModifier&amp;quot;: &amp;quot;public&amp;quot;,
            &amp;quot;generateContractsOutput&amp;quot;: false,
            &amp;quot;contractsNamespace&amp;quot;: null,
            &amp;quot;contractsOutputFilePath&amp;quot;: null,
            &amp;quot;parameterDateTimeFormat&amp;quot;: &amp;quot;s&amp;quot;,
            &amp;quot;parameterDateFormat&amp;quot;: &amp;quot;yyyy-MM-dd&amp;quot;,
            &amp;quot;generateUpdateJsonSerializerSettingsMethod&amp;quot;: true,
            &amp;quot;serializeTypeInformation&amp;quot;: false,
            &amp;quot;queryNullValue&amp;quot;: &amp;quot;&amp;quot;,
            &amp;quot;className&amp;quot;: &amp;quot;StoreClient&amp;quot;,
            &amp;quot;operationGenerationMode&amp;quot;: &amp;quot;MultipleClientsFromOperationId&amp;quot;,
            &amp;quot;additionalNamespaceUsages&amp;quot;: [],
            &amp;quot;additionalContractNamespaceUsages&amp;quot;: [],
            &amp;quot;generateOptionalParameters&amp;quot;: false,
            &amp;quot;generateJsonMethods&amp;quot;: false,
            &amp;quot;enforceFlagEnums&amp;quot;: false,
            &amp;quot;parameterArrayType&amp;quot;: &amp;quot;System.Collections.Generic.IEnumerable&amp;quot;,
            &amp;quot;parameterDictionaryType&amp;quot;: &amp;quot;System.Collections.Generic.IDictionary&amp;quot;,
            &amp;quot;responseArrayType&amp;quot;: &amp;quot;System.Collections.Generic.ICollection&amp;quot;,
            &amp;quot;responseDictionaryType&amp;quot;: &amp;quot;System.Collections.Generic.IDictionary&amp;quot;,
            &amp;quot;wrapResponses&amp;quot;: false,
            &amp;quot;wrapResponseMethods&amp;quot;: [],
            &amp;quot;generateResponseClasses&amp;quot;: true,
            &amp;quot;responseClass&amp;quot;: &amp;quot;SwaggerResponse&amp;quot;,
            &amp;quot;namespace&amp;quot;: &amp;quot;Cheeze.Store.Client&amp;quot;,
            &amp;quot;requiredPropertiesMustBeDefined&amp;quot;: true,
            &amp;quot;dateType&amp;quot;: &amp;quot;System.DateTimeOffset&amp;quot;,
            &amp;quot;jsonConverters&amp;quot;: null,
            &amp;quot;anyType&amp;quot;: &amp;quot;object&amp;quot;,
            &amp;quot;dateTimeType&amp;quot;: &amp;quot;System.DateTimeOffset&amp;quot;,
            &amp;quot;timeType&amp;quot;: &amp;quot;System.TimeSpan&amp;quot;,
            &amp;quot;timeSpanType&amp;quot;: &amp;quot;System.TimeSpan&amp;quot;,
            &amp;quot;arrayType&amp;quot;: &amp;quot;System.Collections.Generic.ICollection&amp;quot;,
            &amp;quot;arrayInstanceType&amp;quot;: &amp;quot;System.Collections.ObjectModel.Collection&amp;quot;,
            &amp;quot;dictionaryType&amp;quot;: &amp;quot;System.Collections.Generic.IDictionary&amp;quot;,
            &amp;quot;dictionaryInstanceType&amp;quot;: &amp;quot;System.Collections.Generic.Dictionary&amp;quot;,
            &amp;quot;arrayBaseType&amp;quot;: &amp;quot;System.Collections.ObjectModel.Collection&amp;quot;,
            &amp;quot;dictionaryBaseType&amp;quot;: &amp;quot;System.Collections.Generic.Dictionary&amp;quot;,
            &amp;quot;classStyle&amp;quot;: &amp;quot;Poco&amp;quot;,
            &amp;quot;generateDefaultValues&amp;quot;: true,
            &amp;quot;generateDataAnnotations&amp;quot;: true,
            &amp;quot;excludedTypeNames&amp;quot;: [],
            &amp;quot;excludedParameterNames&amp;quot;: [],
            &amp;quot;handleReferences&amp;quot;: false,
            &amp;quot;generateImmutableArrayProperties&amp;quot;: false,
            &amp;quot;generateImmutableDictionaryProperties&amp;quot;: false,
            &amp;quot;jsonSerializerSettingsTransformationMethod&amp;quot;: null,
            &amp;quot;inlineNamedArrays&amp;quot;: false,
            &amp;quot;inlineNamedDictionaries&amp;quot;: false,
            &amp;quot;inlineNamedTuples&amp;quot;: true,
            &amp;quot;inlineNamedAny&amp;quot;: false,
            &amp;quot;generateDtoTypes&amp;quot;: true,
            &amp;quot;generateOptionalPropertiesAsNullable&amp;quot;: false,
            &amp;quot;templateDirectory&amp;quot;: null,
            &amp;quot;typeNameGeneratorType&amp;quot;: null,
            &amp;quot;propertyNameGeneratorType&amp;quot;: null,
            &amp;quot;enumNameGeneratorType&amp;quot;: null,
            &amp;quot;serviceHost&amp;quot;: null,
            &amp;quot;serviceSchemes&amp;quot;: null,
            &amp;quot;output&amp;quot;: &amp;quot;$(Target)/StoreClient.Generated.cs&amp;quot;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Edit the project file to use the configuration file to generate the typed client for each project (replacing &lt;code&gt;[PROJECT_NAME]&lt;/code&gt; with &lt;code&gt;Cheeze.Store.Client&lt;/code&gt; or &lt;code&gt;Cheeze.Inventory.Client&lt;/code&gt; as appropriate):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csproj"&gt;&amp;lt;Project Sdk=&amp;quot;Microsoft.NET.Sdk.Web&amp;quot;&amp;gt;
    ...
    &amp;lt;Target Name=&amp;quot;NSwag&amp;quot; AfterTargets=&amp;quot;Build&amp;quot;&amp;gt;
        &amp;lt;Copy SourceFiles=&amp;quot;&amp;#64;(ReferencePath)&amp;quot; DestinationFolder=&amp;quot;$(OutDir)References&amp;quot; /&amp;gt;
        &amp;lt;Exec Condition=&amp;quot;'$(NSwag)'=='true'&amp;quot; Command=&amp;quot;$(NSwagExe_Core31) run nswag.json /variables:Configuration=$(Configuration),OutDir=$(OutDir),Target=$(SolutionDir)[PROJECT_NAME]&amp;quot; /&amp;gt;
        &amp;lt;RemoveDir Directories=&amp;quot;$(OutDir)References&amp;quot; /&amp;gt;
    &amp;lt;/Target&amp;gt;
    ...
&amp;lt;/Project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add a &lt;code&gt;build.ps1&lt;/code&gt; file to the &lt;code&gt;src&lt;/code&gt; directory containing:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;$solutionDir = Get-Location
dotnet build .\Cheeze.Store\Cheeze.Store.csproj /p:NSwag=true /p:SolutionDir=$solutionDir
dotnet build .\Cheeze.Inventory\Cheeze.Inventory.csproj /p:NSwag=true /p:SolutionDir=$solutionDir
dotnet build .\Cheeze.Store.Client\Cheeze.Store.Client.csproj
dotnet build .\Cheeze.Inventory.Client\Cheeze.Inventory.Client.csproj
dotnet build .\Cheeze.Graph\Cheeze.Graph.csproj
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The build script is required to ensure projects are built in the correct order and to ensure we don't try to regenerate our typed clients while containerizing our projects (see below).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adding &lt;code&gt;Newtonsoft.Json&lt;/code&gt; and &lt;code&gt;System.ComponentModel.Annotations&lt;/code&gt; packages to the client projects:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;dotnet add .\Cheeze.Store.Client\Cheeze.Store.Client.csproj package Newtonsoft.Json
dotnet add .\Cheeze.Store.Client\Cheeze.Store.Client.csproj package System.ComponentModel.Annotations
dotnet add .\Cheeze.Inventory.Client\Cheeze.Inventory.Client.csproj package Newtonsoft.Json
dotnet add .\Cheeze.Inventory.Client\Cheeze.Inventory.Client.csproj package System.ComponentModel.Annotations
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Build!&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;.\build.ps1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If all the above is correct, we should have a successful build and see that &lt;code&gt;StoreClient.Generated.cs&lt;/code&gt; and &lt;code&gt;InventoryClient.Generated.cs&lt;/code&gt; appear in the &lt;code&gt;Cheeze.Store&lt;/code&gt; and &lt;code&gt;Cheeze.Inventory&lt;/code&gt; directories respectively.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="graphql-service"&gt;GraphQL Service&lt;/h2&gt;
&lt;p&gt;Finally we can get around to implementing our GraphQL service. We'll undertake the following steps to get this service running as expected:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create an object model of our DTOs and Graph Query as POCO objects&lt;/li&gt;
&lt;li&gt;Build a GraphQL schema from these objects using the SchemaBuilder&lt;/li&gt;
&lt;li&gt;Configure the .Net Core host to correctly run the GraphQL Service&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;First however, as we're not currently able to use Schema Stitching, we need to perform mapping between the &lt;code&gt;Cheeze.Store&lt;/code&gt; and &lt;code&gt;Cheeze.Graph&lt;/code&gt; schemas ourselves. To facilitate this, we're going to use &lt;a href="https://automapper.org/"&gt;Automapper&lt;/a&gt; so we need to add the package to &lt;code&gt;Cheeze.Graph&lt;/code&gt; using:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;dotnet add .\Cheeze.Graph\Cheeze.Graph.csproj package AutoMapper
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="object-model"&gt;Object Model&lt;/h3&gt;
&lt;p&gt;Add a &lt;code&gt;Cheese.cs&lt;/code&gt; to &lt;code&gt;Cheeze.Graph&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using System;

namespace Cheeze.Graph
{
    public class Cheese
    {
        public Guid Id { get; set; }

        public Uri? Uri { get; set; }

        public string Name { get; set; } = string.Empty;

        public string Description { get; set; } = string.Empty;

        public decimal Price { get; set; }

        public int Available { get; set; }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are two things to note here:&lt;/p&gt;
&lt;p&gt;Firstly, the Cheese type is very similar - &lt;strong&gt;but not identical&lt;/strong&gt; - to the Cheese type declared in &lt;code&gt;Cheeze.Store&lt;/code&gt;. Crucially this Cheese type has an Available property which is not in the data provided by &lt;code&gt;Cheeze.Store&lt;/code&gt; and instead will be populated by dependent calls to &lt;code&gt;Cheeze.Inventory&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Secondly this type does not implement any behaviour, it merely declares the shape (i.e. schema) of the data that can be provided by this service. All GraphQL functionality is provided via the SchemaBuilder and associated Resolvers as see below.&lt;/p&gt;
&lt;h3 id="schema-resolvers"&gt;Schema &amp;amp; Resolvers&lt;/h3&gt;
&lt;p&gt;Add a &lt;code&gt;Schema.cs&lt;/code&gt; file to &lt;code&gt;Cheeze.Graph&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using AutoMapper;
using HotChocolate;
using HotChocolate.Resolvers;
using HotChocolate.Types;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;

namespace Cheeze.Graph
{
    public static class Schema
    {
        private static readonly IMapper Mapper;

        static Schema()
        {
            var mapping = new MapperConfiguration(
                configuration =&amp;gt;
                {
                    configuration.CreateMap&amp;lt;Cheeze.Store.Client.Cheese, Cheese&amp;gt;()
                        .ForMember(cheese =&amp;gt; cheese.Available, options =&amp;gt; options.Ignore());
                }
            );

            Mapper = mapping.CreateMapper();
        }
        private static async Task&amp;lt;IReadOnlyDictionary&amp;lt;Guid, int&amp;gt;&amp;gt; FetchInventory(this Cheeze.Inventory.Client.IInventoryClient inventoryClient, IReadOnlyList&amp;lt;Guid&amp;gt; cheeses)
        {
            var response = await inventoryClient.PostAsync(new Cheeze.Inventory.Client.Request { Ids = cheeses.ToArray() });

            return cheeses
                .GroupJoin(response, id =&amp;gt; id, available =&amp;gt; available.Id, (id, available) =&amp;gt; (Id: id, Available: available.Select(a =&amp;gt; a.Quantity).FirstOrDefault()))
                .ToDictionary(tuple =&amp;gt; tuple.Id, tuple =&amp;gt; tuple.Available);
        }

        private static async Task&amp;lt;int&amp;gt; ResolveInventory(this IResolverContext context)
        {
            var dataLoader = context.BatchDataLoader&amp;lt;Guid, int&amp;gt;(
                &amp;quot;availableById&amp;quot;,
                context.Service&amp;lt;Cheeze.Inventory.Client.IInventoryClient&amp;gt;().FetchInventory);

            return await dataLoader.LoadAsync(context.Parent&amp;lt;Cheese&amp;gt;().Id, context.RequestAborted);
        }

        private static async Task&amp;lt;IEnumerable&amp;lt;Cheese&amp;gt;&amp;gt; ResolveCheeses(this IResolverContext context)
        {
            var results = await context.Service&amp;lt;Cheeze.Store.Client.IStoreClient&amp;gt;().GetAsync();

            return results.Select(source =&amp;gt; Mapper.Map&amp;lt;Cheeze.Store.Client.Cheese, Cheese&amp;gt;(source));
        }

        public static ISchemaBuilder Build()
        {
            return SchemaBuilder.New()
                .AddQueryType(
                    typeDescriptor =&amp;gt; typeDescriptor
                        .Field(&amp;quot;Cheese&amp;quot;)
                            .Resolver(context =&amp;gt; context.ResolveCheeses()))
                .AddObjectType&amp;lt;Cheese&amp;gt;(
                    cheese =&amp;gt; cheese
                        .Field(f =&amp;gt; f.Available)
                            .Resolver(context =&amp;gt; context.ResolveInventory()))
                .ModifyOptions(o =&amp;gt; o.RemoveUnreachableTypes = true);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Amazingly, this single class implements &lt;strong&gt;all&lt;/strong&gt; the functionality needed to provide a GraphQL compliant endpoint in ~70 SLoC. There is rather a lot going on though so lets break it down starting with the static public method &lt;code&gt;Build&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Build&lt;/code&gt; method uses (and returns) a &lt;code&gt;SchemaBuilder&lt;/code&gt; to define the schema that will be presented through the GraphQL endpoint. This comprises two main elements: the &lt;code&gt;QueryType&lt;/code&gt; - provided by the &lt;code&gt;.AddQueryType()&lt;/code&gt; fluent method - and the &lt;code&gt;Cheese&lt;/code&gt; object type - provided by the &lt;code&gt;.AddObjectType&amp;lt;Cheese&amp;gt;()&lt;/code&gt; fluent method. We'll dig into each of these here.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;AddQueryType&lt;/code&gt; defines the types of queries that can be executed by this GraphQL endpoint in a purely code-first manner. The code above adds a field &lt;code&gt;Cheese&lt;/code&gt; which, when used in the query, uses the &lt;code&gt;ResolveCheeses()&lt;/code&gt; extension method to provide data for the query. The &lt;code&gt;ResolveCheeses()&lt;/code&gt; extension method uses the &lt;code&gt;IResolverContext&lt;/code&gt; to retrieve the typed client for the &lt;code&gt;Cheeze.Store&lt;/code&gt; ReST endpoint and calls the &lt;code&gt;GetAsync()&lt;/code&gt; method on it. Finally, AutoMapper is used to map between the &lt;code&gt;Cheeze.Store.Client.Cheese&lt;/code&gt; and &lt;code&gt;Cheeze.Graph.Cheese&lt;/code&gt; types, specifically ignoring the &lt;code&gt;Available&lt;/code&gt; property of &lt;code&gt;Cheeze.Graph.Cheese&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Similarly, the &lt;code&gt;AddObjectType&amp;lt;Cheese&amp;gt;&lt;/code&gt; method intercepts objects of type &lt;code&gt;Cheese&lt;/code&gt; and uses the &lt;code&gt;ResolveInventory()&lt;/code&gt; extension method to populate the &lt;code&gt;Available&lt;/code&gt; property. This time however, a &lt;code&gt;BatchDataLoader&lt;/code&gt; is used from within the extension method to neatly avoid the &lt;a href="https://itnext.io/what-is-the-n-1-problem-in-graphql-dd4921cb3c1a"&gt;N+1 problem&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="service-binding-configuration"&gt;Service Binding &amp;amp; Configuration&lt;/h3&gt;
&lt;p&gt;Finally we need to bind required service and configuration types so, again in &lt;code&gt;Cheeze.Graph&lt;/code&gt; add the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;A &lt;code&gt;Configuration.cs&lt;/code&gt; file in an &lt;code&gt;Inventory&lt;/code&gt; folder containing:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using System;

namespace Cheeze.Graph.Inventory
{
    public class Configuration
    {
        public Uri BaseAddress { get; set; } = new Uri(&amp;quot;https://inventory&amp;quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A &lt;code&gt;Configuration.cs&lt;/code&gt; file in a &lt;code&gt;Store&lt;/code&gt; folder containing:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using System;

namespace Cheeze.Graph.Store
{
    public class Configuration
    {
        public Uri BaseAddress { get; set; } = new Uri(&amp;quot;https://store&amp;quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In &lt;code&gt;Program.cs&lt;/code&gt; refactor &lt;code&gt;CreateWebHostBuilder&lt;/code&gt; method to the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;public static IWebHostBuilder CreateWebHostBuilder(string[] args)
{
    return WebHost
        .CreateDefaultBuilder(args)
        .ConfigureAppConfiguration((hostingContext, config) =&amp;gt; config.AddEnvironmentVariables(&amp;quot;Cheeze:Graph:&amp;quot;))
        .ConfigureServices(
            (hostContext, services) =&amp;gt;
            {
                services.AddOptions&amp;lt;Store.Configuration&amp;gt;().Bind(hostContext.Configuration.GetSection(&amp;quot;Store&amp;quot;));
                services.AddOptions&amp;lt;Inventory.Configuration&amp;gt;().Bind(hostContext.Configuration.GetSection(&amp;quot;Inventory&amp;quot;));
            })
        .UseStartup&amp;lt;Startup&amp;gt;();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And add the two required usings:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.DependencyInjection;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we're adding configuration from Environment Variables (prefixed with &lt;code&gt;Cheeze:Graph&lt;/code&gt;) to our application and binding this configuration to the types added above.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In &lt;code&gt;Startup.cs&lt;/code&gt; refactor the &lt;code&gt;ConfigureServices&lt;/code&gt; method to the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;public void ConfigureServices(IServiceCollection services)
{
    services.AddHttpClient&amp;lt;Cheeze.Store.Client.IStoreClient, Cheeze.Store.Client.StoreClient&amp;gt;(
        (serviceProvider, httpClient) =&amp;gt; httpClient.BaseAddress = serviceProvider.GetRequiredService&amp;lt;IOptions&amp;lt;Store.Configuration&amp;gt;&amp;gt;().Value.BaseAddress
    );

    services.AddHttpClient&amp;lt;Cheeze.Inventory.Client.IInventoryClient, Cheeze.Inventory.Client.InventoryClient&amp;gt;(
        (serviceProvider, httpClient) =&amp;gt; httpClient.BaseAddress = serviceProvider.GetRequiredService&amp;lt;IOptions&amp;lt;Inventory.Configuration&amp;gt;&amp;gt;().Value.BaseAddress
    );

    // this enables you to use DataLoader in your resolvers.
    services.AddDataLoaderRegistry();

    // Add GraphQL Services
    services.AddGraphQL(Schema.Build());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And again add the required using:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cs"&gt;using Microsoft.Extensions.Options;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we're binding the typed clients for &lt;code&gt;Cheeze.Store&lt;/code&gt; and &lt;code&gt;Cheeze.Inventory&lt;/code&gt; and ensuring they're configured with the appropriate base addresses. Finally we're using the &lt;code&gt;Schema.Build()&lt;/code&gt; method to provide the GraphQL schema to the &lt;code&gt;services.AddGraphQL()&lt;/code&gt; method.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And that - as the say - is that. If we run our build script now we should find everything builds successfully.&lt;/p&gt;
&lt;h2 id="containerization"&gt;Containerization&lt;/h2&gt;
&lt;p&gt;Now, rather than configuring and spinning up all the services manually, we'll simplify our debug/deploy loop by containerizing our services and using &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt; to do the job for us. From Visual Studio this would be a simple case of using the &amp;quot;Add &amp;gt; Docker Support&amp;quot; and &amp;quot;Add &amp;gt; Container Orchestration Support&amp;quot; options from the &amp;quot;Solution Explorer&amp;quot; as described &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/docker/visual-studio-tools-for-docker?view=aspnetcore-3.1"&gt;here&lt;/a&gt;. However, as we've so far done pretty much everything from the command-line, lets try carrying that on.&lt;/p&gt;
&lt;h3 id="docker-support"&gt;Docker Support&lt;/h3&gt;
&lt;p&gt;First we'll add docker support to each of the top-level projects by using the standard multi-stage dockerfile template. I was unable to find an official source for this template so uploaded a version to my &lt;a href="https://github.com/ibebbs/DotnetCliDocker"&gt;DotnetCliDocker&lt;/a&gt; repository which we're be using here.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&amp;#64;(Invoke-WebRequest &amp;quot;https://raw.githubusercontent.com/ibebbs/DotnetCliDocker/master/Dockerfile3_1&amp;quot; | Select-Object -ExpandProperty Content) -replace &amp;quot;\(ProjectName\)&amp;quot;,&amp;quot;Cheeze.Graph&amp;quot; | Set-Content .\Cheeze.Graph\Dockerfile
&amp;#64;(Invoke-WebRequest &amp;quot;https://raw.githubusercontent.com/ibebbs/DotnetCliDocker/master/Dockerfile3_1&amp;quot; | Select-Object -ExpandProperty Content) -replace &amp;quot;\(ProjectName\)&amp;quot;,&amp;quot;Cheeze.Store&amp;quot; | Set-Content .\Cheeze.Store\Dockerfile
&amp;#64;(Invoke-WebRequest &amp;quot;https://raw.githubusercontent.com/ibebbs/DotnetCliDocker/master/Dockerfile3_1&amp;quot; | Select-Object -ExpandProperty Content) -replace &amp;quot;\(ProjectName\)&amp;quot;,&amp;quot;Cheeze.Inventory&amp;quot; | Set-Content .\Cheeze.Inventory\Dockerfile
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="container-orchestration-support"&gt;Container Orchestration Support&lt;/h3&gt;
&lt;p&gt;Now lets add a couple of files so that we can use Docker Compose to run our microservice environment&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Add a &lt;code&gt;docker-compose.yml&lt;/code&gt; file to the &lt;code&gt;src&lt;/code&gt; directory containing:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: '3.4'

services:
cheeze.store:
    image: ${DOCKER_REGISTRY-}cheezestore
    build:
    context: .
    dockerfile: Cheeze.Store/Dockerfile

cheeze.inventory:
    image: ${DOCKER_REGISTRY-}cheezeinventory
    build:
    context: .
    dockerfile: Cheeze.Inventory/Dockerfile

cheeze.graph:
    image: ${DOCKER_REGISTRY-}cheezegraph
    build:
    context: .
    dockerfile: Cheeze.Graph/Dockerfile
    ports:
    - &amp;quot;8081:80&amp;quot;
    environment:
    - Cheeze__Graph__Store__BaseAddress=http://cheeze.store
    - Cheeze__Graph__Inventory__BaseAddress=http://cheeze.inventory
    depends_on:
    - cheeze.store
    - cheeze.inventory
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add a &lt;code&gt;.dockerignore&lt;/code&gt; to the &lt;code&gt;src&lt;/code&gt; directory by running:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&amp;#64;(Invoke-WebRequest &amp;quot;https://raw.githubusercontent.com/ibebbs/DotnetCliDocker/master/.dockerignore&amp;quot;) | Set-Content .\.dockerignore
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Build and run our containers&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker-compose build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This might take some time but should result in a successful build afterwhich you can run the containers using:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker-compose run
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="testing"&gt;Testing&lt;/h2&gt;
&lt;p&gt;With our composed containers running, open up a browser and navigate to &lt;code&gt;http://localhost:8081/playground&lt;/code&gt;. You should see something like the following:&lt;/p&gt;
&lt;img src="/Content/LessReSTMoreHotChocolate/Playground.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="GraphQL Playground"&gt;
&lt;p&gt;The two tabs on the right hand side of the screen - &amp;quot;Docs&amp;quot; &amp;amp; &amp;quot;Schema&amp;quot; - allow you to examine the GraphQL endpoint to determine the queries you can execute and the content the service is able to receive. As we've got very little data in our services, we'll just use a basic query to retrieve the data we've defined. In the left pain of the playground (underneath &amp;quot;# Write your query or mutation here&amp;quot;) enter the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-graphql"&gt;{
  Cheese {
    id,
    name,
    available
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Note: As you're typing this, you should see that auto-complete is available and extremely quick.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Finally, once the query is complete, click the &amp;quot;Play&amp;quot; button in the centre of the screen. If everything has compiled and build correctly, you should see the following in the right hand pane:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;data&amp;quot;: {
    &amp;quot;Cheese&amp;quot;: [
      {
        &amp;quot;id&amp;quot;: &amp;quot;1468841a-5fbe-41c5-83b3-ab136b7ae70c&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;API Cheese&amp;quot;,
        &amp;quot;available&amp;quot;: 9
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And there we go. We've successfully used GraphQL to integrate and intelligently query two independent ReST services. Nice!&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If you're hitting up against some of the limitations of ReST - particularly for mobile client applications - I would very much recommend taking a look at GraphQL and &lt;a href="https://chillicream.com/"&gt;ChilliCream's&lt;/a&gt; Hot Chocolate library in particular. Hot Chocolate makes setting up a GraphQL endpoint incredibly easy, and it's code-first capabilities allow you to concentrate on modelling a domain that works for you and your customers rather than the GraphQL framework.&lt;/p&gt;
&lt;p&gt;Hot Chocolate is under &lt;strong&gt;very&lt;/strong&gt; heavy development with fantastic new features getting added at an amazing cadence (hopefully ReST based Schema Stitching will bubble to the top of ChilliCream's priority list soon). Furthermore support for this library is excellent; in point of fact, while authoring this article I posted a question in their Slack workspace only to get it answered by Michael Steib himself just moments later and which culminated in a discussion that lasted the better part of an hour.&lt;/p&gt;
&lt;p&gt;ChilliCream also have a &lt;a href="https://www.nuget.org/packages/StrawberryShake/11.0.0-preview.75"&gt;client-side library&lt;/a&gt; for GraphQL called &lt;a href="https://chillicream.com/blog/2019/11/25/strawberry-shake_2"&gt;&amp;quot;Strawberry Shake&amp;quot;&lt;/a&gt;. While currently in alpha it looks extremely promising for creating strongly-typed GraphQL clients as it will - apparently - provide &lt;a href="https://grpc.io/blog/grpc-dotnet-build/"&gt;&amp;quot;protobuff style&amp;quot;&lt;/a&gt; code generation for the client direct from a GraphQL service's schema.&lt;/p&gt;
&lt;p&gt;Lastly, if you are authoring ReST endpoints, I would very much recommend considering &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/tutorials/getting-started-with-nswag?view=aspnetcore-3.1&amp;amp;tabs=visual-studio"&gt;NSwag&lt;/a&gt; over &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/tutorials/getting-started-with-swashbuckle?view=aspnetcore-3.1&amp;amp;tabs=visual-studio"&gt;Swashbuckle&lt;/a&gt;. For me, NSwag's integration is a bit nicer than Swashbuckle and has a greater focus on the OpenAPI toolchain. Furthermore NSwag's tooling is first class allowing you to generate OpenAPI documents and/or client side libraries (in a number of languages) using a variety of tools, not least of which being the MSBuild target we used here.&lt;/p&gt;
&lt;p&gt;All code for from this post can be found in my &lt;a href="https://github.com/ibebbs/Cheeze"&gt;&amp;quot;Cheeze&amp;quot;&lt;/a&gt; repository on GitHub.&lt;/p&gt;
&lt;p&gt;As always, if you have any questions or comments on the above or would like to discuss any point further, please don't hesitate to contact me using any of the links below or from my &lt;a href="https://ian.bebbs.co.uk/about"&gt;about page&lt;/a&gt;.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Network Booting Many Raspberry Pis</title>
			<link>http://ian.bebbs.co.uk/posts/NetworkBootingManyRaspberryPis</link>
			<description>&lt;p&gt;This is just a short post - mostly for my own benefit - on how to network boot multiple Raspberry Pis from an x86 Linux Server. While this has been covered &lt;a href="https://hackaday.com/2019/11/11/network-booting-the-pi-4/"&gt;many&lt;/a&gt; &lt;a href="https://hackaday.com/2018/10/08/hack-my-house-running-raspberry-pi-without-an-sd-card/"&gt;times&lt;/a&gt; in &lt;a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/net_tutorial.md"&gt;other&lt;/a&gt; &lt;a href="https://github.com/raspberrypi/rpi-eeprom/blob/master/firmware/raspberry_pi4_network_boot_beta.md"&gt;posts&lt;/a&gt; none of them worked for me "out of the box". Here's what does.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/NetworkBootingManyRaspberryPis</guid>
			<pubDate>Thu, 02 Jan 2020 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;This is just a short post - mostly for my own benefit - on how to network boot multiple Raspberry Pis from an x86 Linux Server. While this has been covered &lt;a href="https://hackaday.com/2019/11/11/network-booting-the-pi-4/"&gt;many&lt;/a&gt; &lt;a href="https://hackaday.com/2018/10/08/hack-my-house-running-raspberry-pi-without-an-sd-card/"&gt;times&lt;/a&gt; in &lt;a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/net_tutorial.md"&gt;other&lt;/a&gt; &lt;a href="https://github.com/raspberrypi/rpi-eeprom/blob/master/firmware/raspberry_pi4_network_boot_beta.md"&gt;posts&lt;/a&gt; none of them worked for me &amp;quot;out of the box&amp;quot;. Here's what does.&lt;/p&gt;
&lt;h2 id="infrastructure"&gt;Infrastructure&lt;/h2&gt;
&lt;p&gt;I will be using the following components&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hyper-V Virtual Machine running Raspberry Pi Desktop (aka Debian Buster with Raspberry Pi Desktop) downloaded from &lt;a href="https://www.raspberrypi.org/downloads/raspberry-pi-desktop/"&gt;here&lt;/a&gt; as the network boot server.&lt;/li&gt;
&lt;li&gt;Multiple Raspberry Pi 3B+ (the non-plus Raspberry Pi 3B requires &lt;a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/net_tutorial.md"&gt;additional steps&lt;/a&gt;) as network boot clients&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="requirements"&gt;Requirements&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/net_tutorial.md"&gt;official Raspberry Pi Network Boot instructions&lt;/a&gt; assume you're using a Raspberry Pi as the network boot server and can therefore &amp;quot;copy&amp;quot; a Raspbian installation from an SD Card that has been installed on the network boot client Raspberry Pi. As I want to use an Linux server - running in a virtualised environment no less - I will be using additional steps from Hackaday's excellent article on &lt;a href="https://hackaday.com/2019/11/11/network-booting-the-pi-4/"&gt;Network Booting The Pi 4&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Additionally, while each of the network boot client Raspberry Pi's will be running Raspbian Buster Lite, they will be used for different purposes so must run a unique Raspbian installation.&lt;/p&gt;
&lt;h2 id="steps"&gt;Steps&lt;/h2&gt;
&lt;h3 id="network-boot-server"&gt;Network Boot Server&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Create a virtual machine and install Debian Buster with Raspberry Pi Desktop. I will not cover instructions for doing this here as there are many virtualisation engines and instructions for each would be different; suffice to say I used a Gen 1 Hyper-V instance on Windows Server 2016 with 4 virtual cores, 8Gb of RAM and 64Gb of disk-space. Furthermore, after installation, I enabled SSH and used SSH to execute the following.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Install required software using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get install unzip kpartx dnsmasq nfs-kernel-server
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Make a directory to contain the first network boot client image:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo mkdir -p /nfs/raspi1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Download and unzip the latest Raspbian Buster Lite image:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;wget https://downloads.raspberrypi.org/raspbian_lite/images/raspbian_lite-2019-09-30/2019-09-26-raspbian-buster-lite.zip
unzip 2019-09-26-raspbian-buster-lite.zip
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mount the Raspbian Buster Lite image to known locations:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo kpartx -a -v 2019-09-26-raspbian-buster.img
mkdir rootmnt
mkdir bootmnt
sudo mount /dev/mapper/loop0p2 rootmnt/
sudo mount /dev/mapper/loop0p1 bootmnt/
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Copy the Raspbian Buster Lite image to the network boot client image directory created above:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo cp -a rootmnt/* /nfs/raspi1/
sudo cp -a bootmnt/* /nfs/raspi1/boot/
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ensure the network boot client image doesn't attempt to look for filesystems on the SD Card:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo sed -i /UUID/d /nfs/raspi1/etc/fstab
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Replace the boot command in the network boot client image to boot from a network share. Ensure you replace [IP Address] with the IP address of your network boot server (note the &lt;code&gt;modprobe.blacklist&lt;/code&gt; is required to successfully boot the Raspberry Pi 3B+ as described &lt;a href="https://raspberrypi.stackexchange.com/a/105886"&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;echo &amp;quot;console=serial0,115200 console=tty root=/dev/nfs nfsroot=[IP Address]:/nfs/raspi1,vers=3 rw ip=dhcp rootwait elevator=deadline modprobe.blacklist=bcm2835_v4l2&amp;quot; | sudo tee /nfs/raspi1/boot/cmdline.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Enable SSH in the network boot client image:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo touch /nfs/raspi1/boot/ssh
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a network share containing the network boot client image:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;echo &amp;quot;/nfs/raspi1 *(rw,sync,no_subtree_check,no_root_squash)&amp;quot; | sudo tee -a /etc/exports
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a TrivialFTP folder containing boot code for all network boot clients&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo mkdir /tftpboot
sudo cp /nfs/raspi1/boot/bootcode.bin /tftpboot/bootcode.bin
sudo chmod 777 /tftpboot
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Enable and restart &lt;code&gt;rpcbind&lt;/code&gt; and &lt;code&gt;nfs-kernel-server&lt;/code&gt; services:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo systemctl enable rpcbind
sudo systemctl enable nfs-kernel-server
sudo systemctl restart rpcbind
sudo systemctl restart nfs-kernel-server
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reconfigure &lt;code&gt;dnsmasq&lt;/code&gt; to server TFTP files only to Raspberry Pi instances as described here:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;We need to add our settings to the dnsmasq config file, which is where most of the magic happens. Let’s talk about that “proxy” setting. What we’re asking dnsmasq to do is watch for DHCP requests, and rather than respond to those requests directly, wait for the primary DHCP server to assign an IP address. If dnsmasq sees a request for PXE information, it will send additional information to inform the PXE-capable device of the PXE server information. The upside is that this approach lets us support PXE booting without modifying the primary DHCP server.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Be sure to replace [Broadcast Address] with the broadcast address for your network (use &lt;code&gt;ip address | grep brd&lt;/code&gt; to find it):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;echo 'dhcp-range=[Broadcast Address],proxy' | sudo tee -a /etc/dnsmasq.conf
echo 'log-dhcp' | sudo tee -a /etc/dnsmasq.conf
echo 'enable-tftp' | sudo tee -a /etc/dnsmasq.conf
echo 'tftp-root=/tftpboot' | sudo tee -a /etc/dnsmasq.conf
echo 'pxe-service=0,&amp;quot;Raspberry Pi Boot&amp;quot;' | sudo tee -a /etc/dnsmasq.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Enable and restart the &lt;code&gt;dnsmasq&lt;/code&gt; service:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo systemctl enable dnsmasq
sudo systemctl restart dnsmasq
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Find the serial number of the first network boot client:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Tail &lt;code&gt;daemon.log&lt;/code&gt; to :&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo tail -f /var/log/daemon.log
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Plug in a network cable and power cable to the first network boot client. After 10-30 seconds you should see output like this in the daemon.log:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;dnsmasq-dhcp[9460]: 653460281 available DHCP subnet: 192.168.1.255/255.255.255.0&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 vendor class: PXEClient:Arch:00000:UNDI:002001&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 PXE(eth0) b8:27:eb:ec:46:57 proxy&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 tags: eth0&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 broadcast response&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  1 option: 53 message-type  2&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  4 option: 54 server-identifier  192.168.1.102&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  9 option: 60 vendor-class  50:58:45:43:6c:69:65:6e:74&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size: 17 option: 97 client-machine-id 00:44:44:44:44:44:44:44:44:44:44:44:44:44...&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size: 32 option: 43 vendor-encap  06:01:03:0a:04:00:50:58:45:09:14:00:00:11...&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/bootsig.bin not found&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/bootcode.bin to 192.168.1.112&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 available DHCP subnet: 192.168.1.255/255.255.255.0&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 vendor class: PXEClient:Arch:00000:UNDI:002001&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 PXE(eth0) b8:27:eb:ec:46:57 proxy&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 tags: eth0&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 broadcast response&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  1 option: 53 message-type  2&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  4 option: 54 server-identifier  192.168.1.102&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  9 option: 60 vendor-class  50:58:45:43:6c:69:65:6e:74&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size: 17 option: 97 client-machine-id  00:57:46:ec:fe:57:46:ec:fe:57:46:ec:fe:57...&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size: 32 option: 43 vendor-encap  06:01:03:0a:04:00:50:58:45:09:14:00:00:11...&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/start.elf not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/autoboot.txt not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/config.txt not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/recovery.elf not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/start.elf not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/fixup.dat not found&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This shows that the first network boot client has successfully made requests to the TFTP service on the network boot service.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Notice the &lt;code&gt;dnsmasq-tftp[9460]: file /tftpboot/feec4657/start.elf not found&lt;/code&gt; line. The 'feec4657' value is the serial number of the network boot client (it will obviously be different for you) and allows you to use different images for different devices.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a directory for the first network boot client in the &lt;code&gt;/tftpboot&lt;/code&gt; directory (remembering to replace &lt;code&gt;[SerialNumber]&lt;/code&gt; with the value you found above):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo mkdir /tftpboot/[SerialNumber]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Copy the boot directory from the &lt;code&gt;/nfs/raspi1&lt;/code&gt; directory to the new directory in &lt;code&gt;/tftpboot&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo cp -a /nfs/raspi1/boot/* /tftpboot/[SerialNumber]/
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reconnect the power to the network boot client and it should now boot successfully. If you use &lt;code&gt;sudo tail -f /var/log/daemon.log&lt;/code&gt; again you should see something like the following:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;dnsmasq-dhcp[9460]: 653460281 vendor class: PXEClient:Arch:00000:UNDI:002001&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 PXE(eth0) b8:27:eb:ec:46:57 proxy&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 tags: eth0&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 broadcast response&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  1 option: 53 message-type  2&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  4 option: 54 server-identifier  192.168.1.102&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  9 option: 60 vendor-class  50:58:45:43:6c:69:65:6e:74&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size: 17 option: 97 client-machine-id  00:44:44:44:44:44:44:44:44:44:44:44:44:44...&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size: 32 option: 43 vendor-encap  06:01:03:0a:04:00:50:58:45:09:14:00:00:11...&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/bootsig.bin not found&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/bootcode.bin to 192.168.1.112&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 available DHCP subnet: 192.168.1.255/255.255.255.0&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 vendor class: PXEClient:Arch:00000:UNDI:002001&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 PXE(eth0) b8:27:eb:ec:46:57 proxy&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 tags: eth0&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 broadcast response&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  1 option: 53 message-type  2&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  4 option: 54 server-identifier  192.168.1.102&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size:  9 option: 60 vendor-class  50:58:45:43:6c:69:65:6e:74&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size: 17 option: 97 client-machine-id  00:57:46:ec:fe:57:46:ec:fe:57:46:ec:fe:57...&lt;br /&gt;
dnsmasq-dhcp[9460]: 653460281 sent size: 32 option: 43 vendor-encap  06:01:03:0a:04:00:50:58:45:09:14:00:00:11...&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/autoboot.txt not found&lt;br /&gt;
dnsmasq-tftp[9460]: error 0 Early terminate received from 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: failed sending /tftpboot/feec4657/start.elf to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/feec4657/config.txt to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/recovery.elf not found&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/feec4657/start.elf to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/feec4657/fixup.dat to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/recovery.elf not found&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/feec4657/config.txt to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/dt-blob.bin not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/recovery.elf not found&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/feec4657/config.txt to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/bootcfg.txt not found&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/feec4657/cmdline.txt to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/feec4657/bcm2710-rpi-3-b.dtb to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/feec4657/config.txt to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/recovery8.img not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/recovery8-32.img not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/recovery7.img not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/recovery.img not found&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/kernel8-32.img not found&lt;br /&gt;
dnsmasq-tftp[9460]: error 0 Early terminate received from 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: failed sending /tftpboot/feec4657/kernel8.img to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: error 0 Early terminate received from 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: failed sending /tftpboot/feec4657/kernel7.img to 192.168.1.112&lt;br /&gt;
dnsmasq-tftp[9460]: file /tftpboot/feec4657/armstub8-32.bin not found&lt;br /&gt;
dnsmasq-tftp[9460]: sent /tftpboot/feec4657/kernel7.img to 192.168.1.112&lt;br /&gt;
dnsmasq-dhcp[9460]: 1754635714 available DHCP subnet: 192.168.1.255/255.255.255.0&lt;br /&gt;
dnsmasq-dhcp[9460]: 1754635714 available DHCP subnet: 192.168.1.255/255.255.255.0&lt;br /&gt;
rpc.mountd[26471]: authenticated mount request from 192.168.1.112:843 for /nfs/raspi1 (/nfs/raspi1)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here we can see the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sent /tftpboot/bootcode.bin to 192.168.1.112&lt;/code&gt; -&amp;gt; We successfully sent the &lt;code&gt;bootcode.bin&lt;/code&gt; to the network boot client&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sent /tftpboot/feec4657/[FILENAME] to 192.168.1.112&lt;/code&gt; -&amp;gt; We successfully sent boot files from the device specific &lt;code&gt;/tftpboot&lt;/code&gt; directory to the network boot client&lt;/li&gt;
&lt;li&gt;&lt;code&gt;authenticated mount request from 192.168.1.112:843 for /nfs/raspi1 (/nfs/raspi1)&lt;/code&gt; -&amp;gt; the network boot client mounted to the system drive from the nfs share.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You should now be able to ssh into the network boot client using the following (replacing the [IP Address]) with the one you see):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;ssh pi&amp;#64;[IP Address]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the default password of 'raspberry'.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="additional-network-boot-clients"&gt;Additional Network Boot Clients&lt;/h2&gt;
&lt;p&gt;To add additional network boot clients, simply repeat steps 3, 6-10, 15-18 replacing all instances of &lt;code&gt;raspi1&lt;/code&gt; with a new name.&lt;/p&gt;
&lt;h2 id="enjoy"&gt;Enjoy&lt;/h2&gt;
</content:encoded>
		</item>
		<item>
			<title>The Seven GUIs of Christmas</title>
			<link>http://ian.bebbs.co.uk/posts/Uno</link>
			<description>&lt;p&gt;The &lt;a href="https://platform.uno/"&gt;Uno platform&lt;/a&gt; allows native UWP code to be run across Windows, Android, iOS and even in the browser. In this post I will cover the use of the Uno Platform to implement the &lt;a href="https://eugenkiss.github.io/7guis/"&gt;7GUIs: A GUI Programming Benchmark&lt;/a&gt;, across 5 platforms, employing FRP paradigms and all in a (mostly) seasonal style! Will it all hang together? Read on to find out.&lt;/p&gt;</description>
			<enclosure url="http://ian.bebbs.co.uk/Content/Uno/Background.png" length="0" type="image" />
			<guid>http://ian.bebbs.co.uk/posts/Uno</guid>
			<pubDate>Sun, 01 Dec 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="tldr"&gt;TL;DR&lt;/h1&gt;
&lt;p&gt;The &lt;a href="https://platform.uno/"&gt;Uno platform&lt;/a&gt; allows native UWP code to be run across Windows, Android, iOS and even in the browser. In this post I will cover the use of the Uno Platform to implement the &lt;a href="https://eugenkiss.github.io/7guis/"&gt;7GUIs: A GUI Programming Benchmark&lt;/a&gt;, across 5 platforms, employing FRP paradigms and all in a (mostly) seasonal style! Will it all hang together? Read on to find out.&lt;/p&gt;
&lt;h1 id="the-twelve-days.err.seven-guis-of-christmas"&gt;The Twelve Days ... err.... Seven GUIs of Christmas&lt;/h1&gt;
&lt;p&gt;This is a lengthy post so first up, let me provide you with a seasonal - if a little tenuous - index:&lt;/p&gt;
&lt;p&gt;Ahem...&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;On the seventh day of Christmas my true love gave to me:&lt;br /&gt;
&lt;a href="#seven-guis-shining"&gt;Seven GUIs shining&lt;/a&gt;&lt;br /&gt;
&lt;a href="#six-points-opining"&gt;Six points opining&lt;/a&gt;&lt;br /&gt;
&lt;a href="#five-platform-binaries"&gt;Five platform bin[arie]s&lt;/a&gt;!&lt;br /&gt;
&lt;a href="#four-important-words"&gt;Four important words&lt;/a&gt;&lt;br /&gt;
&lt;a href="#third-advent-yens"&gt;Third advent yens&lt;/a&gt;&lt;br /&gt;
&lt;a href="#dual-screen-loves"&gt;Dual screen loves&lt;/a&gt;&lt;br /&gt;
&lt;a href="#on-the-first-day-of-christmas.an-app-bridge-for-uwp"&gt;And an app-bridge for UWP&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Well, it almost works.&lt;/p&gt;
&lt;p&gt;Anyway, this post starts with &amp;quot;the first day of Christmas&amp;quot; and provides some background to, and explanation of, the use of the Uno Platform for implementing the 7GUIs &amp;quot;programming benchmark&amp;quot;. If you're not interested in this background and just want to see the actual GUIs in action then feel free to jump ahead to the &lt;a href="#seven-guis-shining"&gt;&amp;quot;Seven GUIs shining&amp;quot;&lt;/a&gt; or the &lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt; where I summarise my findings.&lt;/p&gt;
&lt;h1 id="on-the-first-day-of-christmas.an-app-bridge-for-uwp"&gt;On the first day of Christmas... an app-bridge for UWP.&lt;/h1&gt;
&lt;p&gt;Well, to be honest, it was some time before the first day of Xmas when I became aware of the &lt;a href="https://platform.uno/"&gt;Uno platform&lt;/a&gt; by &lt;a href="https://nventive.com/"&gt;nventive&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;a Universal Windows Platform Bridge that allows UWP-based code to run on iOS, Android, and WebAssembly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I have been writing Xaml for over a decade and find it to be the most powerful and productive UI framework I've ever encountered. As such, I was immediately intrigued by the Uno platform and interested in what it might bring to the table for a UI technology that is increasingly being overlooked in favour of (&lt;a href="https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f"&gt;the scourge that is&lt;/a&gt;) web front-ends.&lt;/p&gt;
&lt;p&gt;Obviously there had been attempts at this kind of thing before - most notably &lt;a href="https://dotnet.microsoft.com/apps/xamarin"&gt;Xamarin&lt;/a&gt; and &lt;a href="http://avaloniaui.net/"&gt;Avalonia&lt;/a&gt; - but the approach taken by nventive is notable in that, instead of having to learn a new dialect of Xaml and/or buy into a framework to the exclusion of all else, they would allow UWP code to be run 'as is' across each platform. Furthermore, by supporting transpilation to WebAssembly, the same code could then be run in the browser.&lt;/p&gt;
&lt;p&gt;Unfortunately, I was a little too busy to dive into it at the time so I added the Uno Platform to my (ever growing) backlog of things to evaluate and continued with current projects until...&lt;/p&gt;
&lt;h1 id="dual-screen-loves"&gt;Dual Screen Loves&lt;/h1&gt;
&lt;p&gt;... October, when Microsoft's Panos Panay surprised everyone with these beauties:&lt;/p&gt;
&lt;img src="/Content/Uno/PanayNeoDuo.jpg" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Panos Panay Reveals Surface Neo and Duo"/&gt;
&lt;p&gt;A new category of Surface device featuring dual screens, similar to the previously cancelled - but much lauded - &lt;a href="https://www.youtube.com/watch?v=UmIgNfp-MdI"&gt;Courier project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Having been mourning the loss of Windows Mobile/Phone since begrudgingly switching to an Android device some months back, these devices looked like salvation. The two devices, aimed at productivity and mobility respectively, looked amazing in the &lt;a href="https://www.youtube.com/watch?v=kU78s9ExFFA"&gt;introductory videos&lt;/a&gt; and I was immediately, and unashamedly, sold.&lt;/p&gt;
&lt;p&gt;Until, that is, I learned something rather perplexing. You see, while the larger device - the Surface Neo - would be running Microsoft's new Windows 10X OS, the smaller 'mobile' device - the Surface Duo - was apparently running a heavily customised version of Android.&lt;/p&gt;
&lt;p&gt;What? Really? Surely not!&lt;/p&gt;
&lt;p&gt;While I understood why Microsoft might not want to re-engage in a smartphone market war it had already fought for and lost (twice!), Windows 10X was supposedly based on CShell, a UI layer specifically designed to adapt to any form factor and - it would seem - perfectly suited to running on devices like these. Indeed, I wasn't the only one surprised by this announcement and many echoed my confusion, some even going so far as to set up a &lt;a href="https://www.change.org/p/panos-panay-satya-nadella-panos-satya-give-us-a-microsoft-surface-duo-running-windows-10x"&gt;petition to provide the Duo with Win 10X&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Despite the immediate outcry, Microsoft remained adamant that the Duo will run Android and so it was that I realised that the Uno platform seemed perfectly - and almost uniquely - positioned as a framework for developing apps for these devices. Then...&lt;/p&gt;
&lt;h1 id="third-advent-yens"&gt;Third Advent Yens&lt;/h1&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;yen n. - A strong desire or inclination; a yearning or craving.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;... the day after Microsoft announced these devices, two articles arrived in my news feed: &lt;a href="https://crosscuttingconcerns.com/The-Third-Annual-csharp-Advent"&gt;&amp;quot;The Third Annual C# Advent&amp;quot;&lt;/a&gt; from &lt;a href="https://crosscuttingconcerns.com/"&gt;Matthew Groves's blog&lt;/a&gt; and, &lt;a href="https://eugenkiss.github.io/7guis/"&gt;7GUIs: A GUI Programming Benchmark&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&amp;quot;So let's get this straight&amp;quot;, I thought, &amp;quot;I have a GUI framework I want to evaluate, a GUI programming benchmark to attempt and a call for blog posts on .NET technologies&amp;quot;. Well, sometimes synchronicity simply can't be ignored. I decided a blog post on the 7GUIs using the Uno platform would make for a great post while allowing me to evaluate this platform for UWP + Android development ahead of the release of the Surface Neo and Surface Duo devices.&lt;/p&gt;
&lt;p&gt;I applied for a slot in the Annual C# Advent series and got the 16th December, which is what you're reading now. If you enjoy this post (or even if you don't!), perhaps you might like to take the time to visit the &lt;a href="https://crosscuttingconcerns.com/The-Third-Annual-csharp-Advent"&gt;full list of posts in this series&lt;/a&gt; and check out some of the others. There are &lt;em&gt;loads&lt;/em&gt; of great posts by some really terrific authors.&lt;/p&gt;
&lt;h1 id="four-important-words"&gt;Four Important Words&lt;/h1&gt;
&lt;p&gt;Over the course of a software engineering career spanning more than 20 years, I have developed and refined (and occasionally changed) opinions about how best to perform this craft. While most of my career has been spent following OOD/OOP paradigms, in recent years I have developed a strong preference for &lt;a href="https://en.wikipedia.org/wiki/Declarative_programming"&gt;declarative programming&lt;/a&gt; - typically using some form of &lt;a href="https://en.wikipedia.org/wiki/Functional_reactive_programming"&gt;functional, reactive programming (FRP)&lt;/a&gt; - following &lt;a href="https://en.wikipedia.org/wiki/Behavior-driven_development"&gt;behavioural/domain driven design&lt;/a&gt; principles. I &lt;a href="https://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl"&gt;wrote a blog post&lt;/a&gt; back in 2016 showing a practical application of these principles for an app I had released and, in the intervening years, have become only more convinced that these approaches represent an elegant and productive means of taming complexity in many modern software systems.&lt;/p&gt;
&lt;p&gt;Below I outline four &amp;quot;important words&amp;quot; (aka principles) I intend to use while implementing the 7GUIs.&lt;/p&gt;
&lt;h3 id="behavioural"&gt;Behavioural&lt;/h3&gt;
&lt;p&gt;From &lt;a href="https://en.wikipedia.org/wiki/Behavior-driven_development"&gt;Wikipedia&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Behavior-driven development combines the general techniques and principles of TDD with ideas from domain-driven design and object-oriented analysis and design to provide software development and management teams with shared tools and a shared process to collaborate on software development.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While I agree with this quote, for me BDD doesn't stop at writing tests in a behavioural style but should instead permeate deep into the implementation of the software itself. Fundamentally I believe the desired behaviours of the software system should be encapsulated and expressed in such a way that even a non-technical reader could see reference to them should they happen across the code.&lt;/p&gt;
&lt;p&gt;In a &lt;a href="https://ian.bebbs.co.uk/posts/ReactiveBehaviors"&gt;blog post&lt;/a&gt; back in 2015 I explored ways in which this might be achieved through the use of declarative FRP principles. While aged (and containing a questionable use of a Subject), I believe this post still provides a decent introduction to how specific behaviours - i.e. 'The login button should be enabled when the user has entered both a username and a password' - can be implemented in, and fully encapsulated within, a single appropriately named method - i.e. &lt;code&gt;ShouldEnableTheLogInButtonWhenTheUserHasEnteredBothUsernameAndPassword&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id="declarative"&gt;Declarative&lt;/h3&gt;
&lt;p&gt;Paraphrased from &lt;a href="https://en.wikipedia.org/wiki/Declarative_programming"&gt;Wikipedia&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Declarative programming focuses on 'what' the program must accomplish instead of 'how' that task is to be accomplished. This is in contrast with imperative programming, which implements algorithms in explicit steps.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ostensibly, this can be seen through a comparison of the following two code snippets, both of which sum a value from a collection:&lt;/p&gt;
&lt;h4 id="imperative"&gt;Imperative:&lt;/h4&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;int value = 0;
foreach (var item in collection)
{
  value += item.Value;
}
return value;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id="declarative-1"&gt;Declarative:&lt;/h4&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;return collection.Sum(item =&amp;gt; item.Value);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now being declarative &lt;a href="https://lispcast.com/is-functional-programming-declarative/"&gt;can be considered a somewhat relative term&lt;/a&gt; but, as you can see from the simplistic example above, if you follow the principle of expressing 'intent rather than algorithm' you can, in my opinion, greatly improve readability and transparency of functionality. Obviously this approach compliments the goals of behavioural design expressed above.&lt;/p&gt;
&lt;h3 id="functional"&gt;Functional&lt;/h3&gt;
&lt;p&gt;More &lt;a href="https://en.wikipedia.org/wiki/Functional_programming"&gt;Wikipedia&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;[Functional programming] is a declarative programming paradigm in that programming is done with expressions or declarations instead of statements. In functional code, the output value of a function depends only on its arguments, so calling a function with the same value for an argument always produces the same result. This is in contrast to imperative programming where, in addition to a function's arguments, global program state can affect a function's resulting value. Eliminating side effects, that is, changes in state that do not depend on the function inputs, can make understanding a program easier, which is one of the key motivations for the development of functional programming.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Functional programming (FP) has become fashionable in the software industry recently and support for functional paradigms are increasingly being released for - and, in some cases, are core to - many languages and frameworks that were once solely object-oriented. Unfortunately FP still faces significant opposition from many quarters, mainly - I believe - due to a perceived complexity around it's core principles; a perception somewhat fomented by the idiom of many functional practitioners! Indeed, I often encounter this issue when discussing FP with clients and have to explain how it is, in many ways, far simpler than many of the &lt;a href="https://scotch.io/bar-talk/s-o-l-i-d-the-first-five-principles-of-object-oriented-design"&gt;myriad principles&lt;/a&gt; employed by those writing object-oriented code.&lt;/p&gt;
&lt;p&gt;C# has enjoyed first class support for functional constructs since the introduction of LINQ back in .NET 3.5 yet many using the language today - even those employing LINQ-to-X features - are unaware of functional programming or how it can be used to simplify and improve their code. This is a shame because - as will be seen in many of the GUIs below - C# is able to elegantly mix OO and FP paradigms such that the relative strengths of each can be leveraged where they make most sense.&lt;/p&gt;
&lt;h3 id="reactive"&gt;Reactive&lt;/h3&gt;
&lt;p&gt;Last couple of &lt;a href="https://en.wikipedia.org/wiki/Reactive_programming"&gt;Wikipedia&lt;/a&gt; quotes for a while:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change. [It] has been proposed as a way to simplify the creation of interactive user interfaces and near-real-time system animation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Wikipedia goes on to state how:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;In an imperative programming setting, &lt;code&gt;a := b + c&lt;/code&gt; would mean that &lt;code&gt;a&lt;/code&gt; is being assigned the result of &lt;code&gt;b + c&lt;/code&gt; in the instant the expression is evaluated, and later, the values of &lt;code&gt;b&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt; can be changed with no effect on the value of &lt;code&gt;a&lt;/code&gt;. On the other hand, in reactive programming, the value of &lt;code&gt;a&lt;/code&gt; is automatically updated whenever the values of &lt;code&gt;b&lt;/code&gt; or &lt;code&gt;c&lt;/code&gt; change, without the program having to re-execute the statement &lt;code&gt;a := b + c&lt;/code&gt; to determine the presently assigned value of &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a somewhat long handed way of saying that, in reactive programming, state is derived from declarative flows of functional computations over source values such that it is not necessary to explicitly recompute state when one of these values change.&lt;/p&gt;
&lt;p&gt;Again C# has had fantastic support for Reactive Programming for many years in the form of the &lt;a href="https://github.com/dotnet/reactive"&gt;Reactive Extensions library&lt;/a&gt;. In fact, such was the success of this library that, since it's original implementation in C#, it has been ported to numerous other languages and used within an incredible variety of software systems; not least of which being a significant number of modern web frameworks.&lt;/p&gt;
&lt;h1 id="five-platform-binaries"&gt;Five Platform Bin[arie]s!&lt;/h1&gt;
&lt;p&gt;Well, sort of.&lt;/p&gt;
&lt;h3 id="wpf"&gt;WPF&lt;/h3&gt;
&lt;p&gt;Out of the box, Uno supports four platforms; UWP, Android, iOS &amp;amp; WebAssembly. For this blog post, I also wanted to try supporting WPF due, in most part, to the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;WPF is XAML based and, in many ways, the progenitor to UWP so it should be able to leverage much of the code that will be written&lt;/li&gt;
&lt;li&gt;WPF still plays an important role in the .NET GUI ecosystem, particularly for enterprise applications.&lt;/li&gt;
&lt;li&gt;WPF was recently &lt;a href="https://github.com/dotnet/wpf"&gt;open-sourced as part of .NET Core 3.0&lt;/a&gt; and I hadn't yet had a chance to try it!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Fortunately, it turns out that, once various other considerations had been accounted for (see below) supporting WPF didn't present much friction at all. In fact, with the exception of a couple of compiler directives in &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.windows.data.ivalueconverter?view=netframework-4.8"&gt;IValueConverter&lt;/a&gt; implementations, supporting WPF necessitated hardly any additional code at all.&lt;/p&gt;
&lt;h3 id="ios"&gt;iOS&lt;/h3&gt;
&lt;p&gt;Until recently, I viewed Apple devices as over-priced, walled-off, proprietary guff bought by fan-bois with more money than sense. In light of Apple's stance on privacy, this opinion has softened slightly in the last couple of years such that you &lt;em&gt;may&lt;/em&gt; no longer &lt;em&gt;have&lt;/em&gt; to be a fan-boi to buy an Apple device. Regardless I still refuse to buy Apple products and am extremely happy with a combination of devices from other manufactures - most notably Microsoft and Dell. These manufactures don't artificially limit the interoperability of their products nor do they engage in &lt;a href="https://www.itworld.com/article/3316958/apple-and-samsung-fined-for-planned-obsolescence.html"&gt;'planned obsolescence'&lt;/a&gt; to force consumers into a viscous and costly upgrade cycle (seriously, I have a 7 year old Dell laptop which - despite being bulky - is still my main mobile workhorse).&lt;/p&gt;
&lt;p&gt;Unfortunately, given Apple's ludicrous position that you must own (or &lt;a href="https://www.macincloud.com/"&gt;rent!?!&lt;/a&gt;) an Apple device to build applications for iOS (it seems it's still illegal to run iOS on anything other than an approved Apple device), I have no way of testing the iOS binaries being produced herein. As such, all the screen shots for Apple will be a simple placeholder until some kind soul decides they want to run them for me (I promise not to call you a fan-boi) and provide screen shots / bug reports / PRs.&lt;/p&gt;
&lt;h1 id="six-points-opining"&gt;Six Points Opining&lt;/h1&gt;
&lt;p&gt;Some other considerations for implementation:&lt;/p&gt;
&lt;h3 id="model-view-viewmodel"&gt;1. Model-View-ViewModel&lt;/h3&gt;
&lt;p&gt;To me, the MVVM pattern is one of those methodologies that once you &amp;quot;get&amp;quot; you wonder how you ever managed to deliver anything without. In fact, decoupling a view from its interaction model is critical if you wish to achieve many of the paradigms listed above (i.e. behavioural driven, declarative, functional and reactive). Therefore, all GUIs presented here use this pattern despite it possibly rating lower on a number of the 7GUIs &lt;a href="https://eugenkiss.github.io/7guis/dimensions"&gt;Dimensions of Evaluation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This then leads us to the question of whether to adopt a 'View-First' or 'ViewModel-First' approach (a good comparison of which can be found in &lt;a href="https://stackoverflow.com/questions/3763072/what-are-the-pros-and-cons-of-view-first-vs-viewmodel-first-in-the-mvvm-pattern"&gt;this&lt;/a&gt; SO question). While I generally prefer the latter over the former - particularly when writing large applications - the 'ViewModel-First' is undeniably more complicated given that UWP and WPF apps adopt, by default, 'View-first' mechanisms (e.g. &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.windows.application.startupuri?view=netframework-4.8"&gt;StartupUri&lt;/a&gt;). So, for simplicity's sake, I've used a 'View-First' approach for these GUIs wherein each View creates the associated ViewModel within it's constructor.&lt;/p&gt;
&lt;p&gt;Lifetime management of the view model (and it's constituent behaviours) is provided by &lt;code&gt;Activate&lt;/code&gt;/&lt;code&gt;Deactivate&lt;/code&gt; calls to the ViewModel from within the &lt;code&gt;OnNavigatedTo&lt;/code&gt;/&lt;code&gt;OnNavigatedFrom&lt;/code&gt; methods (for UWP) or &lt;code&gt;OnActivated&lt;/code&gt;/&lt;code&gt;OnClosed&lt;/code&gt; (for WPF). Where the GUI being implemented requires intimate interaction with the UI (i.e. the CircleDrawer GUI), these interaction points are passed - as &lt;code&gt;IObservable&lt;/code&gt; instances - to the ViewModel as parameters to the &lt;code&gt;Activate&lt;/code&gt; call.&lt;/p&gt;
&lt;h3 id="reactiveui"&gt;2. ReactiveUI&lt;/h3&gt;
&lt;p&gt;The Uno platform comes with templates for implementing GUIs using &lt;a href="https://reactiveui.net/"&gt;ReactiveUI&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;An advanced, composable, functional reactive model-view-viewmodel framework for all .NET platforms that is inspired by functional reactive programming.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ostensibly this sounds like a great fit for satisfying the paradigms outlined above and I had initially intended to use ReactiveUI as another exploratory feature of this blog post. Unfortunately this intention was quashed almost immediately as I found the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Platform support&lt;br /&gt;
At the point of attempting to use ReactiveUI, the latest Universal Windows platform it supported was 1803 (the April 2018 Update). This was quite surprising and somewhat troubling given the age of this platform.&lt;/li&gt;
&lt;li&gt;Inheriting a Framework&lt;br /&gt;
ReactiveUI requires that ViewModels derive from specific base classes. This, to me, puts it firmly on the Framework side of the &lt;a href="http://tomasp.net/blog/2015/library-frameworks/"&gt;Framework vs Library debate&lt;/a&gt;. Given I would already be adopting various constraints from the Uno platform, I didn't want to find myself in a position of encountering potential incompatibility between these technologies some way down the line.&lt;/li&gt;
&lt;li&gt;Overly complex API Structure&lt;br /&gt;
Just getting started with ReactiveUI is a daunting prospect when its &lt;a href="https://reactiveui.net/docs/handbook/"&gt;handbook&lt;/a&gt; contains some 22 &lt;em&gt;sections&lt;/em&gt; on subjects ranging from data persistence to logging. While I appreciate that opinionated frameworks can have a lot to offer, this sort of complexity is indicative of one which, in my opinion, ought to be broken into smaller, composable libraries which can be adopted as and when necessary.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="mvx.observable"&gt;3. MVx.Observable&lt;/h3&gt;
&lt;p&gt;Rather than shoe-horn ReactiveUI into this evaluation I instead elected to modernize and generalize a package I had written some time ago: &lt;a href="https://github.com/ibebbs/Caliburn.Micro.Reactive.Extensions"&gt;Caliburn.Micro.Reactive.Extensions&lt;/a&gt;. This package, as it's name implies, was implemented specifically for use within the &lt;a href="https://caliburnmicro.com/"&gt;Caliburn Micro&lt;/a&gt; framework and provides all the &amp;quot;good stuff&amp;quot; of ReactiveUI (i.e. composable, functional, reactive) while remaining a library that places no untoward restrictions or dependencies on consumer code.&lt;/p&gt;
&lt;p&gt;Fundamentally this library constitutes just three classes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ObservableProperty&lt;T&gt;&lt;br /&gt;
A class which implements both &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.iobservable-1?view=netframework-4.8"&gt;&lt;code&gt;IObservable&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.iobserver-1?view=netframework-4.8"&gt;&lt;code&gt;IObserver&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/a&gt; - such that it can be used within declarative reactive flows - and which provides some additional functionality to facilitate its use as a data-binding source (i.e. Get/Set methods).&lt;/li&gt;
&lt;li&gt;ObservableCommand&lt;br /&gt;
A class which implements &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.windows.input.icommand?view=netframework-4.8"&gt;&lt;code&gt;ICommand&lt;/code&gt;&lt;/a&gt; through implementations of the &lt;code&gt;IObservable&amp;lt;bool&amp;gt;&lt;/code&gt; (for 'can execute' state changes) and &lt;code&gt;IObservable&amp;lt;T&amp;gt;&lt;/code&gt; (for invocations) interfaces.&lt;/li&gt;
&lt;li&gt;ObservableBus&lt;br /&gt;
An &amp;quot;observable&amp;quot; implementation of an &lt;a href="https://www.martinfowler.com/eaaDev/EventAggregator.html"&gt;Event Aggregator pattern&lt;/a&gt; for inter-ViewModel communication.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Generalizing this library required removing the use of Caliburn.Micro's base classes - which were typically used to facilitate property change notification - and replacing them with callbacks (which can then be hidden in derived classes for specific frameworks if so desired). Modernizing involved recreating the project as a .NET Standard 2.0 library and using up-to-date dependency versions (specifically System.Reactive 4.x).&lt;/p&gt;
&lt;p&gt;The most difficult part of bringing this library up to date was undoubtedly picking a name for it. I spent ages playing with acronyms that accurately reflected the library's purpose and, for a second, even toyed with naming it the &lt;a href="https://www.youtube.com/watch?v=k8xFbWLUDoQ"&gt;&amp;quot;IBCBDFR&amp;quot;&lt;/a&gt;. Finally I decided on 'MVx.Observable' to indicate its reactive nature and its applicability to multiple forms of the Model-View pattern.&lt;/p&gt;
&lt;p&gt;Source is available on &lt;a href="https://github.com/ibebbs/MVx"&gt;GitHub&lt;/a&gt; and a prebuilt package is available in &lt;a href="https://www.nuget.org/packages/MVx.Observable/"&gt;Nuget&lt;/a&gt; should you wish to give it a try.&lt;/p&gt;
&lt;h3 id="separate-views"&gt;4. Separate Views&lt;/h3&gt;
&lt;p&gt;The Uno platform is, somewhat amazingly, able to display (almost) the exact same XAML page across multiple platforms (or 'heads' to use Uno parlance) with a very high degree of fidelity. This is quite an achievement and the team at nventive are rightly proud of this capability.&lt;/p&gt;
&lt;p&gt;However, from the perspective of someone looking to write large applications on this platform, I don't believe this facility is particularly important nor - to a certain extent - even desirable. You see, in my experience, it is often the case that each platform and/or form-factor requires such different UI and/or UX that trying to shoe-horn everything into a single XAML page results in a page that is difficult, if not impossible, to maintain. Instead I find it much better to be able to share business logic, user flows and - where it makes sense - common controls across platforms while using specific page layouts for each form-factor.&lt;/p&gt;
&lt;p&gt;As such, the GUI's presented here will use a dedicated view implementation on each platform while using a common view-model to share interaction patterns and user-flows.&lt;/p&gt;
&lt;h3 id="implementation-process"&gt;5. Implementation Process&lt;/h3&gt;
&lt;p&gt;For each of the GUIs I separated implementation into two phases; first implementing the prerequisite functionality in UWP then porting (which mainly constituted lots of copy/pasting) the completed GUI to Uno. This allowed me to ensure the GUI was functionally complete prior to incurring the additional friction of multi-platform builds.&lt;/p&gt;
&lt;h3 id="project-structure"&gt;6. Project Structure&lt;/h3&gt;
&lt;p&gt;When you create a new Uno project, the standard template gives you the following structure:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Solution
|-Project.Droid
|-Project.iOS
|-Project.UWP
|-Project.Wasm
|-Project.Shared
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this structure, the 'Shared' project contains the majority of the code/Xaml including the App.xaml[.cs] and MainPage.xaml[.cs] files. It is literally a &lt;a href="http://rion.io/2017/03/22/sharing-is-caring-using-shared-projects-in-asp-net/"&gt;&amp;quot;Shared Project&amp;quot;&lt;/a&gt; which each of the other project reference in order to - in essence - copy its contents into themselves.&lt;/p&gt;
&lt;p&gt;To support WPF and remove the need to share a single view across all platforms (as described above), I refactored to the following structure:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Solution
|-Project.Common
|-Project.Droid
|-Project.iOS
|-Project.UWP
|-Project.Wasm
|-Project.Wpf
|-Project.Shared
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this structure, the (fully implemented) App.xaml[.cs] and MainPage.xaml[.cs] were copied from the Shared project to each head project where they could be suitably customised. Next the ViewModel (and any other reusable code) was moved to the new .Net Standard 2.0 Common project and referenced by each head project. This left the Shared project containing just assets and, where necessary, any common controls or &lt;code&gt;IValueConverter&lt;/code&gt; implementations.&lt;/p&gt;
&lt;h1 id="seven-guis-shining"&gt;Seven GUIs Shining&lt;/h1&gt;
&lt;p&gt;Now, without further ado (of which there has been plenty), may I present the &lt;a href="https://eugenkiss.github.io/7guis"&gt;7GUIs&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Each of the GUIs shown here represent an implementation of one of the tasks from the &lt;a href="https://eugenkiss.github.io/7guis/tasks"&gt;7 GUIs task list&lt;/a&gt;. Despite the fact that many of the GUIs in this list represent - in my opinion - particularly poor UI/UX implementations, I've endeavoured to stay as close as possible to the example GUI provided for the task so that my implementation might be easily compared to &lt;a href="https://eugenkiss.github.io/7guis/implementations"&gt;other implementations&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Furthermore, given the various constraints presented by writing for multiple platforms, I have employed a 'lowest common denominator' approach to implementing some features. For example, dialogs are typically represented by messages appearing in the current UI rather than opening an additional modal overlay. Obviously each platform presents various mechanisms for implementing these common UI metaphors and it would be entirely possible, using the Uno platform, to leverage these mechanism by means of platform specific implementations of an abstracted interface. However, for expediency, I chose not to do this at this time and to just keep it simple.&lt;/p&gt;
&lt;p&gt;For each GUI I have provided a visualization of the GUI running on each platform (click/press to see a larger version) along with a description of the specific challenges and issues presented by the implementation. It is my hope that these details provide the reader with a good insight into the value of implementing interaction patterns as a series of declarative, functional, behavioural flows along with how the Uno platform may be used to provide 'write-once, run-anywhere' style, cross-platform, native applications.&lt;/p&gt;
&lt;h2 id="counter"&gt;1. Counter&lt;/h2&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Challenge: Understanding the basic ideas of a language/toolkit.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="row justify-content-center unobackground"&gt;
    &lt;div class="col-md-8"&gt;
        &lt;div class="row"&gt;
            &lt;a href="https://eugenkiss.github.io/7guis/static/counter.9cd92091.png" data-toggle="lightbox" data-gallery="counter" data-title="Counter Task" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://eugenkiss.github.io/7guis/static/counter.9cd92091.png" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Counter-Android.gif" data-toggle="lightbox" data-gallery="counter" data-title="Counter on Android" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Counter-Android.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" data-toggle="lightbox" data-gallery="counter" data-title="Counter on iOS" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;a href="/Content/Uno/Counter-UWP.gif" data-toggle="lightbox" data-gallery="counter" data-title="Counter in UWP" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Counter-UWP.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Counter-WASM.gif" data-toggle="lightbox" data-gallery="counter" data-title="Counter in Edge" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Counter-WASM.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Counter-WPF.gif" data-toggle="lightbox" data-gallery="counter" data-title="Counter in WPF" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Counter-WPF.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id="implementation"&gt;Implementation&lt;/h3&gt;
&lt;p&gt;This task required just a single &lt;code&gt;CounterShouldBeIncrementedWhenIncrementIsInvoked&lt;/code&gt; behaviour in the &lt;a href="https://github.com/ibebbs/SevenGuis/blob/master/src/Counter/Counter.Common/MainPageViewModel.cs"&gt;view model&lt;/a&gt;. Given its simplicity, here's the behaviour in full:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;private IDisposable CounterShouldBeIncrementedWhenIncrementIsInvoked()
{
    return _increment
        .Scan(0, (value, _) =&amp;gt; value + 1)
        .Subscribe(_counter);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, &lt;code&gt;_increment&lt;/code&gt; is an &lt;code&gt;Observable.Command&lt;/code&gt; and &lt;code&gt;_counter&lt;/code&gt; is an &lt;code&gt;Observable.Property&amp;lt;int&amp;gt;&lt;/code&gt;. Both these members are exposed as properties for data-binding. And that's it. There's no class level &lt;code&gt;_currentValue&lt;/code&gt; member variable as all state is encapsulated within the reactive function.&lt;/p&gt;
&lt;h2 id="temperature-converter"&gt;2. Temperature Converter&lt;/h2&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Challenges: bidirectional data flow, user-provided text input.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="row justify-content-center unobackground"&gt;
    &lt;div class="col-md-8"&gt;
        &lt;div class="row"&gt;
            &lt;a href="https://eugenkiss.github.io/7guis/static/tempconv.de9aff1f.png" data-toggle="lightbox" data-gallery="temperatureconverter" data-title="Temperature Converter Task" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://eugenkiss.github.io/7guis/static/tempconv.de9aff1f.png" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/TemperatureConverter-Android.gif" data-toggle="lightbox" data-gallery="temperatureconverter" data-title="Temperature Converter on Android" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/TemperatureConverter-Android.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" data-toggle="lightbox" data-gallery="temperatureconverter" data-title="Temperature Converter on iOS" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;a href="/Content/Uno/TemperatureConverter-UWP.gif" data-toggle="lightbox" data-gallery="temperatureconverter" data-title="Temperature Converter in UWP" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/TemperatureConverter-UWP.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/TemperatureConverter-WASM.gif" data-toggle="lightbox" data-gallery="temperatureconverter" data-title="Temperature Converter in Edge" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/TemperatureConverter-WASM.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/TemperatureConverter-WPF.gif" data-toggle="lightbox" data-gallery="temperatureconverter" data-title="Temperature Converter in WPF" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/TemperatureConverter-WPF.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id="implementation-1"&gt;Implementation&lt;/h3&gt;
&lt;p&gt;This task required just two behaviours in the &lt;a href="https://github.com/ibebbs/SevenGuis/blob/master/src/TemperatureConverter/TemperatureConverter.Common/MainPageViewModel.cs"&gt;view model&lt;/a&gt;; &lt;code&gt;ShouldUpdateFahrenheitWhenCelciusIsChanged&lt;/code&gt; and &lt;code&gt;ShouldUpdateCelciusWhenFahrenheitIsChanged&lt;/code&gt;. These behaviours follow the same pattern but use a different conversion so, for brevity, only the &lt;code&gt;ShouldUpdateFahrenheitWhenCelciusIsChanged&lt;/code&gt; behaviour as shown here:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;private IDisposable ShouldUpdateFahrenheitWhenCelciusIsChanged()
{
    return _celcius
        .DistinctUntilChanged()
        .Select(Domain.ConvertCelciusToFahrenheit)
        .Subscribe(_fahrenheit);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the actual domain logic has been split into a static function on a &lt;code&gt;Domain&lt;/code&gt; class and used to convert the values from the &lt;code&gt;_celcius&lt;/code&gt; &lt;code&gt;Observable.Property&amp;lt;int&amp;gt;&lt;/code&gt; into Fahrenheit which is then forwarded to the &lt;code&gt;_fahrenheit&lt;/code&gt; &lt;code&gt;Observable.Property&amp;lt;int&amp;gt;&lt;/code&gt;. As these values write to each other, the &lt;code&gt;DistinctUntilChanged&lt;/code&gt; operator is used to prevent a feedback loop.&lt;/p&gt;
&lt;h2 id="flight-booker"&gt;3. Flight Booker&lt;/h2&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Challenge: Constraints.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="row justify-content-center unobackground"&gt;
    &lt;div class="col-md-8"&gt;
        &lt;div class="row"&gt;
            &lt;a href="https://eugenkiss.github.io/7guis/static/bookflight.a5434663.png" data-toggle="lightbox" data-gallery="flightbooker" data-title="Flight Booker Task" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://eugenkiss.github.io/7guis/static/bookflight.a5434663.png" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/FlightBooker-Android.gif" data-toggle="lightbox" data-gallery="flightbooker" data-title="Flight Booker on Android" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/FlightBooker-Android.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" data-toggle="lightbox" data-gallery="flightbooker" data-title="Flight Booker on iOS" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;a href="/Content/Uno/FlightBooker-UWP.gif" data-toggle="lightbox" data-gallery="flightbooker" data-title="Flight Booker in UWP" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/FlightBooker-UWP.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/FlightBooker-WASM.gif" data-toggle="lightbox" data-gallery="flightbooker" data-title="Flight Booker in Edge" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/FlightBooker-WASM.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/FlightBooker-WPF.gif" data-toggle="lightbox" data-gallery="flightbooker" data-title="Flight Booker in WPF" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/FlightBooker-WPF.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id="implementation-2"&gt;Implementation&lt;/h3&gt;
&lt;p&gt;The relatively simple paragraph describing the behaviour of this task belies quite a bit of complexity and required five behaviours to fully implement:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ShouldEnableReturnWhenFlightTypeIsReturn&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldSetOutboundValidWhenOutboundDateHasValue&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldSetReturnValidWhenReturnDateHasValueOrFlightTypeIsOneWay&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldEnableBookWhenDatesAreValidForTheSelectedFlightType&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldDisplayMessageWhenBookInvoked&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I won't dig into each of these behaviours as you should be getting the gist of how this might work now. If not you can find the implementation in the &lt;a href="https://github.com/ibebbs/SevenGuis/tree/master/src/FlightBooker"&gt;view model&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;ShouldSetOutboundValidWhenOutboundDateHasValue&lt;/code&gt; and &lt;code&gt;ShouldSetReturnValidWhenReturnDateHasValueOrFlightTypeIsOneWay&lt;/code&gt; could have been implemented in the view with various bindings and converters but as they form part of the behaviour specification, they're kept in the view model so that they can be tested.&lt;/p&gt;
&lt;p&gt;Amazingly, the most difficult bit of this task was finding a means of reliably setting the initial value of the &amp;quot;Flight Type&amp;quot; combo-box. It turns out that this was due to a bug in UWP that means the &lt;code&gt;SelectedValue&lt;/code&gt; property of a &lt;a href="https://stackoverflow.com/questions/35599479/combobox-does-not-select-binding-value-initially"&gt;combo-box doesn't support binding to an enumeration property&lt;/a&gt;. This was eventually resolved by binding the &lt;code&gt;SelectedIndex&lt;/code&gt; property of the combobox to the enumeration via a converter.&lt;/p&gt;
&lt;h2 id="timer"&gt;4. Timer&lt;/h2&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Challenges: concurrency, competing user/signal interactions, responsiveness.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="row justify-content-center unobackground"&gt;
    &lt;div class="col-md-8"&gt;
        &lt;div class="row"&gt;
            &lt;a href="https://eugenkiss.github.io/7guis/static/timer.ed46b6b4.png" data-toggle="lightbox" data-gallery="timer" data-title="Timer Task" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://eugenkiss.github.io/7guis/static/timer.ed46b6b4.png" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Timer-Android.gif" data-toggle="lightbox" data-gallery="timer" data-title="Timer on Android" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Timer-Android.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" data-toggle="lightbox" data-gallery="timer" data-title="Timer on iOS" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;a href="/Content/Uno/Timer-UWP.gif" data-toggle="lightbox" data-gallery="timer" data-title="Timer in UWP" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Timer-UWP.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Timer-WASM.gif" data-toggle="lightbox" data-gallery="timer" data-title="Timer in Edge" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Timer-WASM.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Timer-WPF.gif" data-toggle="lightbox" data-gallery="timer" data-title="Timer in WPF" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Timer-WPF.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id="implementation-3"&gt;Implementation&lt;/h3&gt;
&lt;p&gt;This task is where the Reactive Extensions and MVx.Observables really shine. Here's the task description:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;The task is to build a frame containing a gauge G for the elapsed time e, a label which shows the elapsed time as a numerical value, a slider S by which the duration d of the timer can be adjusted while the timer is running and a reset button R. Adjusting S must immediately reflect on d and not only when S is released. It follows that while moving S the filled amount of G will (usually) change immediately. When e ≥ d is true then the timer stops (and G will be full). If, thereafter, d is increased such that d &amp;gt; e will be true then the timer restarts to tick until e ≥ d is true again. Clicking R will reset e to zero.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And here's the single behaviour required to satisfy this specification:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;private IDisposable ShouldIncrementElapsedUntilResetOrEqualToMax()
{
    return _reset
        .StartWith((object)null)
        .Select(_ =&amp;gt; Observable
            .Interval(Interval)
            .WithLatestFrom(_max, (interval, max) =&amp;gt; max)
            .Scan((long)0, (acc, max) =&amp;gt; acc + Interval.Ticks &amp;gt;= max ? max : acc + Interval.Ticks))
            .DistinctUntilChanged()
        .Switch()
        .ObserveOn(_scheduler)
        .Subscribe(_elapsed);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To break this down: Every time the &lt;code&gt;_reset&lt;/code&gt; &lt;code&gt;Observable.Command&lt;/code&gt; is invoked and starting with an initial invocation, select a new observable. This new observable will emit a value at a specific interval which will be incremented automatically until it is equal to the &lt;code&gt;_max&lt;/code&gt; value. Once it is equal to the &lt;code&gt;_max&lt;/code&gt; value, no further values will be emitted until &lt;code&gt;_max&lt;/code&gt; changes or the timer is reset. Finally, subscribe to the new observable and forward the emitted values to the &lt;code&gt;_elapsed&lt;/code&gt; &lt;code&gt;Observable.Property&amp;lt;int&amp;gt;&lt;/code&gt; on the UI thread.&lt;/p&gt;
&lt;p&gt;Now, admittedly the timer underlying this observable doesn't 'stop' once the value has reached the max value per the description. While it would be possible to do this in a single behaviour, the required expression would be significantly more complicated and, given the low cost of recalculating the value every interval, I elected to keep the observable simple and obvious.&lt;/p&gt;
&lt;h2 id="crud"&gt;5. CRUD&lt;/h2&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Challenges: separating the domain and presentation logic, managing mutation, building a non-trivial layout.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="row justify-content-center unobackground"&gt;
    &lt;div class="col-md-8"&gt;
        &lt;div class="row"&gt;
            &lt;a href="https://eugenkiss.github.io/7guis/static/crud.515ce94b.png" data-toggle="lightbox" data-gallery="crud" data-title="CRUD Task" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://eugenkiss.github.io/7guis/static/crud.515ce94b.png" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Crud-Android.gif" data-toggle="lightbox" data-gallery="crud" data-title="CRUD on Android" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Crud-Android.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" data-toggle="lightbox" data-gallery="crud" data-title="CRUD on iOS" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;a href="/Content/Uno/Crud-UWP.gif" data-toggle="lightbox" data-gallery="crud" data-title="CRUD in UWP" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Crud-UWP.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Crud-WASM.gif" data-toggle="lightbox" data-gallery="crud" data-title="CRUD in Edge" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Crud-WASM.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Crud-WPF.gif" data-toggle="lightbox" data-gallery="crud" data-title="CRUD in WPF" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Crud-WPF.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;CRUD is a great test of a UI as it forms a matrix of operations across numerous controls. This is shown by the &lt;a href="https://eugenkiss.github.io/7guis/tasks#crud"&gt;complexity of the description of the task&lt;/a&gt; and the number of behaviours required to meet this specification:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ShouldEnableUpdateWhenSelected&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldEnableDeleteWhenSelected&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldEnableCreateWhenNameAndSurnameArePopulated&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldPopulateNamesWithFilteredNames&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldAddFullNameWhenCreateInvoked&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldUpdateFullNameWhenUpdatedInvoked&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldRemoveFullNameWhenDeleteInvoked&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldPopulateNameWhenFullNameSelected&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldPopulateSurnameWhenFullNameSelected&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="circle-drawer"&gt;6. Circle Drawer&lt;/h2&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Challenges: undo/redo, custom drawing, dialog control*.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="row justify-content-center unobackground"&gt;
    &lt;div class="col-md-8"&gt;
        &lt;div class="row"&gt;
            &lt;a href="https://eugenkiss.github.io/7guis/static/circledraw.235dfd8b.png" data-toggle="lightbox" data-gallery="circledrawer" data-title="Circle Drawer Task" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://eugenkiss.github.io/7guis/static/circledraw.235dfd8b.png" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/CircleDrawer-Android.gif" data-toggle="lightbox" data-gallery="circledrawer" data-title="Circle Drawer on Android" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/CircleDrawer-Android.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" data-toggle="lightbox" data-gallery="circledrawer" data-title="Circle Drawer on iOS" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;a href="/Content/Uno/CircleDrawer-UWP.gif" data-toggle="lightbox" data-gallery="circledrawer" data-title="Circle Drawer in UWP" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/CircleDrawer-UWP.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/CircleDrawer-WASM.gif" data-toggle="lightbox" data-gallery="circledrawer" data-title="Circle Drawer in Edge" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/CircleDrawer-WASM.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/CircleDrawer-WPF.gif" data-toggle="lightbox" data-gallery="circledrawer" data-title="Circle Drawer in WPF" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/CircleDrawer-WPF.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;I think it's fair to say Uno struggled with this task. While the UWP version was completed in short order, neither the Android nor WASM heads worked &lt;em&gt;at all&lt;/em&gt; and the WPF project had several issues.&lt;/p&gt;
&lt;p&gt;It turned out that both the UWP and WASM platforms suffered similar - but not the exactly the same - issues. The first issue I encountered was with determining where a user clicked on a Canvas used as an items container for a ListView control. Digging into this I found further issues where the &lt;code&gt;TappedRoutedEventArgs&lt;/code&gt; resulting from the click returned different &lt;code&gt;OriginalSource&lt;/code&gt; objects - sometimes the Canvas, sometimes the ListView - and getting the clicked position relative to the &lt;code&gt;OriginalSource&lt;/code&gt; always returned the position &lt;code&gt;{X: 0, Y: 0}&lt;/code&gt;. Then I found that the attached property binding mechanism I'd used to bind &lt;code&gt;Canvas.X&lt;/code&gt; and &lt;code&gt;Canvas.Y&lt;/code&gt; properties on the ListViewItem instances representing the circles just wasn't being applied consistently. The WPF head, on the other hand, struggled with distinguishing between clicks on an item and clicks in an empty area of the ListView such that it's not possible to reselect a circle once it's been deselected.&lt;/p&gt;
&lt;p&gt;Perhaps a lot of the above issues could have been resolved by using a custom control or a custom item container for the ListView but, as the UWP solution worked perfectly, this was something I felt I ought not to have to do. Ultimately I hacked through as many of the issues as I could but this was one task where all the heads don't perform in the same way. Furthermore, I'm sure the WPF issue could be resolved by working out if the click caused an item to be selected but unfortunately I ran out of time before I could investigate this.&lt;/p&gt;
&lt;p&gt;Anyway, this solution used a basic form of command processor to apply interactions to a state container which contained the current circles along with undo and redo stacks of commands. This provided a very simple mechanism for undoing or redoing a command such that the view model needed only the following behaviours:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ShouldPopulateCirclesFromState&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldEnableOrDisableUndoBasedOnState&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldEnableOrDisableRedoBasedOnState&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldEnableOrDisableAdjustDiameterBasedOnSelectedItem&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldSetSelectedFromState&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldShowAdjustDiameterDialogWhenAdjustDiameterInvoked&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="cells"&gt;7. Cells&lt;/h2&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Challenges: change propagation, widget customization, implementing a more authentic/involved GUI application.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="row justify-content-center unobackground"&gt;
    &lt;div class="col-md-8"&gt;
        &lt;div class="row"&gt;
            &lt;a href="https://eugenkiss.github.io/7guis/static/cells.9544a72f.png" data-toggle="lightbox" data-gallery="cells" data-title="Cells Task" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://eugenkiss.github.io/7guis/static/cells.9544a72f.png" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Cells-Android.gif" data-toggle="lightbox" data-gallery="cells" data-title="Cells on Android" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Cells-Android.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" data-toggle="lightbox" data-gallery="cells" data-title="Cells on iOS" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;a href="/Content/Uno/Cells-UWP.gif" data-toggle="lightbox" data-gallery="cells" data-title="Cells in UWP" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Cells-UWP.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Cells-WASM.gif" data-toggle="lightbox" data-gallery="cells" data-title="Cells in Edge" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Cells-WASM.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
            &lt;a href="/Content/Uno/Cells-WPF.gif" data-toggle="lightbox" data-gallery="cells" data-title="Cells in WPF" class="col-xs-4 col-sm-4"&gt;
                &lt;img src="/Content/Uno/Cells-WPF.gif" class="img-fluid ekko-lightbox-image"&gt;
            &lt;/a&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This project was a lot of fun to write; well, at least for the UWP head anyway. Never before had I even conceived of trying to write a spreadsheet, yet here I was six GUI's in with one to go and I didn't want to turn back now. It actually turned out to be both easier and more difficult than I had imagined:&lt;/p&gt;
&lt;p&gt;Easier in that the business logic of a spreadsheet application turned out to be surprisingly simple and involved building a recursive dependency tree whenever any cell changed and then evaluating each of the dependencies using an &lt;a href="https://www.nuget.org/packages/XLParser/"&gt;off-the-shelf expression parser&lt;/a&gt; married to a custom expression visitor implementation. All this was isolated in a &lt;a href="https://github.com/ibebbs/SevenGuis/tree/master/src/Cells/Cells.Common/Spreadsheet"&gt;business domain&lt;/a&gt; with communication between this domain and the MVVM layer taking place via events transmitted over a message bus.&lt;/p&gt;
&lt;p&gt;The view layer on the other hand was very, very frustrating. It proved to be impossible to find a DataGrid control for UWP that worked with both row &lt;em&gt;and&lt;/em&gt; column virtualization so I ended up having to instantiate the entire spreadsheet ahead of time. This was possible due to the description of the problem specifying that there need be only 100 rows and 26 columns otherwise I would have had to write some (probably quite clunky) custom control or give up as it would have been too much work for a blog post. After this I then found that the DataGrid I had chosen to use (because it had been ported specifically to the Uno platform - &lt;a href="https://www.nuget.org/packages/Uno.Microsoft.Toolkit.Uwp.UI.Controls.DataGrid/5.1.0-build.200.gf9c311b069"&gt;Uno.Microsoft.Toolkit.Uwp.UI.Controls.DataGrid&lt;/a&gt;) didn't actually work for Android or WASM anyway and just displayed an empty grid.&lt;/p&gt;
&lt;p&gt;It would have been fun to dig into the issues I found with the DataGrid on Android and WASM as it would have been cool to say that I'd written a cross-platform spreadsheet. Unfortunately I ran out of time and will, for now, have to admit defeat here.&lt;/p&gt;
&lt;p&gt;Anyway, in this task the &lt;code&gt;MainPageViewModel&lt;/code&gt; simply consisted of a collection of &lt;code&gt;RowViewModel&lt;/code&gt; instances which, in turn, consisted of &lt;code&gt;CellViewModel&lt;/code&gt; instances. As I wasn't able to use virtualisation in the DataGrid, all behaviour was in the &lt;code&gt;CellViewModel&lt;/code&gt; and consisted of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ShouldUpdateContentWhenContentChangedReceived&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ShouldPublishTextChangedWhenTextChanged&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both these behaviours interact with the message bus to send change events or receive content updates.&lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;h3 id="uno-platform"&gt;Uno Platform&lt;/h3&gt;
&lt;p&gt;As I hope you have seen from the above, the Uno Platform really does make it possible to develop true &amp;quot;write-once, run-anywhere&amp;quot; applications. Its ability to provide a consistent UWP API across multiple devices/browsers is truly a monumental achievement.&lt;/p&gt;
&lt;p&gt;However, as we have also seen, it can sometimes struggle with low-level or complicated UIs which can make some advanced UX patterns difficult to get working consistently across all platforms. I was very surprised that the DataGrid control didn't function at all on Android or WASM as this control is often considered central to a lot of line-of-business applications.&lt;/p&gt;
&lt;p&gt;Fortunately Uno is currently under active development and has a very engaged community of developers reporting issues and submitting pull-requests. Version 2.0 of the platform has &lt;a href="https://platform.uno/announcing-uno-platform-2-0/"&gt;just been released&lt;/a&gt; and new packages are pushed to &lt;a href="https://www.nuget.org/packages/Uno.UI"&gt;nuget&lt;/a&gt; almost every day. I therefore have high hopes that many of the issues I encountered here will be resolved in the near future.&lt;/p&gt;
&lt;p&gt;So would I advocate the use of Uno platform? Well, as any good developer will tell you, &amp;quot;It depends&amp;quot;. It certainly has a great many strengths and should be considered a viable alternative to Xamarin but the fact that it's still suffering some growing pains can't be denied. I guess if I were &lt;a href="https://www.thoughtworks.com/radar"&gt;ThoughtWorks&lt;/a&gt;, the Uno Platform would feature in the 'Trial' section of my &lt;a href="https://www.thoughtworks.com/radar/languages-and-frameworks"&gt;Technology Radar&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="guis"&gt;7GUIs&lt;/h3&gt;
&lt;p&gt;The &amp;quot;7GUIs Programming Benchmark&amp;quot; provided a diverse and interesting set of challenges. From the super simple 'Counter' to the implementation of a full spreadsheet it really does cover a lot of common UI/UX patterns.&lt;/p&gt;
&lt;p&gt;As a benchmark for evaluating the Uno platform however, I don't think it was a particularly good choice. Uno is targeted at rich visuals using controls which have native interaction patterns across multiple form-factors, something that almost certainly wasn't a consideration for the creators of the 7GUIs.&lt;/p&gt;
&lt;h3 id="declarative-behaviours-frp"&gt;Declarative Behaviours &amp;amp; FRP&lt;/h3&gt;
&lt;p&gt;While a significant amount of the detail regarding these aspects of the UI implementation had to be omitted from the descriptions of each task, I trust you are able to see how Behavioural Design can be incorporated into declarative code and how FRP can provide numerous benefits to an implementation.&lt;/p&gt;
&lt;p&gt;I would very much encourage you to examine the use of these paradigms in the implementation of the UIs and more broadly from the growing body of code employing these practices. Also, if you get the chance, take some time to &lt;a href="https://fsharp.org/"&gt;learn F#&lt;/a&gt;; I almost guarantee that, once you hit that functional &amp;quot;light-bulb&amp;quot; moment, your C# will never be the same again.&lt;/p&gt;
&lt;h3 id="dual-screen-devices"&gt;Dual-Screen Devices&lt;/h3&gt;
&lt;p&gt;So how does this all fare for the underlying use case of developing applications for the Surface Neo and Surface Duo? Well, personally I'm very encouraged. The current version of Uno works beautifully with my preferred implementation paradigms and, with just a couple of exceptions, provided an extremely consistent and stable API surface to work with across all its supported platforms.&lt;/p&gt;
&lt;p&gt;I am very much looking forward to getting my hands on these devices (nudge, nudge, Microsoft) and spending some serious time looking at what can be achieved with these tools and form-factors. I'm especially interested to try some of the new &lt;a href="https://platform.uno/winui-on-windows7-via-unoplatform/"&gt;WinUI features&lt;/a&gt; in a cross platform application; I mean, can you imagine some of the beautiful new &lt;a href="https://docs.microsoft.com/en-us/windows/uwp/design/style/acrylic"&gt;Acrylic UIs&lt;/a&gt; running natively on Android... woah.&lt;/p&gt;
&lt;h3 id="source-questions-feedback"&gt;Source, Questions &amp;amp; Feedback&lt;/h3&gt;
&lt;p&gt;All the source code for this article can be found in my &lt;a href="https://github.com/ibebbs/SevenGuis"&gt;SevenGuis Github Repository&lt;/a&gt;. Fork it and have a play (and send me a PR if you manage to resolve any of the issues I got stumped by).&lt;/p&gt;
&lt;p&gt;I'd also love to hear any questions or feedback you may have about this article. Feel free to get in touch using any of the social links below or from my &lt;a href="https://ian.bebbs.co.uk/about"&gt;about page&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="and-finally"&gt;And finally...&lt;/h1&gt;
&lt;p&gt;&lt;img src="https://media.giphy.com/media/kBM8KY3zrk7D2/giphy.gif" class="img-fluid" alt="Merry Christmas" /&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;
$(document).on('click', '[data-toggle="lightbox"]', function(event) {
                event.preventDefault();
                $(this).ekkoLightbox();
            });
&lt;/script&gt;
&lt;div id="myModal" class="modal"&gt;
  &lt;span class="close cursor" onclick="closeModal()"&gt;&amp;times;&lt;/span&gt;
  &lt;div class="modal-content"&gt;
    &lt;div class="mySlides"&gt;
      &lt;div class="numbertext"&gt;1 / 4&lt;/div&gt;
      &lt;img src="https://eugenkiss.github.io/7guis/static/counter.9cd92091.png" alt="Counter Task"&gt;
    &lt;/div&gt;
    &lt;div class="mySlides"&gt;
      &lt;div class="numbertext"&gt;2 / 4&lt;/div&gt;
      &lt;img src="/Content/Uno/Counter-Android.gif" alt="Counter on Android"&gt;
    &lt;/div&gt;
    &lt;div class="mySlides"&gt;
      &lt;div class="numbertext"&gt;3 / 4&lt;/div&gt;
      &lt;img src="https://media.giphy.com/media/D28t0Rto3daKI/giphy.gif" alt="Counter on iOS"/&gt;
    &lt;/div&gt;
    &lt;div class="mySlides"&gt;
      &lt;div class="numbertext"&gt;4 / 4&lt;/div&gt;
      &lt;img src="/Content/Uno/Counter-UWP.gif" alt="Counter on UWP"/&gt;
    &lt;/div&gt;
    &lt;div class="mySlides"&gt;
      &lt;div class="numbertext"&gt;5 / 5&lt;/div&gt;
      &lt;img src="/Content/Uno/Counter-WASM.gif" alt="Counter on WASM"/&gt;
    &lt;/div&gt;
    &lt;div class="mySlides"&gt;
      &lt;div class="numbertext"&gt;6 / 6&lt;/div&gt;
      &lt;img src="/Content/Uno/Counter-WPF.gif" alt="Counter on WPF"/&gt;
    &lt;/div&gt;
    &lt;!-- Next/previous controls --&gt;
    &lt;a class="prev" onclick="plusSlides(-1)"&gt;&amp;#10094;&lt;/a&gt;
    &lt;a class="next" onclick="plusSlides(1)"&gt;&amp;#10095;&lt;/a&gt;
    &lt;!-- Caption text --&gt;
    &lt;div class="caption-container"&gt;
      &lt;p id="caption"&gt;&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
</content:encoded>
		</item>
		<item>
			<title>Augmenting the .NET Core 3.0 Generic Host</title>
			<link>http://ian.bebbs.co.uk/posts/AugmentingTheGenericHost</link>
			<description>&lt;p&gt;I love the .NET Core 3.0 Generic Host, I really do. As a framework for simplifying common scaffolding and lifetime management of long-running services, it's &lt;em&gt;almost&lt;/em&gt; faultless. Unfortunately, the mere fact of &lt;a href="http://tomasp.net/blog/2015/library-frameworks/"&gt;being a framework rather than a library&lt;/a&gt; can lead to issues where, as a user of the framework, you're unable to accomplish a specific goal. For me, this happened while trying to get instrumentation written to a various &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing.eventsource"&gt;EventSource&lt;/a&gt; instances to be output - in a configurable manner - through the Generic Host's logging infrastructure. Sounds simple huh, and it really ought to be. But it wasn't. Here's why:&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/AugmentingTheGenericHost</guid>
			<pubDate>Mon, 18 Nov 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="background"&gt;Background&lt;/h1&gt;
&lt;p&gt;I love the .NET Core 3.0 Generic Host, I really do. As a framework for simplifying common scaffolding and lifetime management of long-running services, it's &lt;em&gt;almost&lt;/em&gt; faultless. Unfortunately, the mere fact of &lt;a href="http://tomasp.net/blog/2015/library-frameworks/"&gt;being a framework rather than a library&lt;/a&gt; can lead to issues where, as a user of the framework, you're unable to accomplish a specific goal. For me, this happened while trying to get instrumentation written to a various &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing.eventsource"&gt;EventSource&lt;/a&gt; instances to be output - in a configurable manner - through the Generic Host's logging infrastructure. Sounds simple huh, and it really ought to be. But it wasn't. Here's why:&lt;/p&gt;
&lt;h1 id="the-open-closed-principle"&gt;The Open-Closed Principle&lt;/h1&gt;
&lt;p&gt;In the unlikely event you're not familiar with this principle, you can read about it &lt;a href="https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Generic Host is a beacon of SOLID-design and seems to embrace the 'Open-closed principal' particularly closely. Perhaps this is due to the fact that, almost by definition, the Generic Host needs to be extremely extensible. Therefore, to ensure it's able to guide it's users into the &lt;a href="https://blog.codinghorror.com/falling-into-the-pit-of-success/"&gt;pit of success&lt;/a&gt;, the implementation of the Generic Host closes many avenues for modifying its default behaviours.&lt;/p&gt;
&lt;p&gt;Unfortunately there are instances where users have good reason to want to modify default behaviour. For example, there have been &lt;a href="https://github.com/aspnet/Extensions/issues/1151"&gt;multiple&lt;/a&gt; &lt;a href="https://github.com/aspnet/Extensions/issues/810"&gt;feature&lt;/a&gt; &lt;a href="https://github.com/aspnet/Extensions/issues/525"&gt;requests&lt;/a&gt; for the Generic Host to provide a means for consumers to add behaviour to the start-up routine &lt;em&gt;after&lt;/em&gt; the dependency injection container has been created but before it's used to resolve any &lt;code&gt;IHostedService&lt;/code&gt; instances. In each of these instances, the maintainers of the &lt;a href="https://github.com/aspnet/Extensions"&gt;Microsoft.Extensions repository&lt;/a&gt; have suggested alternatives for the specific use-case being mooted even though, in my opinion, these alternatives seem to be rather poor workarounds for what I believe to be a valid feature request.&lt;/p&gt;
&lt;p&gt;Why do I believe it's a valid feature when so many other &lt;a href="https://github.com/davidfowl"&gt;awesome&lt;/a&gt; &lt;a href="https://github.com/anurse"&gt;.NET&lt;/a&gt; &lt;a href="https://github.com/Tratcher"&gt;developers&lt;/a&gt; believe differently? Well, because the generic host itself uses this feature, as can be seen &lt;a href="https://github.com/aspnet/Extensions/blob/f4e9a5e1da193faad2338e0a8225a531a2c1417c/src/Hosting/Hosting/src/HostBuilder.cs#L242"&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;_appServices = _serviceProviderFactory.CreateServiceProvider(containerBuilder);

if (_appServices == null)
{
    throw new InvalidOperationException($&amp;quot;The IServiceProviderFactory returned a null IServiceProvider.&amp;quot;);
}

// resolve configuration explicitly once to mark it as resolved within the
// service provider, ensuring it will be properly disposed with the provider
_ = _appServices.GetService&amp;lt;IConfiguration&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, &lt;em&gt;for perfectly valid reasons&lt;/em&gt;, the Generic Host needs to perform an operation &lt;em&gt;after&lt;/em&gt; the service provider has been created but before any further types are resolved. I do not believe it's only the Generic Host infrastructure code that requires this entry-point. Indeed, this is the feature I required to ensure I could correctly instantiate and configure a singleton &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing.eventlistener"&gt;EventListener&lt;/a&gt; instance prior to events being written to (and potentially lost from) various EventSource instances throughout my code.&lt;/p&gt;
&lt;p&gt;So, rather than accept a workaround and potentially compromise some core requirements, I decided to see if there was a way I could implement the above feature without straying too far from canonical Generic Host start-up code.&lt;/p&gt;
&lt;h1 id="ihostapplicationlifetime"&gt;IHostApplicationLifetime&lt;/h1&gt;
&lt;p&gt;The GenericHost has an &lt;a href="https://github.com/aspnet/Extensions/blob/master/src/Hosting/Abstractions/src/IHostApplicationLifetime.cs"&gt;&lt;code&gt;IHostApplicationLifetime&lt;/code&gt;&lt;/a&gt; interface which is responsible for coordinating application lifetime notifications. Registered with the dependency injection container as a singleton, it is ordinarily injected into &lt;code&gt;IHostedService&lt;/code&gt; instances, providing the ability for any service to request that the application be stopped.&lt;/p&gt;
&lt;p&gt;However, this interface is also injected into the various &lt;code&gt;IHostLifetime&lt;/code&gt; implementations (i.e. &lt;a href="https://github.com/aspnet/Extensions/blob/master/src/Hosting/Hosting/src/Internal/ConsoleLifetime.cs"&gt;ConsoleLifetime&lt;/a&gt; for console applications, &lt;a href="https://github.com/aspnet/Extensions/blob/master/src/Hosting/WindowsServices/src/WindowsServiceLifetime.cs"&gt;WindowsServiceLifetime&lt;/a&gt; for Windows services, etc) and, as such, it is instantiated once, after the dependency injection container is created but before any &lt;code&gt;IHostedService&lt;/code&gt; instances are resolved.&lt;/p&gt;
&lt;p&gt;Sounds useful huh.&lt;/p&gt;
&lt;p&gt;Best of all, this interface provides the means to react to application start and stop events via a &lt;a href="https://github.com/aspnet/Extensions/blob/f4e9a5e1da193faad2338e0a8225a531a2c1417c/src/Hosting/Hosting/src/Internal/ConsoleLifetime.cs#L48"&gt;novel use of &lt;code&gt;CancellationToken&lt;/code&gt; instances&lt;/a&gt;. I therefore chose this as my entry point for providing required functionality.&lt;/p&gt;
&lt;h1 id="applicationlifetimeex-ugh"&gt;ApplicationLifetimeEx (ugh)&lt;/h1&gt;
&lt;p&gt;Inheriting from the default the &lt;a href="https://github.com/aspnet/Extensions/blob/master/src/Hosting/Hosting/src/Internal/ApplicationLifetime.cs"&gt;IHostApplicationLifetime implementation&lt;/a&gt;, registering callbacks for the &lt;code&gt;ApplicationStarted&lt;/code&gt; and &lt;code&gt;ApplicationStopping&lt;/code&gt; cancellation tokens and then registering the derived class as the new &lt;code&gt;IHostApplicationLifetime&lt;/code&gt; implementation in the Generic Host's DI container worked perfectly. Using this approach I was able to leverage standard generic host start-up code and functionality to resolve an EventListener, with configuration, prior to any further types being instantiated.&lt;/p&gt;
&lt;p&gt;An example of this can be found in the development branch my Cogenity.Extensions repository &lt;a href="https://github.com/ibebbs/Cogenity.Extensions/tree/develop/src/Cogenity.Extensions.Logging.EventSource"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="sounds-good.so-why-only-in-the-development-branch"&gt;Sounds good. So why only in the development branch?&lt;/h1&gt;
&lt;p&gt;Well, this approach has &lt;em&gt;a lot&lt;/em&gt; of drawbacks, the most significant of which being that it fails to adhere to another important OO design principal; that of &lt;a href="https://en.wikipedia.org/wiki/Composition_over_inheritance"&gt;'Composition over inheritance'&lt;/a&gt;. In fact, the above approach - in it's current form - is not composable &lt;em&gt;at all&lt;/em&gt;. If another library wanted to hijack the IHostApplicationLifetime interface in a similar way, then my implementation (and associated functionality) would be entirely lost.&lt;/p&gt;
&lt;p&gt;As the Generic Host goes to great lengths to ensure that composability is maintained at all times and in all configurations  &lt;em&gt;this approach is probably not one I would recommend&lt;/em&gt;. Given there are no better options at the current time, I will probably proceed with this implementation as, to me, it is a &lt;a href="https://en.wikipedia.org/wiki/White_box_%28software_engineering%29"&gt;white box&lt;/a&gt;, but I don't intend to make a packaged version available for general consumption.&lt;/p&gt;
&lt;p&gt;That said, when the &lt;a href="https://github.com/aspnet/Extensions/issues/2653"&gt;suggested decoration extensions&lt;/a&gt; are made available, decorating the default IHostApplicationLifetime implementation will become a composable operation and this approach could suddenly become a lot more attractive.&lt;/p&gt;
&lt;h1 id="until-then"&gt;Until then...&lt;/h1&gt;
&lt;p&gt;... I kind of hope the project maintainers will take another look at these feature requests and provide a more holistic solution. Perhaps something along the lines of:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;private static async Task Main(string[] args)
{
    var builder = Host.CreateDefaultBuilder(args)
        .ConfigureServices(
            services =&amp;gt;
            {
                ...
            })
        .ConfigureApplicationLifetime(
            (applicationLifetime, appServices) =&amp;gt;
            {
                applicationLifetime.ApplicationStarted.Register(() =&amp;gt; [do something with appServices])
            }
        );

    await builder
        .Build()
        .RunAsync();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I think this could be quite nice as the GenericHost could then move the&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;// resolve configuration explicitly once to mark it as resolved within the
// service provider, ensuring it will be properly disposed with the provider
_ = _appServices.GetService&amp;lt;IConfiguration&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;block into a &lt;code&gt;ConfigureApplicationLifetime&lt;/code&gt; configuration call back within the &lt;code&gt;CreateDefaultBuilder&lt;/code&gt; call.&lt;/p&gt;
&lt;p&gt;Of course, this signature would provide all sorts of opportunities for naughtiness and smells and, while I could probably implement it using the method described above, I'm very much hoping the great minds behind this project might be able to propose something a little safer.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Light-weight run-time composition for the .NET Core 3.0 Generic Host</title>
			<link>http://ian.bebbs.co.uk/posts/LightweightRuntimeCompositionForGenericHost</link>
			<description>&lt;p&gt;&lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition"&gt;Cogenity.Extensions.Hosting.Composition&lt;/a&gt; can provide lightweight, runtime composition for the &lt;a href="(https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.0)"&gt;.NET Core 3.0 Generic Host&lt;/a&gt;... with some caveats. &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition/issues/5"&gt;An issue&lt;/a&gt; has been created as an RFC on how best to address these caveats with comments/contributions welcomed.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/LightweightRuntimeCompositionForGenericHost</guid>
			<pubDate>Mon, 11 Nov 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="tldr"&gt;TL;DR&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition"&gt;Cogenity.Extensions.Hosting.Composition&lt;/a&gt; can provide lightweight, runtime composition for the &lt;a href="(https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.0)"&gt;.NET Core 3.0 Generic Host&lt;/a&gt;... with some caveats. &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition/issues/5"&gt;An issue&lt;/a&gt; has been created as an RFC on how best to address these caveats with comments/contributions welcomed.&lt;/p&gt;
&lt;h1 id="did-you-know"&gt;Did you know...&lt;/h1&gt;
&lt;p&gt;The &lt;a href="https://github.com/aspnet/AspNetCore/issues/9337"&gt;.NET Core 3.0 web stack has been &amp;quot;re-platformed&amp;quot; onto the generic host library&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;Furthermore, did you know that &lt;code&gt;WebHost&lt;/code&gt; allows you to &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/platform-specific-configuration?view=aspnetcore-3.0"&gt;load additional non-referenced assemblies at runtime which can participate in service start-up by implementing the &lt;code&gt;IHostingStartup&lt;/code&gt; interface&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;Well neither did I until I started looking for a way to perform runtime-composition for a service utilizing the &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.0"&gt;.NET Core 3.0 Generic Host&lt;/a&gt;. It turns out that, while both the changes above are great for the web-platform, nothing similar exists out-of-the-box for the Generic Host. So here's what I did...&lt;/p&gt;
&lt;h1 id="background"&gt;Background&lt;/h1&gt;
&lt;p&gt;I'm currently working on a very interesting project which I hope to see open-sourced in a few weeks time. At the moment it's being developed behind closed doors but with various reusable components being segregated into open-source projects/packages for use by the community.&lt;/p&gt;
&lt;p&gt;One facet of this project is a .NET Core 3.0 service which needs to be deployable in a variety of environments and across a number of platforms. While this service provides a set of core behaviours, these behaviours need to be augmented by arbitrary functionality specific to the environment/platform the service is being used within.&lt;/p&gt;
&lt;p&gt;So it was that I came to look for a means to provide light-weight runtime-composition to services implemented using the .NET Core 3.0 Generic Host and, to my surprise, came up empty handed.&lt;/p&gt;
&lt;h1 id="wait-runtime-composition"&gt;Wait, runtime composition?&lt;/h1&gt;
&lt;p&gt;Yes, the ability to add functionality/behaviours to a software component, ostensibly by loading additional assemblies at runtime, without requiring re-compilation of said software component.&lt;/p&gt;
&lt;p&gt;Specifically, my requirements were:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A simple, fast, lightweight means to safely load and configure additional assemblies at service start-up; and&lt;/li&gt;
&lt;li&gt;A means for these assemblies to participate in host composition (i.e. do something like '&lt;code&gt;IHostBuilder.UseRabbitMq&amp;lt;MyMessageHandler&amp;gt;()&lt;/code&gt;').&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With a couple of nice-to-haves:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Allow for multiple instances of a specific assembly to be loaded with different configurations.&lt;/li&gt;
&lt;li&gt;Allow multiple versions of specific assemblies to be loaded concurrently.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="surely-this-is-a-solved-problem"&gt;Surely this is a solved problem?&lt;/h1&gt;
&lt;p&gt;I thought so too. Having used MEF (the Managed Extensibility Framework) in the past I went to see if it had been ported to .NET Core and &lt;a href="https://www.nuget.org/packages/System.Composition"&gt;indeed it had&lt;/a&gt;. Unfortunately, it seems to have fallen out of favour and there's very little documentation about it's use in .NET Core and even less about how one might integrate it into the Generic Host.&lt;/p&gt;
&lt;p&gt;I then found &lt;a href="https://github.com/khellang/Scrutor"&gt;Scrutor&lt;/a&gt; which, while more integrated into the Generic Host eco-system (it provides fantastic assembly scanning and decoration capabilities specfically for Microsoft.Extensions.DependencyInjection), didn't provide a means for the discovered types to participate in host composition.&lt;/p&gt;
&lt;p&gt;Finally I discovered &lt;a href="https://github.com/dapplo/Dapplo.Microsoft.Extensions.Hosting"&gt;Dapplo.Microsoft.Extensions.Hosting&lt;/a&gt; which provides the &lt;a href="https://www.nuget.org/packages/Dapplo.Microsoft.Extensions.Hosting.Plugins/"&gt;Dapplo.Microsoft.Extensions.Hosting.Plugins&lt;/a&gt; package. This was extremely close to what I wanted but relied too heavily on directory scanning (thereby not meeting the &amp;quot;fast and safe&amp;quot; requirements) and, like Scrutor and MEF, also didn't provide a means to participate in host composition (the &amp;quot;plugins&amp;quot; only have access to the &lt;code&gt;HostBuilderContent&lt;/code&gt;).&lt;/p&gt;
&lt;h1 id="right-well-how-hard-can-this-be"&gt;Right, well how hard can this be?&lt;/h1&gt;
&lt;p&gt;Not that hard it turns out... but with several caveats.&lt;/p&gt;
&lt;p&gt;Within a few hours of deciding to roll-my-own solution to the requirements above, and by borrowing extensively from the various projects I'd already encountered, I'd written &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition"&gt;Cogenity.Extensions.Hosting.Composition&lt;/a&gt;. This solution used configuration (rather than directory scanning) to specify the additional assemblies to load and, like the Dapplo project, used .NET Core's &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.loader.assemblyloadcontext?view=netcore-3.0"&gt;&lt;code&gt;AssemblyLoadContext&lt;/code&gt;&lt;/a&gt; to provide scoping of loaded assemblies providing additional safety and reliability characteristics (in the abscence of AppDomains).&lt;/p&gt;
&lt;p&gt;A &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition/tree/master/samples"&gt;&lt;code&gt;GenericHostConsole&lt;/code&gt; sample project&lt;/a&gt; was written to show the library's use and demonstrate it's functionality which worked beautifully. From the host project, all that was required to provide runtime composition was a call to the &lt;code&gt;.UseComposition&lt;/code&gt; extension method and some associated configuration (I decided to use a &lt;a href="https://www.nuget.org/packages/NetEscapades.Configuration.Yaml"&gt;Yaml&lt;/a&gt; file but any &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-3.0"&gt;configuration provider&lt;/a&gt; could be used) as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;private static async Task Main(string[] args)
{
    var builder = Host.CreateDefaultBuilder(args)
        .ConfigureHostConfiguration(configurationBuilder =&amp;gt; configurationBuilder.AddCommandLine(args))
        .UseComposition(config =&amp;gt; config.AddYamlFile(args[0]), &amp;quot;composition&amp;quot;);

    await builder
        .Build()
        .RunAsync();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;composition:
  modules:
    - name: ConsoleWriter
      assembly: GenericHostConsole.Writer
      configurationSection: consolewriterConfiguration
      optional: true

consolewriterConfiguration:
  writeIntervalInSeconds: 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then additional assemblies could be provided (in this case &lt;code&gt;GenericHostConsole.Writer&lt;/code&gt;) which simply needed to implement the &lt;code&gt;IModule&lt;/code&gt; interface as shown here:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;public class Module : IModule
{
    public IHostBuilder Configure(IHostBuilder hostbuilder, string configurationSection)
    {
        return hostbuilder
            .ConfigureServices(
                (hostBuilderContext, serviceCollection) =&amp;gt;
                {
                    serviceCollection.AddOptions&amp;lt;Configuration&amp;gt;().Bind(hostBuilderContext.Configuration.GetSection(configurationSection));
                    serviceCollection.AddSingleton&amp;lt;IHostedService, Service&amp;gt;();
                })
            .ConfigureLogging((hostingContext, logging) =&amp;gt; logging.AddConsole());
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After compiling, copying the &lt;code&gt;GenericHostConsole.Writer&lt;/code&gt; assembly to the &lt;code&gt;GenericHostConsole&lt;/code&gt; project and running the latter's executable, the &lt;code&gt;GenericHostConsole.Writer.Service&lt;/code&gt; wrote to the console every two seconds, as configured.&lt;/p&gt;
&lt;h1 id="boom-done.well.sort-of"&gt;Boom! Done... well... sort of.&lt;/h1&gt;
&lt;p&gt;I returned to the project I required this for and followed the above pattern, expecting (ok, somewhat naively) everything to be rosy. &lt;em&gt;It failed spectacularly&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;You see, while my sample project for Cogenity.Extensions.Hosting.Composition, simply augmented the host by adding a new service with no other dependencies, the original project required new services to interact with core functionality provided by the project, mainly by injection of services defined in a 'common' assembly (i.e. one referenced both by the host project and the composition modules). Starting the project resulting in the DI container reporting that it couldn't locate implementations of required services despite those services being registered with the host's DI container (by throwing a &lt;code&gt;System.InvalidOperationException: Unable to resolve service for type '&amp;lt;service&amp;gt;' while attempting to activate '&amp;lt;consumer&amp;gt;')&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;It turned out that I was being bitten by the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Due to the requirement of needing to allow additional modules to participate in host composition, assemblies were being loaded at composition, not build time as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;var builder = Host.CreateDefaultBuilder(args)
    .ConfigureHostConfiguration(configurationBuilder =&amp;gt; configurationBuilder.AddCommandLine(args))
    .UseComposition(config =&amp;gt; config.AddYamlFile(args[0]), &amp;quot;composition&amp;quot;); // &amp;lt;- Assemblies loaded here
    .ConfigureServices(, serviceCollection) =&amp;gt; serviceCollection.AddSingleton&amp;lt;IEventBus, EventBus&amp;gt;())

await builder
    .Build() // &amp;lt;- Not here
    .RunAsync();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This meant that the &lt;code&gt;AssemblyLoadContext&lt;/code&gt; used to isolate module assemblies was loading new instances of 'common' assemblies rather than using the ones being registered by the host service (i.e. the IEventBus in the above example), thereby explaining why the various implementations couldn't be found.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="so-what-now"&gt;So what now?&lt;/h1&gt;
&lt;p&gt;Well, it can be used as-is for basic composition functionality, but it's really not what I need moving forward.&lt;/p&gt;
&lt;p&gt;I have considered several possible solutions ranging from simply removing assembly isolation (and no-longer providing the 'nice-to-haves') to working more intimately with the &lt;code&gt;HostBuilder.Build&lt;/code&gt; process to ensure shared assemblies are fully loaded prior to loading additional assemblies for composition. Each of the approaches have pros and cons which I am trying to consider from a 'general consumer' point of view before deciding on the solution to adopt.&lt;/p&gt;
&lt;p&gt;To this end, I have &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition/issues/5"&gt;created an issue&lt;/a&gt; in the Github repository for this project in which I describe what I see as the various ways forward and, where possible, links to branches proving out the various approaches. I've labelled it as 'discussion' and would genuinely be interested to hear people's thoughts. If this project is of interest to you and/or you have suggestions about how best to resolve the above issues, please feel free to add a comment with your suggestions and/or requests for modified/additional functionality.&lt;/p&gt;
&lt;p&gt;If you require runtime composition for projects utilizing the .NET Core Generic Host then watch this space as I hope to have a more versatile solution in place within the next week or so.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Building .NET Core 3.0 With Azure Pipelines</title>
			<link>http://ian.bebbs.co.uk/posts/BuildingDotNetCore3WithAzurePipelines</link>
			<description>&lt;p&gt;My "go to" build system and package repository - &lt;a href="https://www.myget.org/"&gt;MyGet&lt;/a&gt; - doesn't yet support building .NET Core 3.0 (or more specifically .NET Standard 2.1) projects. Having recently read about some of the features Microsoft have been adding to Azure DevOps I thought I'd see how easy (or not) it was to get a Pipeline setup to build my project and publish the package back to MyGet.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/BuildingDotNetCore3WithAzurePipelines</guid>
			<pubDate>Fri, 04 Oct 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;My &amp;quot;go to&amp;quot; build system and package repository - &lt;a href="https://www.myget.org/"&gt;MyGet&lt;/a&gt; - doesn't yet support building .NET Core 3.0 (or more specifically .NET Standard 2.1) projects. Having recently read about some of the features Microsoft have been adding to Azure DevOps I thought I'd see how easy (or not) it was to get a Pipeline setup to build my project and publish the package back to MyGet.&lt;/p&gt;
&lt;h2 id="you-need-what"&gt;You need what?!?&lt;/h2&gt;
&lt;p&gt;Azure DevOps is very welcoming and it takes almost no time to set up your organisation and project... all for free no less! Unfortunately, when I then started creating a new build pipeline and selected GitHub in answer to the &amp;quot;Where is your code?&amp;quot; prompt, I was presented with this OAuth request:&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/YouNeedWhatNow.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="You need what now?"&gt;
&lt;p&gt;Yup. In order to build a single, public repository from my GitHub account, I needed to let Azure have access to &lt;em&gt;everything&lt;/em&gt;; public &lt;em&gt;and&lt;/em&gt; private. How about &amp;quot;No&amp;quot;.&lt;/p&gt;
&lt;h2 id="ahh-classic"&gt;Ahh, classic!&lt;/h2&gt;
&lt;p&gt;Fortunately, Azure provides a second means of creating a pipeline - ostensibly, but not necessarily, without Yaml - through the use of a small &amp;quot;Use the classic editor&amp;quot; hyperlink below the main options.&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/UseTheClassicEditor.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Guess I'll be using this then"&gt;
&lt;p&gt;When you do this, you're once again asked to &amp;quot;Select a source&amp;quot; and authenticate with that source as shown below. This time however, you're able to &amp;quot;Authorize with a GitHub personal access token&amp;quot;.&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/GitHubPersonalAccessToken.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="GitHub Personal Access Token"&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Note: it may be possible to use a &amp;quot;personal access token&amp;quot;&amp;quot; with the new &amp;quot;Where is your code?&amp;quot; editor. Unfortunately, I wasn't able to confirm this as I seemed to be stuck in a OAuth loop wherein, each time I click &amp;quot;GitHub&amp;quot;, it no longer asks me to log in but immediately prompts me to &amp;quot;Authorize Azure Pipelines&amp;quot; with all the privileges shown above. As there's no &amp;quot;Cancel&amp;quot; button, my only recourse is to use the browser's back button which doesn't seem to cancel the OAuth flow. ¯\&lt;em&gt;(ツ)&lt;/em&gt;/¯&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I then quickly nipped over to GitHub and created a personal access token (Settings-&amp;gt;Developer settings-&amp;gt;Personal access tokens) which only has access to &lt;em&gt;public&lt;/em&gt; repositories, web-hook settings and basic user information as shown below:&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/NewPersonalAccessToken.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="New Personal Access Token"&gt;
&lt;p&gt;Clicking &amp;quot;Generate token&amp;quot; provided me with a token which I copy/pasted into Azure pipelines. I was then able to select the repository I wanted to build from a list of only my public repositories. Ace!&lt;/p&gt;
&lt;h2 id="yet-still-with-yaml"&gt;Yet still with Yaml!&lt;/h2&gt;
&lt;p&gt;I was then asked to &amp;quot;Select a template&amp;quot;. At this point, I could elect to use a Yaml file (per the &amp;quot;new editor&amp;quot;) as shown below:&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/SelectATemplate.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Select A Token"&gt;
&lt;p&gt;This seemed to be exactly what I wanted until I realised that this path doesn't actually create a Yaml build template for you but instead expects find one in the repository.&lt;/p&gt;
&lt;p&gt;As I hadn't written an Azure Pipelines Yaml file before, the idea of creating one from scratch was a little daunting. I therefore decided to cheat. I copied the repository from GitHub to Azure DevOps Repos and recreated a build pipeline using the new &amp;quot;Where is your code?&amp;quot; editor. I then copied the Yaml file this produced into my GitHub repository and continued building this pipeline.&lt;/p&gt;
&lt;p&gt;So here's the template &lt;code&gt;azure-pipelines.yml&lt;/code&gt; file I ended up with:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;# ASP.NET Core (.NET Framework)
# Build and test ASP.NET Core projects targeting the full .NET Framework.
# Add steps that publish symbols, save build artifacts, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/dotnet-core

trigger:
- master

pool:
  vmImage: 'windows-latest'

variables:
  solution: '**/*.sln'
  buildPlatform: 'Any CPU'
  buildConfiguration: 'Release'

steps:
- task: NuGetToolInstaller&amp;#64;1

- task: NuGetCommand&amp;#64;2
  inputs:
    restoreSolution: '$(solution)'

- task: VSBuild&amp;#64;1
  inputs:
    solution: '$(solution)'
    msbuildArgs: '/p:DeployOnBuild=true /p:WebPublishMethod=Package /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true /p:DesktopBuildPackageLocation=&amp;quot;$(build.artifactStagingDirectory)\WebApp.zip&amp;quot; /p:DeployIisAppPath=&amp;quot;Default Web Site&amp;quot;'
    platform: '$(buildPlatform)'
    configuration: '$(buildConfiguration)'

- task: VSTest&amp;#64;2
  inputs:
    platform: '$(buildPlatform)'
    configuration: '$(buildConfiguration)'
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="its-good-but-its-not-right"&gt;It's good but it's not right&lt;/h2&gt;
&lt;p&gt;Not a bad start but this template was designed to &amp;quot;Build and test ASP.NET Core projects targeting the full .NET Framework.&amp;quot;. I wasn't targeting the full .NET Framework so I &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/?view=azure-devops"&gt;hit the books&lt;/a&gt; and quickly found a section on the &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/dotnet-core?view=azure-devops"&gt;.NET Core Ecosystem&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The information here allowed me to move from &lt;code&gt;VSBuild&lt;/code&gt; based tasks to &lt;code&gt;dotnet&lt;/code&gt; based scripts. Moving to using Ubuntu for the build, only including build steps and removing everything else resulted in this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;trigger:
- master

pool:
  vmImage: 'ubuntu-16.04'

variables:
  solution: '**/*.sln'
  buildPlatform: 'Any CPU'
  buildConfiguration: 'Release'
  version: 1.0.1

steps:
- script: dotnet restore
- script: dotnet build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tentatively, I enqueued a build which resulted in...&lt;/p&gt;
&lt;h2 id="a-spectacular-failure"&gt;A spectacular failure&lt;/h2&gt;
&lt;p&gt;It didn't take long to find the cause of the failure. Digging into the build logs showed the following failure for one of the script steps:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;&amp;quot;The current .NET SDK does not support targeting .NET Standard 2.1.  Either target .NET Standard 2.0 or lower, or use a version of the .NET SDK that supports .NET Standard 2.1.&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&amp;quot;Oh, exactly the same error as Myget&amp;quot; I thought. Fortunately, from perusing the documentation earlier, I had come across the section on &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/dotnet-core?view=azure-devops#build-environment"&gt;&amp;quot;Build Environment&amp;quot;&lt;/a&gt; and the fact that the Microsoft-hosted build agents don't provide all versions of the .NET Core SDK. They do however provide a very simple means of installing additional frameworks by simply adding a &amp;quot;DotNetCoreInstaller&amp;quot; task to your Yaml. I figured it couldn't hurt to try and amended my 'azure-pipelines.yml` to this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;trigger:
- master

pool:
  vmImage: 'ubuntu-16.04'

variables:
  solution: '**/*.sln'
  buildPlatform: 'Any CPU'
  buildConfiguration: 'Release'
  version: 1.0.1

steps:
- task: UseDotNet&amp;#64;2
  displayName: 'Use .NET Core sdk'
  inputs:
    packageType: sdk
    version: 3.x
    installationPath: $(Agent.ToolsDirectory)/dotnet
- script: dotnet restore
- script: dotnet build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And, somewhat amazingly, it worked.&lt;/p&gt;
&lt;h2 id="move-em-on-head-em-up"&gt;Move 'em on, head 'em up!&lt;/h2&gt;
&lt;p&gt;With a successful build running, all that was left was to package the built assembly into a nuget package and push it to MyGet. From prior reading I knew that the first thing I had to do here was add a &amp;quot;Service Connection&amp;quot; to the project from the settings. Which.... are.... where???&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/ProjectSettings.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Project Settings"&gt;
&lt;p&gt;Ah, here they are! Of course! Hidden until you [accidentally] move your mouse over project header bar. (!?!)&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/AhHereTheyAre.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Ah Here They Are!"&gt;
&lt;p&gt;Weird.&lt;/p&gt;
&lt;p&gt;Anyway, having finally found the project settings I was able to add a new &amp;quot;Nuget&amp;quot; connection (from &amp;quot;Pipelines-&amp;gt;Service connections&amp;quot;) which I populated with details provided by MyGet. I then populated the package settings within my library's &lt;code&gt;.csproj&lt;/code&gt; file and enabled the &amp;quot;Generate Nuget package on build&amp;quot; setting. With this all done, I simply needed 'push' the package as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;trigger:
- master

pool:
  vmImage: 'ubuntu-16.04'

variables:
  solution: '**/*.sln'
  buildPlatform: 'Any CPU'
  buildConfiguration: 'Release'
  version: 1.0.1

steps:
- task: UseDotNet&amp;#64;2
  displayName: 'Use .NET Core sdk'
  inputs:
    packageType: sdk
    version: 3.x
    installationPath: $(Agent.ToolsDirectory)/dotnet
- script: dotnet restore
- script: dotnet build
- task: NuGetCommand&amp;#64;2
  inputs:
    command: push
    nuGetFeedType: external
    packagesToPush: '$(Build.Repository.LocalPath)/**/*.nupkg;!$(Build.Repository.LocalPath)/**/*.symbols.nupkg'
    publishFeedCredentials: 'MyGet Bebbs Feed'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the compiled package appeared in my MyGet repository. Boom!&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I am very impressed with Azure pipelines. The tools they've made available in their Yaml based build system are fantastic and make building a project easy and clean yet flexible and powerful. Furthermore, the actual build process is very fast. From git push to package in my nuget repository took less than a minute. Yes, it's just a small library without any tests (for now), but each build required installing a new version of the .NET Core SDK onto the build agent and, even though this was all hosted on the Free tier, I never had to wait for a build agent to become available.&lt;/p&gt;
&lt;p&gt;If they could just tighten up the OAuth permission requested from GitHub I'd be very tempted to adopt Azure DevOps for all my projects. I'd certainly consider recommending it to clients should they be looking to move away from other CI/CD solutions.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Using A Touch Overlay, In Portrait, On Raspbian Buster</title>
			<link>http://ian.bebbs.co.uk/posts/UsingATouchOverlayInPortrainOnRaspbian</link>
			<description>&lt;p&gt;This is just a short post - mostly for my own benefit - on how to use a touch-overlay, in portrait, on Raspbian Buster&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/UsingATouchOverlayInPortrainOnRaspbian</guid>
			<pubDate>Thu, 03 Oct 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;This is just a short post - mostly for my own benefit - on how to use a touch-overlay, in portrait, on Raspbian Buster&lt;/p&gt;
&lt;p&gt;These instructions are for using a standard HDMI monitor (I'm using a Samsung ME46B) and USB Touchscreen overlay (I'm using a Samsung TM46LBC) in a &lt;code&gt;right&lt;/code&gt; portrait (i.e rotated 270° clockwise) configuration. They probably won't work for hat/phat style LCDs with built-in touch-panels.&lt;/p&gt;
&lt;h2 id="changing-to-portrait"&gt;Changing to portrait&lt;/h2&gt;
&lt;p&gt;Raspbian Buster has moved to the 'G2 GL (Fake KMS) OpenGL desktop driver with fake KMS' OpenGL driver by default (&lt;code&gt;dtoverlay=vc4-fkms-v3d&lt;/code&gt; in &lt;code&gt;/boot/config.txt&lt;/code&gt;). Fortunately, as they moved to the 'fake' driver, you're still given significant control over the display configuration from &lt;code&gt;/boot/config.txt&lt;/code&gt; and changing the display orientation remains unchanged.&lt;/p&gt;
&lt;p&gt;As such, use the command &lt;code&gt;sudo nano /boot/config.txt&lt;/code&gt; to start editing the file and add the following lines at the bottom (uncommenting the appropriate line):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# display_rotate=1 # rotate 90° clockwise
# display_rotate=2 # rotate 180° clockwise
display_rotate=3 # rotate 270° clockwise
avoid_warnings=1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reboot the Pi (&lt;code&gt;sudo reboot&lt;/code&gt;) and you should see that the display is now in the correct orientation.&lt;/p&gt;
&lt;h2 id="correcting-overscan"&gt;Correcting Overscan&lt;/h2&gt;
&lt;p&gt;Before moving onto installing/calibrating the touch-panel, it is well worth spending some time correcting the Overscan on your display. To do this, again edit &lt;code&gt;config.txt&lt;/code&gt; and find lines similar to below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# uncomment this if your display has a black border of unused pixels visible
# and your display can output without overscan
disable_overscan=0

# uncomment the following to adjust overscan. Use positive numbers if console
# goes off screen, and negative if there is too much border
overscan_left=-10
overscan_right=-10
overscan_top=8
overscan_bottom=8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The values you see above are those required to make my panel display correctly (nothing off-screen, no big borders). If you need to change overscan you'll need to find the values that work for you by changing values and rebooting to see the effect.&lt;/p&gt;
&lt;h2 id="calibrating-the-touch-panel"&gt;Calibrating the Touch-Panel&lt;/h2&gt;
&lt;p&gt;While the touch panel I am using was correctly identified as a 'Nexio Touch Device' by &lt;code&gt;xinput --list&lt;/code&gt; getting it to respect the display orientation and calibrating it correctly turned out to be a pain. After &lt;em&gt;a lot&lt;/em&gt; of searching I finally found &lt;a href="https://www.instructables.com/id/Rotate-Raspberry-Pi-Display-and-Touchscreen/"&gt;two&lt;/a&gt; &lt;a href="https://www.raspberrypi.org/forums/viewtopic.php?t=179477#p1163460"&gt;posts&lt;/a&gt; which, when combined, got the touch panel working correctly.&lt;/p&gt;
&lt;p&gt;Firstly, you'll need to install the &lt;code&gt;evdev&lt;/code&gt; driver and the &lt;code&gt;xinput_calibrator&lt;/code&gt; using the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install xserver-xorg-input-evdev xinput_calibrator
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next locate the touch-panel display configuration file as described in this &lt;a href="https://www.instructables.com/id/Rotate-Raspberry-Pi-Display-and-Touchscreen/"&gt;instructable&lt;/a&gt;; mine was &lt;code&gt;/usr/share/X11/xorg.conf.d/40-libinput.conf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In this file, find the &lt;code&gt;InputClass&lt;/code&gt; Section which includes the Identifier &lt;code&gt;libinput touchscreen catchall&lt;/code&gt;. In this section, change the &lt;code&gt;Driver&lt;/code&gt; value from &lt;code&gt;libinput&lt;/code&gt; to &lt;code&gt;evdev&lt;/code&gt; and add a &lt;code&gt;TransformationMatrix&lt;/code&gt; option to reflect to display orientation as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Section &amp;quot;InputClass&amp;quot;
        Identifier &amp;quot;libinput touchscreen catchall&amp;quot;
        MatchIsTouchscreen &amp;quot;on&amp;quot;
        MatchDevicePath &amp;quot;/dev/input/event*&amp;quot;
        Driver &amp;quot;evdev&amp;quot; # &amp;lt;- change this
        Option &amp;quot;TransformationMatrix&amp;quot; &amp;quot;0 1 0 -1 0 1 0 0 1&amp;quot; # &amp;lt;- Add this
EndSection
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The exact transformation matrix you need is available in the instructable but I've repeated them here for easy reference:&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Angle&lt;/th&gt;
&lt;th&gt;Transformation Matrix&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;90°&lt;/td&gt;
&lt;td&gt;&amp;quot;0 -1 1 1 0 0 0 0 1&amp;quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;180°&lt;/td&gt;
&lt;td&gt;&amp;quot;-1 0 1 0 -1 1 0 0 1&amp;quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;270°&lt;/td&gt;
&lt;td&gt;&amp;quot;0 1 0 -1 0 1 0 0 1&amp;quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now, if you restart your Pi you should notice that the touch panel is at least in the correct orientation (mouse cursor moves in the same direction as your finger). To calibrate it such that the mouse cursor moves to exactly where you touch, use the &lt;code&gt;xinput_calibrator&lt;/code&gt; tool by running it from the Terminal window in a desktop session.&lt;/p&gt;
&lt;p&gt;Follow the instructions and &lt;code&gt;input_calibrator&lt;/code&gt; will do two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Correctly calibrate the display - the mouse cursor should now be under your touch; and&lt;/li&gt;
&lt;li&gt;Give you a block of text to add to persistent configuration as shown below:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;Calibrating EVDEV driver for &amp;quot;Nexio Touch Device(HS) Nexio HID Multi-Touch ATI0460-06 &amp;quot; id=7
	current calibration values (from XInput): min_x=15929, max_x=149 and min_y=16328, max_y=171

Doing dynamic recalibration:
	Setting calibration data: 15872, 0, 16498, -69
	--&amp;gt; Making the calibration permanent &amp;lt;--
  copy the snippet below into '/etc/X11/xorg.conf.d/99-calibration.conf' (/usr/share/X11/xorg.conf.d/ in some distro's)
Section &amp;quot;InputClass&amp;quot;
	Identifier	&amp;quot;calibration&amp;quot;
	MatchProduct	&amp;quot;Nexio Touch Device(HS) Nexio HID Multi-Touch ATI0460-06 &amp;quot;
	Option	&amp;quot;Calibration&amp;quot;	&amp;quot;15872 0 16498 -69&amp;quot;
	Option	&amp;quot;SwapAxes&amp;quot;	&amp;quot;0&amp;quot;
EndSection
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Follow the instructions it provides by copying the region from &lt;code&gt;Section &amp;quot;InputClass&amp;quot;&lt;/code&gt; down to &lt;code&gt;EndSection&lt;/code&gt; then using the following command to create (or edit) the persistent configuration file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo nano /usr/share/X11/xorg.conf.d/99-calibration.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Paste the block of text you copied earlier, save and exit, then reboot.&lt;/p&gt;
&lt;p&gt;Voila, a perfectly configured touch overlay. Enjoy!&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Tech Adventures in Sustainability</title>
			<link>http://ian.bebbs.co.uk/posts/TechAdventuresInSustainability-PartI</link>
			<description>&lt;p&gt;Installing solar panels and monitoring solar production not only provides immediate benefits in sustainable living but also highlights new, simple ways to change your lifestyle to further save money and energy. Here's how we do it.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/TechAdventuresInSustainability-PartI</guid>
			<pubDate>Thu, 26 Sep 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="tldr"&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;Installing solar panels and monitoring solar production not only provides immediate benefits in sustainable living but also highlights new, simple ways to change your lifestyle to further save money and energy. Here's how we do it.&lt;/p&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;As with most people nowadays, the environment and climate change is weighing heavily on my thoughts. As such, my partner and I have been looking into ways we can make our lifestyle more sustainable. Being in tech, I have chosen to &amp;quot;use what I know&amp;quot; to enable or facilitate changes to our lifestyle that promote sustainability without compromising on quality of living or requiring unnecessarily onerous daily chores.&lt;/p&gt;
&lt;p&gt;In this series of blog posts, I will be describing the decisions, approaches, tools and devices we've employed since starting down this road. Where possible, I will share as much of the tech as possible so others can adopt or adapt similar practises and, hopefully, enhance the sustainability of their lifestyle too.&lt;/p&gt;
&lt;h2 id="solar-power"&gt;Solar Power&lt;/h2&gt;
&lt;p&gt;Our first - and possibly most significant - step towards a more sustainable lifestyle has been to install solar panels. Until recently, installing solar panels on a domestic property in the UK has been a questionable value proposition due to the return on investment sometimes being longer than the lifetime of the panels/inverter. The UK government went someway to alleviating this issue with &lt;a href="https://www.gov.uk/feed-in-tariffs"&gt;Feed-in Tarrifs (FiT)&lt;/a&gt; but still repayment times tended to be longer than the warranty period of many of the components in the installation.&lt;/p&gt;
&lt;p&gt;Nowadays, the drop in costs and improved efficiency of solar panels coupled with improved and more robust technology in other components (particularly the inverter) mean that, despite the UK government ending the FIT program, a solar installation can easily provide a return on investment within the warrantied lifetime it's components.&lt;/p&gt;
&lt;p&gt;And so it was that, when we moved into our new house, we set aside money to install solar panels. After a lot of research into the underlying technologies, comparing features provided by various manufactures and talking to a number of solar installation specialists, we chose a local company to install a 6.18kWp system comprising of &lt;a href="http://www.jasolar.com/html/en/"&gt;JA Solar&lt;/a&gt; panels and a &lt;a href="http://www.jasolar.com/html/en/"&gt;SolarEdge&lt;/a&gt; inverter.&lt;/p&gt;
&lt;h2 id="monitoring-solar-production"&gt;Monitoring Solar Production&lt;/h2&gt;
&lt;p&gt;While JA Solar was chosen simply due to it's price/performance ratio, we were especially keen to install a SolarEdge system due to it's ability to be monitored in multiple ways.&lt;/p&gt;
&lt;p&gt;First up, SolarEdge provides an excellent cloud-based monitoring platform with both web and native apps compatible with major platforms. Furthermore SolarEdge provide a &lt;a href="https://www.solaredge.com/sites/default/files/se_monitoring_api.pdf"&gt;RESTful API&lt;/a&gt; facilitating automated data collection and monitoring. Unfortunately the cloud-based apps/API require that all data collection (and a significant amount of inverter control) is delegated to SolarEdge servers (with all the &lt;a href="https://horusscenario.com/what-is-the-horus-scenario/"&gt;privacy and security considerations&lt;/a&gt; that implies) and are then subject to usage-restrictions, request limits and significant latency.&lt;/p&gt;
&lt;p&gt;Fortunately, the SolarEdge inverter also provides numerous means of &lt;a href="https://www.solaredge.com/sites/default/files/solaredge-communication_options_application_note_v2_250_and_above.pdf"&gt;local data collection and control&lt;/a&gt;. The most powerful of these means is the onboard RS-485 connector which allows full control over the inverter and the ability to collect virtually all data generated by the unit. The github user &lt;a href="https://github.com/jbuehl"&gt;'jbuehl'&lt;/a&gt; has by-far the most accomplished open-source code available for interacting with this interface in his &lt;a href="https://github.com/jbuehl/solaredge"&gt;'solaredge'&lt;/a&gt; repository. Unfortunately, while it is the most powerful, it is also the most difficult means of recording data from the inverter, requiring the user to open the inverter and wire up to the RS-485 connector directly.&lt;/p&gt;
&lt;p&gt;However, if you don't require control over the inverter and merely want to record the data being generated, there is a much easier means: &lt;a href="https://www.solaredge.com/sites/default/files/sunspec-implementation-technical-note.pdf"&gt;ModBus over TCP&lt;/a&gt;. While this does require a setting to be enabled on the inverter (a completely trivial series of button presses), connection is made via standard TCP/IP on port 502.&lt;/p&gt;
&lt;h2 id="solaredge.monitor"&gt;SolarEdge.Monitor&lt;/h2&gt;
&lt;p&gt;While there were &lt;a href="https://github.com/search?q=solaredge"&gt;numerous repositories on Github&lt;/a&gt; for interacting with SolarEdge inverters, there didn't seem to be any that met all my requirements. Specifically, I wanted a solution that could be easily deployed to a variety of target platforms, which could read all available inverter parameters and publish these parameters to an MQTT broker (for consumption by other services) at a configurable interval.&lt;/p&gt;
&lt;p&gt;I therefore wrote &lt;a href="https://github.com/ibebbs/SolarEdge.Monitor"&gt;SolarEdge.Monitor&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This project was a lot of fun and utilised the following technologies and techniques:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dotnet/core"&gt;.NET Core 2.2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; (and &lt;a href="https://www.docker.com/products/docker-hub"&gt;Docker Hub&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/xamarin/mqtt"&gt;MQTT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rossmann-engineering/EasyModbusTCP.NET"&gt;ModBus over TCP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.0&amp;amp;tabs=visual-studio"&gt;Background tasks with hosted services in ASP.NET Core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-3.0"&gt;The .NET Core Options pattern for configuration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ian.bebbs.co.uk/posts/FluentNamespacing"&gt;Fluent Namespacing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ian.bebbs.co.uk/posts/ReactiveStateMachines"&gt;Reactive State Machines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While it can be cloned and run locally, it's real value comes when used as a containerized application as part of a composed solution.&lt;/p&gt;
&lt;h2 id="docker-docker-compose"&gt;Docker &amp;amp; Docker Compose&lt;/h2&gt;
&lt;p&gt;SolarEdge.Monitor is available as a Linux container image from &lt;a href="https://hub.docker.com/r/ibebbs/solaredge.monitor"&gt;Docker Hub&lt;/a&gt;. It can therefore be run from any docker host (anything from a RaspberryPi to Windows Server) by simply issuing the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker pull ibebbs/solaredge.monitor
docker run [environment variables] ibebbs/solaredge.monitor
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The various environment variables are (or will be shortly) fully documented on Docker Hub but here are a simple set that will get the service running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Solaredge:Monitor:Inverter:Address=[IP Address of the Inverter]
Solaredge:Monitor:MQTT:Address=[IP Address of the MQTT broker]
Solaredge:Monitor:Service:ModelsToRead=inverter
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running with these settings will poll the inverter every 10 seconds and publish a JSON serialized message containing data read from the inverter to the MQTT broker on a topic named &lt;code&gt;home/solar/inverter&lt;/code&gt;. This can be consumed by any MQTT client for further processing.&lt;/p&gt;
&lt;p&gt;To provide data persistence, aggregation and visualization, I use docker-compose to supplement SolarEdge.Monitor with other services such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://nodered.org/"&gt;Node-Red&lt;/a&gt; - for receiving MQTT messages and reshaping them into metrics for submission to...&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.influxdata.com/"&gt;InfluxDB&lt;/a&gt; - for persisting the metrics and providing a querying back-end to...&lt;/li&gt;
&lt;li&gt;&lt;a href="https://grafana.com/"&gt;Grafana&lt;/a&gt; - for visualizing persisted data and extracting insights&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here's an example &lt;code&gt;docker-compose.yml&lt;/code&gt; that, while requiring some substitution of environment variables, provides most of the ground work for getting these services running together (I'm afraid I don't yet have the customised Node-Red image or flows hosted in a public repository, but I hope to have this available soon):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: &amp;quot;3.2&amp;quot;

services:
  # https://hub.docker.com/_/eclipse-mosquitto
  mqtt:
    image: eclipse-mosquitto
    ports:
      - &amp;quot;1883:1883&amp;quot;
      - &amp;quot;9001:9001&amp;quot;

  # https://hub.docker.com/r/nodered/node-red-docker/
  nodered:
    build: ./nodered
    ports:
      - &amp;quot;1880:1880&amp;quot;
    volumes:
      - type: volume
        source: nodered
        target: /data
        volume:
          nocopy: true
    depends_on:
      - &amp;quot;mqtt&amp;quot;

  # https://hub.docker.com/_/influxdb
  influxdb:
    image: influxdb
    ports:
      - &amp;quot;8086:8086&amp;quot;
    environment:
    - INFLUXDB_DB=SmartHome
    - INFLUXDB_HTTP_AUTH_ENABLED
    - INFLUXDB_ADMIN_USER=InfluxAdmin
    - INFLUXDB_ADMIN_PASSWORD=[Admin password]
    - INFLUXDB_USER=InfluxUser
    - INFLUXDB_USER_PASSWORD=[User password]
    volumes:
      - type: volume
        source: influxdb
        target: /var/lib/influxdb
        volume:
          nocopy: true

  # https://hub.docker.com/r/grafana/grafana
  grafana:
    image: grafana/grafana
    ports:
      - &amp;quot;3000:3000&amp;quot;
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=[Admin password to set for Grafana]
      - GF_PANELS_DISABLE_SANITIZE_HTML=true
    depends_on:
      - influxdb
    volumes:
      - type: volume
        source: grafana
        target: /var/lib/grafana
        volume:
          nocopy: true

  # https://hub.docker.com/r/ibebbs/solaredge.monitor
  solaredgemonitor:
    image: ibebbs/solaredge.monitor
    environment:
      - Solaredge:Monitor:Inverter:Address=[Address of SolarEdge Inverter]
      - Solaredge:Monitor:MQTT:Address=mqtt
      - Solaredge:Monitor:MQTT:ClientId=InverterMonitor
      - Solaredge:Monitor:Service:ModelsToRead=inverter
    depends_on:
      - mqtt

volumes:
  nodered:
    driver_opts:
      type: nfs
      o: &amp;quot;addr=192.168.1.11,nolock,soft,rw&amp;quot;
      device: &amp;quot;:/smartHome/nodered&amp;quot;
  influxdb:
    driver_opts:
      type: nfs
      o: &amp;quot;addr=192.168.1.11,nolock,soft,rw&amp;quot;
      device: &amp;quot;:/smartHome/influxdb&amp;quot;
  grafana:
    driver_opts:
      type: nfs
      o: &amp;quot;addr=192.168.1.11,nolock,soft,rw&amp;quot;
      device: &amp;quot;:/smartHome/grafana&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that I use IP-Address protected NFS volume shares for persisting data to a Windows Server. These can be quite tricky to set up but it's the most reliable means I've found of persisting docker volumes with stock docker-compose (i.e. without additional plugins).&lt;/p&gt;
&lt;p&gt;With this file in hand (or, more to the point, on disk), all the services can be started together by simply navigating to the file's location and issuing the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here's a screen capture of my current Grafana dashboard (today hasn't been a great day for solar):&lt;/p&gt;
&lt;img src="../Content/TechAdventuresInSustainability-PartI/GrafanaDashboard.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Grafana Dashboard"&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Being able to quickly and reliably monitor our solar production has drastically changed how we use electricity in the house. For example, the washing machine and (shock, horror!) tumble dryer (sorry, we have kids and therefore too much washing to hang everything out) now get put on only when we have surplus electricity. We've also become super conscious of the multitude of energy zapping devices we have plugged in all over the house which we now endeavour to turn off as often as possible.&lt;/p&gt;
&lt;p&gt;Furthermore, being able to aggregate and analyse this data retrospectively has allowed us to make informed decisions on future sustainability choices like whether to get an electric car or solar battery. Unfortunately neither of these options have yet made the cut, mostly due to RoI considerations.&lt;/p&gt;
&lt;p&gt;In future posts, I'll show some of the ways in which I've used this data and other forms of technology to further promote sustainable living. For now though I would like to conclude by saying that having solar panels installed and being able to see the impact they're having has had a profound effect on our electricity usage and our views on sustainability in general. We feel very good about having made this important step to reducing our carbon foot-print and that, in itself, has provided the motivation to explore more ways to live more sustainably.&lt;/p&gt;
&lt;img src="../Content/TechAdventuresInSustainability-PartI/EnvironmentalBenefits.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Environmental Benefits"&gt;
</content:encoded>
		</item>
		<item>
			<title>Be Brave. Like BAT, man!</title>
			<link>http://ian.bebbs.co.uk/posts/BeBraveLikeBATMan</link>
			<description>&lt;p&gt;Brave is a privacy focused browser with a revolutionary means of supporting content publisher's revenue streams. Here's why you  should &lt;a href="https://brave.com/beb095"&gt;give it a try&lt;/a&gt;, particularly if you maintain a blog or publish open-source software.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/BeBraveLikeBATMan</guid>
			<pubDate>Fri, 06 Sep 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="tldr"&gt;TL;DR&lt;/h1&gt;
&lt;p&gt;Brave is a privacy focused browser with a revolutionary means of supporting content publisher's revenue streams. Here's why you  should &lt;a href="https://brave.com/beb095"&gt;give it a try&lt;/a&gt;, particularly if you maintain a blog or publish open-source software.&lt;/p&gt;
&lt;h2 id="it-all-starts-with-privacy"&gt;It all starts with Privacy&lt;/h2&gt;
&lt;p&gt;As anyone who knows me will tell you, I care deeply about privacy. In fact, should you happen to ask one of these people about my insistence on privacy, they'll give a nod confirmation accompanied by a not so subtle eye-roll of derision. This used to bother me but I've learned the hard way the lesson which Cory Doctorow states so eloquently:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;It’s really hard to get people to care about dangers that are far in the future, especially when the action that puts you in danger and the consequences of that action are separated by an unbridgeable gap of time and space. Privacy disclosures are a public health problem, like smoking. No one puff on a cigarette will definitely give you cancer, but take enough puffs and you’ll virtually guarantee cancer, eventually. No one act of disclosure of personal information will harm you, but once enough disclosures have taken place, over enough time, you’re going to get into serious privacy trouble.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I am that schmuck who actual reads (and, more often than not, is terrified by) the list of permissions installing an app on your phone requires. Therefore, when my beloved Windows Mobile phone was finally - and somewhat forcibly - supplanted by an Android device, my first action was to endeavour to replace all the privacy invading dross that came pre-installed and find more secure alternatives.&lt;/p&gt;
&lt;p&gt;And so it was that I chose &lt;a href="https://brave.com/beb095"&gt;Brave&lt;/a&gt; to replace the stock Chrome browser.&lt;/p&gt;
&lt;h2 id="the-brave-browser"&gt;The Brave Browser&lt;/h2&gt;
&lt;p&gt;Brave is a Chromium based browser focused on user privacy. It's privacy features include the ability to block ads, cross site trackers, cross site cookies and device identification; all features used by nefarious advertising agencies to aggressively profile and target individuals without consent. Moreover, on a mobile device, using Brave saves time, money and battery as adverts and trackers are not downloaded resulting in sites that load quicker, use less data allowance and consume less power.&lt;/p&gt;
&lt;p&gt;It works really well and, to me, is a no brainer. I've yet to find a site that didn't work in Brave or has been otherwise negatively impacted by the removal of adverts/trackers. I would unreservedly recommend that everyone swap Google Chrome for Brave immediately; you won't look back.&lt;/p&gt;
&lt;h2 id="its-a-win-win-but-not-a-win-win-win"&gt;It's a win-win, but not a win-win-win.&lt;/h2&gt;
&lt;p&gt;Of course, there's an issue with blocking adverts: Many content publishers rely on the use of advertising to pay the bills and, by preventing adverts from appearing, you're depriving the sites you visit most of a vital source of revenue.&lt;/p&gt;
&lt;p&gt;Brave's founders were very aware of the web's dependence on the trichotomy of users, content publishers and advertisers when they released their browser. In the years since, they have released and refined various approaches to resolving this issue, finally arriving at the BAT.&lt;/p&gt;
&lt;h2 id="basic-attention-token-bat"&gt;Basic Attention Token (BAT)&lt;/h2&gt;
&lt;p&gt;The Basic Attention Token endeavours to address this issue by providing a means for advertisers to reach users through content publisher's sites while doing so anonymously and providing financial incentives to &lt;em&gt;all the involved parties&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As the old adage goes, a picture is worth a thousand words so here's one worth many times that, direct from the &lt;a href="https://basicattentiontoken.org"&gt;basicattentiontoken.org&lt;/a&gt; website:&lt;/p&gt;
&lt;img src="https://basicattentiontoken.org/wp-content/uploads/2017/03/bat_triad_diagram.png" class="img-responsive" style="margin: auto; width:80%; margin-top: 6px; margin-bottom: 6px;" alt="BAT Triad"&gt;
&lt;p&gt;In short, users are able to support the sites they visit most by being exposed to advertisements that are truly relevant to them, all without compromising privacy. Amazingly the user is even &lt;em&gt;rewarded&lt;/em&gt; for being exposed to these ads and will accumulate BAT (directly tradable against other crypto - and by extension - fiat currencies) in the browser's built-in wallet.&lt;/p&gt;
&lt;h1 id="brave-rewards"&gt;Brave Rewards&lt;/h1&gt;
&lt;p&gt;This really is a revolution in how the modern web operates and is monetized yet, amazingly, it is entirely optional in the Brave Browser.&lt;/p&gt;
&lt;p&gt;It is enabled by opting in to 'Brave Rewards' as shown below:&lt;/p&gt;
&lt;img src="../Content/BeBraveLikeBATman/BraveRewards.jpg" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Brave Rewards Summary"&gt;
&lt;p&gt;I enabled &amp;quot;Brave Rewards&amp;quot; a couple of months back after being prompted by Brave and reading about it in depth. As you can see, just by using the browser as I normal would, without any obvious, annoying or intrusive ads, and despite having 'Auto-Contribute' enabled, I have accumulated ~26 BAT.&lt;/p&gt;
&lt;p&gt;&amp;quot;But that's less than five dollars!&amp;quot; I hear you say. True, but that's five dollars that would otherwise have been in the pockets of the big internet advertising agencies and, as with other crypto currencies, has the possibility to be worth much more should the BAT continue it's current growth. More importantly though, by auto-contributing accrued BAT to the sites I visit most, I have directly supported these sites with (micro) payments in a way I ordinarily would not have been able to do.&lt;/p&gt;
&lt;h2 id="now-get-pay-for-attention"&gt;Now [get] pay [for] attention!&lt;/h2&gt;
&lt;p&gt;All in all, I feel pretty good about my adoption and promotion of BAT. So much so that I recently registered as a &lt;a href="https://publishers.basicattentiontoken.org/"&gt;'Verified Content Creator'&lt;/a&gt; and added both my &lt;a href="ian.bebbs.co.uk"&gt;blog&lt;/a&gt; and my &lt;a href="https://github.com/ibebbs"&gt;github account&lt;/a&gt; as revenue channels. By registering in this way, anyone who uses the Brave browser to read my blog or open-source projects will automatically help support the further creation of these forms of content by contributing BAT.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://publishers.basicattentiontoken.org/"&gt;Brave Rewards Creators program&lt;/a&gt; allows you to accrue BAT through numerous channels including (at the time of writing) web sites, YouTube, Twitch, Twitter, Vimeo, Reddit and Github. If you create content in any of these ways, I very much recommend you register as a verified content creator. Brave maintains historical contributions to creators not currently registered, so you could be in for a windfall of BAT when you do!&lt;/p&gt;
&lt;h2 id="bat-sht-crazy"&gt;BAT-sh*t crazy!&lt;/h2&gt;
&lt;p&gt;More recently I've moved to using Brave as my primary desktop browser too. Initial experiences are that it provides the same excellent browsing characteristics of it's Android cousin but that it's use of system notifications for ad delivery is a little too &amp;quot;in your face&amp;quot;. I'm going to stick with it for a while and see how it goes. If the ads get too much, I'll simply disable &amp;quot;Brave Rewards&amp;quot; on the desktop while continuing to enjoy privacy and speed enhancements delivered by this excellent browser.&lt;/p&gt;
&lt;h2 id="support-me"&gt;Support me&lt;/h2&gt;
&lt;p&gt;If you have had your interest piqued by this post and are now interested in trying out the Brave browser, it would be great if you could use this &lt;a href="https://brave.com/beb095"&gt;referral link&lt;/a&gt; for download. It will net me approximately $5 of BAT via the &lt;a href="https://brave.com/referral-program/"&gt;Brave referral program&lt;/a&gt;. Thanks!&lt;/p&gt;
&lt;h2 id="further-reading"&gt;Further Reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://basicattentiontoken.org/"&gt;Basic Attention Token homepage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arunoda.me/blog/all-about-basic-attention-token"&gt;All about Basic Attention Token (BAT)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://locusmag.com/2016/07/cory-doctorow-peak-indifference/"&gt;Cory Doctorow: Peak Indifference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://batgrowth.com/"&gt;BATGrowth.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded>
		</item>
		<item>
			<title>Ignoring a Billion-Dollar Mistake is simply not an Option</title>
			<link>http://ian.bebbs.co.uk/posts/IgnoringABillionDollarMistakeIsNotAnOption</link>
			<description>&lt;p&gt;In 1965, computer scientist and otherwise all round good egg, Sir Charles Antony Richard Hoare (Tony to most) unleashed the 'null reference' upon an unsuspecting world, simply because it was "so easy". Five decades later, the vast majority of computer programmers remain all too au fait with the "null reference" exception, battling it's seemingly unstoppable encroachment into otherwise flawless program flows.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/IgnoringABillionDollarMistakeIsNotAnOption</guid>
			<pubDate>Thu, 06 Jun 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="a-billion-dollar-mistake"&gt;A 'Billion-Dollar Mistake'?&lt;/h2&gt;
&lt;p&gt;In 1965, computer scientist and otherwise all round good egg, Sir Charles Antony Richard Hoare (Tony to most) unleashed the 'null reference' upon an unsuspecting world, simply because it was &amp;quot;so easy&amp;quot;. Five decades later, the vast majority of computer programmers remain all too au fait with the &amp;quot;null reference&amp;quot; exception, battling it's seemingly unstoppable encroachment into otherwise flawless program flows.&lt;/p&gt;
&lt;p&gt;In 2009, Tony apologised for inventing the null reference, stating:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;I call it my billion-dollar mistake. It was the invention of the null reference in 1965. At that time, I was designing the first comprehensive type system for references in an object oriented language (ALGOL W). My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn't resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&amp;quot;Innumerable errors, vulnerabilities, and system crashes&amp;quot;? How so? Well, in most programming languages, null is not just a valid value for a reference type, it is the &lt;em&gt;default&lt;/em&gt; value. This means that any uninitialized reference type variable will cause a null reference exception if it is dereferenced. Furthermore, because null is the default reference type value, it tends to be the value returned when a process cannot be completed/calculated correctly causing otherwise innocuous dependent code to become inherently error prone. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;string value = ParseValue(); // &amp;lt;= returns null as value cannot be parsed
Console.WriteLine($&amp;quot;Value contains {value.Length} characters&amp;quot;); // &amp;lt;= Boom!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes, we all look at the above code and shrug it off with a &amp;quot;D'uh, of course the value should be null checked&amp;quot;. But why? Why, in a statically typed and run-time checked language should there exist such a simple - and indeed default - means of causing an exception when, by definition, &lt;a href="https://www.google.com/search?q=exceptions+should+be+exceptional"&gt;exceptions should be exceptional&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="c-8.0-to-the-rescue"&gt;C# 8.0 to the rescue?&lt;/h2&gt;
&lt;p&gt;With the rise in prominence of functional languages (particularly F#) which do not suffer this issue (at least by default), the C# community is working to address this mistake with the release of a major new feature in version 8.0 of the language: &lt;a href="https://docs.microsoft.com/en-us/dotnet/csharp/nullable-references"&gt;Nullable reference types&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Firstly, kudos to the community for calling the feature &amp;quot;Nullable reference types&amp;quot; rather than &amp;quot;Non-nullable reference types&amp;quot; inferring that nullability is the &amp;quot;non-default behaviour&amp;quot; you can have if you explicitly want. Unfortunately, the implementation of this feature is, in my opinion, completely hamstrung by backwards compatibility. Specifically:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It will (in it's current guise) only ever cause compiler warnings not errors. Obviously you can enable warnings as errors but this isn't always feasible on large legacy projects.&lt;/li&gt;
&lt;li&gt;It must be specifically enabled at a project level - potentially a large undertaking on legacy projects - or via messy directives in code.&lt;/li&gt;
&lt;li&gt;It can't be applied consistently in all cases or at all in some cases. For example Jon Skeet's IEqualityComparer&lt;T&gt; example &lt;a href="https://codeblog.jonskeet.uk/2018/04/21/first-steps-with-nullable-reference-types/"&gt;here&lt;/a&gt; or the &amp;quot;Generics and nullable types&amp;quot; section of &lt;a href="https://www.infoq.com/articles/csharp-nullable-reference-case-study/"&gt;this InfoQ post&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Mixing code using &amp;quot;null reference types&amp;quot; with class libraries which have not implemented this functionality is likely to be extremely messy in the short to medium term requiring &amp;quot;nullable shims&amp;quot; etc.&lt;/li&gt;
&lt;li&gt;In the majority of cases, it doesn't actually remove the need for null reference checks.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To me the &amp;quot;Nullable reference types&amp;quot; feature feels a bit like the proverbial hammer used to crack a nut. Except that, in this instance, the hammer isn't actually capable of cracking the nut, it is just a vehicle for the label on the side providing instructions on how to get the nut cracked.&lt;/p&gt;
&lt;p&gt;Ok, that's a little facetious. On new or small code-bases, I'm sure utilizing &amp;quot;nullable reference types&amp;quot; will pay dividends and I would support it's use whole-heartedly. But what about large legacy code bases where having to specifically enable &amp;quot;nullable reference types&amp;quot; or enabling &amp;quot;warnings as errors&amp;quot; might not be viable.&lt;/p&gt;
&lt;h2 id="perhaps-theres-another-option"&gt;Perhaps there's another Option?&lt;/h2&gt;
&lt;p&gt;The more astute readers out there have no doubt have seen where this blog post is heading due to my nod to F# above and the not so subtle use of the word Option. As a functional language, F# eschews the use of null (unless specifically enabled on a type by type basis) by explicitly modelling the concept of &amp;quot;nothing-able&amp;quot; with a type: the discriminated union type called Option.&lt;/p&gt;
&lt;p&gt;Here's a description of the Option type from the &lt;a href="https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/discriminated-unions"&gt;FSharp Language Reference&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;The option type is a simple discriminated union in the F# core library. The option type is declared as follows.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-F#"&gt;// The option type is a discriminated union.
type Option&amp;lt;'a&amp;gt; =
    | Some of 'a
    | None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The previous code specifies that the type Option is a discriminated union that has two cases, Some and None. The Some case has an associated value that consists of one anonymous field whose type is represented by the type parameter 'a. The None case has no associated value. Thus the option type specifies a generic type that either has a value of some type or no value.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In short, instead of allowing a value to be null, the value is wrapped inside another object which is able to explicitly say whether the value is something or nothing. While this is an F# concept, it can be mirrored quite simply in C# as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;public struct Option&amp;lt;T&amp;gt;
{
    public static readonly Option&amp;lt;T&amp;gt; None = new Option&amp;lt;T&amp;gt;();

    public static Option&amp;lt;T&amp;gt; Some(T value)
    {
        return new Option&amp;lt;T&amp;gt;(value);
    }

    private Option(T value)
    {
        IsSome = true;
        Value = value;
    }

    public T Value { get; private set; }
    public bool IsSome { get; private set; }
    public bool IsNone =&amp;gt; !IsSome;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that this is a struct (i.e. a value type which cannot be null) but also generic meaning it can hold a reference type value. Using this class we can write code which in which we can be confident that we won't encounter a null reference:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;var option = GetSomeOption();
if (option.IsSome)
{
    Console.WriteLine($&amp;quot;Found a value of {option.Value}&amp;quot;);
}
else
{
    Console.WriteLine(&amp;quot;Did not find a value&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What's that? This code looks exactly like the code for a null reference check? True, except for three important differences:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The use of an Option as the return type indicates to the consumer that &amp;quot;None&amp;quot; is a valid value and must be considered - as opposed to a null which may or may not be deliberate.&lt;/li&gt;
&lt;li&gt;The Value property must be explicitly read from the Option meaning the consumer is less likely to access the property without checking that it 'IsSome' first.&lt;/li&gt;
&lt;li&gt;You can do more with &lt;em&gt;something&lt;/em&gt; than you can with &lt;em&gt;nothing&lt;/em&gt;; read on.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Regarding that last point, once we have something - i.e. an Option type - we can work with it to facilitate it's use in code. For example, consider the following extension methods:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;/// &amp;lt;summary&amp;gt;
/// Projects an &amp;lt;see cref=&amp;quot;Option{T}&amp;quot;/&amp;gt; of &amp;lt;typeparamref name=&amp;quot;TSource&amp;quot;/&amp;gt; to
/// an &amp;lt;see cref=&amp;quot;Option{T}&amp;quot;/&amp;gt; of &amp;lt;typeparamref name=&amp;quot;TDest&amp;quot;/&amp;gt; using the
/// specified &amp;lt;paramref name=&amp;quot;projection&amp;quot;/&amp;gt;
/// &amp;lt;/summary&amp;gt;
public static Option&amp;lt;TDest&amp;gt; Select&amp;lt;TSource, TDest&amp;gt;(this Option&amp;lt;TSource&amp;gt; source, Func&amp;lt;TSource, Option&amp;lt;TDest&amp;gt;&amp;gt; projection)
{
    return source.IsSome ? projection(source.Value) : None&amp;lt;TDest&amp;gt;();
}

/// &amp;lt;summary&amp;gt;
/// If the &amp;lt;see cref=&amp;quot;Option{T}.IsSome&amp;quot;/&amp;gt; returns true for the &amp;lt;see cref=&amp;quot;Option{T}&amp;quot;/&amp;gt; specified in &amp;lt;paramref name=&amp;quot;source&amp;quot;/&amp;gt;
/// then this method will return it's &amp;lt;see cref=&amp;quot;Option{T}.Value&amp;quot;/&amp;gt;, otherwise the value of the &amp;lt;paramref name=&amp;quot;value&amp;quot;/&amp;gt; parameter
/// is returned
/// &amp;lt;/summary&amp;gt;
public static T Coalesce&amp;lt;T&amp;gt;(this Option&amp;lt;T&amp;gt; source, T value)
{
    return source.IsSome ? source.Value : value;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using these we can move away from imperative property checking an adopt a more declarative style:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;var response = GetSomeOption()
    .Select(value =&amp;gt; $&amp;quot;Found a value of {value}&amp;quot;)
    .Coalesce(&amp;quot;Did not find a value&amp;quot;);

Console.WriteLine(response);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The benefits of declarative code vs imperative code will likely be the subject of my next &amp;quot;contentious&amp;quot; blog post. I have repeatedly debated  the various pros and cons of declarative code with co-workers and clients and still believe it's a fundamentally better way of expressing intent while simultaneously and writing &amp;quot;safer&amp;quot; code.&lt;/p&gt;
&lt;p&gt;So anyway, notice anything about the Option type?&lt;/p&gt;
&lt;h2 id="oh-isnt-this-one-of-those.err.gonad-things"&gt;Oh, isn't this one of those... err... gonad things?&lt;/h2&gt;
&lt;p&gt;Monad? Yes. The Option type is, in my opinion, the quintessential monad as, when combined with compositional functions like those shown above, it is able to provide &amp;quot;a design pattern that allows structuring programs generically while automating away boilerplate code needed by the program logic&amp;quot;; i.e. removing all those damn ugly null checks!&lt;/p&gt;
&lt;p&gt;After working with the Option type for a number of years across numerous project's I've accumulated (mostly by plagiarizing F#) a number of monadic functions which can almost eliminate imperative code (at least with respect to null checking). These functions are especially useful for collections as shown (in the somewhat contrived example) below:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;var result = Enumerable
    .Range(1, 100)
    .Select(value =&amp;gt; ReturnSomeIfAValidValueOtherwiseNone(value)) // &amp;lt;= Returns an Option
    .Collect() // &amp;lt;= Do not propagate values of Option.None
    .FirstOption() // &amp;lt;= Take the first value of Option.Some or return Option.None if none exist
    .Select(value =&amp;gt; $&amp;quot;{value} is the first valid value&amp;quot;)
    .Coalesce(&amp;quot;No valid values found&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="ok-so-where-does-this-get-us"&gt;Ok, so where does this get us?&lt;/h2&gt;
&lt;p&gt;Well, looking back and comparing this with &amp;quot;nullable reference types&amp;quot;, I believe explicitly modelling the concept of nothing using the Option type provides many advantages such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You can adopt this approach incrementally - one method at a time if need be - without huge numbers of warnings or messy code directives.&lt;/li&gt;
&lt;li&gt;Explicitly stating that a method can return &amp;quot;nothing&amp;quot; with the Option type is a much more obvious means of expressing intent than a &amp;quot;nullable reference type&amp;quot;.&lt;/li&gt;
&lt;li&gt;You can finally get rid of null reference checks!&lt;/li&gt;
&lt;li&gt;Returning &lt;em&gt;something&lt;/em&gt; rather than &lt;em&gt;nothing&lt;/em&gt; facilitates the adoption of a more declarative programming style.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So there we go. A safe, obvious, easy and, most-importantly, low-cost means of dealing with the &amp;quot;Billion-Dollar Mistake&amp;quot;. Give it a stab and see what you think. As shown above, there's a very low barrier to entry so there's very little to lose.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Fluent Namespacing</title>
			<link>http://ian.bebbs.co.uk/posts/FluentNamespacing</link>
			<description>&lt;p&gt;&lt;em&gt;So, it's been a while since I've blogged. Mostly this has been due to other commitments (family, friends, side projects, etc), working more hours contracting than I would ideally like and generally not having any dead-time (such as when I used to commute). Since my last blog post (over a year ago!!) I've been maintaining an ever increasing list of things I'd like to blog about but haven't found the time. Given it's a new year, I've decided to pick a couple of the more challenging/contentious blog ideas and endeavour to get them written. This is the first and, while not necessarily the most contentious, might take some getting your head around. You have been warned...&lt;/em&gt;&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/FluentNamespacing</guid>
			<pubDate>Thu, 09 May 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;&lt;em&gt;So, it's been a while since I've blogged. Mostly this has been due to other commitments (family, friends, side projects, etc), working more hours contracting than I would ideally like and generally not having any dead-time (such as when I used to commute). Since my last blog post (over a year ago!!) I've been maintaining an ever increasing list of things I'd like to blog about but haven't found the time. Given it's a new year, I've decided to pick a couple of the more challenging/contentious blog ideas and endeavour to get them written. This is the first and, while not necessarily the most contentious, might take some getting your head around. You have been warned...&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There is a convention at the heart of enterprise development and many modern development frameworks which seems to have been blindly adopted by the development community at large. I hope to challenge this convention as I believe changing it can provide many useful benefits in day to day development.&lt;/p&gt;
&lt;p&gt;The convention I'm referring to is the tendency to group classes by &lt;em&gt;functional pattern&lt;/em&gt; rather than &lt;em&gt;functional domain&lt;/em&gt;. What does this mean? Well, to illustrate, lets start a new webapi project:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dotnet new webapi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will end up with a folder structure similar to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$:.
│   appsettings.Development.json
│   appsettings.json
│   FluentNamespacing.csproj
│   Program.cs
│   Startup.cs
│   
├───Controllers
│       ValuesController.cs
│       
└───Properties
        launchSettings.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There, you see it don't you? No? Well, that just shows how ingrained this convention is.&lt;/p&gt;
&lt;p&gt;I'm referring to the &lt;code&gt;ValuesController&lt;/code&gt; class residing a &lt;code&gt;Controllers&lt;/code&gt; folder. What's the problem with that, you ask? Well, lets develop this project a little further and revisit.&lt;/p&gt;
&lt;p&gt;Lets say, after a little &lt;em&gt;conventional&lt;/em&gt; development, we're now here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$:.
│   appsettings.Development.json
│   appsettings.json
│   FluentNamespacing.csproj
│   Program.cs
│   Startup.cs
│               
├───Controllers
│       PersonController.cs
│       
├───Factories
│       PersonFactory.cs
│       
├───Models
│       PersonModel.cs
│               
├───Properties
│       launchSettings.json
│       
└───Repositories
        PersonRepository.cs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our abstract &lt;code&gt;ValuesController&lt;/code&gt; has become a &lt;code&gt;PersonController&lt;/code&gt; as we want to serve instances of the &lt;code&gt;PersonModel&lt;/code&gt;. But wait, where is the &lt;code&gt;PersonModel&lt;/code&gt; class? Ah, of course, in the &lt;code&gt;Models&lt;/code&gt; folder. Ok, we'll add &lt;code&gt;using FluentNamespacing.Models&lt;/code&gt; to the top of the &lt;code&gt;PersonController.cs&lt;/code&gt; and continue.&lt;/p&gt;
&lt;p&gt;Now as is common practice, we might want to abstract our datastore via the &lt;a href="https://martinfowler.com/eaaCatalog/repository.html"&gt;repository pattern&lt;/a&gt; so we dutifully create a &lt;code&gt;Repositories&lt;/code&gt; folder within which we add a &lt;code&gt;PersonRepository&lt;/code&gt; class. We need to use this in the &lt;code&gt;PersonController&lt;/code&gt; so we add another using statement to the file (&lt;code&gt;using FluentNamespacing.Repositories&lt;/code&gt;) bringing the &lt;code&gt;PersonRepository&lt;/code&gt; into scope.&lt;/p&gt;
&lt;p&gt;Finally, when a user uses a POST call to create a new user, the &lt;code&gt;PersonController&lt;/code&gt; should again follow common practise and use the &lt;a href="https://en.wikipedia.org/wiki/Factory_method_pattern"&gt;factory pattern&lt;/a&gt; to create a new &lt;code&gt;PersonModel&lt;/code&gt; which can then be saved via the repository. Again we go round the loop of creating a directory (&lt;code&gt;Factories&lt;/code&gt;), adding a class to it (&lt;code&gt;PersonFactory&lt;/code&gt;) and adding a using to the &lt;code&gt;PersonController.cs&lt;/code&gt; file (&lt;code&gt;using FluentNamespacing.Factories&lt;/code&gt;). Phew.&lt;/p&gt;
&lt;p&gt;Now look at our project. We have almost as many folders as we do classes and the classes related to the &amp;quot;Person&amp;quot; entity are spread across the project. Furthermore, we've had to prefix each of our classes with the  entity (i.e. &lt;code&gt;Person&lt;/code&gt;) it relates to in order to differentiate it from similar classes for other entities (i.e. &lt;code&gt;Job&lt;/code&gt;, &lt;code&gt;Role&lt;/code&gt;, &lt;code&gt;Group&lt;/code&gt;). That's a lot of typing and/or mouse navigation to get basic functionality in place.&lt;/p&gt;
&lt;p&gt;Now consider this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;D:.
│   appsettings.Development.json
│   appsettings.json
│   FluentlyNamespaced.csproj
│   Program.cs
│   Startup.cs
│               
├───Person
│       Controller.cs
│       Factory.cs
│       Model.cs
│       Repository.cs
│       
└───Properties
        launchSettings.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we have exactly the same functionality but grouped by functional domain not functional pattern; i.e. all classes related to a Person are in the same folder. This has resulted in far less structural noise, simplified class names and no need for additional using statements to be added to any of the classes.&lt;/p&gt;
&lt;h3 id="fluent-namespacing"&gt;Fluent Namespacing&lt;/h3&gt;
&lt;p&gt;I have been applying this approach in medium to large enterprise code-bases for some time now and find it provides simplified code, less structural overhead, easier navigation, faster comprehension and improved code architecture. I refer to it as &amp;quot;Fluent Namespacing&amp;quot; because, when you start referring to your classes via the [partial] namespace rather than long class names (requiring additional &lt;code&gt;using&lt;/code&gt; statements), the code tends to read like a &lt;a href="https://martinfowler.com/bliki/FluentInterface.html"&gt;fluent interface&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I believe this approach provides numerous additional benefits such as:&lt;/p&gt;
&lt;h4 id="propinquity"&gt;1. Propinquity&lt;/h4&gt;
&lt;p&gt;Want the repository for your entity? It's right along side it. As are all the other classes related to that entity. This means you can very quickly skip between these classes without needing to navigate the breadth of your project looking for a folder for the appropriate functional pattern.&lt;/p&gt;
&lt;h4 id="scope"&gt;2. Scope&lt;/h4&gt;
&lt;p&gt;When you write code which involves multiple entities, these entities need to be brought into scope. Rather than adding using statements, I have found that utilising the entity's namespace in a fluent fashion gives very elegant results.
For example, say we have introduce a &lt;code&gt;Role&lt;/code&gt; entity and the controller for this entity needs to be able to add &lt;code&gt;Person&lt;/code&gt; instances to a role. A (naïve) implementation of this class might look something akin to:&lt;/p&gt;
&lt;script src="https://gist.github.com/ibebbs/117531fb4a3a3556fd3788d45ffaaa57.js"&gt;&lt;/script&gt;
&lt;p&gt;Note the lack of additional using statements and how bringing classes related to other entities into scope requires only a partial namespace which then reads like natural language (i.e. Person.Repository / Person.Model).&lt;/p&gt;
&lt;h4 id="coupling"&gt;3. Coupling&lt;/h4&gt;
&lt;p&gt;In general, it is desirable for classes in your project to be loosely coupled. Fluent namespacing can visually illustrate when a class might be tightly-coupled by requiring long namespace traversals. For example:&lt;/p&gt;
&lt;script src="https://gist.github.com/ibebbs/52ecb2051da6812d2a023cfc76cb0331.js"&gt;&lt;/script&gt;
&lt;p&gt;Should the Group controller really be using the Person entity's data source (&lt;code&gt;Person.Data.Source&lt;/code&gt;) and mapping provider (&lt;code&gt;Person.Mapping.Provider&lt;/code&gt;) to fetch a &lt;code&gt;Person.Model&lt;/code&gt; instances or would they be better using the Person entity's repository (&lt;code&gt;Person.Repository&lt;/code&gt;)?&lt;/p&gt;
&lt;h3 id="other-considerations"&gt;Other considerations&lt;/h3&gt;
&lt;p&gt;There are a couple of downsides to this approach such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Refactoring&lt;/p&gt;
&lt;p&gt;When you use Visual Studio's built in refactoring methods, it will always endeavour add a &lt;code&gt;using&lt;/code&gt; to your class for classes outside the current namespace, even if you've already referred to them via the namespace:
&lt;img src="/Content/FluentNamespacing/FluentlyNamespaced-AddReadOnlyField.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Field - yes please, using - no thanks!"&gt;&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Field? Yes please. Using? No thanks!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Searching&lt;/p&gt;
&lt;p&gt;In Visual Studio, when you need to search for a specific class, you may find you get many more hits than expected; afterall, if the &lt;code&gt;Model&lt;/code&gt; class for all entities is called &lt;code&gt;Model&lt;/code&gt; searching for 'Model' will return all the entity classes. Fortunately, Visual Studio's 'Go to All' functionality supports search by multiple key word matches so this works:
&lt;img src="/Content/FluentNamespacing/Go to All.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Ah, there it is"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Note: The fact that these downsides are all related to tooling shows just how ingrained this convention is to modern development.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id="conclusion"&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;As shown, moving away from the &amp;quot;grouping by functional pattern&amp;quot; convention and instead using &amp;quot;Fluent Namespacing&amp;quot; can make your code much more readable and maintainable while requiring very little overhead. The side benefits of simplified navigation leading to easier comprehension and the potential for highlighting possible code-smells can really pay dividends in a large code base. I'd very much encourage you to try Fluent Namespacing in your next project, I don't think you'll regret it.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>A SmartHome... NoT - Part II</title>
			<link>http://ian.bebbs.co.uk/posts/ASmartHome-Part2</link>
			<description>&lt;p&gt;In &lt;a href="http://ian.bebbs.co.uk/posts/ASmartHome-Part1"&gt;part I&lt;/a&gt; of this series I described how to use Xiaomi Mi Smart Home devices without compromising your home privacy or security.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/ASmartHome-Part2</guid>
			<pubDate>Tue, 06 Feb 2018 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;In &lt;a href="http://ian.bebbs.co.uk/posts/ASmartHome-Part1"&gt;part I&lt;/a&gt; of this series I described how to use Xiaomi Mi Smart Home devices without compromising your home privacy or security.&lt;/p&gt;
&lt;p&gt;And lo, with the &lt;em&gt;sweet, sweet nut&lt;/em&gt; of privacy-friendly sensors laid before me, I raised the metaphorical &lt;em&gt;hammer of code&lt;/em&gt; like an allegorical Thor about to deliver righteous justice to... and then I stopped. What was I trying to deliver righteous justice to. In fact, what the smeg did I actually want to &lt;em&gt;do&lt;/em&gt; with all these things?&lt;/p&gt;
&lt;p&gt;So focused had I been on finding a 'how', I hadn't really considered the what or why? Monitoring, sure but there had to be useful things I could automate.&lt;/p&gt;
&lt;p&gt;At this point I decided to take a look around at what other people were doing and, almost inevitably, came upon the &lt;a href="https://community.openhab.org/"&gt;OpenHAB forums&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="openhabian"&gt;OpenHABian&lt;/h1&gt;
&lt;p&gt;OpenHAB has been around for years and for much of this time has been the &lt;em&gt;go to&lt;/em&gt; software for home automation.  Nowadays there a numerous other offerings and OpenHAB has had to rapidly evolve to stay competitive. To this end OpenHAB recently released OpenHAB 2 which, as far as I can tell, is a full rewrite based on &lt;a href="https://www.eclipse.org/smarthome/"&gt;Eclipse SmartHome framework&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While &lt;a href="http://www.myopenhab.org/"&gt;'cloud based' versions of OpenHAB are available&lt;/a&gt; the normal use-case is to deploy a version of OpenHAB on the local network thereby keeping all processing locally too. To facilitate this, they now offer pre-built images of OpenHabian - a distribution for single board computes (i.e. the Raspberry Pi et al) that comes with OpenHAB pre-installed.&lt;/p&gt;
&lt;p&gt;Anyway, I was interested in how OpenHAB might have evolved and love trying out new images on the Raspberry Pi (seriously it's like Docker except on real hardware and... well... works) so downloaded &lt;a href="https://github.com/openhab/openhabian/releases"&gt;the latest version&lt;/a&gt; (somewhat confusing named 'version 1.4' even though it contains OpenHAB 2.2), &lt;a href="https://etcher.io/"&gt;etched it&lt;/a&gt; to an SD card, put the SD card in a spare RPi3 and booted.&lt;/p&gt;
&lt;h2 id="installation"&gt;Installation&lt;/h2&gt;
&lt;p&gt;Installation of OpenHABian is pretty straight forward, simply insert the newly prepared SD card and power on the Pi. One thing to note however is that the setup of OpenHABian requires internet access to download additional components / updates. As I had added the RPi3 running OpenHABian to my secured subnet, my first install of OpenHABian failed as there was no internet access available. A quick firewall exclusion and restart solved the problem.&lt;/p&gt;
&lt;h2 id="paper-ui"&gt;Paper UI&lt;/h2&gt;
&lt;p&gt;One of the key enhancements in OpenHAB 2 is the introduction of 'Paper UI'. Paper UI is an HTML5 web application which allows a fully graphical setup and administration of &lt;a href="https://docs.openhab.org/configuration/things.html"&gt;Things&lt;/a&gt; and &lt;a href="https://docs.openhab.org/configuration/items.html"&gt;Items&lt;/a&gt;. Where previously you'd have to drop into textual configuration of components, Paper UI offers a simplified means of getting your home automation devices known to, and used by, OpenHAB.&lt;/p&gt;
&lt;p&gt;Indeed, getting Paper UI to recognise and use my Xiaomi Mi Smart Home devices was simple and can be done as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Install the &lt;a href="https://docs.openhab.org/addons/bindings/mihome/readme.html"&gt;'Xiaomi Mi Smart Home Binding'&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From the Paper UI, click the 'Add-ons' menu item on the left&lt;/li&gt;
&lt;li&gt;Click the 'Bindings' tab at the top of the page&lt;/li&gt;
&lt;li&gt;Search for 'Xiaomi'&lt;/li&gt;
&lt;li&gt;Click the 'INSTALL' button to the right of the 'Xiaomi Mi Smart Home Binding'&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add the Xiaomi Gateway(s)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Once the 'Xiaomi Mi Smart Home Binding' has been installed, any gateways on the current subnet that have 'local network functions' enabled should magically appear in the 'Inbox' and have a notification shown.&lt;/li&gt;
&lt;li&gt;For each gateway on the subnet, simply add it as a 'Thing' with a unique name and in an appropriate location. Also don't forget to add the 'developer key' (copied from the Xiami Mi Home app after enabling 'local network functions') so you can issue commands to the gateway.&lt;/li&gt;
&lt;li&gt;Each time you add a gateway, the binding will query sub-devices registered with the gateway which will also then be shown in the inbox. These sub-devices can then be added as 'Things' for which you should  remember to set the location so 'Items' linked to the 'Thing' (see below) are displayed correctly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add 'Items' to be displayed&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You should now see all your devices in 'Things'. Each one has several 'Channels' which can be 'linked' to an 'Item' by clicking the blue and white circular icon beside it. For most types of 'Channels', the default values displayed in the 'Link Channel' can be left as is.&lt;/li&gt;
&lt;li&gt;Each 'Item' linked to a channel is shown on the Control page with Locations seperated on to discrete tabs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once all your Xiaomi devices have been added as 'Things' and their respective 'Channels' linked to 'Items' you should end up with something like this in the 'Control' page:&lt;/p&gt;
&lt;img src="/Content/posts/OpenHAB - Paper UI - Configured.png" alt="OpenHAB - Paper UI - Configured" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;So far so good. Now what?&lt;/p&gt;
&lt;p&gt;Well, turns out not a lot. After getting your devices added to OpenHABian, you have to move into textual configuration if you want to actually perform any automation via interaction between devices.&lt;/p&gt;
&lt;p&gt;&amp;quot;Oh&amp;quot;, I thought, &amp;quot;That was a waste of time then&amp;quot;.&lt;/p&gt;
&lt;h2 id="node-red"&gt;Node-RED&lt;/h2&gt;
&lt;p&gt;On a whim, I decided to SSH into OpenHABian and play with the &lt;a href="https://docs.openhab.org/installation/openhabian.html#openhabian-config"&gt;OpenHABian Configuration Tool&lt;/a&gt;. Most of the options were fairly straight forward and unexciting until I got to the &lt;a href="https://docs.openhab.org/installation/openhabian.html#optional-components"&gt;Optional Components&lt;/a&gt; menu. Here a couple of items caught my eye, particularly the option to install Node-RED along side OpenHAB.&lt;/p&gt;
&lt;p&gt;I'd heard of &lt;a href="https://nodered.org/"&gt;Node-RED&lt;/a&gt; previously but had never tried it. As I was about to junk the install of OpenHABian anyway, I decided I'd have a play... and this is where the magic happened.&lt;/p&gt;
&lt;p&gt;For others who have not used Node-RED, it is a Node.js app designed for &amp;quot;wiring together hardware devices, APIs and online services in new and interesting ways&amp;quot;. It has an amazingly simple yet ludicrously brilliant UI which makes experimentation with it's various 'nodes' extremely quick and easy. Moreover, the installation on OpenHABian comes pre-installed with nodes to interact with 'Items' in OpenHAB.&lt;/p&gt;
&lt;p&gt;Despite, never having used Node-RED before, in just a few minutes I had the following flow deployed and running:&lt;/p&gt;
&lt;img src="/Content/posts/Node-RED - First Flow.png" alt="First Node-RED flow" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;Which does the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Uses an &lt;code&gt;openhab2-in&lt;/code&gt; node to listen to changes to the &lt;code&gt;OfficeDoorSensor_OpenStatus&lt;/code&gt; value.&lt;/li&gt;
&lt;li&gt;Uses a &lt;code&gt;switch&lt;/code&gt; node to compare the status value to 'OPEN' or 'CLOSED' and emit the message to the appropriate port.&lt;/li&gt;
&lt;li&gt;If the door has been opened:
&lt;ul&gt;
&lt;li&gt;Use a &lt;code&gt;openhab2-out&lt;/code&gt; node to issue a 'ON' &lt;code&gt;ItemCommand&lt;/code&gt; to the &lt;code&gt;OfficeGateway_Brightness&lt;/code&gt; channel (i.e. turn the light in the Xiami Mi Smart Gateway on).&lt;/li&gt;
&lt;li&gt;Wait five seconds then use a &lt;code&gt;openhab2-out&lt;/code&gt; node to issue a 'OFF' &lt;code&gt;ItemCommand&lt;/code&gt; to the &lt;code&gt;OfficeGateway_Brightness&lt;/code&gt; channel (i.e. turn the light in the Xiami Mi Smart Gateway off).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the door has been closed then use a &lt;code&gt;openhab2-out&lt;/code&gt; node to issue a 'OFF' &lt;code&gt;ItemCommand&lt;/code&gt; to the &lt;code&gt;OfficeGateway_Brightness&lt;/code&gt; channel (i.e. turn the light in the Xiami Mi Smart Gateway off).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ok, the use case is fairly simple but wow, what an incredibly level of integration between disparate sensors / lights with just five nodes, a few connections and no bespoke code what-so-ever.&lt;/p&gt;
&lt;p&gt;I was hooked.&lt;/p&gt;
&lt;p&gt;Playing with Node-RED inspired me to start brain-storming potential use-cases and they soon started coming thick and fast. Broadly the use-cases fell into three main categories:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Utility - mitigate small frustrations around the house&lt;/li&gt;
&lt;li&gt;Security - enhance home security&lt;/li&gt;
&lt;li&gt;Efficiency - reduce home power consumption&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;However, one use case I came up with fell into all three of these categories &lt;strong&gt;and&lt;/strong&gt; a logical progression from the above flow.&lt;/p&gt;
&lt;h1 id="a-use-case-at-last"&gt;A use case at last!&lt;/h1&gt;
&lt;p&gt;Our new 'forever home' has a built in double garage. While the doors on the garage are in pretty good condition, the locks are nothing special and present an obvious security weak spot. Indeed, we use the garage doors every day as it's a very convenient way into the house which increases the likelihood we'll forget to close the doors properly.&lt;/p&gt;
&lt;p&gt;Furthermore, the flurescent lights in the garage are old and take an age to turn on. As we need to go through the garage to get to the utility room and can't see the way to the utility room until the light is on, we tended to simply turn them on at the beginning of the day and turn them off before going to bed each night, thereby consuming way more energy than necessary.&lt;/p&gt;
&lt;p&gt;Understanding this, I used an additional gateway in the garage, coupled with sensors on each of the doors (garage door, kitchen door, utility room door) and an easily controllable &lt;a href="https://www.amazon.co.uk/gp/product/B077HLQMBD"&gt;IP camera&lt;/a&gt; to put together the following flow:&lt;/p&gt;
&lt;img src="/Content/posts/Node-RED - Garage.png" alt="Node-RED garage flow" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;This does a couple of things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Turns on the light in the gateway whenever any of the doors open&lt;/p&gt;
&lt;p&gt;The light in the gateway is more than enough to light the way to the utility room which addresses the utility aspect of the use-case as we no longer need to wait for the garage light to come on. Furthermore, three minutes after the door was opened (regardless of whether it's been closed again), the light in the gateway is turned off. This is normally long enough for us to do whatever we needed in the garage and addresses the efficiency aspect of the use-case as we no longer leave a light on all day.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Turns the IP Camera to look at the opened door and takes a snapshot&lt;/p&gt;
&lt;p&gt;The IP camera I've used has a useful feature whereby it can record several Pan/Tilt positions which it can then return to using a single command. I use this feature to point the camera at the door which has just been opened and use a further command to take a snapshot image of what it sees. This addresses the security aspect of the use case by ensuring video surveilance coverage of activity within the garage.&lt;br /&gt;
&lt;em&gt;Ultimately I intend to upload this image to a cloud storage provider and send a notification to my phone if this happens within certain time constraints but this has yet to be implemented.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="moving-forward"&gt;Moving forward&lt;/h1&gt;
&lt;p&gt;As you can see, the combination of Xiaomi Mi Smart devices, OpenHAB[ian] and Node-RED is extremely potent. Without writing any code (compiled, intepreted or DSL), I'm able to orchestrate some very advanced interactions between sensors, actuators and other services.&lt;/p&gt;
&lt;p&gt;In the next post, I'll discuss how I've developed this platform even further into a full, voice activated, digital assistant while &lt;em&gt;still&lt;/em&gt; maintaining privacy and security.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>A SmartHome... NoT - Part I</title>
			<link>http://ian.bebbs.co.uk/posts/ASmartHome-Part1</link>
			<description>&lt;p&gt;I moved house a couple of months back to, what my partner likes to describe as, our "forever home". As such, I was keen to start looking into home monitoring / automation again as I knew things had progressed significantly since I last considered such things and I was keen to see what could be done. After lots of investigation I believe I have found the basis of a home automation solution which meets my current needs, should be extensible moving forward and which does not compromise the securty or privacy of my home.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/ASmartHome-Part1</guid>
			<pubDate>Mon, 29 Jan 2018 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;I moved house a couple of months back to, what my partner likes to describe as, our &amp;quot;forever home&amp;quot;. As such, I was keen to start looking into home monitoring / automation again as I knew things had progressed significantly since I last considered such things and I was keen to see what could be done. After lots of investigation I believe I have found the basis of a home automation solution which meets my current needs, should be extensible moving forward and which does not compromise the securty or privacy of my home.&lt;/p&gt;
&lt;p&gt;This post is, I hope, the first in a series that discuss the various devices and software I use to monitor and automate my home.&lt;/p&gt;
&lt;h1 id="private-by-design"&gt;Private by design&lt;/h1&gt;
&lt;p&gt;Firstly a word on privacy. While &amp;quot;smart devices&amp;quot; are everywhere nowadays, they almost all require connection to the internet and, often, a subscription to a &amp;quot;cloud&amp;quot; service. I wrote about &lt;a href="http://ian.bebbs.co.uk/posts/MonsterPi"&gt;this before&lt;/a&gt; and expressed my desire for smart devices to &amp;quot;drop the 'Inter' from IoT and expand the 'net' to become a 'Network of Things', or NoT&amp;quot; which could optionally be bridged to the internet if desired. To quote myself:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;I've long loved the idea of home automation. From X10 and LightwaveRF through to modern Bluetooth and Wifi connected devices, I have played with dozens of technologies in search of home automation nirvana. But recently I have watched with growing bewilderment at the incredible number of &amp;quot;cloud-connected&amp;quot; home automation devices being released and the eagerness with which they're snapped up by naive consumers hungry to control everything from the carefree comfort of their iPhone.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;You see, while you can buy a myriad of IoT devices off the shelf nowadays, they nearly all come with some form of &amp;quot;cloud-service&amp;quot; that is necessary in order for the device to work as sold. As the more wily of reader will no doubt be aware, this exposes your home network to innumerable &lt;a href="https://it.slashdot.org/story/16/10/03/1359200/source-code-for-iot-botnet-mirai-which-took-down-krebs-on-security-website-with-ddos-attack-released"&gt;security concerns&lt;/a&gt;, &lt;a href="https://it.slashdot.org/story/16/08/08/1449221/hackers-make-the-first-ever-ransomware-for-smart-thermostats"&gt;potential abuses&lt;/a&gt; and an &lt;a href="https://tech.slashdot.org/story/16/01/14/1347243/nest-thermostat-bug-leaves-owners-without-heating"&gt;external point of failure&lt;/a&gt; that cannot be closed/fixed without sacrificing some or all of the functionality of the new fangled device.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since I wrote post, the market for internet connected home automation devices has exploded... as have the concerns around the &lt;a href="(https://gizmodo.com/amazon-agrees-to-hand-over-data-in-echo-murder-case-1793039360)"&gt;privacy&lt;/a&gt;, &lt;a href="https://www.bleepingcomputer.com/news/government/germany-preparing-law-for-backdoors-in-any-type-of-modern-device/"&gt;security&lt;/a&gt; and &lt;a href="https://torrentfreak.com/piracy-notices-can-mess-with-your-thermostat-isp-warns-171224/"&gt;functionality&lt;/a&gt; (or &lt;a href="https://gizmodo.com/yes-your-amazon-echo-is-an-ad-machine-1821712916"&gt;unwanted functionality&lt;/a&gt;) of the devices. I am &lt;a href="http://uk.businessinsider.com/consumers-holding-off-on-smart-home-gadgets-thanks-to-privacy-fears-2017-11?r=US&amp;amp;IR=T"&gt;not alone&lt;/a&gt; in being sufficiently concerned by these issues that I choose the devices I allow on my home network very carefully and &lt;a href="http://ian.bebbs.co.uk/tags/monitoring"&gt;monitor them closely&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In short, the list of &amp;quot;off-the-shelf&amp;quot; devices I would feel comfortable having on my home network is very short and, until recently, I was resigned to having to build these devices myself using &lt;a href="https://en.wikipedia.org/wiki/Single-board_computer"&gt;single board computers&lt;/a&gt; or &lt;a href="https://en.wikipedia.org/wiki/ESP8266"&gt;Wifi connected microcontrollers&lt;/a&gt;. That is until a family of devices came to my attention that originated from the most unlikely of places...&lt;/p&gt;
&lt;h2 id="mi-smart-home"&gt;Mi Smart Home&lt;/h2&gt;
&lt;p&gt;China isn't the first country that comes to mind when you think about privacy yet, with the release of the &lt;a href="https://xiaomi-mi.com/mi-smart-home/"&gt;&amp;quot;Mi Smart Home&amp;quot;&lt;/a&gt; family of devices, the Chinese electronics manufacturer &lt;a href="https://en.wikipedia.org/wiki/Xiaomi"&gt;Xiaomi Inc&lt;/a&gt; seems to have delivered a smart-device eco-system that is privacy-friendly... albeit somewhat tacitly as we will see below.&lt;/p&gt;
&lt;p&gt;The Mi Smart family consists of a number of small, battery powered Zigbee devices such as &lt;a href="https://xiaomi-mi.com/sockets-and-sensors/xiaomi-mi-temperature-humidity-sensor/"&gt;temperature and humidity sensors&lt;/a&gt;, &lt;a href="https://xiaomi-mi.com/sockets-and-sensors/xiaomi-mi-door-window-sensors/"&gt;door / window sensors&lt;/a&gt;, &lt;a href="https://xiaomi-mi.com/sockets-and-sensors/xiaomi-mi-occupancy-sensor/"&gt;movement sensors&lt;/a&gt; and &lt;a href="https://www.gearbest.com/alarm-systems/pp_610096.html"&gt;various switches&lt;/a&gt;. Oh... and a curious &lt;a href="https://xiaomi-mi.com/sockets-and-sensors/xiaomi-mi-smart-home-cube-white/"&gt;'cube' controller&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These devices connect to your internal Wifi network via a &lt;a href="https://xiaomi-mi.com/mi-smart-home/xiaomi-mi-gateway-2/"&gt;Gateway device&lt;/a&gt;. In addition to providing the Zigbee to Wifi bridge, this gateway also provides an ambient light sensor, a very useful RGB light and a umm... not so useful speaker. This is all packaged in a small, round, 30 gram device about 8 centimeters in diameter and 3 cenitmeters deep. Frustratingly the gateway only comes with the Chinese/Australian type I plug so you need an adapter to use it in the UK which adds significantly to the depth (although I've taken to using a &lt;a href="https://www.gearbest.com/plugs-sockets/pp_1168562.html"&gt;convenient extension lead&lt;/a&gt; instead).&lt;/p&gt;
&lt;p&gt;To set up the Wifi Gateway device and add sensors, you have to install the &lt;a href="https://play.google.com/store/apps/details?id=com.xiaomi.smarthome&amp;amp;hl=en_GB"&gt;Xiaomi Mi Home app&lt;/a&gt; which, to be frank, is a privacy nightmare. The list of permissions it needs is quite incredible:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Version 5.1.1 can access:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Device &amp;amp; app history
&lt;ul&gt;
&lt;li&gt;retrieve running apps&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Identity
&lt;ul&gt;
&lt;li&gt;find accounts on the device&lt;/li&gt;
&lt;li&gt;add or remove accounts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Calendar
&lt;ul&gt;
&lt;li&gt;read calendar events plus confidential information&lt;/li&gt;
&lt;li&gt;add or modify calendar events and send emails to guests without owners' knowledge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Contacts
&lt;ul&gt;
&lt;li&gt;find accounts on the device&lt;/li&gt;
&lt;li&gt;read your contacts&lt;/li&gt;
&lt;li&gt;modify your contacts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Location
&lt;ul&gt;
&lt;li&gt;approximate location (network-based)&lt;/li&gt;
&lt;li&gt;precise location (GPS and network-based)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SMS
&lt;ul&gt;
&lt;li&gt;read your text messages (SMS or MMS)&lt;/li&gt;
&lt;li&gt;receive text messages (SMS)&lt;/li&gt;
&lt;li&gt;send SMS messages&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Phone
&lt;ul&gt;
&lt;li&gt;directly call phone numbers&lt;/li&gt;
&lt;li&gt;reroute outgoing calls&lt;/li&gt;
&lt;li&gt;read call log&lt;/li&gt;
&lt;li&gt;read phone status and identity&lt;/li&gt;
&lt;li&gt;write call log&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Photos / Media / Files
&lt;ul&gt;
&lt;li&gt;read the contents of your USB storage&lt;/li&gt;
&lt;li&gt;modify or delete the contents of your USB storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Storage
&lt;ul&gt;
&lt;li&gt;read the contents of your USB storage&lt;/li&gt;
&lt;li&gt;modify or delete the contents of your USB storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Camera
&lt;ul&gt;
&lt;li&gt;take pictures and videos&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Microphone
&lt;ul&gt;
&lt;li&gt;record audio&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Wi-Fi connection information
&lt;ul&gt;
&lt;li&gt;view Wi-Fi connections&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Device ID &amp;amp; call information
&lt;ul&gt;
&lt;li&gt;read phone status and identity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other
&lt;ul&gt;
&lt;li&gt;download files without notification&lt;/li&gt;
&lt;li&gt;interact across users&lt;/li&gt;
&lt;li&gt;full licence to interact across users&lt;/li&gt;
&lt;li&gt;transmit infrared&lt;/li&gt;
&lt;li&gt;modify secure system settings&lt;/li&gt;
&lt;li&gt;read Home settings and shortcuts&lt;/li&gt;
&lt;li&gt;write Home settings and shortcuts&lt;/li&gt;
&lt;li&gt;view network connections&lt;/li&gt;
&lt;li&gt;create accounts and set passwords&lt;/li&gt;
&lt;li&gt;read battery statistics&lt;/li&gt;
&lt;li&gt;pair with Bluetooth devices&lt;/li&gt;
&lt;li&gt;access Bluetooth settings&lt;/li&gt;
&lt;li&gt;send sticky broadcast&lt;/li&gt;
&lt;li&gt;change network connectivity&lt;/li&gt;
&lt;li&gt;allow Wi-Fi Multicast reception&lt;/li&gt;
&lt;li&gt;connect and disconnect from Wi-Fi&lt;/li&gt;
&lt;li&gt;disable your screen lock&lt;/li&gt;
&lt;li&gt;control flashlight&lt;/li&gt;
&lt;li&gt;full network access&lt;/li&gt;
&lt;li&gt;change your audio settings&lt;/li&gt;
&lt;li&gt;control Near-Field Communication&lt;/li&gt;
&lt;li&gt;read sync settings&lt;/li&gt;
&lt;li&gt;run at startup&lt;/li&gt;
&lt;li&gt;draw over other apps&lt;/li&gt;
&lt;li&gt;use accounts on the device&lt;/li&gt;
&lt;li&gt;control vibration&lt;/li&gt;
&lt;li&gt;prevent device from sleeping&lt;/li&gt;
&lt;li&gt;modify system settings&lt;/li&gt;
&lt;li&gt;toggle sync on and off&lt;/li&gt;
&lt;li&gt;install shortcuts&lt;/li&gt;
&lt;li&gt;uninstall shortcuts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Scary huh! How can I possibly claim these devices are privacy friendly when you've basically just given a Chinese company permission to do pretty much anything it likes with your phone's hardware and data? Well, notice how I said you need the app to &amp;quot;set up the Wifi Gateway device and add sensors&amp;quot;. Once they're setup you no longer need the app and, furthermore, once &amp;quot;local network functions&amp;quot; are enabled (more on this in a second) neither the gateway nor sensors need internet access to function.&lt;/p&gt;
&lt;p&gt;So, how to go about using these sensors in a privacy friendly way?&lt;/p&gt;
&lt;h1 id="preparation"&gt;Preparation&lt;/h1&gt;
&lt;p&gt;To get set up with these devices without compromising your privacy, you will need:&lt;/p&gt;
&lt;h2 id="a-dedicated-vlan-and-wifi-network-for-smart-home-devices"&gt;A dedicated VLAN and Wifi network for &amp;quot;smart home&amp;quot; devices&lt;/h2&gt;
&lt;p&gt;I recommend putting any 3rd party &amp;quot;smart&amp;quot; devices in an isolated environment within which you can easily enable or disable internet access. To do this I am using the VLAN feature of my Draytek 2860 router which involves  creating a second VLAN on my network, enabling &amp;quot;Inter-LAN' routing so I could access the VLAN from my existing subnet and, finally, adding firewall rules to prevent devices on this VLAN from accessing the internet / other vlans.&lt;/p&gt;
&lt;h2 id="a-clean-android-device"&gt;A clean Android device&lt;/h2&gt;
&lt;p&gt;I had an old Android phone laying around on which I performed a hard-reset and wiped all user-data. With a clean device I could then install the app without worrying about sharing anything private with Xiaomi&lt;/p&gt;
&lt;h1 id="installation"&gt;Installation&lt;/h1&gt;
&lt;p&gt;First, install the Xiaomi Mi Home app on your clean Android device. On first run after installation you will be prompted for a region and asked to sign in. In order to use all the Mi Smart devices, you &lt;strong&gt;must&lt;/strong&gt; select &amp;quot;Mainland China&amp;quot; for your region (this doesn't affect the language in the app) following which you can just create a new account to sign in.&lt;/p&gt;
&lt;p&gt;Once the app is installed you can plug in a gateway. This results in a nice flashing yellow ring of light around the device... and a harsh female voice babbling Chinese at an almost intolerable volume;  basically an audio and visual indication that the gateway is in &amp;quot;pairing&amp;quot; mode.&lt;/p&gt;
&lt;p&gt;Go ahead and pair the gateway to the app following the walk-through &lt;a href="https://www.youtube.com/watch?v=nkFF284OFRE"&gt;here&lt;/a&gt;. At this point it's a good idea to also install any additional &amp;quot;sub devices&amp;quot; you have (i.e. the various Zigbee sensors) which can be done by following &lt;a href="https://www.youtube.com/watch?v=TiAgeg5P1T4"&gt;this&lt;/a&gt; walkthrough.&lt;/p&gt;
&lt;p&gt;Finally, in order to use the gateway and sensors without the app and/or internet access, it is necessary to enable &amp;quot;local network functions&amp;quot;. This can be done from the app by following the instructions &lt;a href="https://www.domoticz.com/wiki/Xiaomi_Gateway_(Aqara)"&gt;here&lt;/a&gt;. Quite why Xiaomi decided to hide what its possible the killer feature of these devices behind a &amp;quot;secret&amp;quot; button I've no idea... fortunately it's an open secret and Xiaomi don't seem to be making any effort to conceal it further.&lt;/p&gt;
&lt;p&gt;With all the above done, feel free to junk the app and disable internet access from the &amp;quot;smart device&amp;quot; subnet / ip range.&lt;/p&gt;
&lt;h1 id="usage"&gt;Usage&lt;/h1&gt;
&lt;p&gt;Once 'local network functions' have been enabled, each Gateway uses the multicast address &lt;code&gt;224.0.0.50&lt;/code&gt; to broadcast UDP messages on port &lt;code&gt;9898&lt;/code&gt; from the gateway and sub-devices. The gateway publishes a &amp;quot;heartbeat&amp;quot; messages every 10-15 seconds or so meaning you can easily determine everything is working by spinning up Wireshark (on a device connected to the &amp;quot;smart device&amp;quot; subnet) filtering out anything that isn't a UDP message (&lt;code&gt;ip.proto == &amp;quot;udp&amp;quot;&lt;/code&gt;) and looking for messages from the gateway IP address. You should eventually see something like this:&lt;/p&gt;
&lt;img src="/Content/posts/Heartbeat.png" alt="Wireshark Heartbeat capture" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;Once you can see these messages you can start interacting with the gateway and devices using various commands. For example, to get a list of the sub-devices from a gateway you can send a 'get_id_list' command using a UDP packet container this string (as ASCII encoded binary) to the gateway's IP address, again on port &lt;code&gt;9898&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;get_id_list&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will result in a &lt;code&gt;get_id_list_ack&lt;/code&gt; response containing a list of &lt;code&gt;sid&lt;/code&gt; (aka 'simple' id) values for devices registered with the gateway (including the gateway sensor/status itself)  as follows:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;get_id_list_ack&amp;quot;,&amp;quot;sid&amp;quot;:&amp;quot;7811dcb06972&amp;quot;,&amp;quot;token&amp;quot;:&amp;quot;L0DI4IiFAvAgInyL&amp;quot;,&amp;quot;data&amp;quot;:&amp;quot;[\&amp;quot;158d0001a200f5\&amp;quot;,\&amp;quot;158d0001c1cdfb\&amp;quot;]&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You're then able to retrieve the device status using the &lt;code&gt;read&lt;/code&gt; command for each &lt;code&gt;sid&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;read&amp;quot;,&amp;quot;sid&amp;quot;:&amp;quot;7811dcb06972&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Which will return a &lt;code&gt;read_ack&lt;/code&gt; response containing device specific information in the 'data' property. For example, if you send a &lt;code&gt;read&lt;/code&gt; command specifying the &lt;code&gt;sid&lt;/code&gt; of the gateway you will receive something like the following:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;read_ack&amp;quot;,&amp;quot;model&amp;quot;:&amp;quot;gateway&amp;quot;,&amp;quot;sid&amp;quot;:&amp;quot;7811dcb06972&amp;quot;,&amp;quot;short_id&amp;quot;:0,&amp;quot;data&amp;quot;:&amp;quot;{\&amp;quot;rgb\&amp;quot;:0,\&amp;quot;illumination\&amp;quot;:1292,\&amp;quot;proto_version\&amp;quot;:\&amp;quot;1.0.9\&amp;quot;}&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, when the status of a sensor changes (for example a door sensor opens or closes) a &lt;code&gt;report&lt;/code&gt; message is broadcast as follows:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;report&amp;quot;,&amp;quot;model&amp;quot;:&amp;quot;magnet&amp;quot;,&amp;quot;sid&amp;quot;:&amp;quot;158d0001c1cdfb&amp;quot;,&amp;quot;short_id&amp;quot;:56258,&amp;quot;data&amp;quot;:&amp;quot;{\&amp;quot;status\&amp;quot;:\&amp;quot;open\&amp;quot;}&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;h1 id="heres-one-i-made-earlier"&gt;Here's one I made earlier...&lt;/h1&gt;
&lt;p&gt;I used the above information to create a small application for listening to and interacting with the gateway and devices. Mostly out of interest, I used &lt;a href="https://dotnet.github.io/orleans/"&gt;Microsoft's Orleans framework&lt;/a&gt; to create a console application which wraps up the interaction with various devices into strongly typed agents (also an agent approach seemed to nicely mirror the segregated nature of the devices themselves).&lt;/p&gt;
&lt;p&gt;I didn't take this too far as I subsequently decided to use an &amp;quot;off-the-shelf&amp;quot; system for interacting with the Xiaomi devices (the subject of my next &amp;quot;smart home&amp;quot; post) but it's a decent proof-of-concept. I've published the source in a &lt;a href="https://github.com/ibebbs/MiOrleans"&gt;repository on Github&lt;/a&gt;; feel free to have a play and drop me a line with any questions you might have.&lt;/p&gt;
&lt;p&gt;In the next post I'll disucss the off-the-shelf system I'm now using to privately interact with the Xiaomi devices.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Nano2Docker</title>
			<link>http://ian.bebbs.co.uk/posts/Nano2Docker</link>
			<description>&lt;p&gt;While my current contract doesn't leave much time for personal projects, I have made some progress on my current project (details on exactly what this is to follow). In fact, some of the smaller, peripheral services have their primary use-cases functionally complete and are ready for deployment and I am now faced with the question: Deployment to where?&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/Nano2Docker</guid>
			<pubDate>Mon, 10 Jul 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="deployment-at-last"&gt;Deployment at last&lt;/h1&gt;
&lt;p&gt;While my current contract doesn't leave much time for personal projects, I have made some progress on my current project (details on exactly what this is to follow). In fact, some of the smaller, peripheral services have their primary use-cases functionally complete and are ready for deployment and I am now faced with the question: Deployment to where?&lt;/p&gt;
&lt;h1 id="fabric-or-container"&gt;Fabric or Container&lt;/h1&gt;
&lt;p&gt;Given this project constitutes multiple micro-services using message based, asynchronous communication with the potential to scale services horizontally, I required some form of elastic service fabric. Furthermore, I wanted a local development environment which would simulate a cluster of machines but with which I could monkey about as much as I liked without fear of accidentally incurring massive hosting fees in the cloud.&lt;/p&gt;
&lt;p&gt;As I had just upgraded my home server with plenty of memory, I decided to use one of more virtual machines running on this server to host the environment during development, but which technology to use?&lt;/p&gt;
&lt;p&gt;Initially I had intended to use a &lt;a href="https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-get-started-with-a-local-cluster"&gt;local Service Fabric cluster&lt;/a&gt;. However, upon further investigation I found that the SDK and API introduced significant friction to the development process (needing additional projects for supplying manifest / configuration data for services, overly complex deployment scripts, etc). Even the 'guest executable' approach seemed overly complex and I quickly went off this approach.&lt;/p&gt;
&lt;p&gt;My second thought was &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;; specifically the creation of a local &lt;a href="https://docs.docker.com/engine/swarm/"&gt;Docker Swarm&lt;/a&gt; which I could deploy servies to with &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;. &lt;a href="https://docs.docker.com/machine/"&gt;Docker Machine&lt;/a&gt; made short work of provisioning Docker hosts in Hyper-V but with one caveat: it's &lt;a href="http://boot2docker.io/"&gt;boot2docker&lt;/a&gt; image would only run Linux based containers and, while many of the services I have written / will write run quite happily on .NET Core, some require packages that do not yet provide support for .NET Core / Standard.&lt;/p&gt;
&lt;p&gt;Given that a recent update made &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;Swarm mode available to Windows Server 2016&lt;/a&gt; host operating systems, I decided I would look into provisioning a series of Windows Server VM's with container support and configure Docker on these VM's to operate in swarm mode.&lt;/p&gt;
&lt;h1 id="using-nano-server-as-a-docker-host"&gt;Using Nano Server as a Docker host&lt;/h1&gt;
&lt;p&gt;While I had previously used Microsoft Nano Server as a &lt;a href="http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII"&gt;guest OS&lt;/a&gt; for &lt;a href="http://ian.bebbs.co.uk/posts/DockerAndKafka"&gt;containerized apps&lt;/a&gt;, I hadn't realised that it was possible to use it as a host OS for Docker until I came across &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/deploy-containers-on-nano"&gt;this article&lt;/a&gt;. For those not familiar with Nano Server it is an extremely slimmed down (the OS image is less than 170Mb) and fast booting (5-10 seconds), headless version of Windows Server 2016 which, given it is capable of acting as a Docker host, effectively makes it 'boot2docker' but for Windows containers.&lt;/p&gt;
&lt;p&gt;Nano Server is shipped with Windows Server 2016 and is accompanied by a Powershell module which provides some terrific facilities for working with Nano Server images. &lt;a href="https://docs.microsoft.com/en-us/windows-server/get-started/deploy-nano-server"&gt;This document&lt;/a&gt; shows how to use this Powershell module to create customised Nano Server images as either &lt;a href="https://en.wikipedia.org/wiki/Windows_Imaging_Format"&gt;'.wim'&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ISO_image"&gt;'.iso'&lt;/a&gt; or - most interestingly for me -  &lt;a href="https://technet.microsoft.com/en-us/library/hh831446(v=ws.11).aspx"&gt;'.vhdx'&lt;/a&gt;. In short, the following powershell command will create a virtual HD that can be attached to a virtual machine and which will boot directly into Nano Server with support for - but no utilites to provide - containerization services:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-NanoServerImage -Edition Standard -DeploymentType Guest -MediaPath &amp;lt;path to root of media&amp;gt; -BasePath &amp;lt;path in which to build the image&amp;gt; -TargetPath &amp;lt;destination path&amp;gt;\NanoServer.vhdx -ComputerName &amp;lt;computer name&amp;gt; -Containers -EnableRemoteManagementPort
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will also open &lt;a href="https://msdn.microsoft.com/en-us/library/aa384426(v=vs.85).aspx"&gt;WinRM&lt;/a&gt; ports on the Nano Server which allows you to use &lt;a href="https://technet.microsoft.com/en-us/library/ff700227.aspx"&gt;PS Remoting&lt;/a&gt; to remote into the virtual machine and examine it's state; indispensable for debugging purposes.&lt;/p&gt;
&lt;h1 id="updating-nano-server"&gt;Updating Nano Server&lt;/h1&gt;
&lt;p&gt;Referring back to the &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;'Getting Started with Swarm Mode'&lt;/a&gt; article, it states that a &lt;a href="https://support.microsoft.com/en-us/help/4015217/windows-10-update-kb4015217"&gt;relatively recent update&lt;/a&gt; is required to run Docker Swarms on Windows Server 2016 based OS's. It is therefore necessary to ensure this update is applied to any NanoServer image we create for the purpose of running Docker, ideally during the creation of the image not a subsequent setup script.&lt;/p&gt;
&lt;p&gt;Well, those clever people at Microsoft thought of this too and provided a &lt;code&gt;-ServicingPackagePath&lt;/code&gt; argument for the &lt;code&gt;New-NanoServerImage&lt;/code&gt; command which takes a path to a cab update file and applies the update to the NanoServer OS during image creation. A mechanism for getting an update from Microsoft (as an *.msu) and extracting it into a (series of) cab-files for use in the &lt;code&gt;New-NanoServerImage&lt;/code&gt; is provided by Thomas Maurer in &lt;a href="http://www.thomasmaurer.ch/2016/10/how-to-install-updates-on-nano-server/"&gt;an excellent blog post here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="installing-docker-as-part-of-a-nano-server-image"&gt;Installing Docker as part of a Nano Server image&lt;/h1&gt;
&lt;p&gt;Now, just like 'boot2docker' we want our Nano Server to be ready to host Windows Containers as soon as it's booted and without further manual configuration. To this end, I needed to find a way to install Docker as part of the deployment process. Fortunately the 'New-NanoServer' command provides a &lt;code&gt;-SetupCompleteCommand&lt;/code&gt; argument which allows you to 'run custom commands as part of setupcomplete.cmd' (i.e. on first boot). Great, so now to prepare a script to deploy Docker which we can call via the &lt;code&gt;-SetupCompleteCommand&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;Conveniently, Docker's &lt;a href="https://docs.docker.com/docker-ee-for-windows/install/#using-a-script-to-install-docker-ee"&gt;documentation for installing Docker EE&lt;/a&gt; (the version supported by Windows) provides exactly the script required, copied below with some additional configuration copied from the 'Prepare Container Host' section of &lt;a href=""&gt;'Deploy Containers on Nano'&lt;/a&gt; article:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# On an online machine, download the zip file
Invoke-Webrequest -UseBasicparsing -Outfile docker.zip https://download.docker.com/components/engine/windows-server/17.03/docker-17.03.0-ee.zip

# Extract the archive.
Expand-Archive docker.zip -DestinationPath $Env:ProgramFiles

# Clean up the zip file.
Remove-Item -Force docker.zip

# Install Docker. This will require rebooting.
# This is not required as we have already prepared out image with container support
# $null = Install-WindowsFeature containers

# Add Docker to the path for the current session.
$env:path += &amp;quot;;$env:ProgramFiles\docker&amp;quot;

# Modify PATH to persist across sessions.
# Note: Nano Server's SetEnvironmentVariable method does not take a scope parameter 
[Environment]::SetEnvironmentVariable(&amp;quot;PATH&amp;quot;, $env:path)

# Open an inbound port for the docker daemon  
netsh advfirewall firewall add rule name=&amp;quot;Docker daemon &amp;quot; dir=in action=allow protocol=TCP localport=2375

# Create and populate docker daemon's configuration file
New-Item -Type File 'C:\ProgramData\docker\config\daemon.json' -Force
Add-Content 'C:\programdata\docker\config\daemon.json' '{ &amp;quot;hosts&amp;quot;: [&amp;quot;tcp://0.0.0.0:2375&amp;quot;, &amp;quot;npipe://&amp;quot;] }'

# Register the Docker daemon as a service.
dockerd --register-service

# Start the daemon.
Start-Service docker
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this script requires that the Nano Server be online when the script is run so that it can download the Docker binaries. Unfortunately, given that this script will run as part of the deployment process, this is unlikely to be the case. Instead, we'll need to lean on another feature of the &lt;code&gt;New-NanoServerImage&lt;/code&gt;, &lt;code&gt;-CopyPath&lt;/code&gt;. This argument allows you to specify one or more files to copy to the Nano Server image as part of it's creation and we'll use it to copy a pre-downloaded copy of the docker binaries (along with a copy of the deployment script) to the root of the images C:\ drive, as shown here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-NanoServerImage -Edition Standard -DeploymentType Guest -MediaPath &amp;lt;path to root of media&amp;gt; -BasePath &amp;lt;path in which to build the image&amp;gt; -TargetPath &amp;lt;destination path&amp;gt;\NanoServer.vhdx -ComputerName &amp;lt;computer name&amp;gt; -Containers -EnableRemoteManagementPort -CopyPath &amp;#64;('&amp;lt;path to deployment script&amp;gt;\DeployDocker.ps1', '&amp;lt;path in which docker is downloaded&amp;gt;\docker.zip') -SetupCompleteCommand &amp;#64;('Powershell.exe -Command .\DeployDocker.ps1') 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, now we can comment out the first line of the script above and it'll run fine, right? Unfortunately not. It seems that, at the stage of the boot process at which this script runs, powershell isn't quite ready to run powershell. Fortunately, others have encountered this issue before and Sergey Babkin provides &lt;a href="https://blogs.msdn.microsoft.com/sergey_babkins_blog/2017/01/05/how-to-run-powershell-from-setupcomplete-cmd/"&gt;this solution&lt;/a&gt;; copied below with customisation for our requirements:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set LOCALAPPDATA=%USERPROFILE%\AppData\Local
set PSExecutionPolicyPreference=Unrestricted
Powershell -Command C:\DeployDocker.ps1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so we'll add and deploy this batch file as 'DeployDocker.bat' and then execute this instead of the powershell script as the &lt;code&gt;-SetupCompleteCommand&lt;/code&gt;, as shown here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-NanoServerImage -Edition Standard -DeploymentType Guest -MediaPath &amp;lt;path to root of media&amp;gt; -BasePath &amp;lt;path in which to build the image&amp;gt; -TargetPath &amp;lt;destination path&amp;gt;\NanoServer.vhdx -ComputerName &amp;lt;computer name&amp;gt; -Containers -EnableRemoteManagementPort -CopyPath &amp;#64;('&amp;lt;path to deployment batch file'\DeployDocker.bat', '&amp;lt;path to deployment script&amp;gt;\DeployDocker.ps1', '&amp;lt;path in which docker is downloaded&amp;gt;\docker.zip') -SetupCompleteCommand 'C:\DeployDocker.bat' 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And thats it. If you now create a virtual machine with the new 'NanoServer.vhdx' image as it's boot drive, you should find that, once it's booted you're able to communicate with the Docker daemon on the VM. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker -H &amp;lt;IP Address of VM&amp;gt; ps
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Should return a (empty) list of containers present on the Nano Server host.&lt;/p&gt;
&lt;h1 id="scripting-the-creation-of-a-vm"&gt;Scripting the creation of a VM&lt;/h1&gt;
&lt;p&gt;Now, jumping through all the hoops above each time we want to make a new VM to host docker would be arduous to say the least. As such, I put together a powershell module which is able to directly create VM's ready to host Docker containers in just a few steps. From a powershell command prompr, this can be done as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Get the Nano2Docker powershell module&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This module is available in my Docker repository on Github and can be downloaded directly using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Invoke-WebRequest -OutFile Nano2Docker.psm1 https://raw.githubusercontent.com/ibebbs/Docker/master/Nano2Docker/Nano2Docker.psm1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then installed using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Import-Module Nano2Docker.psm1
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Prepare a base NanoServer image&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The process of downloading docker and applying updates can be extremely slow. Therefore we first create a reusable base NanoServer image that has docker installed and updates applied. This is done using the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Initialize-Nano2DockerImage -MediaPath &amp;lt;Drive letter for Windows Server 2016&amp;gt; -BuildPath &amp;lt;Path to a build location&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, if your Windows Server 2016 media is mounted in the 'G' drive and you want to build the new Nano2Docker image in the 'C:\Nano2Docker' folder, you'd use the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Initialize-Nano2DockerImage -MediaPath G: -BuildPath &amp;quot;C:\Nano2Docker&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The command provides defaults download locations for docker and required updates but these can be overriden using the &lt;code&gt;-DockerUrl&lt;/code&gt; and &lt;code&gt;-UpdateUrl&lt;/code&gt; parameters repsectively. Furthermore, if you already have an '.msu' file downloaded you can save a lot of time by providing this to the command using the &lt;code&gt;-UpdateFile&lt;/code&gt; parameter.&lt;/p&gt;
&lt;p&gt;When you run this command, you will be prompted for Administrator credentials for the new Nano2Docker image. Either enter them when prompted or supply a &lt;code&gt;SecureString&lt;/code&gt; value to the &lt;code&gt;-Password&lt;/code&gt; argument (which is usually done using the &lt;code&gt;Get-Credentials&lt;/code&gt; commandlet).&lt;/p&gt;
&lt;p&gt;When this command completes - which can take a while - you will find a 'Nano2Docker.vhdx' file in the BuildPath directory.&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Create a VM using the new NanoServer image&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can now use the &lt;code&gt;New-Nano2Docker&lt;/code&gt; commandlet to quickly create new VM docker hosts. The command is used as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-Nano2Docker -MediaPath &amp;lt;Drive letter for Windows Server 2016&amp;gt; -ImagePath &amp;lt;Path to a previously created Nano2Docker.vhdx&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using our previous example, the command would be:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-Nano2Docker -MediaPath G: -ImagePath &amp;quot;C:\Nano2Docker\Nano2Docker.vhdx&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will copy the base image to the VM path (defaults to 'C:\Users\Public\Documents\Hyper-V\Virtual Hard Disks'), provision a new, local, Hyper-V VM named 'Nano2Docker' with reasonable resources (4 cores / 2Gb of dynamic ram) and attached to the first available virtual switch.
Obviously, each of these characteristics can be changed using the appropriate arguments - use &lt;code&gt;Get-Help New-Nano2Docker&lt;/code&gt; to list the available arguments. You will again be asked to an Administrator password for the new VM which can be entered during creation or specified as a parameter to the commandlet.&lt;/p&gt;
&lt;p&gt;Once the new VM has been created, it will be started and the script will wait for NanoServer to start correctly. Once started, the IP address of the new VM is displayed and it should be immediately possible to use docker to communicate with the docker daemon on the VM.&lt;/p&gt;
&lt;h1 id="scripting-the-deployment-of-a-docker-swarm"&gt;Scripting the deployment of a Docker Swarm&lt;/h1&gt;
&lt;p&gt;Given it was now trivial to create docker hosts, I wrote a final commandlet which leverages previous commandlets to provision an entire docker swarm. This is done using the &lt;code&gt;New-Nano2DockerSwarm&lt;/code&gt; commandlet as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-Nano2DockerSwarm -MediaPath &amp;lt;Drive letter for Windows Server 2016&amp;gt; -ImagePath &amp;lt;Path to a previously created Nano2Docker.vhdx&amp;gt; -VMPath &amp;lt;Path to a location to store swarm host VMs&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, using our previous example and wanting to store new VM images in the 'C:\Nano2Docker\VMs' directory, the command would be:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-Nano2DockerSwarm -MediaPath G: -ImagePath &amp;quot;C:\Nano2Docker\Nano2Docker.vhdx&amp;quot; -VMPath &amp;quot;C:\Nano2Docker\VMs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command defaults to creating a single manager node and three worker nodes named 'n2d-mngr-0' and 'n2d-wrkr-0/1/2' respectively. All nodes will have already been joined to the swarm in the appropriate capacity and ready for services to be deployed using docker or docker-compose.
Again, the number of manager and worked nodes as well as the name prefix for each node can be changed via the appropriate arguments (use &lt;code&gt;Get-Help New-Nano2DockerSwarm&lt;/code&gt; to list the arguments).&lt;/p&gt;
&lt;h1 id="roundup"&gt;Roundup&lt;/h1&gt;
&lt;p&gt;I've successfully used this script to provision multiple docker hosts and docker swarms but it's worthwhile noting that it can be a bit finickity with directories. If you can an error saying it couldn't find a directory then simply create it first. I really ought to fix up the script (improvements via PR gratefully accepted) but I'm now a bit busy deploying services to my swarm :0)&lt;/p&gt;
&lt;p&gt;Furthermore I've successfully used nodes created by this script to provision a hybrid swarm (see the 'Mixed OS clusters section &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;here&lt;/a&gt;) of boot2docker and nano2docker images. With the appropriate labels on the nodes, it is possible to use &lt;code&gt;docker-compose&lt;/code&gt; to automatically deploy images to the correct hosts while retaining all the benefits of overlay networking.&lt;/p&gt;
&lt;p&gt;It's a lot of docking fun!&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Unicorn Pi Tweet Bot</title>
			<link>http://ian.bebbs.co.uk/posts/RaspberryPiUnicornTwitterBot</link>
			<description>&lt;p&gt;So, my partner and I - being &lt;a href="https://www.stem.org.uk/stem-ambassadors/ambassadors"&gt;STEM Ambassadors&lt;/a&gt; - were asked to prepare and present a talk about Raspberry Pis for a local university on &lt;a href="http://www.inwed.org.uk/"&gt;International Women In Engineering Day&lt;/a&gt;. Unfortunately, this invitation came rather late as a previous presenter had dropped out and this left very little time to prepare.&lt;/p&gt;</description>
			<enclosure url="https://i.ytimg.com/vi/g3sxXgLr1uQ/maxresdefault.jpg" length="0" type="image" />
			<guid>http://ian.bebbs.co.uk/posts/RaspberryPiUnicornTwitterBot</guid>
			<pubDate>Wed, 21 Jun 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;So, my partner and I - being &lt;a href="https://www.stem.org.uk/stem-ambassadors/ambassadors"&gt;STEM Ambassadors&lt;/a&gt; - were asked to prepare and present a talk about Raspberry Pis for a local university on &lt;a href="http://www.inwed.org.uk/"&gt;International Women In Engineering Day&lt;/a&gt;. Unfortunately, this invitation came rather late as a previous presenter had dropped out and this left very little time to prepare.&lt;/p&gt;
&lt;p&gt;While I had a couple of Pis around the house doing IoT related chores, I really wanted something a little more flashy to present so I quickly rushed out to the local Maplins and picked up a new Raspberry Pi 3 and a &lt;a href="https://shop.pimoroni.com/products/unicorn-hat"&gt;Pimoroni Unicorn HAT&lt;/a&gt; - the very definition of flashy.&lt;/p&gt;
&lt;img src="https://cdn.shopify.com/s/files/1/0174/1800/products/Unicorn_Still_4_1024x1024.jpg?v=1418813740" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Pimoroni Unicorn HAT"&gt;
&lt;p&gt;I then needed to think of something to &lt;strong&gt;do&lt;/strong&gt; with it.&lt;/p&gt;
&lt;p&gt;Wanting something interactive and, ideally, internet related (seeing a physical manifestation of an event in cyberspace really has 'wow' factor) I decided to write a Twitter bot that listens for a specific hashtag (#INWED17 in this instance) and scrolls the text of the tweet across the Unicorn HAT leds. As with most things of this nature, a short google session resulted in several articles / blog posts I could mash up to produce the desired effect. These were:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.raspberrypi.org/learning/getting-started-with-the-twitter-api/requirements/"&gt;Getting started with Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://learn.pimoroni.com/tutorial/unicorn-hat/getting-started-with-unicorn-hat"&gt;Settings up Unicorn HAT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/topshed/UnicornHatScroll"&gt;Unicorn HAT scroll&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All in it took about an hour to get the various dependencies installed (including dealling with a rather annoying &lt;a href="https://stackoverflow.com/questions/27341064/how-do-i-fix-importerror-cannot-import-name-incompleteread"&gt;'pip' error&lt;/a&gt;), accounts set up and code mashed together in order to get a functional app up and running. Not bad considering this was my first stab at writing Python on a Pi.&lt;/p&gt;
&lt;p&gt;I pushed the code to a &lt;a href="https://github.com/ibebbs/UnicornPiBot"&gt;Github repository&lt;/a&gt; but have included it below simply because I am impressed with how concise the it is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import sys
import random

from UHScroll import *
from twython import TwythonStreamer
from auth import (
    consumer_key,
    consumer_secret,
    access_token,
    access_token_secret
)

colours = ['red','white','pink','blue','green','cyan']

non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)

class UnicornPiBotStreamer(TwythonStreamer):
    def on_success(self, data):
        if 'text' in data:
            text = data['text'].translate(non_bmp_map)
            colour = random.choice(colours)
            print(text)
            unicorn_scroll(text, colour, 200, 0.05)

stream = UnicornPiBotStreamer(
    consumer_key,
    consumer_secret,
    access_token,
    access_token_secret
)

stream.statuses.filter(track='#INWED17')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I'm now beginning to see why Python has gained such traction in non-enterprise markets and will definitely consider using it for future projects. Skipping the edit-compile-run loop and simply interpretting the code via a command line call certainly makes for fast iterations but I don't think I'd appreciate it so much if I was trying to develop anything of any size/complexity.&lt;/p&gt;
&lt;p&gt;Anyway, having an exhibit visitors can interact with (albeit indirectly) will make a good addition to the &lt;a href="http://ian.bebbs.co.uk/posts/MonsterPi"&gt;other&lt;/a&gt; &lt;a href="https://www.raspberrypi.org/magpi/issues/40/"&gt;Pi&lt;/a&gt; &lt;a href="https://aiyprojects.withgoogle.com/voice"&gt;devices&lt;/a&gt; we'll be taking along and discussing.&lt;/p&gt;
&lt;p&gt;Really quite looking forward to it now...&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>A sentiment(al) analysis of why Red Dwarf is no longer funny</title>
			<link>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII</link>
			<description>&lt;p&gt;I've recently been working on a project that required some natural language processing. After a surprisingly brief search I came upon the &lt;a href="https://stanfordnlp.github.io/CoreNLP/"&gt;Stanford CoreNLP&lt;/a&gt; suite of tools and after playing with their &lt;a href="http://corenlp.run/"&gt;online demo&lt;/a&gt; was astounded at the capabilities it provided. Furthermore, it was free, could be run such that it provided a basic HTTP API and came packaged with everything it needed save a copy of the JRE.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII</guid>
			<pubDate>Wed, 12 Apr 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;I've recently been working on a project that required some natural language processing. After a surprisingly brief search I came upon the &lt;a href="https://stanfordnlp.github.io/CoreNLP/"&gt;Stanford CoreNLP&lt;/a&gt; suite of tools and after playing with their &lt;a href="http://corenlp.run/"&gt;online demo&lt;/a&gt; was astounded at the capabilities it provided. Furthermore, it was free, could be run such that it provided a basic HTTP API and came packaged with everything it needed save a copy of the JRE.&lt;/p&gt;
&lt;p&gt;Having recently &lt;a href="http://ian.bebbs.co.uk/posts/DockerAndKafka"&gt;enjoyed a lot of success&lt;/a&gt; running &lt;a href="https://zookeeper.apache.org/"&gt;various&lt;/a&gt; &lt;a href="https://kafka.apache.org/"&gt;JAVA&lt;/a&gt; &lt;a href="https://neo4j.com/product/"&gt;services&lt;/a&gt; inside a &lt;a href="https://www.docker.com/"&gt;Docker container&lt;/a&gt; running &lt;a href="https://technet.microsoft.com/en-us/windows-server-docs/get-started/getting-started-with-nano-server"&gt;Windows Nano Server&lt;/a&gt;, I decided to see if CoreNLP could be run like this too. Copying my previous &lt;a href="https://github.com/ibebbs/Docker/blob/master/Nanoserver-Zookeeper/Build.ps1"&gt;build script&lt;/a&gt; and &lt;a href="https://github.com/ibebbs/Docker/blob/master/Nanoserver-CoreNLP/Build.ps1"&gt;amending it&lt;/a&gt; to build a &lt;a href="https://hub.docker.com/r/ibebbs/nanonlp/"&gt;container running CoreNLP&lt;/a&gt; was ludicrously easy and in no time I had a local API I could hit to perform all the natural language processing I needed.&lt;/p&gt;
&lt;p&gt;Now, while the project I was working on mainly required the &lt;a href="https://stanfordnlp.github.io/CoreNLP/ner.html"&gt;&amp;quot;Named Entity Recognition&amp;quot;&lt;/a&gt; and &lt;a href="https://stanfordnlp.github.io/CoreNLP/openie.html"&gt;&amp;quot;Open IE&amp;quot;&lt;/a&gt; annotators, I was intrigued to see that CoreNLP also included a basic &lt;a href="https://stanfordnlp.github.io/CoreNLP/sentiment.html"&gt;Sentiment&lt;/a&gt; annotator. Given that I had written part one of this post back in January, had noted at the time how much I'd like to do sentiment analysis on the transcripts of Red Dwarf, and that I hadn't written a blog post since, I decided to take some time out and perform the sentiment analysis so that I could write this post.&lt;/p&gt;
&lt;p&gt;Again employing &lt;a href="https://jupyter.org/"&gt;Project Jupyter&lt;/a&gt; hosted on &lt;a href="https://notebooks.azure.com/"&gt;Azure Notebooks&lt;/a&gt; and using &lt;a href="http://fsharp.org/"&gt;F#&lt;/a&gt; coupled with &lt;a href="https://fslab.org/"&gt;FsLab&lt;/a&gt; as my primary language and toolkit, I had a lot of fun performing the analysis. Like last time, you can find the &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis/blob/master/SentimentAnalysisWithCoreNLP.ipynb"&gt;full notebook&lt;/a&gt; and source material in my &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis"&gt;Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note: As before, Github provides a &amp;quot;limited rendering only&amp;quot; so, to see all the charts running correctly you need to use the 'nbviewer' link shown below to see a full rendering of the notepad.&lt;/p&gt;
&lt;img src="https://mvpfyw-dm2306.files.1drv.com/y3mppldGfaYEhvWkV7mdUw26-lP3SOzlMTGFbf8slchIfjBL57IH-GrJev6ai_rISiHBKrom7Abg9YFjfhZ1ArOFT7a7mh4gJuGq-CErv1dun48GQC_BdhMV08fh6hbw400d9nHSEXJ0jA2nPBIrpOPNrOz0I3lVY1tu_L656ylQKg?width=660&amp;height=283&amp;cropmode=none" class="img-responsive" style="margin: auto; width:660; margin-top: 6px; margin-bottom: 6px;" alt="Open external view with nbviewer"/&gt;
&lt;p&gt;The best bit of all (note: spoilers ahead!) is that it seems my original conclusion may indeed have been wrong... or at least mis-attributed.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>A sentiment(al) analysis of why Red Dwarf is no longer funny</title>
			<link>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarf</link>
			<description>&lt;p&gt;Yesterday I had a lot of fun playing with &lt;a href="http://jupyter.org/"&gt;Project Jupyter&lt;/a&gt;. For those that aren't aware of this project, it's an effort to provide a workspace for performing repeatable experimentation with data. In short it mixes markdown editing capabilities with a &lt;a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;REPL&lt;/a&gt; environment for a large number of languages. From the website:&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarf</guid>
			<pubDate>Tue, 31 Jan 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Yesterday I had a lot of fun playing with &lt;a href="http://jupyter.org/"&gt;Project Jupyter&lt;/a&gt;. For those that aren't aware of this project, it's an effort to provide a workspace for performing repeatable experimentation with data. In short it mixes markdown editing capabilities with a &lt;a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;REPL&lt;/a&gt; environment for a large number of languages. From the website:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;&amp;quot;a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, machine learning and much more&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After having my interest tweaked by the &lt;a href="https://try.jupyter.org/"&gt;browser version&lt;/a&gt; I bit the bullet and spent ages downloading and installing the &lt;a href="http://jupyter.org/install.html"&gt;full version&lt;/a&gt; to a virtual machine. It's a Python based web-app so requires quite a bit of setup and unfortunately I found the documentation to be a bit sparse.&lt;/p&gt;
&lt;p&gt;And so it was that while trying to work out how to install the &lt;a href="https://github.com/fsprojects/IfSharp"&gt;FSharp module&lt;/a&gt; I came across &lt;a href="https://notebooks.azure.com/"&gt;Azure Notebooks&lt;/a&gt;. This is a free, Azure hosted version of Jupyter that has almost all the features of a local installation but with none of the faff. After quickly spinning up a new notebook here I didn't even look back at the local installation.&lt;/p&gt;
&lt;h2 id="a-jupyter-data-mining-core-project"&gt;A Jupyter [Data] Mining Core Project&lt;/h2&gt;
&lt;p&gt;As per the title and lead of this post, I decided to use Jupyter to have a little fun.&lt;/p&gt;
&lt;p&gt;Back in September, while grinding my way through &lt;a href="http://www.imdb.com/title/tt0094535/episodes?season=11&amp;amp;ref_=tt_eps_sn_11"&gt;season 11 of Red Dwarf&lt;/a&gt;, I began to wonder why it wasn't as funny as it used to be. Had the writing deteriorated? Were the actors past it? Or were these elements still as great as they used to be and it was me who had changed?&lt;/p&gt;
&lt;p&gt;I started thinking about ways this could be investigated such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using IMDB rating as a measure of humour in each episode of Red Dwarf&lt;/li&gt;
&lt;li&gt;Performing semantic analysis of episode's transcript to see if the sentiment had changed&lt;/li&gt;
&lt;li&gt;Using word-count to determine whether there was a correlation between character participation and overall humour&lt;/li&gt;
&lt;li&gt;etc&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, it was a funny notion and provided a pleasant distraction from the &lt;a href="http://www.imdb.com/title/tt5218266"&gt;pretty awful episode&lt;/a&gt; of Red Dwarf I was watching at the time. I added it to my &amp;quot;ideas&amp;quot; list in &lt;a href="https://trello.com/b/KoTWuFUi/public-board"&gt;Trello&lt;/a&gt;, finished the episode and went to bed.&lt;/p&gt;
&lt;p&gt;Yesterday, when I came across Project Jupyter, I knew it'd be a great medium for performing this investigation so shifted the analysis from &amp;quot;Ideas&amp;quot; to &amp;quot;In progress&amp;quot; and got cracking.&lt;/p&gt;
&lt;h2 id="data-science-using-f"&gt;Data Science using F#&lt;/h2&gt;
&lt;p&gt;Now, while in relation to this investigation I use the term &amp;quot;data science&amp;quot; to basically mean &amp;quot;munging a few numbers and drawing a few graphs&amp;quot;, I do think F# makes a fantastic language for the discipline in general. It has some incredible mechanisms for &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/fsharp/tutorials/type-providers/"&gt;acquiring&lt;/a&gt; and &lt;a href="http://fsharpforfunandprofit.com/posts/the-option-type/"&gt;cleaning&lt;/a&gt; data as well as for &lt;a href="http://www.quanttec.com/fparsec/"&gt;parsing natural language&lt;/a&gt;. Couple this with it's concise, functional, elegant language and the ability to leverage components from the entire breadth of .NET ecosystem and you have quite a significant offering.&lt;/p&gt;
&lt;h2 id="azure-notebooks"&gt;Azure Notebooks&lt;/h2&gt;
&lt;p&gt;The Azure implementation of Project Jupyter is first class and, for now at least, totally free. Getting started is as simple as logging in with Microsoft credentials and then clicking 'Add notebook'. Being an MS implementation, I used Edge to edit the notebook and found the experience extremely robust, especially given it's a &amp;quot;Preview&amp;quot; program.&lt;/p&gt;
&lt;p&gt;In fact I experience just two issues while authoring my notebook:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data Store - It's not currently possible to upload or store data within the Azure notebook library (despite having functionality to do this in the web-interface). Instead you need to host your data on one of a small number of whitelisted sites. Fortunately Github is one of these sites so this doesn't prove to be much of an issue.&lt;/li&gt;
&lt;li&gt;Packages - While Azure Notebooks provides access to a large number of packages &amp;quot;out-of-the-box&amp;quot; (i.e. FSharp.Data, XPlot.Plotly, etc) it can be tricky to add/use other packages. For example, I wanted to use the XPlot.GoogleCharts package (as it provided trendline capabilities) and ended up having to write a custom display printer for it to work (due to an &lt;a href="https://github.com/fsprojects/IfSharp/issues/118"&gt;open issue&lt;/a&gt; on Github).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Apart from these issues, authoring and scripting F# in an Azure Notebook was almost as fast as using &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/fsharp/tutorials/fsharp-interactive/"&gt;&amp;quot;F# Interactive&amp;quot;&lt;/a&gt;. It even provides Intellisense capabilities but, in practice, these are usually too slow to be of actual use.&lt;/p&gt;
&lt;h2 id="sharing-notebooks"&gt;Sharing Notebooks&lt;/h2&gt;
&lt;p&gt;From Azure Notebooks you're able to download your notebook as a native &amp;quot;.ipynb&amp;quot; file (in fact this is encouraged as MS reserves the right to remove unused notebooks after 60 days). You can then share this file to other people who have Jupyter installed or, preferably, commit it to a repository in Github which has excellent support for Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;You can find my notebook &amp;quot;A sentiment(al) analysis of why Red Dwarf is no longer funny (to me)&amp;quot; &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis/blob/master/Investigation.ipynb"&gt;here&lt;/a&gt;. As you will see when you click the link, Github not only shows you the static parts of the notebook but actually tries to spin up a kernel and execute the code parts too. This is a &amp;quot;limited rendering only&amp;quot; so Github also provides a link to open the notebook in 'nbviewer' &lt;a href="http://nbviewer.jupyter.org/github/ibebbs/RedDwarfAnalysis/blob/2712285e1f9c69fc347bdfe6404792101eaea5f1/Investigation.ipynb"&gt;web-app&lt;/a&gt;. This link is shown below:&lt;/p&gt;
&lt;img src="https://mvpfyw-dm2306.files.1drv.com/y3mppldGfaYEhvWkV7mdUw26-lP3SOzlMTGFbf8slchIfjBL57IH-GrJev6ai_rISiHBKrom7Abg9YFjfhZ1ArOFT7a7mh4gJuGq-CErv1dun48GQC_BdhMV08fh6hbw400d9nHSEXJ0jA2nPBIrpOPNrOz0I3lVY1tu_L656ylQKg?width=660&amp;height=283&amp;cropmode=none" class="img-responsive" style="margin: auto; width:660; margin-top: 6px; margin-bottom: 6px;" alt="Open external view with nbviewer"/&gt;
&lt;h2 id="the-analysis"&gt;The analysis&lt;/h2&gt;
&lt;p&gt;I had timeboxed my investigation into Project Jupyter and therefore didn't get round to performing an actual sentiment anaylsis of the content of each episode. However I did manage to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Programmatically download episode information from several sources in JSON format and use &lt;a href="http://fsharp.github.io/FSharp.Data/library/JsonValue.html"&gt;JsonValue&lt;/a&gt; to dynamically query these sources&lt;/li&gt;
&lt;li&gt;Scrape demographically categorized rating information from IMDB and use &lt;a href="http://fsharp.github.io/FSharp.Data/reference/fsharp-data-htmldocument.html"&gt;HtmlDocument&lt;/a&gt; to parse the data into strong types&lt;/li&gt;
&lt;li&gt;Resolve issue with rendering XPlot.GoogleCharts charts within the notebook and use these charts to provide an interactive visualisation of the decline in rating of Red Dwarf across time and demographic categories.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This provided a fair stab at correlating episode rating with the overall decline in Red Dwarf's humourousness but is a long way short of any form of &amp;quot;data science&amp;quot;. It was both enlightening and a lot of fun doing this small project and I will certainly consider Azure Notebooks as a valuable tool in my toolbox.&lt;/p&gt;
&lt;p&gt;Should I find the time, I would certainly like to return to this project and use &lt;a href="http://www.quanttec.com/fparsec/"&gt;FParsec&lt;/a&gt; and &lt;a href="https://azure.microsoft.com/en-gb/services/cognitive-services/text-analytics/"&gt;Azure Text Analytics&lt;/a&gt; to perform an actual sentiment analysis. Hopefully it'll overturn, or at least help justify, my somewhat disturbing conclusion!&lt;/p&gt;
</content:encoded>
		</item>
	</channel>
</rss>
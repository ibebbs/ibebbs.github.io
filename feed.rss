<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
	<channel>
		<title>Ian Bebbington</title>
		<link>http://ian.bebbs.co.uk/</link>
		<description>IObservable&lt;Opinion&gt;</description>
		<copyright>2019</copyright>
		<pubDate>Mon, 18 Nov 2019 16:28:41 GMT</pubDate>
		<lastBuildDate>Mon, 18 Nov 2019 16:28:41 GMT</lastBuildDate>
		<item>
			<title>Augmenting the .NET Core 3.0 Generic Host</title>
			<link>http://ian.bebbs.co.uk/posts/AugmentingTheGenericHost</link>
			<description>&lt;p&gt;I love the .NET Core 3.0 Generic Host, I really do. As a framework for simplifying common scaffolding and lifetime management of long-running services, it's &lt;em&gt;almost&lt;/em&gt; faultless. Unfortunately, the mere fact of &lt;a href="http://tomasp.net/blog/2015/library-frameworks/"&gt;being a framework rather than a library&lt;/a&gt; can lead to issues where, as a user of the framework, you're unable to accomplish a specific goal. For me, this happened while trying to get instrumentation written to a various &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing.eventsource"&gt;EventSource&lt;/a&gt; instances to be output - in a configurable manner - through the Generic Host's logging infrastructure. Sounds simple huh, and it really ought to be. But it wasn't. Here's why:&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/AugmentingTheGenericHost</guid>
			<pubDate>Mon, 18 Nov 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="background"&gt;Background&lt;/h1&gt;
&lt;p&gt;I love the .NET Core 3.0 Generic Host, I really do. As a framework for simplifying common scaffolding and lifetime management of long-running services, it's &lt;em&gt;almost&lt;/em&gt; faultless. Unfortunately, the mere fact of &lt;a href="http://tomasp.net/blog/2015/library-frameworks/"&gt;being a framework rather than a library&lt;/a&gt; can lead to issues where, as a user of the framework, you're unable to accomplish a specific goal. For me, this happened while trying to get instrumentation written to a various &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing.eventsource"&gt;EventSource&lt;/a&gt; instances to be output - in a configurable manner - through the Generic Host's logging infrastructure. Sounds simple huh, and it really ought to be. But it wasn't. Here's why:&lt;/p&gt;
&lt;h1 id="the-open-closed-principle"&gt;The Open-Closed Principle&lt;/h1&gt;
&lt;p&gt;In the unlikely event you're not familiar with this principle, you can read about it &lt;a href="https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Generic Host is a beacon of SOLID-design and seems to embrace the 'Open-closed principal' particularly closely. Perhaps this is due to the fact that, almost by definition, the Generic Host needs to be extremely extensible. Therefore, to ensure it's able to guide it's users into the &lt;a href="https://blog.codinghorror.com/falling-into-the-pit-of-success/"&gt;pit of success&lt;/a&gt;, the implementation of the Generic Host closes many avenues for modifying its default behaviours.&lt;/p&gt;
&lt;p&gt;Unfortunately there are instances where users have good reason to want to modify default behaviour. For example, there have been &lt;a href="https://github.com/aspnet/Extensions/issues/1151"&gt;multiple&lt;/a&gt; &lt;a href="https://github.com/aspnet/Extensions/issues/810"&gt;feature&lt;/a&gt; &lt;a href="https://github.com/aspnet/Extensions/issues/525"&gt;requests&lt;/a&gt; for the Generic Host to provide a means for consumers to add behaviour to the start-up routine &lt;em&gt;after&lt;/em&gt; the dependency injection container has been created but before it's used to resolve any &lt;code&gt;IHostedService&lt;/code&gt; instances. In each of these instances, the maintainers of the &lt;a href="https://github.com/aspnet/Extensions"&gt;Microsoft.Extensions repository&lt;/a&gt; have suggested alternatives for the specific use-case being mooted even though, in my opinion, these alternatives seem to be rather poor workarounds for what I believe to be a valid feature request.&lt;/p&gt;
&lt;p&gt;Why do I believe it's a valid feature when so many other &lt;a href="https://github.com/davidfowl"&gt;awesome&lt;/a&gt; &lt;a href="https://github.com/anurse"&gt;.NET&lt;/a&gt; &lt;a href="https://github.com/Tratcher"&gt;developers&lt;/a&gt; believe differently? Well, because the generic host itself uses this feature, as can be seen &lt;a href="https://github.com/aspnet/Extensions/blob/f4e9a5e1da193faad2338e0a8225a531a2c1417c/src/Hosting/Hosting/src/HostBuilder.cs#L242"&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;_appServices = _serviceProviderFactory.CreateServiceProvider(containerBuilder);

if (_appServices == null)
{
    throw new InvalidOperationException($&amp;quot;The IServiceProviderFactory returned a null IServiceProvider.&amp;quot;);
}

// resolve configuration explicitly once to mark it as resolved within the
// service provider, ensuring it will be properly disposed with the provider
_ = _appServices.GetService&amp;lt;IConfiguration&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, &lt;em&gt;for perfectly valid reasons&lt;/em&gt;, the Generic Host needs to perform an operation &lt;em&gt;after&lt;/em&gt; the service provider has been created but before any further types are resolved. I do not believe it's only the Generic Host infrastructure code that requires this entry-point. Indeed, this is the feature I required to ensure I could correctly instantiate and configure a singleton &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing.eventlistener"&gt;EventListener&lt;/a&gt; instance prior to events being written to (and potentially lost from) various EventSource instances throughout my code.&lt;/p&gt;
&lt;p&gt;So, rather than accept a workaround and potentially compromise some core requirements, I decided to see if there was a way I could implement the above feature without straying too far from canonical Generic Host start-up code.&lt;/p&gt;
&lt;h1 id="ihostapplicationlifetime"&gt;IHostApplicationLifetime&lt;/h1&gt;
&lt;p&gt;The GenericHost has an &lt;a href="https://github.com/aspnet/Extensions/blob/master/src/Hosting/Abstractions/src/IHostApplicationLifetime.cs"&gt;&lt;code&gt;IHostApplicationLifetime&lt;/code&gt;&lt;/a&gt; interface which is responsible for coordinating application lifetime notifications. Registered with the dependency injection container as a singleton, it is ordinarily injected into &lt;code&gt;IHostedService&lt;/code&gt; instances, providing the ability for any service to request that the application be stopped.&lt;/p&gt;
&lt;p&gt;However, this interface is also injected into the various &lt;code&gt;IHostLifetime&lt;/code&gt; implementations (i.e. &lt;a href="https://github.com/aspnet/Extensions/blob/master/src/Hosting/Hosting/src/Internal/ConsoleLifetime.cs"&gt;ConsoleLifetime&lt;/a&gt; for console applications, &lt;a href="https://github.com/aspnet/Extensions/blob/master/src/Hosting/WindowsServices/src/WindowsServiceLifetime.cs"&gt;WindowsServiceLifetime&lt;/a&gt; for Windows services, etc) and, as such, it is instantiated once, after the dependency injection container is created but before any &lt;code&gt;IHostedService&lt;/code&gt; instances are resolved.&lt;/p&gt;
&lt;p&gt;Sounds useful huh.&lt;/p&gt;
&lt;p&gt;Best of all, this interface provides the means to react to application start and stop events via a &lt;a href="https://github.com/aspnet/Extensions/blob/f4e9a5e1da193faad2338e0a8225a531a2c1417c/src/Hosting/Hosting/src/Internal/ConsoleLifetime.cs#L48"&gt;novel use of &lt;code&gt;CancellationToken&lt;/code&gt; instances&lt;/a&gt;. I therefore chose this as my entry point for providing required functionality.&lt;/p&gt;
&lt;h1 id="applicationlifetimeex-ugh"&gt;ApplicationLifetimeEx (ugh)&lt;/h1&gt;
&lt;p&gt;Inheriting from the default the &lt;a href="https://github.com/aspnet/Extensions/blob/master/src/Hosting/Hosting/src/Internal/ApplicationLifetime.cs"&gt;IHostApplicationLifetime implementation&lt;/a&gt;, registering callbacks for the &lt;code&gt;ApplicationStarted&lt;/code&gt; and &lt;code&gt;ApplicationStopping&lt;/code&gt; cancellation tokens and then registering the derived class as the new &lt;code&gt;IHostApplicationLifetime&lt;/code&gt; implementation in the Generic Host's DI container worked perfectly. Using this approach I was able to leverage standard generic host start-up code and functionality to resolve an EventListener, with configuration, prior to any further types being instantiated.&lt;/p&gt;
&lt;p&gt;An example of this can be found in the development branch my Cogenity.Extensions repository &lt;a href="https://github.com/ibebbs/Cogenity.Extensions/tree/develop/src/Cogenity.Extensions.Logging.EventSource"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="sounds-good.so-why-only-in-the-development-branch"&gt;Sounds good. So why only in the development branch?&lt;/h1&gt;
&lt;p&gt;Well, this approach has &lt;em&gt;a lot&lt;/em&gt; of drawbacks, the most significant of which being that it fails to adhere to another important OO design principal; that of &lt;a href="https://en.wikipedia.org/wiki/Composition_over_inheritance"&gt;'Composition over inheritance'&lt;/a&gt;. In fact, the above approach - in it's current form - is not composable &lt;em&gt;at all&lt;/em&gt;. If another library wanted to hijack the IHostApplicationLifetime interface in a similar way, then my implementation (and associated functionality) would be entirely lost.&lt;/p&gt;
&lt;p&gt;As the Generic Host goes to great lengths to ensure that composability is maintained at all times and in all configurations  &lt;em&gt;this approach is probably not one I would recommend&lt;/em&gt;. Given there are no better options at the current time, I will probably proceed with this implementation as, to me, it is a &lt;a href="https://en.wikipedia.org/wiki/White_box_%28software_engineering%29"&gt;white box&lt;/a&gt;, but I don't intend to make a packaged version available for general consumption.&lt;/p&gt;
&lt;p&gt;That said, when the &lt;a href="https://github.com/aspnet/Extensions/issues/2653"&gt;suggested decoration extensions&lt;/a&gt; are made available, decorating the default IHostApplicationLifetime implementation will become a composable operation and this approach could suddenly become a lot more attractive.&lt;/p&gt;
&lt;h1 id="until-then"&gt;Until then...&lt;/h1&gt;
&lt;p&gt;... I kind of hope the project maintainers will take another look at these feature requests and provide a more holistic solution. Perhaps something along the lines of:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;private static async Task Main(string[] args)
{
    var builder = Host.CreateDefaultBuilder(args)
        .ConfigureServices(
            services =&amp;gt;
            {
                ...
            })
        .ConfigureApplicationLifetime(
            (applicationLifetime, appServices) =&amp;gt;
            {
                applicationLifetime.ApplicationStarted.Register(() =&amp;gt; [do something with appServices])
            }
        );

    await builder
        .Build()
        .RunAsync();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I think this could be quite nice as the GenericHost could then move the&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;// resolve configuration explicitly once to mark it as resolved within the
// service provider, ensuring it will be properly disposed with the provider
_ = _appServices.GetService&amp;lt;IConfiguration&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;block into a &lt;code&gt;ConfigureApplicationLifetime&lt;/code&gt; configuration call back within the &lt;code&gt;CreateDefaultBuilder&lt;/code&gt; call.&lt;/p&gt;
&lt;p&gt;Of course, this signature would provide all sorts of opportunities for naughtiness and smells and, while I could probably implement it using the method described above, I'm very much hoping the great minds behind this project might be able to propose something a little safe.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Light-weight run-time composition for the .NET Core 3.0 Generic Host</title>
			<link>http://ian.bebbs.co.uk/posts/LightweightRuntimeCompositionForGenericHost</link>
			<description>&lt;p&gt;&lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition"&gt;Cogenity.Extensions.Hosting.Composition&lt;/a&gt; can provide lightweight, runtime composition for the &lt;a href="(https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.0)"&gt;.NET Core 3.0 Generic Host&lt;/a&gt;... with some caveats. &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition/issues/5"&gt;An issue&lt;/a&gt; has been created as an RFC on how best to address these caveats with comments/contributions welcomed.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/LightweightRuntimeCompositionForGenericHost</guid>
			<pubDate>Mon, 11 Nov 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="tldr"&gt;TL;DR&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition"&gt;Cogenity.Extensions.Hosting.Composition&lt;/a&gt; can provide lightweight, runtime composition for the &lt;a href="(https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.0)"&gt;.NET Core 3.0 Generic Host&lt;/a&gt;... with some caveats. &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition/issues/5"&gt;An issue&lt;/a&gt; has been created as an RFC on how best to address these caveats with comments/contributions welcomed.&lt;/p&gt;
&lt;h1 id="did-you-know"&gt;Did you know...&lt;/h1&gt;
&lt;p&gt;The &lt;a href="https://github.com/aspnet/AspNetCore/issues/9337"&gt;.NET Core 3.0 web stack has been &amp;quot;re-platformed&amp;quot; onto the generic host library&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;Furthermore, did you know that &lt;code&gt;WebHost&lt;/code&gt; allows you to &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/platform-specific-configuration?view=aspnetcore-3.0"&gt;load additional non-referenced assemblies at runtime which can participate in service start-up by implementing the &lt;code&gt;IHostingStartup&lt;/code&gt; interface&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;Well neither did I until I started looking for a way to perform runtime-composition for a service utilizing the &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.0"&gt;.NET Core 3.0 Generic Host&lt;/a&gt;. It turns out that, while both the changes above are great for the web-platform, nothing similar exists out-of-the-box for the Generic Host. So here's what I did...&lt;/p&gt;
&lt;h1 id="background"&gt;Background&lt;/h1&gt;
&lt;p&gt;I'm currently working on a very interesting project which I hope to see open-sourced in a few weeks time. At the moment it's being developed behind closed doors but with various reusable components being segregated into open-source projects/packages for use by the community.&lt;/p&gt;
&lt;p&gt;One facet of this project is a .NET Core 3.0 service which needs to be deployable in a variety of environments and across a number of platforms. While this service provides a set of core behaviours, these behaviours need to be augmented by arbitrary functionality specific to the environment/platform the service is being used within.&lt;/p&gt;
&lt;p&gt;So it was that I came to look for a means to provide light-weight runtime-composition to services implemented using the .NET Core 3.0 Generic Host and, to my surprise, came up empty handed.&lt;/p&gt;
&lt;h1 id="wait-runtime-composition"&gt;Wait, runtime composition?&lt;/h1&gt;
&lt;p&gt;Yes, the ability to add functionality/behaviours to a software component, ostensibly by loading additional assemblies at runtime, without requiring re-compilation of said software component.&lt;/p&gt;
&lt;p&gt;Specifically, my requirements were:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A simple, fast, lightweight means to safely load and configure additional assemblies at service start-up; and&lt;/li&gt;
&lt;li&gt;A means for these assemblies to participate in host composition (i.e. do something like '&lt;code&gt;IHostBuilder.UseRabbitMq&amp;lt;MyMessageHandler&amp;gt;()&lt;/code&gt;').&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With a couple of nice-to-haves:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Allow for multiple instances of a specific assembly to be loaded with different configurations.&lt;/li&gt;
&lt;li&gt;Allow multiple versions of specific assemblies to be loaded concurrently.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="surely-this-is-a-solved-problem"&gt;Surely this is a solved problem?&lt;/h1&gt;
&lt;p&gt;I thought so too. Having used MEF (the Managed Extensibility Framework) in the past I went to see if it had been ported to .NET Core and &lt;a href="https://www.nuget.org/packages/System.Composition"&gt;indeed it had&lt;/a&gt;. Unfortunately, it seems to have fallen out of favour and there's very little documentation about it's use in .NET Core and even less about how one might integrate it into the Generic Host.&lt;/p&gt;
&lt;p&gt;I then found &lt;a href="https://github.com/khellang/Scrutor"&gt;Scrutor&lt;/a&gt; which, while more integrated into the Generic Host eco-system (it provides fantastic assembly scanning and decoration capabilities specfically for Microsoft.Extensions.DependencyInjection), didn't provide a means for the discovered types to participate in host composition.&lt;/p&gt;
&lt;p&gt;Finally I discovered &lt;a href="https://github.com/dapplo/Dapplo.Microsoft.Extensions.Hosting"&gt;Dapplo.Microsoft.Extensions.Hosting&lt;/a&gt; which provides the &lt;a href="https://www.nuget.org/packages/Dapplo.Microsoft.Extensions.Hosting.Plugins/"&gt;Dapplo.Microsoft.Extensions.Hosting.Plugins&lt;/a&gt; package. This was extremely close to what I wanted but relied too heavily on directory scanning (thereby not meeting the &amp;quot;fast and safe&amp;quot; requirements) and, like Scrutor and MEF, also didn't provide a means to participate in host composition (the &amp;quot;plugins&amp;quot; only have access to the &lt;code&gt;HostBuilderContent&lt;/code&gt;).&lt;/p&gt;
&lt;h1 id="right-well-how-hard-can-this-be"&gt;Right, well how hard can this be?&lt;/h1&gt;
&lt;p&gt;Not that hard it turns out... but with several caveats.&lt;/p&gt;
&lt;p&gt;Within a few hours of deciding to roll-my-own solution to the requirements above, and by borrowing extensively from the various projects I'd already encountered, I'd written &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition"&gt;Cogenity.Extensions.Hosting.Composition&lt;/a&gt;. This solution used configuration (rather than directory scanning) to specify the additional assemblies to load and, like the Dapplo project, used .NET Core's &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.loader.assemblyloadcontext?view=netcore-3.0"&gt;&lt;code&gt;AssemblyLoadContext&lt;/code&gt;&lt;/a&gt; to provide scoping of loaded assemblies providing additional safety and reliability characteristics (in the abscence of AppDomains).&lt;/p&gt;
&lt;p&gt;A &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition/tree/master/samples"&gt;&lt;code&gt;GenericHostConsole&lt;/code&gt; sample project&lt;/a&gt; was written to show the library's use and demonstrate it's functionality which worked beautifully. From the host project, all that was required to provide runtime composition was a call to the &lt;code&gt;.UseComposition&lt;/code&gt; extension method and some associated configuration (I decided to use a &lt;a href="https://www.nuget.org/packages/NetEscapades.Configuration.Yaml"&gt;Yaml&lt;/a&gt; file but any &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-3.0"&gt;configuration provider&lt;/a&gt; could be used) as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;private static async Task Main(string[] args)
{
    var builder = Host.CreateDefaultBuilder(args)
        .ConfigureHostConfiguration(configurationBuilder =&amp;gt; configurationBuilder.AddCommandLine(args))
        .UseComposition(config =&amp;gt; config.AddYamlFile(args[0]), &amp;quot;composition&amp;quot;);

    await builder
        .Build()
        .RunAsync();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;composition:
  modules:
    - name: ConsoleWriter
      assembly: GenericHostConsole.Writer
      configurationSection: consolewriterConfiguration
      optional: true

consolewriterConfiguration:
  writeIntervalInSeconds: 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then additional assemblies could be provided (in this case &lt;code&gt;GenericHostConsole.Writer&lt;/code&gt;) which simply needed to implement the &lt;code&gt;IModule&lt;/code&gt; interface as shown here:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;public class Module : IModule
{
    public IHostBuilder Configure(IHostBuilder hostbuilder, string configurationSection)
    {
        return hostbuilder
            .ConfigureServices(
                (hostBuilderContext, serviceCollection) =&amp;gt;
                {
                    serviceCollection.AddOptions&amp;lt;Configuration&amp;gt;().Bind(hostBuilderContext.Configuration.GetSection(configurationSection));
                    serviceCollection.AddSingleton&amp;lt;IHostedService, Service&amp;gt;();
                })
            .ConfigureLogging((hostingContext, logging) =&amp;gt; logging.AddConsole());
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After compiling, copying the &lt;code&gt;GenericHostConsole.Writer&lt;/code&gt; assembly to the &lt;code&gt;GenericHostConsole&lt;/code&gt; project and running the latter's executable, the &lt;code&gt;GenericHostConsole.Writer.Service&lt;/code&gt; wrote to the console every two seconds, as configured.&lt;/p&gt;
&lt;h1 id="boom-done.well.sort-of"&gt;Boom! Done... well... sort of.&lt;/h1&gt;
&lt;p&gt;I returned to the project I required this for and followed the above pattern, expecting (ok, somewhat naively) everything to be rosy. &lt;em&gt;It failed spectacularly&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;You see, while my sample project for Cogenity.Extensions.Hosting.Composition, simply augmented the host by adding a new service with no other dependencies, the original project required new services to interact with core functionality provided by the project, mainly by injection of services defined in a 'common' assembly (i.e. one referenced both by the host project and the composition modules). Starting the project resulting in the DI container reporting that it couldn't locate implementations of required services despite those services being registered with the host's DI container (by throwing a &lt;code&gt;System.InvalidOperationException: Unable to resolve service for type '&amp;lt;service&amp;gt;' while attempting to activate '&amp;lt;consumer&amp;gt;')&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;It turned out that I was being bitten by the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Due to the requirement of needing to allow additional modules to participate in host composition, assemblies were being loaded at composition, not build time as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;var builder = Host.CreateDefaultBuilder(args)
    .ConfigureHostConfiguration(configurationBuilder =&amp;gt; configurationBuilder.AddCommandLine(args))
    .UseComposition(config =&amp;gt; config.AddYamlFile(args[0]), &amp;quot;composition&amp;quot;); // &amp;lt;- Assemblies loaded here
    .ConfigureServices(, serviceCollection) =&amp;gt; serviceCollection.AddSingleton&amp;lt;IEventBus, EventBus&amp;gt;())

await builder
    .Build() // &amp;lt;- Not here
    .RunAsync();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This meant that the &lt;code&gt;AssemblyLoadContext&lt;/code&gt; used to isolate module assemblies was loading new instances of 'common' assemblies rather than using the ones being registered by the host service (i.e. the IEventBus in the above example), thereby explaining why the various implementations couldn't be found.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="so-what-now"&gt;So what now?&lt;/h1&gt;
&lt;p&gt;Well, it can be used as-is for basic composition functionality, but it's really not what I need moving forward.&lt;/p&gt;
&lt;p&gt;I have considered several possible solutions ranging from simply removing assembly isolation (and no-longer providing the 'nice-to-haves') to working more intimately with the &lt;code&gt;HostBuilder.Build&lt;/code&gt; process to ensure shared assemblies are fully loaded prior to loading additional assemblies for composition. Each of the approaches have pros and cons which I am trying to consider from a 'general consumer' point of view before deciding on the solution to adopt.&lt;/p&gt;
&lt;p&gt;To this end, I have &lt;a href="https://github.com/ibebbs/Cogenity.Extensions.Hosting.Composition/issues/5"&gt;created an issue&lt;/a&gt; in the Github repository for this project in which I describe what I see as the various ways forward and, where possible, links to branches proving out the various approaches. I've labelled it as 'discussion' and would genuinely be interested to hear people's thoughts. If this project is of interest to you and/or you have suggestions about how best to resolve the above issues, please feel free to add a comment with your suggestions and/or requests for modified/additional functionality.&lt;/p&gt;
&lt;p&gt;If you require runtime composition for projects utilizing the .NET Core Generic Host then watch this space as I hope to have a more versatile solution in place within the next week or so.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Building .NET Core 3.0 With Azure Pipelines</title>
			<link>http://ian.bebbs.co.uk/posts/BuildingDotNetCore3WithAzurePipelines</link>
			<description>&lt;p&gt;My "go to" build system and package repository - &lt;a href="https://www.myget.org/"&gt;MyGet&lt;/a&gt; - doesn't yet support building .NET Core 3.0 (or more specifically .NET Standard 2.1) projects. Having recently read about some of the features Microsoft have been adding to Azure DevOps I thought I'd see how easy (or not) it was to get a Pipeline setup to build my project and publish the package back to MyGet.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/BuildingDotNetCore3WithAzurePipelines</guid>
			<pubDate>Fri, 04 Oct 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;My &amp;quot;go to&amp;quot; build system and package repository - &lt;a href="https://www.myget.org/"&gt;MyGet&lt;/a&gt; - doesn't yet support building .NET Core 3.0 (or more specifically .NET Standard 2.1) projects. Having recently read about some of the features Microsoft have been adding to Azure DevOps I thought I'd see how easy (or not) it was to get a Pipeline setup to build my project and publish the package back to MyGet.&lt;/p&gt;
&lt;h2 id="you-need-what"&gt;You need what?!?&lt;/h2&gt;
&lt;p&gt;Azure DevOps is very welcoming and it takes almost no time to set up your organisation and project... all for free no less! Unfortunately, when I then started creating a new build pipeline and selected GitHub in answer to the &amp;quot;Where is your code?&amp;quot; prompt, I was presented with this OAuth request:&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/YouNeedWhatNow.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="You need what now?"&gt;
&lt;p&gt;Yup. In order to build a single, public repository from my GitHub account, I needed to let Azure have access to &lt;em&gt;everything&lt;/em&gt;; public &lt;em&gt;and&lt;/em&gt; private. How about &amp;quot;No&amp;quot;.&lt;/p&gt;
&lt;h2 id="ahh-classic"&gt;Ahh, classic!&lt;/h2&gt;
&lt;p&gt;Fortunately, Azure provides a second means of creating a pipeline - ostensibly, but not necessarily, without Yaml - through the use of a small &amp;quot;Use the classic editor&amp;quot; hyperlink below the main options.&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/UseTheClassicEditor.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Guess I'll be using this then"&gt;
&lt;p&gt;When you do this, you're once again asked to &amp;quot;Select a source&amp;quot; and authenticate with that source as shown below. This time however, you're able to &amp;quot;Authorize with a GitHub personal access token&amp;quot;.&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/GitHubPersonalAccessToken.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="GitHub Personal Access Token"&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Note: it may be possible to use a &amp;quot;personal access token&amp;quot;&amp;quot; with the new &amp;quot;Where is your code?&amp;quot; editor. Unfortunately, I wasn't able to confirm this as I seemed to be stuck in a OAuth loop wherein, each time I click &amp;quot;GitHub&amp;quot;, it no longer asks me to log in but immediately prompts me to &amp;quot;Authorize Azure Pipelines&amp;quot; with all the privileges shown above. As there's no &amp;quot;Cancel&amp;quot; button, my only recourse is to use the browser's back button which doesn't seem to cancel the OAuth flow. ¯\&lt;em&gt;(ツ)&lt;/em&gt;/¯&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I then quickly nipped over to GitHub and created a personal access token (Settings-&amp;gt;Developer settings-&amp;gt;Personal access tokens) which only has access to &lt;em&gt;public&lt;/em&gt; repositories, web-hook settings and basic user information as shown below:&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/NewPersonalAccessToken.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="New Personal Access Token"&gt;
&lt;p&gt;Clicking &amp;quot;Generate token&amp;quot; provided me with a token which I copy/pasted into Azure pipelines. I was then able to select the repository I wanted to build from a list of only my public repositories. Ace!&lt;/p&gt;
&lt;h2 id="yet-still-with-yaml"&gt;Yet still with Yaml!&lt;/h2&gt;
&lt;p&gt;I was then asked to &amp;quot;Select a template&amp;quot;. At this point, I could elect to use a Yaml file (per the &amp;quot;new editor&amp;quot;) as shown below:&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/SelectATemplate.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Select A Token"&gt;
&lt;p&gt;This seemed to be exactly what I wanted until I realised that this path doesn't actually create a Yaml build template for you but instead expects find one in the repository.&lt;/p&gt;
&lt;p&gt;As I hadn't written an Azure Pipelines Yaml file before, the idea of creating one from scratch was a little daunting. I therefore decided to cheat. I copied the repository from GitHub to Azure DevOps Repos and recreated a build pipeline using the new &amp;quot;Where is your code?&amp;quot; editor. I then copied the Yaml file this produced into my GitHub repository and continued building this pipeline.&lt;/p&gt;
&lt;p&gt;So here's the template &lt;code&gt;azure-pipelines.yml&lt;/code&gt; file I ended up with:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;# ASP.NET Core (.NET Framework)
# Build and test ASP.NET Core projects targeting the full .NET Framework.
# Add steps that publish symbols, save build artifacts, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/dotnet-core

trigger:
- master

pool:
  vmImage: 'windows-latest'

variables:
  solution: '**/*.sln'
  buildPlatform: 'Any CPU'
  buildConfiguration: 'Release'

steps:
- task: NuGetToolInstaller&amp;#64;1

- task: NuGetCommand&amp;#64;2
  inputs:
    restoreSolution: '$(solution)'

- task: VSBuild&amp;#64;1
  inputs:
    solution: '$(solution)'
    msbuildArgs: '/p:DeployOnBuild=true /p:WebPublishMethod=Package /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true /p:DesktopBuildPackageLocation=&amp;quot;$(build.artifactStagingDirectory)\WebApp.zip&amp;quot; /p:DeployIisAppPath=&amp;quot;Default Web Site&amp;quot;'
    platform: '$(buildPlatform)'
    configuration: '$(buildConfiguration)'

- task: VSTest&amp;#64;2
  inputs:
    platform: '$(buildPlatform)'
    configuration: '$(buildConfiguration)'
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="its-good-but-its-not-right"&gt;It's good but it's not right&lt;/h2&gt;
&lt;p&gt;Not a bad start but this template was designed to &amp;quot;Build and test ASP.NET Core projects targeting the full .NET Framework.&amp;quot;. I wasn't targeting the full .NET Framework so I &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/?view=azure-devops"&gt;hit the books&lt;/a&gt; and quickly found a section on the &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/dotnet-core?view=azure-devops"&gt;.NET Core Ecosystem&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The information here allowed me to move from &lt;code&gt;VSBuild&lt;/code&gt; based tasks to &lt;code&gt;dotnet&lt;/code&gt; based scripts. Moving to using Ubuntu for the build, only including build steps and removing everything else resulted in this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;trigger:
- master

pool:
  vmImage: 'ubuntu-16.04'

variables:
  solution: '**/*.sln'
  buildPlatform: 'Any CPU'
  buildConfiguration: 'Release'
  version: 1.0.1

steps:
- script: dotnet restore
- script: dotnet build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tentatively, I enqueued a build which resulted in...&lt;/p&gt;
&lt;h2 id="a-spectacular-failure"&gt;A spectacular failure&lt;/h2&gt;
&lt;p&gt;It didn't take long to find the cause of the failure. Digging into the build logs showed the following failure for one of the script steps:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;&amp;quot;The current .NET SDK does not support targeting .NET Standard 2.1.  Either target .NET Standard 2.0 or lower, or use a version of the .NET SDK that supports .NET Standard 2.1.&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&amp;quot;Oh, exactly the same error as Myget&amp;quot; I thought. Fortunately, from perusing the documentation earlier, I had come across the section on &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/dotnet-core?view=azure-devops#build-environment"&gt;&amp;quot;Build Environment&amp;quot;&lt;/a&gt; and the fact that the Microsoft-hosted build agents don't provide all versions of the .NET Core SDK. They do however provide a very simple means of installing additional frameworks by simply adding a &amp;quot;DotNetCoreInstaller&amp;quot; task to your Yaml. I figured it couldn't hurt to try and amended my 'azure-pipelines.yml` to this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;trigger:
- master

pool:
  vmImage: 'ubuntu-16.04'

variables:
  solution: '**/*.sln'
  buildPlatform: 'Any CPU'
  buildConfiguration: 'Release'
  version: 1.0.1

steps:
- task: UseDotNet&amp;#64;2
  displayName: 'Use .NET Core sdk'
  inputs:
    packageType: sdk
    version: 3.x
    installationPath: $(Agent.ToolsDirectory)/dotnet
- script: dotnet restore
- script: dotnet build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And, somewhat amazingly, it worked.&lt;/p&gt;
&lt;h2 id="move-em-on-head-em-up"&gt;Move 'em on, head 'em up!&lt;/h2&gt;
&lt;p&gt;With a successful build running, all that was left was to package the built assembly into a nuget package and push it to MyGet. From prior reading I knew that the first thing I had to do here was add a &amp;quot;Service Connection&amp;quot; to the project from the settings. Which.... are.... where???&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/ProjectSettings.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Project Settings"&gt;
&lt;p&gt;Ah, here they are! Of course! Hidden until you [accidentally] move your mouse over project header bar. (!?!)&lt;/p&gt;
&lt;img src="../Content/BuildingADotNetCore3LibraryWithAzurePipelines/AhHereTheyAre.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Ah Here They Are!"&gt;
&lt;p&gt;Weird.&lt;/p&gt;
&lt;p&gt;Anyway, having finally found the project settings I was able to add a new &amp;quot;Nuget&amp;quot; connection (from &amp;quot;Pipelines-&amp;gt;Service connections&amp;quot;) which I populated with details provided by MyGet. I then populated the package settings within my library's &lt;code&gt;.csproj&lt;/code&gt; file and enabled the &amp;quot;Generate Nuget package on build&amp;quot; setting. With this all done, I simply needed 'push' the package as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;trigger:
- master

pool:
  vmImage: 'ubuntu-16.04'

variables:
  solution: '**/*.sln'
  buildPlatform: 'Any CPU'
  buildConfiguration: 'Release'
  version: 1.0.1

steps:
- task: UseDotNet&amp;#64;2
  displayName: 'Use .NET Core sdk'
  inputs:
    packageType: sdk
    version: 3.x
    installationPath: $(Agent.ToolsDirectory)/dotnet
- script: dotnet restore
- script: dotnet build
- task: NuGetCommand&amp;#64;2
  inputs:
    command: push
    nuGetFeedType: external
    packagesToPush: '$(Build.Repository.LocalPath)/**/*.nupkg;!$(Build.Repository.LocalPath)/**/*.symbols.nupkg'
    publishFeedCredentials: 'MyGet Bebbs Feed'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the compiled package appeared in my MyGet repository. Boom!&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I am very impressed with Azure pipelines. The tools they've made available in their Yaml based build system are fantastic and make building a project easy and clean yet flexible and powerful. Furthermore, the actual build process is very fast. From git push to package in my nuget repository took less than a minute. Yes, it's just a small library without any tests (for now), but each build required installing a new version of the .NET Core SDK onto the build agent and, even though this was all hosted on the Free tier, I never had to wait for a build agent to become available.&lt;/p&gt;
&lt;p&gt;If they could just tighten up the OAuth permission requested from GitHub I'd be very tempted to adopt Azure DevOps for all my projects. I'd certainly consider recommending it to clients should they be looking to move away from other CI/CD solutions.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Using A Touch Overlay, In Portrait, On Raspbian Buster</title>
			<link>http://ian.bebbs.co.uk/posts/UsingATouchOverlayInPortrainOnRaspbian</link>
			<description>&lt;p&gt;This is just a short post - mostly for my own benefit - on how to use a touch-overlay, in portrait, on Raspbian Buster&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/UsingATouchOverlayInPortrainOnRaspbian</guid>
			<pubDate>Thu, 03 Oct 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;This is just a short post - mostly for my own benefit - on how to use a touch-overlay, in portrait, on Raspbian Buster&lt;/p&gt;
&lt;p&gt;These instructions are for using a standard HDMI monitor (I'm using a Samsung ME46B) and USB Touchscreen overlay (I'm using a Samsung TM46LBC) in a &lt;code&gt;right&lt;/code&gt; portrait (i.e rotated 270° clockwise) configuration. They probably won't work for hat/phat style LCDs with built-in touch-panels.&lt;/p&gt;
&lt;h2 id="changing-to-portrait"&gt;Changing to portrait&lt;/h2&gt;
&lt;p&gt;Raspbian Buster has moved to the 'G2 GL (Fake KMS) OpenGL desktop driver with fake KMS' OpenGL driver by default (&lt;code&gt;dtoverlay=vc4-fkms-v3d&lt;/code&gt; in &lt;code&gt;/boot/config.txt&lt;/code&gt;). Fortunately, as they moved to the 'fake' driver, you're still given significant control over the display configuration from &lt;code&gt;/boot/config.txt&lt;/code&gt; and changing the display orientation remains unchanged.&lt;/p&gt;
&lt;p&gt;As such, use the command &lt;code&gt;sudo nano /boot/config.txt&lt;/code&gt; to start editing the file and add the following lines at the bottom (uncommenting the appropriate line):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# display_rotate=1 # rotate 90° clockwise
# display_rotate=2 # rotate 180° clockwise
display_rotate=3 # rotate 270° clockwise
avoid_warnings=1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reboot the Pi (&lt;code&gt;sudo reboot&lt;/code&gt;) and you should see that the display is now in the correct orientation.&lt;/p&gt;
&lt;h2 id="correcting-overscan"&gt;Correcting Overscan&lt;/h2&gt;
&lt;p&gt;Before moving onto installing/calibrating the touch-panel, it is well worth spending some time correcting the Overscan on your display. To do this, again edit &lt;code&gt;config.txt&lt;/code&gt; and find lines similar to below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# uncomment this if your display has a black border of unused pixels visible
# and your display can output without overscan
disable_overscan=0

# uncomment the following to adjust overscan. Use positive numbers if console
# goes off screen, and negative if there is too much border
overscan_left=-10
overscan_right=-10
overscan_top=8
overscan_bottom=8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The values you see above are those required to make my panel display correctly (nothing off-screen, no big borders). If you need to change overscan you'll need to find the values that work for you by changing values and rebooting to see the effect.&lt;/p&gt;
&lt;h2 id="calibrating-the-touch-panel"&gt;Calibrating the Touch-Panel&lt;/h2&gt;
&lt;p&gt;While the touch panel I am using was correctly identified as a 'Nexio Touch Device' by &lt;code&gt;xinput --list&lt;/code&gt; getting it to respect the display orientation and calibrating it correctly turned out to be a pain. After &lt;em&gt;a lot&lt;/em&gt; of searching I finally found &lt;a href="https://www.instructables.com/id/Rotate-Raspberry-Pi-Display-and-Touchscreen/"&gt;two&lt;/a&gt; &lt;a href="https://www.raspberrypi.org/forums/viewtopic.php?t=179477#p1163460"&gt;posts&lt;/a&gt; which, when combined, got the touch panel working correctly.&lt;/p&gt;
&lt;p&gt;Firstly, you'll need to install the &lt;code&gt;evdev&lt;/code&gt; driver and the &lt;code&gt;xinput_calibrator&lt;/code&gt; using the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install xserver-xorg-input-evdev xinput_calibrator
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next locate the touch-panel display configuration file as described in this &lt;a href="https://www.instructables.com/id/Rotate-Raspberry-Pi-Display-and-Touchscreen/"&gt;instructable&lt;/a&gt;; mine was &lt;code&gt;/usr/share/X11/xorg.conf.d/40-libinput.conf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In this file, find the &lt;code&gt;InputClass&lt;/code&gt; Section which includes the Identifier &lt;code&gt;libinput touchscreen catchall&lt;/code&gt;. In this section, change the &lt;code&gt;Driver&lt;/code&gt; value from &lt;code&gt;libinput&lt;/code&gt; to &lt;code&gt;evdev&lt;/code&gt; and add a &lt;code&gt;TransformationMatrix&lt;/code&gt; option to reflect to display orientation as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Section &amp;quot;InputClass&amp;quot;
        Identifier &amp;quot;libinput touchscreen catchall&amp;quot;
        MatchIsTouchscreen &amp;quot;on&amp;quot;
        MatchDevicePath &amp;quot;/dev/input/event*&amp;quot;
        Driver &amp;quot;evdev&amp;quot; # &amp;lt;- change this
        Option &amp;quot;TransformationMatrix&amp;quot; &amp;quot;0 1 0 -1 0 1 0 0 1&amp;quot; # &amp;lt;- Add this
EndSection
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The exact transformation matrix you need is available in the instructable but I've repeated them here for easy reference:&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Angle&lt;/th&gt;
&lt;th&gt;Transformation Matrix&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;90°&lt;/td&gt;
&lt;td&gt;&amp;quot;0 -1 1 1 0 0 0 0 1&amp;quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;180°&lt;/td&gt;
&lt;td&gt;&amp;quot;-1 0 1 0 -1 1 0 0 1&amp;quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;270°&lt;/td&gt;
&lt;td&gt;&amp;quot;0 1 0 -1 0 1 0 0 1&amp;quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now, if you restart your Pi you should notice that the touch panel is at least in the correct orientation (mouse cursor moves in the same direction as your finger). To calibrate it such that the mouse cursor moves to exactly where you touch, use the &lt;code&gt;xinput_calibrator&lt;/code&gt; tool by running it from the Terminal window in a desktop session.&lt;/p&gt;
&lt;p&gt;Follow the instructions and &lt;code&gt;input_calibrator&lt;/code&gt; will do two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Correctly calibrate the display - the mouse cursor should now be under your touch; and&lt;/li&gt;
&lt;li&gt;Give you a block of text to add to persistent configuration as shown below:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;Calibrating EVDEV driver for &amp;quot;Nexio Touch Device(HS) Nexio HID Multi-Touch ATI0460-06 &amp;quot; id=7
	current calibration values (from XInput): min_x=15929, max_x=149 and min_y=16328, max_y=171

Doing dynamic recalibration:
	Setting calibration data: 15872, 0, 16498, -69
	--&amp;gt; Making the calibration permanent &amp;lt;--
  copy the snippet below into '/etc/X11/xorg.conf.d/99-calibration.conf' (/usr/share/X11/xorg.conf.d/ in some distro's)
Section &amp;quot;InputClass&amp;quot;
	Identifier	&amp;quot;calibration&amp;quot;
	MatchProduct	&amp;quot;Nexio Touch Device(HS) Nexio HID Multi-Touch ATI0460-06 &amp;quot;
	Option	&amp;quot;Calibration&amp;quot;	&amp;quot;15872 0 16498 -69&amp;quot;
	Option	&amp;quot;SwapAxes&amp;quot;	&amp;quot;0&amp;quot;
EndSection
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Follow the instructions it provides by copying the region from &lt;code&gt;Section &amp;quot;InputClass&amp;quot;&lt;/code&gt; down to &lt;code&gt;EndSection&lt;/code&gt; then using the following command to create (or edit) the persistent configuration file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo nano /usr/share/X11/xorg.conf.d/99-calibration.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Paste the block of text you copied earlier, save and exit, then reboot.&lt;/p&gt;
&lt;p&gt;Voila, a perfectly configured touch overlay. Enjoy!&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Tech Adventures in Sustainability</title>
			<link>http://ian.bebbs.co.uk/posts/TechAdventuresInSustainability-PartI</link>
			<description>&lt;p&gt;Installing solar panels and monitoring solar production not only provides immediate benefits in sustainable living but also highlights new, simple ways to change your lifestyle to further save money and energy. Here's how we do it.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/TechAdventuresInSustainability-PartI</guid>
			<pubDate>Thu, 26 Sep 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="tldr"&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;Installing solar panels and monitoring solar production not only provides immediate benefits in sustainable living but also highlights new, simple ways to change your lifestyle to further save money and energy. Here's how we do it.&lt;/p&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;As with most people nowadays, the environment and climate change is weighing heavily on my thoughts. As such, my partner and I have been looking into ways we can make our lifestyle more sustainable. Being in tech, I have chosen to &amp;quot;use what I know&amp;quot; to enable or facilitate changes to our lifestyle that promote sustainability without compromising on quality of living or requiring unnecessarily onerous daily chores.&lt;/p&gt;
&lt;p&gt;In this series of blog posts, I will be describing the decisions, approaches, tools and devices we've employed since starting down this road. Where possible, I will share as much of the tech as possible so others can adopt or adapt similar practises and, hopefully, enhance the sustainability of their lifestyle too.&lt;/p&gt;
&lt;h2 id="solar-power"&gt;Solar Power&lt;/h2&gt;
&lt;p&gt;Our first - and possibly most significant - step towards a more sustainable lifestyle has been to install solar panels. Until recently, installing solar panels on a domestic property in the UK has been a questionable value proposition due to the return on investment sometimes being longer than the lifetime of the panels/inverter. The UK government went someway to alleviating this issue with &lt;a href="https://www.gov.uk/feed-in-tariffs"&gt;Feed-in Tarrifs (FiT)&lt;/a&gt; but still repayment times tended to be longer than the warranty period of many of the components in the installation.&lt;/p&gt;
&lt;p&gt;Nowadays, the drop in costs and improved efficiency of solar panels coupled with improved and more robust technology in other components (particularly the inverter) mean that, despite the UK government ending the FIT program, a solar installation can easily provide a return on investment within the warrantied lifetime it's components.&lt;/p&gt;
&lt;p&gt;And so it was that, when we moved into our new house, we set aside money to install solar panels. After a lot of research into the underlying technologies, comparing features provided by various manufactures and talking to a number of solar installation specialists, we chose a local company to install a 6.18kWp system comprising of &lt;a href="http://www.jasolar.com/html/en/"&gt;JA Solar&lt;/a&gt; panels and a &lt;a href="http://www.jasolar.com/html/en/"&gt;SolarEdge&lt;/a&gt; inverter.&lt;/p&gt;
&lt;h2 id="monitoring-solar-production"&gt;Monitoring Solar Production&lt;/h2&gt;
&lt;p&gt;While JA Solar was chosen simply due to it's price/performance ratio, we were especially keen to install a SolarEdge system due to it's ability to be monitored in multiple ways.&lt;/p&gt;
&lt;p&gt;First up, SolarEdge provides an excellent cloud-based monitoring platform with both web and native apps compatible with major platforms. Furthermore SolarEdge provide a &lt;a href="https://www.solaredge.com/sites/default/files/se_monitoring_api.pdf"&gt;RESTful API&lt;/a&gt; facilitating automated data collection and monitoring. Unfortunately the cloud-based apps/API require that all data collection (and a significant amount of inverter control) is delegated to SolarEdge servers (with all the &lt;a href="https://horusscenario.com/what-is-the-horus-scenario/"&gt;privacy and security considerations&lt;/a&gt; that implies) and are then subject to usage-restrictions, request limits and significant latency.&lt;/p&gt;
&lt;p&gt;Fortunately, the SolarEdge inverter also provides numerous means of &lt;a href="https://www.solaredge.com/sites/default/files/solaredge-communication_options_application_note_v2_250_and_above.pdf"&gt;local data collection and control&lt;/a&gt;. The most powerful of these means is the onboard RS-485 connector which allows full control over the inverter and the ability to collect virtually all data generated by the unit. The github user &lt;a href="https://github.com/jbuehl"&gt;'jbuehl'&lt;/a&gt; has by-far the most accomplished open-source code available for interacting with this interface in his &lt;a href="https://github.com/jbuehl/solaredge"&gt;'solaredge'&lt;/a&gt; repository. Unfortunately, while it is the most powerful, it is also the most difficult means of recording data from the inverter, requiring the user to open the inverter and wire up to the RS-485 connector directly.&lt;/p&gt;
&lt;p&gt;However, if you don't require control over the inverter and merely want to record the data being generated, there is a much easier means: &lt;a href="https://www.solaredge.com/sites/default/files/sunspec-implementation-technical-note.pdf"&gt;ModBus over TCP&lt;/a&gt;. While this does require a setting to be enabled on the inverter (a completely trivial series of button presses), connection is made via standard TCP/IP on port 502.&lt;/p&gt;
&lt;h2 id="solaredge.monitor"&gt;SolarEdge.Monitor&lt;/h2&gt;
&lt;p&gt;While there were &lt;a href="https://github.com/search?q=solaredge"&gt;numerous repositories on Github&lt;/a&gt; for interacting with SolarEdge inverters, there didn't seem to be any that met all my requirements. Specifically, I wanted a solution that could be easily deployed to a variety of target platforms, which could read all available inverter parameters and publish these parameters to an MQTT broker (for consumption by other services) at a configurable interval.&lt;/p&gt;
&lt;p&gt;I therefore wrote &lt;a href="https://github.com/ibebbs/SolarEdge.Monitor"&gt;SolarEdge.Monitor&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This project was a lot of fun and utilised the following technologies and techniques:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dotnet/core"&gt;.NET Core 2.2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; (and &lt;a href="https://www.docker.com/products/docker-hub"&gt;Docker Hub&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/xamarin/mqtt"&gt;MQTT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rossmann-engineering/EasyModbusTCP.NET"&gt;ModBus over TCP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.0&amp;amp;tabs=visual-studio"&gt;Background tasks with hosted services in ASP.NET Core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-3.0"&gt;The .NET Core Options pattern for configuration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ian.bebbs.co.uk/posts/FluentNamespacing"&gt;Fluent Namespacing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ian.bebbs.co.uk/posts/ReactiveStateMachines"&gt;Reactive State Machines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While it can be cloned and run locally, it's real value comes when used as a containerized application as part of a composed solution.&lt;/p&gt;
&lt;h2 id="docker-docker-compose"&gt;Docker &amp;amp; Docker Compose&lt;/h2&gt;
&lt;p&gt;SolarEdge.Monitor is available as a Linux container image from &lt;a href="https://hub.docker.com/r/ibebbs/solaredge.monitor"&gt;Docker Hub&lt;/a&gt;. It can therefore be run from any docker host (anything from a RaspberryPi to Windows Server) by simply issuing the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker pull ibebbs/solaredge.monitor
docker run [environment variables] ibebbs/solaredge.monitor
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The various environment variables are (or will be shortly) fully documented on Docker Hub but here are a simple set that will get the service running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Solaredge:Monitor:Inverter:Address=[IP Address of the Inverter]
Solaredge:Monitor:MQTT:Address=[IP Address of the MQTT broker]
Solaredge:Monitor:Service:ModelsToRead=inverter
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running with these settings will poll the inverter every 10 seconds and publish a JSON serialized message containing data read from the inverter to the MQTT broker on a topic named &lt;code&gt;home/solar/inverter&lt;/code&gt;. This can be consumed by any MQTT client for further processing.&lt;/p&gt;
&lt;p&gt;To provide data persistence, aggregation and visualization, I use docker-compose to supplement SolarEdge.Monitor with other services such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://nodered.org/"&gt;Node-Red&lt;/a&gt; - for receiving MQTT messages and reshaping them into metrics for submission to...&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.influxdata.com/"&gt;InfluxDB&lt;/a&gt; - for persisting the metrics and providing a querying back-end to...&lt;/li&gt;
&lt;li&gt;&lt;a href="https://grafana.com/"&gt;Grafana&lt;/a&gt; - for visualizing persisted data and extracting insights&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here's an example &lt;code&gt;docker-compose.yml&lt;/code&gt; that, while requiring some substitution of environment variables, provides most of the ground work for getting these services running together (I'm afraid I don't yet have the customised Node-Red image or flows hosted in a public repository, but I hope to have this available soon):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: &amp;quot;3.2&amp;quot;

services:
  # https://hub.docker.com/_/eclipse-mosquitto
  mqtt:
    image: eclipse-mosquitto
    ports:
      - &amp;quot;1883:1883&amp;quot;
      - &amp;quot;9001:9001&amp;quot;

  # https://hub.docker.com/r/nodered/node-red-docker/
  nodered:
    build: ./nodered
    ports:
      - &amp;quot;1880:1880&amp;quot;
    volumes:
      - type: volume
        source: nodered
        target: /data
        volume:
          nocopy: true
    depends_on:
      - &amp;quot;mqtt&amp;quot;

  # https://hub.docker.com/_/influxdb
  influxdb:
    image: influxdb
    ports:
      - &amp;quot;8086:8086&amp;quot;
    environment:
    - INFLUXDB_DB=SmartHome
    - INFLUXDB_HTTP_AUTH_ENABLED
    - INFLUXDB_ADMIN_USER=InfluxAdmin
    - INFLUXDB_ADMIN_PASSWORD=[Admin password]
    - INFLUXDB_USER=InfluxUser
    - INFLUXDB_USER_PASSWORD=[User password]
    volumes:
      - type: volume
        source: influxdb
        target: /var/lib/influxdb
        volume:
          nocopy: true

  # https://hub.docker.com/r/grafana/grafana
  grafana:
    image: grafana/grafana
    ports:
      - &amp;quot;3000:3000&amp;quot;
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=[Admin password to set for Grafana]
      - GF_PANELS_DISABLE_SANITIZE_HTML=true
    depends_on:
      - influxdb
    volumes:
      - type: volume
        source: grafana
        target: /var/lib/grafana
        volume:
          nocopy: true

  # https://hub.docker.com/r/ibebbs/solaredge.monitor
  solaredgemonitor:
    image: ibebbs/solaredge.monitor
    environment:
      - Solaredge:Monitor:Inverter:Address=[Address of SolarEdge Inverter]
      - Solaredge:Monitor:MQTT:Address=mqtt
      - Solaredge:Monitor:MQTT:ClientId=InverterMonitor
      - Solaredge:Monitor:Service:ModelsToRead=inverter
    depends_on:
      - mqtt

volumes:
  nodered:
    driver_opts:
      type: nfs
      o: &amp;quot;addr=192.168.1.11,nolock,soft,rw&amp;quot;
      device: &amp;quot;:/smartHome/nodered&amp;quot;
  influxdb:
    driver_opts:
      type: nfs
      o: &amp;quot;addr=192.168.1.11,nolock,soft,rw&amp;quot;
      device: &amp;quot;:/smartHome/influxdb&amp;quot;
  grafana:
    driver_opts:
      type: nfs
      o: &amp;quot;addr=192.168.1.11,nolock,soft,rw&amp;quot;
      device: &amp;quot;:/smartHome/grafana&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that I use IP-Address protected NFS volume shares for persisting data to a Windows Server. These can be quite tricky to set up but it's the most reliable means I've found of persisting docker volumes with stock docker-compose (i.e. without additional plugins).&lt;/p&gt;
&lt;p&gt;With this file in hand (or, more to the point, on disk), all the services can be started together by simply navigating to the file's location and issuing the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here's a screen capture of my current Grafana dashboard (today hasn't been a great day for solar):&lt;/p&gt;
&lt;img src="../Content/TechAdventuresInSustainability-PartI/GrafanaDashboard.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Grafana Dashboard"&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Being able to quickly and reliably monitor our solar production has drastically changed how we use electricity in the house. For example, the washing machine and (shock, horror!) tumble dryer (sorry, we have kids and therefore too much washing to hang everything out) now get put on only when we have surplus electricity. We've also become super conscious of the multitude of energy zapping devices we have plugged in all over the house which we now endeavour to turn off as often as possible.&lt;/p&gt;
&lt;p&gt;Furthermore, being able to aggregate and analyse this data retrospectively has allowed us to make informed decisions on future sustainability choices like whether to get an electric car or solar battery. Unfortunately neither of these options have yet made the cut, mostly due to RoI considerations.&lt;/p&gt;
&lt;p&gt;In future posts, I'll show some of the ways in which I've used this data and other forms of technology to further promote sustainable living. For now though I would like to conclude by saying that having solar panels installed and being able to see the impact they're having has had a profound effect on our electricity usage and our views on sustainability in general. We feel very good about having made this important step to reducing our carbon foot-print and that, in itself, has provided the motivation to explore more ways to live more sustainably.&lt;/p&gt;
&lt;img src="../Content/TechAdventuresInSustainability-PartI/EnvironmentalBenefits.png" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Environmental Benefits"&gt;
</content:encoded>
		</item>
		<item>
			<title>Be Brave. Like BAT, man!</title>
			<link>http://ian.bebbs.co.uk/posts/BeBraveLikeBATMan</link>
			<description>&lt;p&gt;Brave is a privacy focused browser with a revolutionary means of supporting content publisher's revenue streams. Here's why you  should &lt;a href="https://brave.com/beb095"&gt;give it a try&lt;/a&gt;, particularly if you maintain a blog or publish open-source software.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/BeBraveLikeBATMan</guid>
			<pubDate>Fri, 06 Sep 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="tldr"&gt;TL;DR&lt;/h1&gt;
&lt;p&gt;Brave is a privacy focused browser with a revolutionary means of supporting content publisher's revenue streams. Here's why you  should &lt;a href="https://brave.com/beb095"&gt;give it a try&lt;/a&gt;, particularly if you maintain a blog or publish open-source software.&lt;/p&gt;
&lt;h2 id="it-all-starts-with-privacy"&gt;It all starts with Privacy&lt;/h2&gt;
&lt;p&gt;As anyone who knows me will tell you, I care deeply about privacy. In fact, should you happen to ask one of these people about my insistence on privacy, they'll give a nod confirmation accompanied by a not so subtle eye-roll of derision. This used to bother me but I've learned the hard way the lesson which Cory Doctorow states so eloquently:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;It’s really hard to get people to care about dangers that are far in the future, especially when the action that puts you in danger and the consequences of that action are separated by an unbridgeable gap of time and space. Privacy disclosures are a public health problem, like smoking. No one puff on a cigarette will definitely give you cancer, but take enough puffs and you’ll virtually guarantee cancer, eventually. No one act of disclosure of personal information will harm you, but once enough disclosures have taken place, over enough time, you’re going to get into serious privacy trouble.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I am that schmuck who actual reads (and, more often than not, is terrified by) the list of permissions installing an app on your phone requires. Therefore, when my beloved Windows Mobile phone was finally - and somewhat forcibly - supplanted by an Android device, my first action was to endeavour to replace all the privacy invading dross that came pre-installed and find more secure alternatives.&lt;/p&gt;
&lt;p&gt;And so it was that I chose &lt;a href="https://brave.com/beb095"&gt;Brave&lt;/a&gt; to replace the stock Chrome browser.&lt;/p&gt;
&lt;h2 id="the-brave-browser"&gt;The Brave Browser&lt;/h2&gt;
&lt;p&gt;Brave is a Chromium based browser focused on user privacy. It's privacy features include the ability to block ads, cross site trackers, cross site cookies and device identification; all features used by nefarious advertising agencies to aggressively profile and target individuals without consent. Moreover, on a mobile device, using Brave saves time, money and battery as adverts and trackers are not downloaded resulting in sites that load quicker, use less data allowance and consume less power.&lt;/p&gt;
&lt;p&gt;It works really well and, to me, is a no brainer. I've yet to find a site that didn't work in Brave or has been otherwise negatively impacted by the removal of adverts/trackers. I would unreservedly recommend that everyone swap Google Chrome for Brave immediately; you won't look back.&lt;/p&gt;
&lt;h2 id="its-a-win-win-but-not-a-win-win-win"&gt;It's a win-win, but not a win-win-win.&lt;/h2&gt;
&lt;p&gt;Of course, there's an issue with blocking adverts: Many content publishers rely on the use of advertising to pay the bills and, by preventing adverts from appearing, you're depriving the sites you visit most of a vital source of revenue.&lt;/p&gt;
&lt;p&gt;Brave's founders were very aware of the web's dependence on the trichotomy of users, content publishers and advertisers when they released their browser. In the years since, they have released and refined various approaches to resolving this issue, finally arriving at the BAT.&lt;/p&gt;
&lt;h2 id="basic-attention-token-bat"&gt;Basic Attention Token (BAT)&lt;/h2&gt;
&lt;p&gt;The Basic Attention Token endeavours to address this issue by providing a means for advertisers to reach users through content publisher's sites while doing so anonymously and providing financial incentives to &lt;em&gt;all the involved parties&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As the old adage goes, a picture is worth a thousand words so here's one worth many times that, direct from the &lt;a href="https://basicattentiontoken.org"&gt;basicattentiontoken.org&lt;/a&gt; website:&lt;/p&gt;
&lt;img src="https://basicattentiontoken.org/wp-content/uploads/2017/03/bat_triad_diagram.png" class="img-responsive" style="margin: auto; width:80%; margin-top: 6px; margin-bottom: 6px;" alt="BAT Triad"&gt;
&lt;p&gt;In short, users are able to support the sites they visit most by being exposed to advertisements that are truly relevant to them, all without compromising privacy. Amazingly the user is even &lt;em&gt;rewarded&lt;/em&gt; for being exposed to these ads and will accumulate BAT (directly tradable against other crypto - and by extension - fiat currencies) in the browser's built-in wallet.&lt;/p&gt;
&lt;h1 id="brave-rewards"&gt;Brave Rewards&lt;/h1&gt;
&lt;p&gt;This really is a revolution in how the modern web operates and is monetized yet, amazingly, it is entirely optional in the Brave Browser.&lt;/p&gt;
&lt;p&gt;It is enabled by opting in to 'Brave Rewards' as shown below:&lt;/p&gt;
&lt;img src="../Content/BeBraveLikeBATman/BraveRewards.jpg" class="img-responsive" style="margin: auto; width:50%; margin-top: 6px; margin-bottom: 6px;" alt="Brave Rewards Summary"&gt;
&lt;p&gt;I enabled &amp;quot;Brave Rewards&amp;quot; a couple of months back after being prompted by Brave and reading about it in depth. As you can see, just by using the browser as I normal would, without any obvious, annoying or intrusive ads, and despite having 'Auto-Contribute' enabled, I have accumulated ~26 BAT.&lt;/p&gt;
&lt;p&gt;&amp;quot;But that's less than five dollars!&amp;quot; I hear you say. True, but that's five dollars that would otherwise have been in the pockets of the big internet advertising agencies and, as with other crypto currencies, has the possibility to be worth much more should the BAT continue it's current growth. More importantly though, by auto-contributing accrued BAT to the sites I visit most, I have directly supported these sites with (micro) payments in a way I ordinarily would not have been able to do.&lt;/p&gt;
&lt;h2 id="now-get-pay-for-attention"&gt;Now [get] pay [for] attention!&lt;/h2&gt;
&lt;p&gt;All in all, I feel pretty good about my adoption and promotion of BAT. So much so that I recently registered as a &lt;a href="https://publishers.basicattentiontoken.org/"&gt;'Verified Content Creator'&lt;/a&gt; and added both my &lt;a href="ian.bebbs.co.uk"&gt;blog&lt;/a&gt; and my &lt;a href="https://github.com/ibebbs"&gt;github account&lt;/a&gt; as revenue channels. By registering in this way, anyone who uses the Brave browser to read my blog or open-source projects will automatically help support the further creation of these forms of content by contributing BAT.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://publishers.basicattentiontoken.org/"&gt;Brave Rewards Creators program&lt;/a&gt; allows you to accrue BAT through numerous channels including (at the time of writing) web sites, YouTube, Twitch, Twitter, Vimeo, Reddit and Github. If you create content in any of these ways, I very much recommend you register as a verified content creator. Brave maintains historical contributions to creators not currently registered, so you could be in for a windfall of BAT when you do!&lt;/p&gt;
&lt;h2 id="bat-sht-crazy"&gt;BAT-sh*t crazy!&lt;/h2&gt;
&lt;p&gt;More recently I've moved to using Brave as my primary desktop browser too. Initial experiences are that it provides the same excellent browsing characteristics of it's Android cousin but that it's use of system notifications for ad delivery is a little too &amp;quot;in your face&amp;quot;. I'm going to stick with it for a while and see how it goes. If the ads get too much, I'll simply disable &amp;quot;Brave Rewards&amp;quot; on the desktop while continuing to enjoy privacy and speed enhancements delivered by this excellent browser.&lt;/p&gt;
&lt;h2 id="support-me"&gt;Support me&lt;/h2&gt;
&lt;p&gt;If you have had your interest piqued by this post and are now interested in trying out the Brave browser, it would be great if you could use this &lt;a href="https://brave.com/beb095"&gt;referral link&lt;/a&gt; for download. It will net me approximately $5 of BAT via the &lt;a href="https://brave.com/referral-program/"&gt;Brave referral program&lt;/a&gt;. Thanks!&lt;/p&gt;
&lt;h2 id="further-reading"&gt;Further Reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://basicattentiontoken.org/"&gt;Basic Attention Token homepage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arunoda.me/blog/all-about-basic-attention-token"&gt;All about Basic Attention Token (BAT)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://locusmag.com/2016/07/cory-doctorow-peak-indifference/"&gt;Cory Doctorow: Peak Indifference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://batgrowth.com/"&gt;BATGrowth.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded>
		</item>
		<item>
			<title>Ignoring a Billion-Dollar Mistake is simply not an Option</title>
			<link>http://ian.bebbs.co.uk/posts/IgnoringABillionDollarMistakeIsNotAnOption</link>
			<description>&lt;p&gt;In 1965, computer scientist and otherwise all round good egg, Sir Charles Antony Richard Hoare (Tony to most) unleashed the 'null reference' upon an unsuspecting world, simply because it was "so easy". Five decades later, the vast majority of computer programmers remain all too au fait with the "null reference" exception, battling it's seemingly unstoppable encroachment into otherwise flawless program flows.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/IgnoringABillionDollarMistakeIsNotAnOption</guid>
			<pubDate>Thu, 06 Jun 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="a-billion-dollar-mistake"&gt;A 'Billion-Dollar Mistake'?&lt;/h2&gt;
&lt;p&gt;In 1965, computer scientist and otherwise all round good egg, Sir Charles Antony Richard Hoare (Tony to most) unleashed the 'null reference' upon an unsuspecting world, simply because it was &amp;quot;so easy&amp;quot;. Five decades later, the vast majority of computer programmers remain all too au fait with the &amp;quot;null reference&amp;quot; exception, battling it's seemingly unstoppable encroachment into otherwise flawless program flows.&lt;/p&gt;
&lt;p&gt;In 2009, Tony apologised for inventing the null reference, stating:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;I call it my billion-dollar mistake. It was the invention of the null reference in 1965. At that time, I was designing the first comprehensive type system for references in an object oriented language (ALGOL W). My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn't resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&amp;quot;Innumerable errors, vulnerabilities, and system crashes&amp;quot;? How so? Well, in most programming languages, null is not just a valid value for a reference type, it is the &lt;em&gt;default&lt;/em&gt; value. This means that any uninitialized reference type variable will cause a null reference exception if it is dereferenced. Furthermore, because null is the default reference type value, it tends to be the value returned when a process cannot be completed/calculated correctly causing otherwise innocuous dependent code to become inherently error prone. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-c#"&gt;string value = ParseValue(); // &amp;lt;= returns null as value cannot be parsed
Console.WriteLine($&amp;quot;Value contains {value.Length} characters&amp;quot;); // &amp;lt;= Boom!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes, we all look at the above code and shrug it off with a &amp;quot;D'uh, of course the value should be null checked&amp;quot;. But why? Why, in a statically typed and run-time checked language should there exist such a simple - and indeed default - means of causing an exception when, by definition, &lt;a href="https://www.google.com/search?q=exceptions+should+be+exceptional"&gt;exceptions should be exceptional&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="c-8.0-to-the-rescue"&gt;C# 8.0 to the rescue?&lt;/h2&gt;
&lt;p&gt;With the rise in prominence of functional languages (particularly F#) which do not suffer this issue (at least by default), the C# community is working to address this mistake with the release of a major new feature in version 8.0 of the language: &lt;a href="https://docs.microsoft.com/en-us/dotnet/csharp/nullable-references"&gt;Nullable reference types&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Firstly, kudos to the community for calling the feature &amp;quot;Nullable reference types&amp;quot; rather than &amp;quot;Non-nullable reference types&amp;quot; inferring that nullability is the &amp;quot;non-default behaviour&amp;quot; you can have if you explicitly want. Unfortunately, the implementation of this feature is, in my opinion, completely hamstrung by backwards compatibility. Specifically:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It will (in it's current guise) only ever cause compiler warnings not errors. Obviously you can enable warnings as errors but this isn't always feasible on large legacy projects.&lt;/li&gt;
&lt;li&gt;It must be specifically enabled at a project level - potentially a large undertaking on legacy projects - or via messy directives in code.&lt;/li&gt;
&lt;li&gt;It can't be applied consistently in all cases or at all in some cases. For example Jon Skeet's IEqualityComparer&lt;T&gt; example &lt;a href="https://codeblog.jonskeet.uk/2018/04/21/first-steps-with-nullable-reference-types/"&gt;here&lt;/a&gt; or the &amp;quot;Generics and nullable types&amp;quot; section of &lt;a href="https://www.infoq.com/articles/csharp-nullable-reference-case-study/"&gt;this InfoQ post&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Mixing code using &amp;quot;null reference types&amp;quot; with class libraries which have not implemented this functionality is likely to be extremely messy in the short to medium term requiring &amp;quot;nullable shims&amp;quot; etc.&lt;/li&gt;
&lt;li&gt;In the majority of cases, it doesn't actually remove the need for null reference checks.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To me the &amp;quot;Nullable reference types&amp;quot; feature feels a bit like the proverbial hammer used to crack a nut. Except that, in this instance, the hammer isn't actually capable of cracking the nut, it is just a vehicle for the label on the side providing instructions on how to get the nut cracked.&lt;/p&gt;
&lt;p&gt;Ok, that's a little facetious. On new or small code-bases, I'm sure utilizing &amp;quot;nullable reference types&amp;quot; will pay dividends and I would support it's use whole-heartedly. But what about large legacy code bases where having to specifically enable &amp;quot;nullable reference types&amp;quot; or enabling &amp;quot;warnings as errors&amp;quot; might not be viable.&lt;/p&gt;
&lt;h2 id="perhaps-theres-another-option"&gt;Perhaps there's another Option?&lt;/h2&gt;
&lt;p&gt;The more astute readers out there have no doubt have seen where this blog post is heading due to my nod to F# above and the not so subtle use of the word Option. As a functional language, F# eschews the use of null (unless specifically enabled on a type by type basis) by explicitly modelling the concept of &amp;quot;nothing-able&amp;quot; with a type: the discriminated union type called Option.&lt;/p&gt;
&lt;p&gt;Here's a description of the Option type from the &lt;a href="https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/discriminated-unions"&gt;FSharp Language Reference&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;The option type is a simple discriminated union in the F# core library. The option type is declared as follows.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-F#"&gt;// The option type is a discriminated union.
type Option&amp;lt;'a&amp;gt; =
    | Some of 'a
    | None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The previous code specifies that the type Option is a discriminated union that has two cases, Some and None. The Some case has an associated value that consists of one anonymous field whose type is represented by the type parameter 'a. The None case has no associated value. Thus the option type specifies a generic type that either has a value of some type or no value.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In short, instead of allowing a value to be null, the value is wrapped inside another object which is able to explicitly say whether the value is something or nothing. While this is an F# concept, it can be mirrored quite simply in C# as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;public struct Option&amp;lt;T&amp;gt;
{
    public static readonly Option&amp;lt;T&amp;gt; None = new Option&amp;lt;T&amp;gt;();

    public static Option&amp;lt;T&amp;gt; Some(T value)
    {
        return new Option&amp;lt;T&amp;gt;(value);
    }

    private Option(T value)
    {
        IsSome = true;
        Value = value;
    }

    public T Value { get; private set; }
    public bool IsSome { get; private set; }
    public bool IsNone =&amp;gt; !IsSome;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that this is a struct (i.e. a value type which cannot be null) but also generic meaning it can hold a reference type value. Using this class we can write code which in which we can be confident that we won't encounter a null reference:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;var option = GetSomeOption();
if (option.IsSome)
{
    Console.WriteLine($&amp;quot;Found a value of {option.Value}&amp;quot;);
}
else
{
    Console.WriteLine(&amp;quot;Did not find a value&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What's that? This code looks exactly like the code for a null reference check? True, except for three important differences:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The use of an Option as the return type indicates to the consumer that &amp;quot;None&amp;quot; is a valid value and must be considered - as opposed to a null which may or may not be deliberate.&lt;/li&gt;
&lt;li&gt;The Value property must be explicitly read from the Option meaning the consumer is less likely to access the property without checking that it 'IsSome' first.&lt;/li&gt;
&lt;li&gt;You can do more with &lt;em&gt;something&lt;/em&gt; than you can with &lt;em&gt;nothing&lt;/em&gt;; read on.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Regarding that last point, once we have something - i.e. an Option type - we can work with it to facilitate it's use in code. For example, consider the following extension methods:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;/// &amp;lt;summary&amp;gt;
/// Projects an &amp;lt;see cref=&amp;quot;Option{T}&amp;quot;/&amp;gt; of &amp;lt;typeparamref name=&amp;quot;TSource&amp;quot;/&amp;gt; to
/// an &amp;lt;see cref=&amp;quot;Option{T}&amp;quot;/&amp;gt; of &amp;lt;typeparamref name=&amp;quot;TDest&amp;quot;/&amp;gt; using the
/// specified &amp;lt;paramref name=&amp;quot;projection&amp;quot;/&amp;gt;
/// &amp;lt;/summary&amp;gt;
public static Option&amp;lt;TDest&amp;gt; Select&amp;lt;TSource, TDest&amp;gt;(this Option&amp;lt;TSource&amp;gt; source, Func&amp;lt;TSource, Option&amp;lt;TDest&amp;gt;&amp;gt; projection)
{
    return source.IsSome ? projection(source.Value) : None&amp;lt;TDest&amp;gt;();
}

/// &amp;lt;summary&amp;gt;
/// If the &amp;lt;see cref=&amp;quot;Option{T}.IsSome&amp;quot;/&amp;gt; returns true for the &amp;lt;see cref=&amp;quot;Option{T}&amp;quot;/&amp;gt; specified in &amp;lt;paramref name=&amp;quot;source&amp;quot;/&amp;gt;
/// then this method will return it's &amp;lt;see cref=&amp;quot;Option{T}.Value&amp;quot;/&amp;gt;, otherwise the value of the &amp;lt;paramref name=&amp;quot;value&amp;quot;/&amp;gt; parameter
/// is returned
/// &amp;lt;/summary&amp;gt;
public static T Coalesce&amp;lt;T&amp;gt;(this Option&amp;lt;T&amp;gt; source, T value)
{
    return source.IsSome ? source.Value : value;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using these we can move away from imperative property checking an adopt a more declarative style:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;var response = GetSomeOption()
    .Select(value =&amp;gt; $&amp;quot;Found a value of {value}&amp;quot;)
    .Coalesce(&amp;quot;Did not find a value&amp;quot;);

Console.WriteLine(response);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The benefits of declarative code vs imperative code will likely be the subject of my next &amp;quot;contentious&amp;quot; blog post. I have repeatedly debated  the various pros and cons of declarative code with co-workers and clients and still believe it's a fundamentally better way of expressing intent while simultaneously and writing &amp;quot;safer&amp;quot; code.&lt;/p&gt;
&lt;p&gt;So anyway, notice anything about the Option type?&lt;/p&gt;
&lt;h2 id="oh-isnt-this-one-of-those.err.gonad-things"&gt;Oh, isn't this one of those... err... gonad things?&lt;/h2&gt;
&lt;p&gt;Monad? Yes. The Option type is, in my opinion, the quintessential monad as, when combined with compositional functions like those shown above, it is able to provide &amp;quot;a design pattern that allows structuring programs generically while automating away boilerplate code needed by the program logic&amp;quot;; i.e. removing all those damn ugly null checks!&lt;/p&gt;
&lt;p&gt;After working with the Option type for a number of years across numerous project's I've accumulated (mostly by plagiarizing F#) a number of monadic functions which can almost eliminate imperative code (at least with respect to null checking). These functions are especially useful for collections as shown (in the somewhat contrived example) below:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-C#"&gt;var result = Enumerable
    .Range(1, 100)
    .Select(value =&amp;gt; ReturnSomeIfAValidValueOtherwiseNone(value)) // &amp;lt;= Returns an Option
    .Collect() // &amp;lt;= Do not propagate values of Option.None
    .FirstOption() // &amp;lt;= Take the first value of Option.Some or return Option.None if none exist
    .Select(value =&amp;gt; $&amp;quot;{value} is the first valid value&amp;quot;)
    .Coalesce(&amp;quot;No valid values found&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="ok-so-where-does-this-get-us"&gt;Ok, so where does this get us?&lt;/h2&gt;
&lt;p&gt;Well, looking back and comparing this with &amp;quot;nullable reference types&amp;quot;, I believe explicitly modelling the concept of nothing using the Option type provides many advantages such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You can adopt this approach incrementally - one method at a time if need be - without huge numbers of warnings or messy code directives.&lt;/li&gt;
&lt;li&gt;Explicitly stating that a method can return &amp;quot;nothing&amp;quot; with the Option type is a much more obvious means of expressing intent than a &amp;quot;nullable reference type&amp;quot;.&lt;/li&gt;
&lt;li&gt;You can finally get rid of null reference checks!&lt;/li&gt;
&lt;li&gt;Returning &lt;em&gt;something&lt;/em&gt; rather than &lt;em&gt;nothing&lt;/em&gt; facilitates the adoption of a more declarative programming style.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So there we go. A safe, obvious, easy and, most-importantly, low-cost means of dealing with the &amp;quot;Billion-Dollar Mistake&amp;quot;. Give it a stab and see what you think. As shown above, there's a very low barrier to entry so there's very little to lose.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Fluent Namespacing</title>
			<link>http://ian.bebbs.co.uk/posts/FluentNamespacing</link>
			<description>&lt;p&gt;&lt;em&gt;So, it's been a while since I've blogged. Mostly this has been due to other commitments (family, friends, side projects, etc), working more hours contracting than I would ideally like and generally not having any dead-time (such as when I used to commute). Since my last blog post (over a year ago!!) I've been maintaining an ever increasing list of things I'd like to blog about but haven't found the time. Given it's a new year, I've decided to pick a couple of the more challenging/contentious blog ideas and endeavour to get them written. This is the first and, while not necessarily the most contentious, might take some getting your head around. You have been warned...&lt;/em&gt;&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/FluentNamespacing</guid>
			<pubDate>Thu, 09 May 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;&lt;em&gt;So, it's been a while since I've blogged. Mostly this has been due to other commitments (family, friends, side projects, etc), working more hours contracting than I would ideally like and generally not having any dead-time (such as when I used to commute). Since my last blog post (over a year ago!!) I've been maintaining an ever increasing list of things I'd like to blog about but haven't found the time. Given it's a new year, I've decided to pick a couple of the more challenging/contentious blog ideas and endeavour to get them written. This is the first and, while not necessarily the most contentious, might take some getting your head around. You have been warned...&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There is a convention at the heart of enterprise development and many modern development frameworks which seems to have been blindly adopted by the development community at large. I hope to challenge this convention as I believe changing it can provide many useful benefits in day to day development.&lt;/p&gt;
&lt;p&gt;The convention I'm referring to is the tendency to group classes by &lt;em&gt;functional pattern&lt;/em&gt; rather than &lt;em&gt;functional domain&lt;/em&gt;. What does this mean? Well, to illustrate, lets start a new webapi project:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dotnet new webapi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will end up with a folder structure similar to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$:.
│   appsettings.Development.json
│   appsettings.json
│   FluentNamespacing.csproj
│   Program.cs
│   Startup.cs
│   
├───Controllers
│       ValuesController.cs
│       
└───Properties
        launchSettings.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There, you see it don't you? No? Well, that just shows how ingrained this convention is.&lt;/p&gt;
&lt;p&gt;I'm referring to the &lt;code&gt;ValuesController&lt;/code&gt; class residing a &lt;code&gt;Controllers&lt;/code&gt; folder. What's the problem with that, you ask? Well, lets develop this project a little further and revisit.&lt;/p&gt;
&lt;p&gt;Lets say, after a little &lt;em&gt;conventional&lt;/em&gt; development, we're now here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$:.
│   appsettings.Development.json
│   appsettings.json
│   FluentNamespacing.csproj
│   Program.cs
│   Startup.cs
│               
├───Controllers
│       PersonController.cs
│       
├───Factories
│       PersonFactory.cs
│       
├───Models
│       PersonModel.cs
│               
├───Properties
│       launchSettings.json
│       
└───Repositories
        PersonRepository.cs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our abstract &lt;code&gt;ValuesController&lt;/code&gt; has become a &lt;code&gt;PersonController&lt;/code&gt; as we want to serve instances of the &lt;code&gt;PersonModel&lt;/code&gt;. But wait, where is the &lt;code&gt;PersonModel&lt;/code&gt; class? Ah, of course, in the &lt;code&gt;Models&lt;/code&gt; folder. Ok, we'll add &lt;code&gt;using FluentNamespacing.Models&lt;/code&gt; to the top of the &lt;code&gt;PersonController.cs&lt;/code&gt; and continue.&lt;/p&gt;
&lt;p&gt;Now as is common practice, we might want to abstract our datastore via the &lt;a href="https://martinfowler.com/eaaCatalog/repository.html"&gt;repository pattern&lt;/a&gt; so we dutifully create a &lt;code&gt;Repositories&lt;/code&gt; folder within which we add a &lt;code&gt;PersonRepository&lt;/code&gt; class. We need to use this in the &lt;code&gt;PersonController&lt;/code&gt; so we add another using statement to the file (&lt;code&gt;using FluentNamespacing.Repositories&lt;/code&gt;) bringing the &lt;code&gt;PersonRepository&lt;/code&gt; into scope.&lt;/p&gt;
&lt;p&gt;Finally, when a user uses a POST call to create a new user, the &lt;code&gt;PersonController&lt;/code&gt; should again follow common practise and use the &lt;a href="https://en.wikipedia.org/wiki/Factory_method_pattern"&gt;factory pattern&lt;/a&gt; to create a new &lt;code&gt;PersonModel&lt;/code&gt; which can then be saved via the repository. Again we go round the loop of creating a directory (&lt;code&gt;Factories&lt;/code&gt;), adding a class to it (&lt;code&gt;PersonFactory&lt;/code&gt;) and adding a using to the &lt;code&gt;PersonController.cs&lt;/code&gt; file (&lt;code&gt;using FluentNamespacing.Factories&lt;/code&gt;). Phew.&lt;/p&gt;
&lt;p&gt;Now look at our project. We have almost as many folders as we do classes and the classes related to the &amp;quot;Person&amp;quot; entity are spread across the project. Furthermore, we've had to prefix each of our classes with the  entity (i.e. &lt;code&gt;Person&lt;/code&gt;) it relates to in order to differentiate it from similar classes for other entities (i.e. &lt;code&gt;Job&lt;/code&gt;, &lt;code&gt;Role&lt;/code&gt;, &lt;code&gt;Group&lt;/code&gt;). That's a lot of typing and/or mouse navigation to get basic functionality in place.&lt;/p&gt;
&lt;p&gt;Now consider this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;D:.
│   appsettings.Development.json
│   appsettings.json
│   FluentlyNamespaced.csproj
│   Program.cs
│   Startup.cs
│               
├───Person
│       Controller.cs
│       Factory.cs
│       Model.cs
│       Repository.cs
│       
└───Properties
        launchSettings.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we have exactly the same functionality but grouped by functional domain not functional pattern; i.e. all classes related to a Person are in the same folder. This has resulted in far less structural noise, simplified class names and no need for additional using statements to be added to any of the classes.&lt;/p&gt;
&lt;h3 id="fluent-namespacing"&gt;Fluent Namespacing&lt;/h3&gt;
&lt;p&gt;I have been applying this approach in medium to large enterprise code-bases for some time now and find it provides simplified code, less structural overhead, easier navigation, faster comprehension and improved code architecture. I refer to it as &amp;quot;Fluent Namespacing&amp;quot; because, when you start referring to your classes via the [partial] namespace rather than long class names (requiring additional &lt;code&gt;using&lt;/code&gt; statements), the code tends to read like a &lt;a href="https://martinfowler.com/bliki/FluentInterface.html"&gt;fluent interface&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I believe this approach provides numerous additional benefits such as:&lt;/p&gt;
&lt;h4 id="propinquity"&gt;1. Propinquity&lt;/h4&gt;
&lt;p&gt;Want the repository for your entity? It's right along side it. As are all the other classes related to that entity. This means you can very quickly skip between these classes without needing to navigate the breadth of your project looking for a folder for the appropriate functional pattern.&lt;/p&gt;
&lt;h4 id="scope"&gt;2. Scope&lt;/h4&gt;
&lt;p&gt;When you write code which involves multiple entities, these entities need to be brought into scope. Rather than adding using statements, I have found that utilising the entity's namespace in a fluent fashion gives very elegant results.
For example, say we have introduce a &lt;code&gt;Role&lt;/code&gt; entity and the controller for this entity needs to be able to add &lt;code&gt;Person&lt;/code&gt; instances to a role. A (naïve) implementation of this class might look something akin to:&lt;/p&gt;
&lt;script src="https://gist.github.com/ibebbs/117531fb4a3a3556fd3788d45ffaaa57.js"&gt;&lt;/script&gt;
&lt;p&gt;Note the lack of additional using statements and how bringing classes related to other entities into scope requires only a partial namespace which then reads like natural language (i.e. Person.Repository / Person.Model).&lt;/p&gt;
&lt;h4 id="coupling"&gt;3. Coupling&lt;/h4&gt;
&lt;p&gt;In general, it is desirable for classes in your project to be loosely coupled. Fluent namespacing can visually illustrate when a class might be tightly-coupled by requiring long namespace traversals. For example:&lt;/p&gt;
&lt;script src="https://gist.github.com/ibebbs/52ecb2051da6812d2a023cfc76cb0331.js"&gt;&lt;/script&gt;
&lt;p&gt;Should the Group controller really be using the Person entity's data source (&lt;code&gt;Person.Data.Source&lt;/code&gt;) and mapping provider (&lt;code&gt;Person.Mapping.Provider&lt;/code&gt;) to fetch a &lt;code&gt;Person.Model&lt;/code&gt; instances or would they be better using the Person entity's repository (&lt;code&gt;Person.Repository&lt;/code&gt;)?&lt;/p&gt;
&lt;h3 id="other-considerations"&gt;Other considerations&lt;/h3&gt;
&lt;p&gt;There are a couple of downsides to this approach such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Refactoring&lt;/p&gt;
&lt;p&gt;When you use Visual Studio's built in refactoring methods, it will always endeavour add a &lt;code&gt;using&lt;/code&gt; to your class for classes outside the current namespace, even if you've already referred to them via the namespace:
&lt;img src="/Content/FluentNamespacing/FluentlyNamespaced-AddReadOnlyField.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Field - yes please, using - no thanks!"&gt;&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Field? Yes please. Using? No thanks!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Searching&lt;/p&gt;
&lt;p&gt;In Visual Studio, when you need to search for a specific class, you may find you get many more hits than expected; afterall, if the &lt;code&gt;Model&lt;/code&gt; class for all entities is called &lt;code&gt;Model&lt;/code&gt; searching for 'Model' will return all the entity classes. Fortunately, Visual Studio's 'Go to All' functionality supports search by multiple key word matches so this works:
&lt;img src="/Content/FluentNamespacing/Go to All.png" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Ah, there it is"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Note: The fact that these downsides are all related to tooling shows just how ingrained this convention is to modern development.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id="conclusion"&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;As shown, moving away from the &amp;quot;grouping by functional pattern&amp;quot; convention and instead using &amp;quot;Fluent Namespacing&amp;quot; can make your code much more readable and maintainable while requiring very little overhead. The side benefits of simplified navigation leading to easier comprehension and the potential for highlighting possible code-smells can really pay dividends in a large code base. I'd very much encourage you to try Fluent Namespacing in your next project, I don't think you'll regret it.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>A SmartHome... NoT - Part II</title>
			<link>http://ian.bebbs.co.uk/posts/ASmartHome-Part2</link>
			<description>&lt;p&gt;In &lt;a href="http://ian.bebbs.co.uk/posts/ASmartHome-Part1"&gt;part I&lt;/a&gt; of this series I described how to use Xiaomi Mi Smart Home devices without compromising your home privacy or security.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/ASmartHome-Part2</guid>
			<pubDate>Tue, 06 Feb 2018 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;In &lt;a href="http://ian.bebbs.co.uk/posts/ASmartHome-Part1"&gt;part I&lt;/a&gt; of this series I described how to use Xiaomi Mi Smart Home devices without compromising your home privacy or security.&lt;/p&gt;
&lt;p&gt;And lo, with the &lt;em&gt;sweet, sweet nut&lt;/em&gt; of privacy-friendly sensors laid before me, I raised the metaphorical &lt;em&gt;hammer of code&lt;/em&gt; like an allegorical Thor about to deliver righteous justice to... and then I stopped. What was I trying to deliver righteous justice to. In fact, what the smeg did I actually want to &lt;em&gt;do&lt;/em&gt; with all these things?&lt;/p&gt;
&lt;p&gt;So focused had I been on finding a 'how', I hadn't really considered the what or why? Monitoring, sure but there had to be useful things I could automate.&lt;/p&gt;
&lt;p&gt;At this point I decided to take a look around at what other people were doing and, almost inevitably, came upon the &lt;a href="https://community.openhab.org/"&gt;OpenHAB forums&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="openhabian"&gt;OpenHABian&lt;/h1&gt;
&lt;p&gt;OpenHAB has been around for years and for much of this time has been the &lt;em&gt;go to&lt;/em&gt; software for home automation.  Nowadays there a numerous other offerings and OpenHAB has had to rapidly evolve to stay competitive. To this end OpenHAB recently released OpenHAB 2 which, as far as I can tell, is a full rewrite based on &lt;a href="https://www.eclipse.org/smarthome/"&gt;Eclipse SmartHome framework&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While &lt;a href="http://www.myopenhab.org/"&gt;'cloud based' versions of OpenHAB are available&lt;/a&gt; the normal use-case is to deploy a version of OpenHAB on the local network thereby keeping all processing locally too. To facilitate this, they now offer pre-built images of OpenHabian - a distribution for single board computes (i.e. the Raspberry Pi et al) that comes with OpenHAB pre-installed.&lt;/p&gt;
&lt;p&gt;Anyway, I was interested in how OpenHAB might have evolved and love trying out new images on the Raspberry Pi (seriously it's like Docker except on real hardware and... well... works) so downloaded &lt;a href="https://github.com/openhab/openhabian/releases"&gt;the latest version&lt;/a&gt; (somewhat confusing named 'version 1.4' even though it contains OpenHAB 2.2), &lt;a href="https://etcher.io/"&gt;etched it&lt;/a&gt; to an SD card, put the SD card in a spare RPi3 and booted.&lt;/p&gt;
&lt;h2 id="installation"&gt;Installation&lt;/h2&gt;
&lt;p&gt;Installation of OpenHABian is pretty straight forward, simply insert the newly prepared SD card and power on the Pi. One thing to note however is that the setup of OpenHABian requires internet access to download additional components / updates. As I had added the RPi3 running OpenHABian to my secured subnet, my first install of OpenHABian failed as there was no internet access available. A quick firewall exclusion and restart solved the problem.&lt;/p&gt;
&lt;h2 id="paper-ui"&gt;Paper UI&lt;/h2&gt;
&lt;p&gt;One of the key enhancements in OpenHAB 2 is the introduction of 'Paper UI'. Paper UI is an HTML5 web application which allows a fully graphical setup and administration of &lt;a href="https://docs.openhab.org/configuration/things.html"&gt;Things&lt;/a&gt; and &lt;a href="https://docs.openhab.org/configuration/items.html"&gt;Items&lt;/a&gt;. Where previously you'd have to drop into textual configuration of components, Paper UI offers a simplified means of getting your home automation devices known to, and used by, OpenHAB.&lt;/p&gt;
&lt;p&gt;Indeed, getting Paper UI to recognise and use my Xiaomi Mi Smart Home devices was simple and can be done as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Install the &lt;a href="https://docs.openhab.org/addons/bindings/mihome/readme.html"&gt;'Xiaomi Mi Smart Home Binding'&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From the Paper UI, click the 'Add-ons' menu item on the left&lt;/li&gt;
&lt;li&gt;Click the 'Bindings' tab at the top of the page&lt;/li&gt;
&lt;li&gt;Search for 'Xiaomi'&lt;/li&gt;
&lt;li&gt;Click the 'INSTALL' button to the right of the 'Xiaomi Mi Smart Home Binding'&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add the Xiaomi Gateway(s)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Once the 'Xiaomi Mi Smart Home Binding' has been installed, any gateways on the current subnet that have 'local network functions' enabled should magically appear in the 'Inbox' and have a notification shown.&lt;/li&gt;
&lt;li&gt;For each gateway on the subnet, simply add it as a 'Thing' with a unique name and in an appropriate location. Also don't forget to add the 'developer key' (copied from the Xiami Mi Home app after enabling 'local network functions') so you can issue commands to the gateway.&lt;/li&gt;
&lt;li&gt;Each time you add a gateway, the binding will query sub-devices registered with the gateway which will also then be shown in the inbox. These sub-devices can then be added as 'Things' for which you should  remember to set the location so 'Items' linked to the 'Thing' (see below) are displayed correctly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add 'Items' to be displayed&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You should now see all your devices in 'Things'. Each one has several 'Channels' which can be 'linked' to an 'Item' by clicking the blue and white circular icon beside it. For most types of 'Channels', the default values displayed in the 'Link Channel' can be left as is.&lt;/li&gt;
&lt;li&gt;Each 'Item' linked to a channel is shown on the Control page with Locations seperated on to discrete tabs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once all your Xiaomi devices have been added as 'Things' and their respective 'Channels' linked to 'Items' you should end up with something like this in the 'Control' page:&lt;/p&gt;
&lt;img src="/Content/posts/OpenHAB - Paper UI - Configured.png" alt="OpenHAB - Paper UI - Configured" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;So far so good. Now what?&lt;/p&gt;
&lt;p&gt;Well, turns out not a lot. After getting your devices added to OpenHABian, you have to move into textual configuration if you want to actually perform any automation via interaction between devices.&lt;/p&gt;
&lt;p&gt;&amp;quot;Oh&amp;quot;, I thought, &amp;quot;That was a waste of time then&amp;quot;.&lt;/p&gt;
&lt;h2 id="node-red"&gt;Node-RED&lt;/h2&gt;
&lt;p&gt;On a whim, I decided to SSH into OpenHABian and play with the &lt;a href="https://docs.openhab.org/installation/openhabian.html#openhabian-config"&gt;OpenHABian Configuration Tool&lt;/a&gt;. Most of the options were fairly straight forward and unexciting until I got to the &lt;a href="https://docs.openhab.org/installation/openhabian.html#optional-components"&gt;Optional Components&lt;/a&gt; menu. Here a couple of items caught my eye, particularly the option to install Node-RED along side OpenHAB.&lt;/p&gt;
&lt;p&gt;I'd heard of &lt;a href="https://nodered.org/"&gt;Node-RED&lt;/a&gt; previously but had never tried it. As I was about to junk the install of OpenHABian anyway, I decided I'd have a play... and this is where the magic happened.&lt;/p&gt;
&lt;p&gt;For others who have not used Node-RED, it is a Node.js app designed for &amp;quot;wiring together hardware devices, APIs and online services in new and interesting ways&amp;quot;. It has an amazingly simple yet ludicrously brilliant UI which makes experimentation with it's various 'nodes' extremely quick and easy. Moreover, the installation on OpenHABian comes pre-installed with nodes to interact with 'Items' in OpenHAB.&lt;/p&gt;
&lt;p&gt;Despite, never having used Node-RED before, in just a few minutes I had the following flow deployed and running:&lt;/p&gt;
&lt;img src="/Content/posts/Node-RED - First Flow.png" alt="First Node-RED flow" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;Which does the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Uses an &lt;code&gt;openhab2-in&lt;/code&gt; node to listen to changes to the &lt;code&gt;OfficeDoorSensor_OpenStatus&lt;/code&gt; value.&lt;/li&gt;
&lt;li&gt;Uses a &lt;code&gt;switch&lt;/code&gt; node to compare the status value to 'OPEN' or 'CLOSED' and emit the message to the appropriate port.&lt;/li&gt;
&lt;li&gt;If the door has been opened:
&lt;ul&gt;
&lt;li&gt;Use a &lt;code&gt;openhab2-out&lt;/code&gt; node to issue a 'ON' &lt;code&gt;ItemCommand&lt;/code&gt; to the &lt;code&gt;OfficeGateway_Brightness&lt;/code&gt; channel (i.e. turn the light in the Xiami Mi Smart Gateway on).&lt;/li&gt;
&lt;li&gt;Wait five seconds then use a &lt;code&gt;openhab2-out&lt;/code&gt; node to issue a 'OFF' &lt;code&gt;ItemCommand&lt;/code&gt; to the &lt;code&gt;OfficeGateway_Brightness&lt;/code&gt; channel (i.e. turn the light in the Xiami Mi Smart Gateway off).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the door has been closed then use a &lt;code&gt;openhab2-out&lt;/code&gt; node to issue a 'OFF' &lt;code&gt;ItemCommand&lt;/code&gt; to the &lt;code&gt;OfficeGateway_Brightness&lt;/code&gt; channel (i.e. turn the light in the Xiami Mi Smart Gateway off).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ok, the use case is fairly simple but wow, what an incredibly level of integration between disparate sensors / lights with just five nodes, a few connections and no bespoke code what-so-ever.&lt;/p&gt;
&lt;p&gt;I was hooked.&lt;/p&gt;
&lt;p&gt;Playing with Node-RED inspired me to start brain-storming potential use-cases and they soon started coming thick and fast. Broadly the use-cases fell into three main categories:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Utility - mitigate small frustrations around the house&lt;/li&gt;
&lt;li&gt;Security - enhance home security&lt;/li&gt;
&lt;li&gt;Efficiency - reduce home power consumption&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;However, one use case I came up with fell into all three of these categories &lt;strong&gt;and&lt;/strong&gt; a logical progression from the above flow.&lt;/p&gt;
&lt;h1 id="a-use-case-at-last"&gt;A use case at last!&lt;/h1&gt;
&lt;p&gt;Our new 'forever home' has a built in double garage. While the doors on the garage are in pretty good condition, the locks are nothing special and present an obvious security weak spot. Indeed, we use the garage doors every day as it's a very convenient way into the house which increases the likelihood we'll forget to close the doors properly.&lt;/p&gt;
&lt;p&gt;Furthermore, the flurescent lights in the garage are old and take an age to turn on. As we need to go through the garage to get to the utility room and can't see the way to the utility room until the light is on, we tended to simply turn them on at the beginning of the day and turn them off before going to bed each night, thereby consuming way more energy than necessary.&lt;/p&gt;
&lt;p&gt;Understanding this, I used an additional gateway in the garage, coupled with sensors on each of the doors (garage door, kitchen door, utility room door) and an easily controllable &lt;a href="https://www.amazon.co.uk/gp/product/B077HLQMBD"&gt;IP camera&lt;/a&gt; to put together the following flow:&lt;/p&gt;
&lt;img src="/Content/posts/Node-RED - Garage.png" alt="Node-RED garage flow" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;This does a couple of things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Turns on the light in the gateway whenever any of the doors open&lt;/p&gt;
&lt;p&gt;The light in the gateway is more than enough to light the way to the utility room which addresses the utility aspect of the use-case as we no longer need to wait for the garage light to come on. Furthermore, three minutes after the door was opened (regardless of whether it's been closed again), the light in the gateway is turned off. This is normally long enough for us to do whatever we needed in the garage and addresses the efficiency aspect of the use-case as we no longer leave a light on all day.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Turns the IP Camera to look at the opened door and takes a snapshot&lt;/p&gt;
&lt;p&gt;The IP camera I've used has a useful feature whereby it can record several Pan/Tilt positions which it can then return to using a single command. I use this feature to point the camera at the door which has just been opened and use a further command to take a snapshot image of what it sees. This addresses the security aspect of the use case by ensuring video surveilance coverage of activity within the garage.&lt;br /&gt;
&lt;em&gt;Ultimately I intend to upload this image to a cloud storage provider and send a notification to my phone if this happens within certain time constraints but this has yet to be implemented.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="moving-forward"&gt;Moving forward&lt;/h1&gt;
&lt;p&gt;As you can see, the combination of Xiaomi Mi Smart devices, OpenHAB[ian] and Node-RED is extremely potent. Without writing any code (compiled, intepreted or DSL), I'm able to orchestrate some very advanced interactions between sensors, actuators and other services.&lt;/p&gt;
&lt;p&gt;In the next post, I'll discuss how I've developed this platform even further into a full, voice activated, digital assistant while &lt;em&gt;still&lt;/em&gt; maintaining privacy and security.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>A SmartHome... NoT - Part I</title>
			<link>http://ian.bebbs.co.uk/posts/ASmartHome-Part1</link>
			<description>&lt;p&gt;I moved house a couple of months back to, what my partner likes to describe as, our "forever home". As such, I was keen to start looking into home monitoring / automation again as I knew things had progressed significantly since I last considered such things and I was keen to see what could be done. After lots of investigation I believe I have found the basis of a home automation solution which meets my current needs, should be extensible moving forward and which does not compromise the securty or privacy of my home.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/ASmartHome-Part1</guid>
			<pubDate>Mon, 29 Jan 2018 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;I moved house a couple of months back to, what my partner likes to describe as, our &amp;quot;forever home&amp;quot;. As such, I was keen to start looking into home monitoring / automation again as I knew things had progressed significantly since I last considered such things and I was keen to see what could be done. After lots of investigation I believe I have found the basis of a home automation solution which meets my current needs, should be extensible moving forward and which does not compromise the securty or privacy of my home.&lt;/p&gt;
&lt;p&gt;This post is, I hope, the first in a series that discuss the various devices and software I use to monitor and automate my home.&lt;/p&gt;
&lt;h1 id="private-by-design"&gt;Private by design&lt;/h1&gt;
&lt;p&gt;Firstly a word on privacy. While &amp;quot;smart devices&amp;quot; are everywhere nowadays, they almost all require connection to the internet and, often, a subscription to a &amp;quot;cloud&amp;quot; service. I wrote about &lt;a href="http://ian.bebbs.co.uk/posts/MonsterPi"&gt;this before&lt;/a&gt; and expressed my desire for smart devices to &amp;quot;drop the 'Inter' from IoT and expand the 'net' to become a 'Network of Things', or NoT&amp;quot; which could optionally be bridged to the internet if desired. To quote myself:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;I've long loved the idea of home automation. From X10 and LightwaveRF through to modern Bluetooth and Wifi connected devices, I have played with dozens of technologies in search of home automation nirvana. But recently I have watched with growing bewilderment at the incredible number of &amp;quot;cloud-connected&amp;quot; home automation devices being released and the eagerness with which they're snapped up by naive consumers hungry to control everything from the carefree comfort of their iPhone.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;You see, while you can buy a myriad of IoT devices off the shelf nowadays, they nearly all come with some form of &amp;quot;cloud-service&amp;quot; that is necessary in order for the device to work as sold. As the more wily of reader will no doubt be aware, this exposes your home network to innumerable &lt;a href="https://it.slashdot.org/story/16/10/03/1359200/source-code-for-iot-botnet-mirai-which-took-down-krebs-on-security-website-with-ddos-attack-released"&gt;security concerns&lt;/a&gt;, &lt;a href="https://it.slashdot.org/story/16/08/08/1449221/hackers-make-the-first-ever-ransomware-for-smart-thermostats"&gt;potential abuses&lt;/a&gt; and an &lt;a href="https://tech.slashdot.org/story/16/01/14/1347243/nest-thermostat-bug-leaves-owners-without-heating"&gt;external point of failure&lt;/a&gt; that cannot be closed/fixed without sacrificing some or all of the functionality of the new fangled device.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since I wrote post, the market for internet connected home automation devices has exploded... as have the concerns around the &lt;a href="(https://gizmodo.com/amazon-agrees-to-hand-over-data-in-echo-murder-case-1793039360)"&gt;privacy&lt;/a&gt;, &lt;a href="https://www.bleepingcomputer.com/news/government/germany-preparing-law-for-backdoors-in-any-type-of-modern-device/"&gt;security&lt;/a&gt; and &lt;a href="https://torrentfreak.com/piracy-notices-can-mess-with-your-thermostat-isp-warns-171224/"&gt;functionality&lt;/a&gt; (or &lt;a href="https://gizmodo.com/yes-your-amazon-echo-is-an-ad-machine-1821712916"&gt;unwanted functionality&lt;/a&gt;) of the devices. I am &lt;a href="http://uk.businessinsider.com/consumers-holding-off-on-smart-home-gadgets-thanks-to-privacy-fears-2017-11?r=US&amp;amp;IR=T"&gt;not alone&lt;/a&gt; in being sufficiently concerned by these issues that I choose the devices I allow on my home network very carefully and &lt;a href="http://ian.bebbs.co.uk/tags/monitoring"&gt;monitor them closely&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In short, the list of &amp;quot;off-the-shelf&amp;quot; devices I would feel comfortable having on my home network is very short and, until recently, I was resigned to having to build these devices myself using &lt;a href="https://en.wikipedia.org/wiki/Single-board_computer"&gt;single board computers&lt;/a&gt; or &lt;a href="https://en.wikipedia.org/wiki/ESP8266"&gt;Wifi connected microcontrollers&lt;/a&gt;. That is until a family of devices came to my attention that originated from the most unlikely of places...&lt;/p&gt;
&lt;h2 id="mi-smart-home"&gt;Mi Smart Home&lt;/h2&gt;
&lt;p&gt;China isn't the first country that comes to mind when you think about privacy yet, with the release of the &lt;a href="https://xiaomi-mi.com/mi-smart-home/"&gt;&amp;quot;Mi Smart Home&amp;quot;&lt;/a&gt; family of devices, the Chinese electronics manufacturer &lt;a href="https://en.wikipedia.org/wiki/Xiaomi"&gt;Xiaomi Inc&lt;/a&gt; seems to have delivered a smart-device eco-system that is privacy-friendly... albeit somewhat tacitly as we will see below.&lt;/p&gt;
&lt;p&gt;The Mi Smart family consists of a number of small, battery powered Zigbee devices such as &lt;a href="https://xiaomi-mi.com/sockets-and-sensors/xiaomi-mi-temperature-humidity-sensor/"&gt;temperature and humidity sensors&lt;/a&gt;, &lt;a href="https://xiaomi-mi.com/sockets-and-sensors/xiaomi-mi-door-window-sensors/"&gt;door / window sensors&lt;/a&gt;, &lt;a href="https://xiaomi-mi.com/sockets-and-sensors/xiaomi-mi-occupancy-sensor/"&gt;movement sensors&lt;/a&gt; and &lt;a href="https://www.gearbest.com/alarm-systems/pp_610096.html"&gt;various switches&lt;/a&gt;. Oh... and a curious &lt;a href="https://xiaomi-mi.com/sockets-and-sensors/xiaomi-mi-smart-home-cube-white/"&gt;'cube' controller&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These devices connect to your internal Wifi network via a &lt;a href="https://xiaomi-mi.com/mi-smart-home/xiaomi-mi-gateway-2/"&gt;Gateway device&lt;/a&gt;. In addition to providing the Zigbee to Wifi bridge, this gateway also provides an ambient light sensor, a very useful RGB light and a umm... not so useful speaker. This is all packaged in a small, round, 30 gram device about 8 centimeters in diameter and 3 cenitmeters deep. Frustratingly the gateway only comes with the Chinese/Australian type I plug so you need an adapter to use it in the UK which adds significantly to the depth (although I've taken to using a &lt;a href="https://www.gearbest.com/plugs-sockets/pp_1168562.html"&gt;convenient extension lead&lt;/a&gt; instead).&lt;/p&gt;
&lt;p&gt;To set up the Wifi Gateway device and add sensors, you have to install the &lt;a href="https://play.google.com/store/apps/details?id=com.xiaomi.smarthome&amp;amp;hl=en_GB"&gt;Xiaomi Mi Home app&lt;/a&gt; which, to be frank, is a privacy nightmare. The list of permissions it needs is quite incredible:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Version 5.1.1 can access:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Device &amp;amp; app history
&lt;ul&gt;
&lt;li&gt;retrieve running apps&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Identity
&lt;ul&gt;
&lt;li&gt;find accounts on the device&lt;/li&gt;
&lt;li&gt;add or remove accounts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Calendar
&lt;ul&gt;
&lt;li&gt;read calendar events plus confidential information&lt;/li&gt;
&lt;li&gt;add or modify calendar events and send emails to guests without owners' knowledge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Contacts
&lt;ul&gt;
&lt;li&gt;find accounts on the device&lt;/li&gt;
&lt;li&gt;read your contacts&lt;/li&gt;
&lt;li&gt;modify your contacts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Location
&lt;ul&gt;
&lt;li&gt;approximate location (network-based)&lt;/li&gt;
&lt;li&gt;precise location (GPS and network-based)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SMS
&lt;ul&gt;
&lt;li&gt;read your text messages (SMS or MMS)&lt;/li&gt;
&lt;li&gt;receive text messages (SMS)&lt;/li&gt;
&lt;li&gt;send SMS messages&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Phone
&lt;ul&gt;
&lt;li&gt;directly call phone numbers&lt;/li&gt;
&lt;li&gt;reroute outgoing calls&lt;/li&gt;
&lt;li&gt;read call log&lt;/li&gt;
&lt;li&gt;read phone status and identity&lt;/li&gt;
&lt;li&gt;write call log&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Photos / Media / Files
&lt;ul&gt;
&lt;li&gt;read the contents of your USB storage&lt;/li&gt;
&lt;li&gt;modify or delete the contents of your USB storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Storage
&lt;ul&gt;
&lt;li&gt;read the contents of your USB storage&lt;/li&gt;
&lt;li&gt;modify or delete the contents of your USB storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Camera
&lt;ul&gt;
&lt;li&gt;take pictures and videos&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Microphone
&lt;ul&gt;
&lt;li&gt;record audio&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Wi-Fi connection information
&lt;ul&gt;
&lt;li&gt;view Wi-Fi connections&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Device ID &amp;amp; call information
&lt;ul&gt;
&lt;li&gt;read phone status and identity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other
&lt;ul&gt;
&lt;li&gt;download files without notification&lt;/li&gt;
&lt;li&gt;interact across users&lt;/li&gt;
&lt;li&gt;full licence to interact across users&lt;/li&gt;
&lt;li&gt;transmit infrared&lt;/li&gt;
&lt;li&gt;modify secure system settings&lt;/li&gt;
&lt;li&gt;read Home settings and shortcuts&lt;/li&gt;
&lt;li&gt;write Home settings and shortcuts&lt;/li&gt;
&lt;li&gt;view network connections&lt;/li&gt;
&lt;li&gt;create accounts and set passwords&lt;/li&gt;
&lt;li&gt;read battery statistics&lt;/li&gt;
&lt;li&gt;pair with Bluetooth devices&lt;/li&gt;
&lt;li&gt;access Bluetooth settings&lt;/li&gt;
&lt;li&gt;send sticky broadcast&lt;/li&gt;
&lt;li&gt;change network connectivity&lt;/li&gt;
&lt;li&gt;allow Wi-Fi Multicast reception&lt;/li&gt;
&lt;li&gt;connect and disconnect from Wi-Fi&lt;/li&gt;
&lt;li&gt;disable your screen lock&lt;/li&gt;
&lt;li&gt;control flashlight&lt;/li&gt;
&lt;li&gt;full network access&lt;/li&gt;
&lt;li&gt;change your audio settings&lt;/li&gt;
&lt;li&gt;control Near-Field Communication&lt;/li&gt;
&lt;li&gt;read sync settings&lt;/li&gt;
&lt;li&gt;run at startup&lt;/li&gt;
&lt;li&gt;draw over other apps&lt;/li&gt;
&lt;li&gt;use accounts on the device&lt;/li&gt;
&lt;li&gt;control vibration&lt;/li&gt;
&lt;li&gt;prevent device from sleeping&lt;/li&gt;
&lt;li&gt;modify system settings&lt;/li&gt;
&lt;li&gt;toggle sync on and off&lt;/li&gt;
&lt;li&gt;install shortcuts&lt;/li&gt;
&lt;li&gt;uninstall shortcuts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Scary huh! How can I possibly claim these devices are privacy friendly when you've basically just given a Chinese company permission to do pretty much anything it likes with your phone's hardware and data? Well, notice how I said you need the app to &amp;quot;set up the Wifi Gateway device and add sensors&amp;quot;. Once they're setup you no longer need the app and, furthermore, once &amp;quot;local network functions&amp;quot; are enabled (more on this in a second) neither the gateway nor sensors need internet access to function.&lt;/p&gt;
&lt;p&gt;So, how to go about using these sensors in a privacy friendly way?&lt;/p&gt;
&lt;h1 id="preparation"&gt;Preparation&lt;/h1&gt;
&lt;p&gt;To get set up with these devices without compromising your privacy, you will need:&lt;/p&gt;
&lt;h2 id="a-dedicated-vlan-and-wifi-network-for-smart-home-devices"&gt;A dedicated VLAN and Wifi network for &amp;quot;smart home&amp;quot; devices&lt;/h2&gt;
&lt;p&gt;I recommend putting any 3rd party &amp;quot;smart&amp;quot; devices in an isolated environment within which you can easily enable or disable internet access. To do this I am using the VLAN feature of my Draytek 2860 router which involves  creating a second VLAN on my network, enabling &amp;quot;Inter-LAN' routing so I could access the VLAN from my existing subnet and, finally, adding firewall rules to prevent devices on this VLAN from accessing the internet / other vlans.&lt;/p&gt;
&lt;h2 id="a-clean-android-device"&gt;A clean Android device&lt;/h2&gt;
&lt;p&gt;I had an old Android phone laying around on which I performed a hard-reset and wiped all user-data. With a clean device I could then install the app without worrying about sharing anything private with Xiaomi&lt;/p&gt;
&lt;h1 id="installation"&gt;Installation&lt;/h1&gt;
&lt;p&gt;First, install the Xiaomi Mi Home app on your clean Android device. On first run after installation you will be prompted for a region and asked to sign in. In order to use all the Mi Smart devices, you &lt;strong&gt;must&lt;/strong&gt; select &amp;quot;Mainland China&amp;quot; for your region (this doesn't affect the language in the app) following which you can just create a new account to sign in.&lt;/p&gt;
&lt;p&gt;Once the app is installed you can plug in a gateway. This results in a nice flashing yellow ring of light around the device... and a harsh female voice babbling Chinese at an almost intolerable volume;  basically an audio and visual indication that the gateway is in &amp;quot;pairing&amp;quot; mode.&lt;/p&gt;
&lt;p&gt;Go ahead and pair the gateway to the app following the walk-through &lt;a href="https://www.youtube.com/watch?v=nkFF284OFRE"&gt;here&lt;/a&gt;. At this point it's a good idea to also install any additional &amp;quot;sub devices&amp;quot; you have (i.e. the various Zigbee sensors) which can be done by following &lt;a href="https://www.youtube.com/watch?v=TiAgeg5P1T4"&gt;this&lt;/a&gt; walkthrough.&lt;/p&gt;
&lt;p&gt;Finally, in order to use the gateway and sensors without the app and/or internet access, it is necessary to enable &amp;quot;local network functions&amp;quot;. This can be done from the app by following the instructions &lt;a href="https://www.domoticz.com/wiki/Xiaomi_Gateway_(Aqara)"&gt;here&lt;/a&gt;. Quite why Xiaomi decided to hide what its possible the killer feature of these devices behind a &amp;quot;secret&amp;quot; button I've no idea... fortunately it's an open secret and Xiaomi don't seem to be making any effort to conceal it further.&lt;/p&gt;
&lt;p&gt;With all the above done, feel free to junk the app and disable internet access from the &amp;quot;smart device&amp;quot; subnet / ip range.&lt;/p&gt;
&lt;h1 id="usage"&gt;Usage&lt;/h1&gt;
&lt;p&gt;Once 'local network functions' have been enabled, each Gateway uses the multicast address &lt;code&gt;224.0.0.50&lt;/code&gt; to broadcast UDP messages on port &lt;code&gt;9898&lt;/code&gt; from the gateway and sub-devices. The gateway publishes a &amp;quot;heartbeat&amp;quot; messages every 10-15 seconds or so meaning you can easily determine everything is working by spinning up Wireshark (on a device connected to the &amp;quot;smart device&amp;quot; subnet) filtering out anything that isn't a UDP message (&lt;code&gt;ip.proto == &amp;quot;udp&amp;quot;&lt;/code&gt;) and looking for messages from the gateway IP address. You should eventually see something like this:&lt;/p&gt;
&lt;img src="/Content/posts/Heartbeat.png" alt="Wireshark Heartbeat capture" class="img-responsive" style="margin-left: auto; margin-right: auto; margin-top: 4px; margin-bottom: 4px"&gt;
&lt;p&gt;Once you can see these messages you can start interacting with the gateway and devices using various commands. For example, to get a list of the sub-devices from a gateway you can send a 'get_id_list' command using a UDP packet container this string (as ASCII encoded binary) to the gateway's IP address, again on port &lt;code&gt;9898&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;get_id_list&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will result in a &lt;code&gt;get_id_list_ack&lt;/code&gt; response containing a list of &lt;code&gt;sid&lt;/code&gt; (aka 'simple' id) values for devices registered with the gateway (including the gateway sensor/status itself)  as follows:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;get_id_list_ack&amp;quot;,&amp;quot;sid&amp;quot;:&amp;quot;7811dcb06972&amp;quot;,&amp;quot;token&amp;quot;:&amp;quot;L0DI4IiFAvAgInyL&amp;quot;,&amp;quot;data&amp;quot;:&amp;quot;[\&amp;quot;158d0001a200f5\&amp;quot;,\&amp;quot;158d0001c1cdfb\&amp;quot;]&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You're then able to retrieve the device status using the &lt;code&gt;read&lt;/code&gt; command for each &lt;code&gt;sid&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;read&amp;quot;,&amp;quot;sid&amp;quot;:&amp;quot;7811dcb06972&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Which will return a &lt;code&gt;read_ack&lt;/code&gt; response containing device specific information in the 'data' property. For example, if you send a &lt;code&gt;read&lt;/code&gt; command specifying the &lt;code&gt;sid&lt;/code&gt; of the gateway you will receive something like the following:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;read_ack&amp;quot;,&amp;quot;model&amp;quot;:&amp;quot;gateway&amp;quot;,&amp;quot;sid&amp;quot;:&amp;quot;7811dcb06972&amp;quot;,&amp;quot;short_id&amp;quot;:0,&amp;quot;data&amp;quot;:&amp;quot;{\&amp;quot;rgb\&amp;quot;:0,\&amp;quot;illumination\&amp;quot;:1292,\&amp;quot;proto_version\&amp;quot;:\&amp;quot;1.0.9\&amp;quot;}&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, when the status of a sensor changes (for example a door sensor opens or closes) a &lt;code&gt;report&lt;/code&gt; message is broadcast as follows:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&amp;quot;cmd&amp;quot;:&amp;quot;report&amp;quot;,&amp;quot;model&amp;quot;:&amp;quot;magnet&amp;quot;,&amp;quot;sid&amp;quot;:&amp;quot;158d0001c1cdfb&amp;quot;,&amp;quot;short_id&amp;quot;:56258,&amp;quot;data&amp;quot;:&amp;quot;{\&amp;quot;status\&amp;quot;:\&amp;quot;open\&amp;quot;}&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;h1 id="heres-one-i-made-earlier"&gt;Here's one I made earlier...&lt;/h1&gt;
&lt;p&gt;I used the above information to create a small application for listening to and interacting with the gateway and devices. Mostly out of interest, I used &lt;a href="https://dotnet.github.io/orleans/"&gt;Microsoft's Orleans framework&lt;/a&gt; to create a console application which wraps up the interaction with various devices into strongly typed agents (also an agent approach seemed to nicely mirror the segregated nature of the devices themselves).&lt;/p&gt;
&lt;p&gt;I didn't take this too far as I subsequently decided to use an &amp;quot;off-the-shelf&amp;quot; system for interacting with the Xiaomi devices (the subject of my next &amp;quot;smart home&amp;quot; post) but it's a decent proof-of-concept. I've published the source in a &lt;a href="https://github.com/ibebbs/MiOrleans"&gt;repository on Github&lt;/a&gt;; feel free to have a play and drop me a line with any questions you might have.&lt;/p&gt;
&lt;p&gt;In the next post I'll disucss the off-the-shelf system I'm now using to privately interact with the Xiaomi devices.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Nano2Docker</title>
			<link>http://ian.bebbs.co.uk/posts/Nano2Docker</link>
			<description>&lt;p&gt;While my current contract doesn't leave much time for personal projects, I have made some progress on my current project (details on exactly what this is to follow). In fact, some of the smaller, peripheral services have their primary use-cases functionally complete and are ready for deployment and I am now faced with the question: Deployment to where?&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/Nano2Docker</guid>
			<pubDate>Mon, 10 Jul 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h1 id="deployment-at-last"&gt;Deployment at last&lt;/h1&gt;
&lt;p&gt;While my current contract doesn't leave much time for personal projects, I have made some progress on my current project (details on exactly what this is to follow). In fact, some of the smaller, peripheral services have their primary use-cases functionally complete and are ready for deployment and I am now faced with the question: Deployment to where?&lt;/p&gt;
&lt;h1 id="fabric-or-container"&gt;Fabric or Container&lt;/h1&gt;
&lt;p&gt;Given this project constitutes multiple micro-services using message based, asynchronous communication with the potential to scale services horizontally, I required some form of elastic service fabric. Furthermore, I wanted a local development environment which would simulate a cluster of machines but with which I could monkey about as much as I liked without fear of accidentally incurring massive hosting fees in the cloud.&lt;/p&gt;
&lt;p&gt;As I had just upgraded my home server with plenty of memory, I decided to use one of more virtual machines running on this server to host the environment during development, but which technology to use?&lt;/p&gt;
&lt;p&gt;Initially I had intended to use a &lt;a href="https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-get-started-with-a-local-cluster"&gt;local Service Fabric cluster&lt;/a&gt;. However, upon further investigation I found that the SDK and API introduced significant friction to the development process (needing additional projects for supplying manifest / configuration data for services, overly complex deployment scripts, etc). Even the 'guest executable' approach seemed overly complex and I quickly went off this approach.&lt;/p&gt;
&lt;p&gt;My second thought was &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;; specifically the creation of a local &lt;a href="https://docs.docker.com/engine/swarm/"&gt;Docker Swarm&lt;/a&gt; which I could deploy servies to with &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;. &lt;a href="https://docs.docker.com/machine/"&gt;Docker Machine&lt;/a&gt; made short work of provisioning Docker hosts in Hyper-V but with one caveat: it's &lt;a href="http://boot2docker.io/"&gt;boot2docker&lt;/a&gt; image would only run Linux based containers and, while many of the services I have written / will write run quite happily on .NET Core, some require packages that do not yet provide support for .NET Core / Standard.&lt;/p&gt;
&lt;p&gt;Given that a recent update made &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;Swarm mode available to Windows Server 2016&lt;/a&gt; host operating systems, I decided I would look into provisioning a series of Windows Server VM's with container support and configure Docker on these VM's to operate in swarm mode.&lt;/p&gt;
&lt;h1 id="using-nano-server-as-a-docker-host"&gt;Using Nano Server as a Docker host&lt;/h1&gt;
&lt;p&gt;While I had previously used Microsoft Nano Server as a &lt;a href="http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII"&gt;guest OS&lt;/a&gt; for &lt;a href="http://ian.bebbs.co.uk/posts/DockerAndKafka"&gt;containerized apps&lt;/a&gt;, I hadn't realised that it was possible to use it as a host OS for Docker until I came across &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/deploy-containers-on-nano"&gt;this article&lt;/a&gt;. For those not familiar with Nano Server it is an extremely slimmed down (the OS image is less than 170Mb) and fast booting (5-10 seconds), headless version of Windows Server 2016 which, given it is capable of acting as a Docker host, effectively makes it 'boot2docker' but for Windows containers.&lt;/p&gt;
&lt;p&gt;Nano Server is shipped with Windows Server 2016 and is accompanied by a Powershell module which provides some terrific facilities for working with Nano Server images. &lt;a href="https://docs.microsoft.com/en-us/windows-server/get-started/deploy-nano-server"&gt;This document&lt;/a&gt; shows how to use this Powershell module to create customised Nano Server images as either &lt;a href="https://en.wikipedia.org/wiki/Windows_Imaging_Format"&gt;'.wim'&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ISO_image"&gt;'.iso'&lt;/a&gt; or - most interestingly for me -  &lt;a href="https://technet.microsoft.com/en-us/library/hh831446(v=ws.11).aspx"&gt;'.vhdx'&lt;/a&gt;. In short, the following powershell command will create a virtual HD that can be attached to a virtual machine and which will boot directly into Nano Server with support for - but no utilites to provide - containerization services:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-NanoServerImage -Edition Standard -DeploymentType Guest -MediaPath &amp;lt;path to root of media&amp;gt; -BasePath &amp;lt;path in which to build the image&amp;gt; -TargetPath &amp;lt;destination path&amp;gt;\NanoServer.vhdx -ComputerName &amp;lt;computer name&amp;gt; -Containers -EnableRemoteManagementPort
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will also open &lt;a href="https://msdn.microsoft.com/en-us/library/aa384426(v=vs.85).aspx"&gt;WinRM&lt;/a&gt; ports on the Nano Server which allows you to use &lt;a href="https://technet.microsoft.com/en-us/library/ff700227.aspx"&gt;PS Remoting&lt;/a&gt; to remote into the virtual machine and examine it's state; indispensable for debugging purposes.&lt;/p&gt;
&lt;h1 id="updating-nano-server"&gt;Updating Nano Server&lt;/h1&gt;
&lt;p&gt;Referring back to the &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;'Getting Started with Swarm Mode'&lt;/a&gt; article, it states that a &lt;a href="https://support.microsoft.com/en-us/help/4015217/windows-10-update-kb4015217"&gt;relatively recent update&lt;/a&gt; is required to run Docker Swarms on Windows Server 2016 based OS's. It is therefore necessary to ensure this update is applied to any NanoServer image we create for the purpose of running Docker, ideally during the creation of the image not a subsequent setup script.&lt;/p&gt;
&lt;p&gt;Well, those clever people at Microsoft thought of this too and provided a &lt;code&gt;-ServicingPackagePath&lt;/code&gt; argument for the &lt;code&gt;New-NanoServerImage&lt;/code&gt; command which takes a path to a cab update file and applies the update to the NanoServer OS during image creation. A mechanism for getting an update from Microsoft (as an *.msu) and extracting it into a (series of) cab-files for use in the &lt;code&gt;New-NanoServerImage&lt;/code&gt; is provided by Thomas Maurer in &lt;a href="http://www.thomasmaurer.ch/2016/10/how-to-install-updates-on-nano-server/"&gt;an excellent blog post here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="installing-docker-as-part-of-a-nano-server-image"&gt;Installing Docker as part of a Nano Server image&lt;/h1&gt;
&lt;p&gt;Now, just like 'boot2docker' we want our Nano Server to be ready to host Windows Containers as soon as it's booted and without further manual configuration. To this end, I needed to find a way to install Docker as part of the deployment process. Fortunately the 'New-NanoServer' command provides a &lt;code&gt;-SetupCompleteCommand&lt;/code&gt; argument which allows you to 'run custom commands as part of setupcomplete.cmd' (i.e. on first boot). Great, so now to prepare a script to deploy Docker which we can call via the &lt;code&gt;-SetupCompleteCommand&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;Conveniently, Docker's &lt;a href="https://docs.docker.com/docker-ee-for-windows/install/#using-a-script-to-install-docker-ee"&gt;documentation for installing Docker EE&lt;/a&gt; (the version supported by Windows) provides exactly the script required, copied below with some additional configuration copied from the 'Prepare Container Host' section of &lt;a href=""&gt;'Deploy Containers on Nano'&lt;/a&gt; article:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# On an online machine, download the zip file
Invoke-Webrequest -UseBasicparsing -Outfile docker.zip https://download.docker.com/components/engine/windows-server/17.03/docker-17.03.0-ee.zip

# Extract the archive.
Expand-Archive docker.zip -DestinationPath $Env:ProgramFiles

# Clean up the zip file.
Remove-Item -Force docker.zip

# Install Docker. This will require rebooting.
# This is not required as we have already prepared out image with container support
# $null = Install-WindowsFeature containers

# Add Docker to the path for the current session.
$env:path += &amp;quot;;$env:ProgramFiles\docker&amp;quot;

# Modify PATH to persist across sessions.
# Note: Nano Server's SetEnvironmentVariable method does not take a scope parameter 
[Environment]::SetEnvironmentVariable(&amp;quot;PATH&amp;quot;, $env:path)

# Open an inbound port for the docker daemon  
netsh advfirewall firewall add rule name=&amp;quot;Docker daemon &amp;quot; dir=in action=allow protocol=TCP localport=2375

# Create and populate docker daemon's configuration file
New-Item -Type File 'C:\ProgramData\docker\config\daemon.json' -Force
Add-Content 'C:\programdata\docker\config\daemon.json' '{ &amp;quot;hosts&amp;quot;: [&amp;quot;tcp://0.0.0.0:2375&amp;quot;, &amp;quot;npipe://&amp;quot;] }'

# Register the Docker daemon as a service.
dockerd --register-service

# Start the daemon.
Start-Service docker
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this script requires that the Nano Server be online when the script is run so that it can download the Docker binaries. Unfortunately, given that this script will run as part of the deployment process, this is unlikely to be the case. Instead, we'll need to lean on another feature of the &lt;code&gt;New-NanoServerImage&lt;/code&gt;, &lt;code&gt;-CopyPath&lt;/code&gt;. This argument allows you to specify one or more files to copy to the Nano Server image as part of it's creation and we'll use it to copy a pre-downloaded copy of the docker binaries (along with a copy of the deployment script) to the root of the images C:\ drive, as shown here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-NanoServerImage -Edition Standard -DeploymentType Guest -MediaPath &amp;lt;path to root of media&amp;gt; -BasePath &amp;lt;path in which to build the image&amp;gt; -TargetPath &amp;lt;destination path&amp;gt;\NanoServer.vhdx -ComputerName &amp;lt;computer name&amp;gt; -Containers -EnableRemoteManagementPort -CopyPath &amp;#64;('&amp;lt;path to deployment script&amp;gt;\DeployDocker.ps1', '&amp;lt;path in which docker is downloaded&amp;gt;\docker.zip') -SetupCompleteCommand &amp;#64;('Powershell.exe -Command .\DeployDocker.ps1') 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, now we can comment out the first line of the script above and it'll run fine, right? Unfortunately not. It seems that, at the stage of the boot process at which this script runs, powershell isn't quite ready to run powershell. Fortunately, others have encountered this issue before and Sergey Babkin provides &lt;a href="https://blogs.msdn.microsoft.com/sergey_babkins_blog/2017/01/05/how-to-run-powershell-from-setupcomplete-cmd/"&gt;this solution&lt;/a&gt;; copied below with customisation for our requirements:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set LOCALAPPDATA=%USERPROFILE%\AppData\Local
set PSExecutionPolicyPreference=Unrestricted
Powershell -Command C:\DeployDocker.ps1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so we'll add and deploy this batch file as 'DeployDocker.bat' and then execute this instead of the powershell script as the &lt;code&gt;-SetupCompleteCommand&lt;/code&gt;, as shown here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-NanoServerImage -Edition Standard -DeploymentType Guest -MediaPath &amp;lt;path to root of media&amp;gt; -BasePath &amp;lt;path in which to build the image&amp;gt; -TargetPath &amp;lt;destination path&amp;gt;\NanoServer.vhdx -ComputerName &amp;lt;computer name&amp;gt; -Containers -EnableRemoteManagementPort -CopyPath &amp;#64;('&amp;lt;path to deployment batch file'\DeployDocker.bat', '&amp;lt;path to deployment script&amp;gt;\DeployDocker.ps1', '&amp;lt;path in which docker is downloaded&amp;gt;\docker.zip') -SetupCompleteCommand 'C:\DeployDocker.bat' 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And thats it. If you now create a virtual machine with the new 'NanoServer.vhdx' image as it's boot drive, you should find that, once it's booted you're able to communicate with the Docker daemon on the VM. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker -H &amp;lt;IP Address of VM&amp;gt; ps
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Should return a (empty) list of containers present on the Nano Server host.&lt;/p&gt;
&lt;h1 id="scripting-the-creation-of-a-vm"&gt;Scripting the creation of a VM&lt;/h1&gt;
&lt;p&gt;Now, jumping through all the hoops above each time we want to make a new VM to host docker would be arduous to say the least. As such, I put together a powershell module which is able to directly create VM's ready to host Docker containers in just a few steps. From a powershell command prompr, this can be done as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Get the Nano2Docker powershell module&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This module is available in my Docker repository on Github and can be downloaded directly using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Invoke-WebRequest -OutFile Nano2Docker.psm1 https://raw.githubusercontent.com/ibebbs/Docker/master/Nano2Docker/Nano2Docker.psm1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then installed using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Import-Module Nano2Docker.psm1
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Prepare a base NanoServer image&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The process of downloading docker and applying updates can be extremely slow. Therefore we first create a reusable base NanoServer image that has docker installed and updates applied. This is done using the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Initialize-Nano2DockerImage -MediaPath &amp;lt;Drive letter for Windows Server 2016&amp;gt; -BuildPath &amp;lt;Path to a build location&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, if your Windows Server 2016 media is mounted in the 'G' drive and you want to build the new Nano2Docker image in the 'C:\Nano2Docker' folder, you'd use the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Initialize-Nano2DockerImage -MediaPath G: -BuildPath &amp;quot;C:\Nano2Docker&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The command provides defaults download locations for docker and required updates but these can be overriden using the &lt;code&gt;-DockerUrl&lt;/code&gt; and &lt;code&gt;-UpdateUrl&lt;/code&gt; parameters repsectively. Furthermore, if you already have an '.msu' file downloaded you can save a lot of time by providing this to the command using the &lt;code&gt;-UpdateFile&lt;/code&gt; parameter.&lt;/p&gt;
&lt;p&gt;When you run this command, you will be prompted for Administrator credentials for the new Nano2Docker image. Either enter them when prompted or supply a &lt;code&gt;SecureString&lt;/code&gt; value to the &lt;code&gt;-Password&lt;/code&gt; argument (which is usually done using the &lt;code&gt;Get-Credentials&lt;/code&gt; commandlet).&lt;/p&gt;
&lt;p&gt;When this command completes - which can take a while - you will find a 'Nano2Docker.vhdx' file in the BuildPath directory.&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Create a VM using the new NanoServer image&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can now use the &lt;code&gt;New-Nano2Docker&lt;/code&gt; commandlet to quickly create new VM docker hosts. The command is used as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-Nano2Docker -MediaPath &amp;lt;Drive letter for Windows Server 2016&amp;gt; -ImagePath &amp;lt;Path to a previously created Nano2Docker.vhdx&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using our previous example, the command would be:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-Nano2Docker -MediaPath G: -ImagePath &amp;quot;C:\Nano2Docker\Nano2Docker.vhdx&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will copy the base image to the VM path (defaults to 'C:\Users\Public\Documents\Hyper-V\Virtual Hard Disks'), provision a new, local, Hyper-V VM named 'Nano2Docker' with reasonable resources (4 cores / 2Gb of dynamic ram) and attached to the first available virtual switch.
Obviously, each of these characteristics can be changed using the appropriate arguments - use &lt;code&gt;Get-Help New-Nano2Docker&lt;/code&gt; to list the available arguments. You will again be asked to an Administrator password for the new VM which can be entered during creation or specified as a parameter to the commandlet.&lt;/p&gt;
&lt;p&gt;Once the new VM has been created, it will be started and the script will wait for NanoServer to start correctly. Once started, the IP address of the new VM is displayed and it should be immediately possible to use docker to communicate with the docker daemon on the VM.&lt;/p&gt;
&lt;h1 id="scripting-the-deployment-of-a-docker-swarm"&gt;Scripting the deployment of a Docker Swarm&lt;/h1&gt;
&lt;p&gt;Given it was now trivial to create docker hosts, I wrote a final commandlet which leverages previous commandlets to provision an entire docker swarm. This is done using the &lt;code&gt;New-Nano2DockerSwarm&lt;/code&gt; commandlet as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-Nano2DockerSwarm -MediaPath &amp;lt;Drive letter for Windows Server 2016&amp;gt; -ImagePath &amp;lt;Path to a previously created Nano2Docker.vhdx&amp;gt; -VMPath &amp;lt;Path to a location to store swarm host VMs&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, using our previous example and wanting to store new VM images in the 'C:\Nano2Docker\VMs' directory, the command would be:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;New-Nano2DockerSwarm -MediaPath G: -ImagePath &amp;quot;C:\Nano2Docker\Nano2Docker.vhdx&amp;quot; -VMPath &amp;quot;C:\Nano2Docker\VMs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command defaults to creating a single manager node and three worker nodes named 'n2d-mngr-0' and 'n2d-wrkr-0/1/2' respectively. All nodes will have already been joined to the swarm in the appropriate capacity and ready for services to be deployed using docker or docker-compose.
Again, the number of manager and worked nodes as well as the name prefix for each node can be changed via the appropriate arguments (use &lt;code&gt;Get-Help New-Nano2DockerSwarm&lt;/code&gt; to list the arguments).&lt;/p&gt;
&lt;h1 id="roundup"&gt;Roundup&lt;/h1&gt;
&lt;p&gt;I've successfully used this script to provision multiple docker hosts and docker swarms but it's worthwhile noting that it can be a bit finickity with directories. If you can an error saying it couldn't find a directory then simply create it first. I really ought to fix up the script (improvements via PR gratefully accepted) but I'm now a bit busy deploying services to my swarm :0)&lt;/p&gt;
&lt;p&gt;Furthermore I've successfully used nodes created by this script to provision a hybrid swarm (see the 'Mixed OS clusters section &lt;a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode"&gt;here&lt;/a&gt;) of boot2docker and nano2docker images. With the appropriate labels on the nodes, it is possible to use &lt;code&gt;docker-compose&lt;/code&gt; to automatically deploy images to the correct hosts while retaining all the benefits of overlay networking.&lt;/p&gt;
&lt;p&gt;It's a lot of docking fun!&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Unicorn Pi Tweet Bot</title>
			<link>http://ian.bebbs.co.uk/posts/RaspberryPiUnicornTwitterBot</link>
			<description>&lt;p&gt;So, my partner and I - being &lt;a href="https://www.stem.org.uk/stem-ambassadors/ambassadors"&gt;STEM Ambassadors&lt;/a&gt; - were asked to prepare and present a talk about Raspberry Pis for a local university on &lt;a href="http://www.inwed.org.uk/"&gt;International Women In Engineering Day&lt;/a&gt;. Unfortunately, this invitation came rather late as a previous presenter had dropped out and this left very little time to prepare.&lt;/p&gt;</description>
			<enclosure url="https://i.ytimg.com/vi/g3sxXgLr1uQ/maxresdefault.jpg" length="0" type="image" />
			<guid>http://ian.bebbs.co.uk/posts/RaspberryPiUnicornTwitterBot</guid>
			<pubDate>Wed, 21 Jun 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;So, my partner and I - being &lt;a href="https://www.stem.org.uk/stem-ambassadors/ambassadors"&gt;STEM Ambassadors&lt;/a&gt; - were asked to prepare and present a talk about Raspberry Pis for a local university on &lt;a href="http://www.inwed.org.uk/"&gt;International Women In Engineering Day&lt;/a&gt;. Unfortunately, this invitation came rather late as a previous presenter had dropped out and this left very little time to prepare.&lt;/p&gt;
&lt;p&gt;While I had a couple of Pis around the house doing IoT related chores, I really wanted something a little more flashy to present so I quickly rushed out to the local Maplins and picked up a new Raspberry Pi 3 and a &lt;a href="https://shop.pimoroni.com/products/unicorn-hat"&gt;Pimoroni Unicorn HAT&lt;/a&gt; - the very definition of flashy.&lt;/p&gt;
&lt;img src="https://cdn.shopify.com/s/files/1/0174/1800/products/Unicorn_Still_4_1024x1024.jpg?v=1418813740" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="Pimoroni Unicorn HAT"&gt;
&lt;p&gt;I then needed to think of something to &lt;strong&gt;do&lt;/strong&gt; with it.&lt;/p&gt;
&lt;p&gt;Wanting something interactive and, ideally, internet related (seeing a physical manifestation of an event in cyberspace really has 'wow' factor) I decided to write a Twitter bot that listens for a specific hashtag (#INWED17 in this instance) and scrolls the text of the tweet across the Unicorn HAT leds. As with most things of this nature, a short google session resulted in several articles / blog posts I could mash up to produce the desired effect. These were:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.raspberrypi.org/learning/getting-started-with-the-twitter-api/requirements/"&gt;Getting started with Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://learn.pimoroni.com/tutorial/unicorn-hat/getting-started-with-unicorn-hat"&gt;Settings up Unicorn HAT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/topshed/UnicornHatScroll"&gt;Unicorn HAT scroll&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All in it took about an hour to get the various dependencies installed (including dealling with a rather annoying &lt;a href="https://stackoverflow.com/questions/27341064/how-do-i-fix-importerror-cannot-import-name-incompleteread"&gt;'pip' error&lt;/a&gt;), accounts set up and code mashed together in order to get a functional app up and running. Not bad considering this was my first stab at writing Python on a Pi.&lt;/p&gt;
&lt;p&gt;I pushed the code to a &lt;a href="https://github.com/ibebbs/UnicornPiBot"&gt;Github repository&lt;/a&gt; but have included it below simply because I am impressed with how concise the it is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import sys
import random

from UHScroll import *
from twython import TwythonStreamer
from auth import (
    consumer_key,
    consumer_secret,
    access_token,
    access_token_secret
)

colours = ['red','white','pink','blue','green','cyan']

non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)

class UnicornPiBotStreamer(TwythonStreamer):
    def on_success(self, data):
        if 'text' in data:
            text = data['text'].translate(non_bmp_map)
            colour = random.choice(colours)
            print(text)
            unicorn_scroll(text, colour, 200, 0.05)

stream = UnicornPiBotStreamer(
    consumer_key,
    consumer_secret,
    access_token,
    access_token_secret
)

stream.statuses.filter(track='#INWED17')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I'm now beginning to see why Python has gained such traction in non-enterprise markets and will definitely consider using it for future projects. Skipping the edit-compile-run loop and simply interpretting the code via a command line call certainly makes for fast iterations but I don't think I'd appreciate it so much if I was trying to develop anything of any size/complexity.&lt;/p&gt;
&lt;p&gt;Anyway, having an exhibit visitors can interact with (albeit indirectly) will make a good addition to the &lt;a href="http://ian.bebbs.co.uk/posts/MonsterPi"&gt;other&lt;/a&gt; &lt;a href="https://www.raspberrypi.org/magpi/issues/40/"&gt;Pi&lt;/a&gt; &lt;a href="https://aiyprojects.withgoogle.com/voice"&gt;devices&lt;/a&gt; we'll be taking along and discussing.&lt;/p&gt;
&lt;p&gt;Really quite looking forward to it now...&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>A sentiment(al) analysis of why Red Dwarf is no longer funny</title>
			<link>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII</link>
			<description>&lt;p&gt;I've recently been working on a project that required some natural language processing. After a surprisingly brief search I came upon the &lt;a href="https://stanfordnlp.github.io/CoreNLP/"&gt;Stanford CoreNLP&lt;/a&gt; suite of tools and after playing with their &lt;a href="http://corenlp.run/"&gt;online demo&lt;/a&gt; was astounded at the capabilities it provided. Furthermore, it was free, could be run such that it provided a basic HTTP API and came packaged with everything it needed save a copy of the JRE.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarfPartII</guid>
			<pubDate>Wed, 12 Apr 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;I've recently been working on a project that required some natural language processing. After a surprisingly brief search I came upon the &lt;a href="https://stanfordnlp.github.io/CoreNLP/"&gt;Stanford CoreNLP&lt;/a&gt; suite of tools and after playing with their &lt;a href="http://corenlp.run/"&gt;online demo&lt;/a&gt; was astounded at the capabilities it provided. Furthermore, it was free, could be run such that it provided a basic HTTP API and came packaged with everything it needed save a copy of the JRE.&lt;/p&gt;
&lt;p&gt;Having recently &lt;a href="http://ian.bebbs.co.uk/posts/DockerAndKafka"&gt;enjoyed a lot of success&lt;/a&gt; running &lt;a href="https://zookeeper.apache.org/"&gt;various&lt;/a&gt; &lt;a href="https://kafka.apache.org/"&gt;JAVA&lt;/a&gt; &lt;a href="https://neo4j.com/product/"&gt;services&lt;/a&gt; inside a &lt;a href="https://www.docker.com/"&gt;Docker container&lt;/a&gt; running &lt;a href="https://technet.microsoft.com/en-us/windows-server-docs/get-started/getting-started-with-nano-server"&gt;Windows Nano Server&lt;/a&gt;, I decided to see if CoreNLP could be run like this too. Copying my previous &lt;a href="https://github.com/ibebbs/Docker/blob/master/Nanoserver-Zookeeper/Build.ps1"&gt;build script&lt;/a&gt; and &lt;a href="https://github.com/ibebbs/Docker/blob/master/Nanoserver-CoreNLP/Build.ps1"&gt;amending it&lt;/a&gt; to build a &lt;a href="https://hub.docker.com/r/ibebbs/nanonlp/"&gt;container running CoreNLP&lt;/a&gt; was ludicrously easy and in no time I had a local API I could hit to perform all the natural language processing I needed.&lt;/p&gt;
&lt;p&gt;Now, while the project I was working on mainly required the &lt;a href="https://stanfordnlp.github.io/CoreNLP/ner.html"&gt;&amp;quot;Named Entity Recognition&amp;quot;&lt;/a&gt; and &lt;a href="https://stanfordnlp.github.io/CoreNLP/openie.html"&gt;&amp;quot;Open IE&amp;quot;&lt;/a&gt; annotators, I was intrigued to see that CoreNLP also included a basic &lt;a href="https://stanfordnlp.github.io/CoreNLP/sentiment.html"&gt;Sentiment&lt;/a&gt; annotator. Given that I had written part one of this post back in January, had noted at the time how much I'd like to do sentiment analysis on the transcripts of Red Dwarf, and that I hadn't written a blog post since, I decided to take some time out and perform the sentiment analysis so that I could write this post.&lt;/p&gt;
&lt;p&gt;Again employing &lt;a href="https://jupyter.org/"&gt;Project Jupyter&lt;/a&gt; hosted on &lt;a href="https://notebooks.azure.com/"&gt;Azure Notebooks&lt;/a&gt; and using &lt;a href="http://fsharp.org/"&gt;F#&lt;/a&gt; coupled with &lt;a href="https://fslab.org/"&gt;FsLab&lt;/a&gt; as my primary language and toolkit, I had a lot of fun performing the analysis. Like last time, you can find the &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis/blob/master/SentimentAnalysisWithCoreNLP.ipynb"&gt;full notebook&lt;/a&gt; and source material in my &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis"&gt;Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note: As before, Github provides a &amp;quot;limited rendering only&amp;quot; so, to see all the charts running correctly you need to use the 'nbviewer' link shown below to see a full rendering of the notepad.&lt;/p&gt;
&lt;img src="https://mvpfyw-dm2306.files.1drv.com/y3mppldGfaYEhvWkV7mdUw26-lP3SOzlMTGFbf8slchIfjBL57IH-GrJev6ai_rISiHBKrom7Abg9YFjfhZ1ArOFT7a7mh4gJuGq-CErv1dun48GQC_BdhMV08fh6hbw400d9nHSEXJ0jA2nPBIrpOPNrOz0I3lVY1tu_L656ylQKg?width=660&amp;height=283&amp;cropmode=none" class="img-responsive" style="margin: auto; width:660; margin-top: 6px; margin-bottom: 6px;" alt="Open external view with nbviewer"/&gt;
&lt;p&gt;The best bit of all (note: spoilers ahead!) is that it seems my original conclusion may indeed have been wrong... or at least mis-attributed.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>A sentiment(al) analysis of why Red Dwarf is no longer funny</title>
			<link>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarf</link>
			<description>&lt;p&gt;Yesterday I had a lot of fun playing with &lt;a href="http://jupyter.org/"&gt;Project Jupyter&lt;/a&gt;. For those that aren't aware of this project, it's an effort to provide a workspace for performing repeatable experimentation with data. In short it mixes markdown editing capabilities with a &lt;a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;REPL&lt;/a&gt; environment for a large number of languages. From the website:&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/ASentimentalAnalysisOfRedDwarf</guid>
			<pubDate>Tue, 31 Jan 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Yesterday I had a lot of fun playing with &lt;a href="http://jupyter.org/"&gt;Project Jupyter&lt;/a&gt;. For those that aren't aware of this project, it's an effort to provide a workspace for performing repeatable experimentation with data. In short it mixes markdown editing capabilities with a &lt;a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;REPL&lt;/a&gt; environment for a large number of languages. From the website:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;&amp;quot;a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, machine learning and much more&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After having my interest tweaked by the &lt;a href="https://try.jupyter.org/"&gt;browser version&lt;/a&gt; I bit the bullet and spent ages downloading and installing the &lt;a href="http://jupyter.org/install.html"&gt;full version&lt;/a&gt; to a virtual machine. It's a Python based web-app so requires quite a bit of setup and unfortunately I found the documentation to be a bit sparse.&lt;/p&gt;
&lt;p&gt;And so it was that while trying to work out how to install the &lt;a href="https://github.com/fsprojects/IfSharp"&gt;FSharp module&lt;/a&gt; I came across &lt;a href="https://notebooks.azure.com/"&gt;Azure Notebooks&lt;/a&gt;. This is a free, Azure hosted version of Jupyter that has almost all the features of a local installation but with none of the faff. After quickly spinning up a new notebook here I didn't even look back at the local installation.&lt;/p&gt;
&lt;h2 id="a-jupyter-data-mining-core-project"&gt;A Jupyter [Data] Mining Core Project&lt;/h2&gt;
&lt;p&gt;As per the title and lead of this post, I decided to use Jupyter to have a little fun.&lt;/p&gt;
&lt;p&gt;Back in September, while grinding my way through &lt;a href="http://www.imdb.com/title/tt0094535/episodes?season=11&amp;amp;ref_=tt_eps_sn_11"&gt;season 11 of Red Dwarf&lt;/a&gt;, I began to wonder why it wasn't as funny as it used to be. Had the writing deteriorated? Were the actors past it? Or were these elements still as great as they used to be and it was me who had changed?&lt;/p&gt;
&lt;p&gt;I started thinking about ways this could be investigated such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using IMDB rating as a measure of humour in each episode of Red Dwarf&lt;/li&gt;
&lt;li&gt;Performing semantic analysis of episode's transcript to see if the sentiment had changed&lt;/li&gt;
&lt;li&gt;Using word-count to determine whether there was a correlation between character participation and overall humour&lt;/li&gt;
&lt;li&gt;etc&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, it was a funny notion and provided a pleasant distraction from the &lt;a href="http://www.imdb.com/title/tt5218266"&gt;pretty awful episode&lt;/a&gt; of Red Dwarf I was watching at the time. I added it to my &amp;quot;ideas&amp;quot; list in &lt;a href="https://trello.com/b/KoTWuFUi/public-board"&gt;Trello&lt;/a&gt;, finished the episode and went to bed.&lt;/p&gt;
&lt;p&gt;Yesterday, when I came across Project Jupyter, I knew it'd be a great medium for performing this investigation so shifted the analysis from &amp;quot;Ideas&amp;quot; to &amp;quot;In progress&amp;quot; and got cracking.&lt;/p&gt;
&lt;h2 id="data-science-using-f"&gt;Data Science using F#&lt;/h2&gt;
&lt;p&gt;Now, while in relation to this investigation I use the term &amp;quot;data science&amp;quot; to basically mean &amp;quot;munging a few numbers and drawing a few graphs&amp;quot;, I do think F# makes a fantastic language for the discipline in general. It has some incredible mechanisms for &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/fsharp/tutorials/type-providers/"&gt;acquiring&lt;/a&gt; and &lt;a href="http://fsharpforfunandprofit.com/posts/the-option-type/"&gt;cleaning&lt;/a&gt; data as well as for &lt;a href="http://www.quanttec.com/fparsec/"&gt;parsing natural language&lt;/a&gt;. Couple this with it's concise, functional, elegant language and the ability to leverage components from the entire breadth of .NET ecosystem and you have quite a significant offering.&lt;/p&gt;
&lt;h2 id="azure-notebooks"&gt;Azure Notebooks&lt;/h2&gt;
&lt;p&gt;The Azure implementation of Project Jupyter is first class and, for now at least, totally free. Getting started is as simple as logging in with Microsoft credentials and then clicking 'Add notebook'. Being an MS implementation, I used Edge to edit the notebook and found the experience extremely robust, especially given it's a &amp;quot;Preview&amp;quot; program.&lt;/p&gt;
&lt;p&gt;In fact I experience just two issues while authoring my notebook:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data Store - It's not currently possible to upload or store data within the Azure notebook library (despite having functionality to do this in the web-interface). Instead you need to host your data on one of a small number of whitelisted sites. Fortunately Github is one of these sites so this doesn't prove to be much of an issue.&lt;/li&gt;
&lt;li&gt;Packages - While Azure Notebooks provides access to a large number of packages &amp;quot;out-of-the-box&amp;quot; (i.e. FSharp.Data, XPlot.Plotly, etc) it can be tricky to add/use other packages. For example, I wanted to use the XPlot.GoogleCharts package (as it provided trendline capabilities) and ended up having to write a custom display printer for it to work (due to an &lt;a href="https://github.com/fsprojects/IfSharp/issues/118"&gt;open issue&lt;/a&gt; on Github).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Apart from these issues, authoring and scripting F# in an Azure Notebook was almost as fast as using &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/fsharp/tutorials/fsharp-interactive/"&gt;&amp;quot;F# Interactive&amp;quot;&lt;/a&gt;. It even provides Intellisense capabilities but, in practice, these are usually too slow to be of actual use.&lt;/p&gt;
&lt;h2 id="sharing-notebooks"&gt;Sharing Notebooks&lt;/h2&gt;
&lt;p&gt;From Azure Notebooks you're able to download your notebook as a native &amp;quot;.ipynb&amp;quot; file (in fact this is encouraged as MS reserves the right to remove unused notebooks after 60 days). You can then share this file to other people who have Jupyter installed or, preferably, commit it to a repository in Github which has excellent support for Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;You can find my notebook &amp;quot;A sentiment(al) analysis of why Red Dwarf is no longer funny (to me)&amp;quot; &lt;a href="https://github.com/ibebbs/RedDwarfAnalysis/blob/master/Investigation.ipynb"&gt;here&lt;/a&gt;. As you will see when you click the link, Github not only shows you the static parts of the notebook but actually tries to spin up a kernel and execute the code parts too. This is a &amp;quot;limited rendering only&amp;quot; so Github also provides a link to open the notebook in 'nbviewer' &lt;a href="http://nbviewer.jupyter.org/github/ibebbs/RedDwarfAnalysis/blob/2712285e1f9c69fc347bdfe6404792101eaea5f1/Investigation.ipynb"&gt;web-app&lt;/a&gt;. This link is shown below:&lt;/p&gt;
&lt;img src="https://mvpfyw-dm2306.files.1drv.com/y3mppldGfaYEhvWkV7mdUw26-lP3SOzlMTGFbf8slchIfjBL57IH-GrJev6ai_rISiHBKrom7Abg9YFjfhZ1ArOFT7a7mh4gJuGq-CErv1dun48GQC_BdhMV08fh6hbw400d9nHSEXJ0jA2nPBIrpOPNrOz0I3lVY1tu_L656ylQKg?width=660&amp;height=283&amp;cropmode=none" class="img-responsive" style="margin: auto; width:660; margin-top: 6px; margin-bottom: 6px;" alt="Open external view with nbviewer"/&gt;
&lt;h2 id="the-analysis"&gt;The analysis&lt;/h2&gt;
&lt;p&gt;I had timeboxed my investigation into Project Jupyter and therefore didn't get round to performing an actual sentiment anaylsis of the content of each episode. However I did manage to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Programmatically download episode information from several sources in JSON format and use &lt;a href="http://fsharp.github.io/FSharp.Data/library/JsonValue.html"&gt;JsonValue&lt;/a&gt; to dynamically query these sources&lt;/li&gt;
&lt;li&gt;Scrape demographically categorized rating information from IMDB and use &lt;a href="http://fsharp.github.io/FSharp.Data/reference/fsharp-data-htmldocument.html"&gt;HtmlDocument&lt;/a&gt; to parse the data into strong types&lt;/li&gt;
&lt;li&gt;Resolve issue with rendering XPlot.GoogleCharts charts within the notebook and use these charts to provide an interactive visualisation of the decline in rating of Red Dwarf across time and demographic categories.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This provided a fair stab at correlating episode rating with the overall decline in Red Dwarf's humourousness but is a long way short of any form of &amp;quot;data science&amp;quot;. It was both enlightening and a lot of fun doing this small project and I will certainly consider Azure Notebooks as a valuable tool in my toolbox.&lt;/p&gt;
&lt;p&gt;Should I find the time, I would certainly like to return to this project and use &lt;a href="http://www.quanttec.com/fparsec/"&gt;FParsec&lt;/a&gt; and &lt;a href="https://azure.microsoft.com/en-gb/services/cognitive-services/text-analytics/"&gt;Azure Text Analytics&lt;/a&gt; to perform an actual sentiment analysis. Hopefully it'll overturn, or at least help justify, my somewhat disturbing conclusion!&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Combining the UWP SpeechSynthesizer and AudioGraph APIs</title>
			<link>http://ian.bebbs.co.uk/posts/CombiningUwpSpeechSynthesizerWithAudioGraph</link>
			<description>&lt;p&gt;Synchronicity is a wonderful thing.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/CombiningUwpSpeechSynthesizerWithAudioGraph</guid>
			<pubDate>Wed, 25 Jan 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Synchronicity is a wonderful thing.&lt;/p&gt;
&lt;p&gt;Just this morning I was considering using the new &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.speechsynthesis.speechsynthesizer.aspx"&gt;SpeechSynthesizer&lt;/a&gt; capabilities of the UWP platform to add spoken language to my &lt;a href="https://www.microsoft.com/en-gb/store/p/toddlerbox/9nblggh3zr4l"&gt;ToddlerBox app for Xbox&lt;/a&gt;. I had already started using the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiograph.aspx"&gt;AudioGraph&lt;/a&gt; classes to play sounds in the app so ideally wanted to continue using this API to emit speech.&lt;/p&gt;
&lt;p&gt;Then, during my morning... ahem... ablutions, I came across &lt;a href="https://mtaulty.com/2017/01/15/windows-10-uwp-iot-core-speechsynthesizer-raspberry-pi-and-audio-popping/"&gt;this post&lt;/a&gt; by Mike Taulty who was looking to do the same thing but for different reasons. It seems that the RaspberryPi has a firmware issue that causes a &lt;a href="https://social.msdn.microsoft.com/Forums/en-US/7c312972-6a09-4acd-8a3f-c59485a81d74/clicking-sound-during-start-and-stop-of-audio-playback?forum=WindowsIoT"&gt;popping noise&lt;/a&gt;  every time speech is emitted using the MediaPlayer and AudioGraph seems to be a way of resolving it.&lt;/p&gt;
&lt;h2 id="the-problem"&gt;The problem&lt;/h2&gt;
&lt;p&gt;Mike had implemented a means of emitting speech via AudioGraph by saving the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.speechsynthesis.speechsynthesisstream.aspx?f=255&amp;amp;MSPPError=-2147217396"&gt;SpeechSynthesisStream&lt;/a&gt; to a  temporary file and then using multiple &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiofileinputnode.aspx"&gt;AudioFileInputNode&lt;/a&gt; instances to render the speech to the AudioGraph.&lt;/p&gt;
&lt;p&gt;&amp;quot;Well&amp;quot;, I thought, &amp;quot;there's got to be a better way. How hard can this be...&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Turns out the answer is: &amp;quot;Not all that hard, but...&amp;quot;.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id="my-approach"&gt;My approach&lt;/h2&gt;
&lt;p&gt;I wanted to find a way to eliminate the need for the temporary files and render the speech stream directly to the graph.&lt;/p&gt;
&lt;p&gt;To do this, I first saved the SpeechSynthesisStream to a file so that I could examine the content. As expected, the file turned out to be a simple 32-bit, mono, ADPCM waveform in &lt;a href="http://soundfile.sapp.org/doc/WaveFormat/"&gt;WAV/RIFF format&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Having previously messed about with AudioGraph I knew there was a way of creating an in-memory waveform and that the &lt;a href="https://github.com/Microsoft/Windows-universal-samples"&gt;Windows-Universal-Samples github repository&lt;/a&gt; had an &lt;a href="https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/AudioCreation"&gt;AudioCreation sample&lt;/a&gt; that &lt;a href="https://github.com/Microsoft/Windows-universal-samples/blob/master/Samples/AudioCreation/cs/AudioCreation/Scenario3_FrameInputNode.xaml.cs"&gt;showed how to do this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fundamentally, this sample shows how to use the &lt;a href="https://msdn.microsoft.com/en-gb/library/windows/apps/windows.media.audio.audioframeinputnode.quantumstarted"&gt;QuantumStarted event&lt;/a&gt; of the &lt;a href="https://msdn.microsoft.com/library/windows/apps/dn914147"&gt;AudioFrameInputNode&lt;/a&gt; to dynamically add &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audioframe.aspx"&gt;AudioFrame&lt;/a&gt; to the AudioFrameInputNode which are then rendered to the &lt;a href="https://msdn.microsoft.com/en-gb/library/windows/apps/dn914151"&gt;output node&lt;/a&gt;. An extract from the sample is shown here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  unsafe private AudioFrame GenerateAudioData(uint samples)
  {
      // Buffer size is (number of samples) * (size of each sample)
      // We choose to generate single channel (mono) audio. For multi-channel, multiply by number of channels
      uint bufferSize = samples * sizeof(float);
      AudioFrame frame = new Windows.Media.AudioFrame(bufferSize);

      using (AudioBuffer buffer = frame.LockBuffer(AudioBufferAccessMode.Write))
      using (IMemoryBufferReference reference = buffer.CreateReference())
      {
          byte* dataInBytes;
          uint capacityInBytes;
          float* dataInFloat;

          // Get the buffer from the AudioFrame
          ((IMemoryBufferByteAccess)reference).GetBuffer(out dataInBytes, out capacityInBytes);

          // Cast to float since the data we are generating is float
          dataInFloat = (float*)dataInBytes;

          float freq = 1000; // choosing to generate frequency of 1kHz
          float amplitude = 0.3f;
          int sampleRate = (int)graph.EncodingProperties.SampleRate;
          double sampleIncrement = (freq * (Math.PI * 2)) / sampleRate;

          // Generate a 1kHz sine wave and populate the values in the memory buffer
          for (int i = 0; i &amp;lt; samples; i++)
          {
              double sinValue = amplitude * Math.Sin(theta);
              dataInFloat[i] = (float)sinValue;
              theta += sampleIncrement;
          }
      }

      return frame;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Imitation being the sincerest form of flattery, I then refactored this code to read the binary data from the SpeechSynthesisStream rather than generate a sine wave as shown above. This was greatly facilited by the &lt;a href="https://msdn.microsoft.com/en-us/library/hh582142.aspx"&gt;WindowsRuntimeStreamExtensions.AsStreamForRead&lt;/a&gt; method which allowed me to use basic &lt;a href="https://msdn.microsoft.com/en-us/library/system.io.stream.aspx"&gt;Stream&lt;/a&gt; methods  (specifically &lt;a href="https://msdn.microsoft.com/en-us/library/system.io.stream.readbyte.aspx"&gt;Stream.ReadByte()&lt;/a&gt;) instead of having to mess about with &lt;a href="https://msdn.microsoft.com/en-us/library/windows.media.speechsynthesis.speechsynthesisstream.readasync.aspx"&gt;IBuffer&lt;/a&gt; instances.&lt;/p&gt;
&lt;p&gt;In short order, I ended up with the code below (where &lt;code&gt;_stream&lt;/code&gt; is a member of the containing class pointing to the underlying SpeechSynthesisStream):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    private unsafe void QuantumStarted(AudioFrameInputNode sender, FrameInputNodeQuantumStartedEventArgs args)
    {
        uint numSamplesNeeded = (uint)args.RequiredSamples;

        if (numSamplesNeeded != 0 &amp;amp;&amp;amp; _stream.Position &amp;lt; _stream.Length)
        {
            uint bufferSize = numSamplesNeeded * sizeof(float);
            AudioFrame frame = new AudioFrame(bufferSize);

            using (AudioBuffer buffer = frame.LockBuffer(AudioBufferAccessMode.Write))
            {
                using (IMemoryBufferReference reference = buffer.CreateReference())
                {
                    byte* dataInBytes;
                    uint capacityInBytes;

                    // Get the buffer from the AudioFrame
                    ((IMemoryBufferByteAccess)reference).GetBuffer(out dataInBytes, out capacityInBytes);

                    for (int i = 0; i &amp;lt; bufferSize; i++)
                    {
                        if (_stream.Position &amp;lt; _stream.Length)
                        {
                            dataInBytes[i] = (byte)_stream.ReadByte();
                        }
                        else
                        {
                            dataInBytes[i] = 0;
                        }
                    }
                }
            }

            _frameInputNode.AddFrame(frame);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to my surprised, it worked!&lt;/p&gt;
&lt;p&gt;I encapsulated this code into a class named &lt;a href="https://github.com/ibebbs/BlogProjects/blob/master/UwpSpeechAudio/GraphExtensions.cs"&gt;AudioSpeechInputNode&lt;/a&gt; and made this class implement &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudioinputnode.aspx"&gt;IAudioInputNode&lt;/a&gt; so it could be treated like any other node in the AudioGraph. Finally I added an extension method to AudioGraph that created instance of this node in the same way that other nodes are created. This is shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    AudioSpeechInputNode speechInputNode = await _graph.CreateSpeechInputNodeAsync(new SpeechSynthesizer(), &amp;quot;As input node&amp;quot;);
    speechInputNode.AddOutgoingConnection(_outputNode); // device output node
    speechInputNode.Stop();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this node in hand you're then at liberty to call the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudionode.start.aspx"&gt;Start&lt;/a&gt;, &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudionode.stop.aspx"&gt;Stop&lt;/a&gt; and &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.iaudionode.reset.aspx"&gt;Reset&lt;/a&gt; methods as you see fit.&lt;/p&gt;
&lt;p&gt;Et voila, a SpeechSynthesisStream rendered in an AudioGraph without the need for an intermediary file.&lt;/p&gt;
&lt;h2 id="you-said-there-was-a-but"&gt;You said there was a 'but' ...&lt;/h2&gt;
&lt;p&gt;Well, yes. Three of them actually.&lt;/p&gt;
&lt;h3 id="the-big-but"&gt;The big 'but'&lt;/h3&gt;
&lt;p&gt;While this approach certainly solves the issue with needing temporary files and a 'popping' sound each time speech is emitted, I'm afraid to say it does not resolve the 'popping' noise encountered when the application starts on a RaspberryPi.&lt;/p&gt;
&lt;p&gt;Being a good nerd, I had a spare RaspberryPi 3 hanging around with a recent version of Windows 10 IoT Core installed. It took just a few minutes to recompile my &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/UwpSpeechAudio"&gt;sample app&lt;/a&gt; to ARM and deploy it to the Pi whereupon I could confirm that there is no popping when emitting speech but there is when the application starts. In fact, I receive three distinct 'pops' during application start-up which, by studiously placing breakpoints, I isolated to &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiograph.createasync.aspx"&gt;AudioGraph.CreateAsync&lt;/a&gt; (two pops) and &lt;a href="https://msdn.microsoft.com/en-us/library/windows/apps/windows.media.audio.audiograph.start.aspx"&gt;AudioGraph.Start&lt;/a&gt; (one pop).&lt;/p&gt;
&lt;p&gt;Microsoft would have us believe that this is an issue with the RaspberryPi firmware but, as it also occurs on &lt;a href="https://developer.qualcomm.com/hardware/dragonboard-410c"&gt;DragonBoard 410c&lt;/a&gt; I'm more inclined to believe it's an issue with the Windows drivers. On a hunch, I've just ordered a &lt;a href="https://www.amazon.co.uk/dp/B016CU2PEU"&gt;USB Sound Adapter from Amazon&lt;/a&gt;. This device is &lt;em&gt;meant&lt;/em&gt; to be Windows and RaspberryPi compatible (which doesn't necessarily mean it'll work with IoT Core on RPi) and, if it works, I'll be very interested to see if I still get the popping noises when the application starts. I'll update this post once I have an answer...&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Update: I'm pleased to say that, not only does &lt;a href="https://www.amazon.co.uk/dp/B016CU2PEU"&gt;this device&lt;/a&gt; work with Windows 10 IoT Core running on the RaspberryPi 3, but it also resolves the issue with popping noises when the application starts. Of course, this would probably also solve the issue with popping noises when rendering speech through MediaPlayer too making my solution above less necessary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="the-intermediate-but"&gt;The intermediate 'but'&lt;/h3&gt;
&lt;p&gt;My code makes a number of assumptions about the format of the SpeechSynthesisStream and encapsulates these as constants. It would be much better to read the format from the WAVE 'fmt ' chunk of the underlying RIFF structures in the stream but, being a pragmatic, &lt;a href="https://martinfowler.com/bliki/Yagni.html"&gt;YAGNI principled&lt;/a&gt; developer... I skipped this for now.&lt;/p&gt;
&lt;h3 id="the-small-but"&gt;The small 'but'&lt;/h3&gt;
&lt;p&gt;As is probably very obvious, the code above is in no way optimised. I'm sure there are &lt;em&gt;much&lt;/em&gt; better and faster ways of storing and copying the binary data from the SpeechSynthesisStream into the AudioBuffer (perhaps just using an intermediate byte array would help) but, for now, this code works fine.&lt;/p&gt;
&lt;h2 id="show-me-the-code"&gt;Show me the code&lt;/h2&gt;
&lt;p&gt;All the code for the above can be found in a &lt;a href="https://github.com/ibebbs/BlogProjects/tree/master/UwpSpeechAudio"&gt;UWP sample app&lt;/a&gt; within the &lt;a href="https://github.com/ibebbs/BlogProjects"&gt;BlogProjects&lt;/a&gt; repository of my &lt;a href="https://github.com/ibebbs"&gt;Github&lt;/a&gt; account.&lt;/p&gt;
&lt;p&gt;Do &lt;a href="https://twitter.com/ibebbs"&gt;get in touch&lt;/a&gt; if you find this code helpful or have suggestions for improving it.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>The Year In Review</title>
			<link>http://ian.bebbs.co.uk/posts/TheYearInReview</link>
			<description>&lt;p&gt;Saturday morning, having realized that we had no commitments or prior engagements until the following Tuesday, my partner and I decided to go on a trip. We rapidly packed bags for ourselves and our little girl, threw them in the van and set off with no set destination other than "the south-west". We ended up staying in a small farm on Exmoor and having a terrific time walking on the moor and visiting nearby sites.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/TheYearInReview</guid>
			<pubDate>Wed, 18 Jan 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Saturday morning, having realized that we had no commitments or prior engagements until the following Tuesday, my partner and I decided to go on a trip. We rapidly packed bags for ourselves and our little girl, threw them in the van and set off with no set destination other than &amp;quot;the south-west&amp;quot;. We ended up staying in a small farm on Exmoor and having a terrific time walking on the moor and visiting nearby sites.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Other than the liberty of being able to just &amp;quot;get away&amp;quot;, this weekend was notable as the previous week marked exactly one year since I left full-time employment.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Back in July, following an epic road-trip around Europe with my girls, I wrote &lt;a href="http://ian.bebbs.co.uk/posts/WotNoBlogPosts"&gt;a long blog post&lt;/a&gt; about the trip and my plans for the future. These plans centred on taking the rest of the year off as a career-break and using this time to support my family while investigating/evaluating emerging technologies in the .NET ecosystem.&lt;/p&gt;
&lt;p&gt;Now, six months on, it's time to look back over the last year and perform a retrospective; what went well, what could have been better and what should be changed moving forward.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Note: This is a long, detailed post with a lot of information/reflection about the previous year. As such I have published it as a MVP (Minimal Viable Post) and will iterate additional information into the post in the future.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="a-timeline"&gt;A Timeline&lt;/h2&gt;
&lt;p&gt;To aid the retrospective process, I spent last week learning &lt;a href="https://www.dartlang.org/"&gt;Dart&lt;/a&gt; and &lt;a href="http://www.pixijs.com/"&gt;Pixi.js&lt;/a&gt; in order to create a timeline visualization of the year. I'm not going to go into the process of making this visualization here as I want to focus on the retrospective, however I will be writing a &amp;quot;making of&amp;quot; follow-up post as the process was both very interesting and thoroughly enjoyable.&lt;/p&gt;
&lt;p&gt;Below you can see the visualization; a timeline covering the entirity of last year and showing the various aspects of my behaviour / productivity on a day-by-day basis. In order to fit into the horizontal space available in most browsers/platforms, the timeline is scaled-down along the horizontal axis. As this obscures much of the data, the timeline was designed to allow you to use your mouse or finger to interactively zoom in and and pan across the it. Give it a go.&lt;/p&gt;
&lt;p&gt;In the following sections I will discuss the various datasets displayed along with a summary of what they represent.&lt;/p&gt;
&lt;script defer="" src="../Content/Scripts/timeline.dart.js"&gt;&lt;/script&gt;
&lt;div id="timeline"&gt;&lt;/div&gt;
&lt;h2 id="state"&gt;State&lt;/h2&gt;
&lt;p&gt;This timeline represents my primary oocupation at any given time. From a high-level, last year can be broadly split into two halves, travelling for the first half and working for the latter. However, the detail is more telling so the timeline has been further split into seven disctinct states:&lt;/p&gt;
&lt;h3 id="employment"&gt;Employment&lt;/h3&gt;
&lt;p&gt;My last day of employment was Friday 15th January, 2016. I had worked at my previous company for over four years and very much enjoyed my time there. Unfortunately an &lt;a href="http://www.daedtech.com/top-heavy-department-growth/"&gt;internal power struggle&lt;/a&gt; resulted in a change of senior management and a move away the progressive development methodologes which had made the company such a great place to work. This, to me, signalled that it was time to move on.&lt;/p&gt;
&lt;h3 id="sabatical"&gt;Sabatical&lt;/h3&gt;
&lt;p&gt;I considered the couple of months following ending full time employment as a sabatical; time to reflect, get my affairs in order and spend time with my young family before  considering how to move forward.&lt;/p&gt;
&lt;p&gt;At this time my daughter was just 4 months old so this presented a great opportunity to support my partner and engage with my baby. Having also taken 6 weeks of &lt;a href="https://www.gov.uk/shared-parental-leave-and-pay/overview"&gt;Shared Parental Leave&lt;/a&gt; the previous year, this meant that, of her first six months of life, I'd been able to spend almost four with her. I feel incredibly fortunate to be in a situation where this is could be the case. The first few months of a baby's life are incredibly tough for both the parents and the baby and I'm very happy that I was able to be with my girls throughout this time.&lt;/p&gt;
&lt;p&gt;It was towards the end of this period that my partner and I decided to capitalise on our unique situation and put the remainder of her maternity leave to use by taking our little girl on a road-trip around Europe. The implications of this decision were to dominate and, to a large degree, consume the entirity of the next three months.&lt;/p&gt;
&lt;h3 id="preparation"&gt;Preparation&lt;/h3&gt;
&lt;p&gt;Having made the decision to spend a significant amount of time touring Europe, with an 8 month old baby no less, it became apparent that there would be a whole lot of preparation required to make this happen. In March we decided to buy a Nissan Elgrand E51 Rider Autech (shown below) and April onwards was spent preparing it for our trip.&lt;/p&gt;
&lt;img src="https://zdfcta.db.files.1drv.com/y4mQKizez_l7UqminQJ370W0zOqSjgp8dzr9A6BJzxI7FYaFdaYeD57W4wemr8e-owerWw7fUQEXBQGf1qnZHAh6isrlvzMILL48wBWU0xnvlTkwB-cbw6R0AYZpCIT8zCKnjtp9fk6jSNRgzQR7ezNV3TKgT_cunpk9Cma-S5A5N2Z6tPzb21HxzhRQLvfF7z5fcshZnxaVzmuOIlkiUpnVA?width=660&amp;height=495&amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Nissan Elgrand E51 Rider Autech"/&gt;
&lt;p&gt;This preparation was complex, with numerous requirements, constraints and learning curves across a variety of disciplines... but also a whole lot of fun. On our return I wrote a &lt;a href="http://elgrandoc.uk/forum/index.php?threads/touring-europe-in-an-elgrand-part-i-to-v.3311"&gt;very long post&lt;/a&gt; for the &lt;a href="http://elgrandoc.uk/forum/index.php"&gt;Elgrand Owners Club&lt;/a&gt; which detailed all the work I had done on the van. While the post took a significant amount of time to write, the forums were invaluable in providing the information I needed to do the work in the first place so I thought it was worth investing this time in case the post helped someone else in the same manner. To this day, the post is still one of the most viewed and commented on posts in the forum and  well worth a read a read.&lt;/p&gt;
&lt;p&gt;During this time I learned a lot about carpentry, electronics and engineering... but I almost didn't. Prior to undertaking the work, I had looked to find a conversion specialist who would do the work for me but most either only provided pattern-part conversions or were too busy to undertake a bespoke project. Well, &amp;quot;necessity being the mother of invention&amp;quot;, I set to it and, in retrospect, am extremely glad I did.&lt;/p&gt;
&lt;p&gt;Despite barely having used an electric drill previously and never having dabbled in 240v electronics, I enjoyed every aspect of the work and am immensely proud of it. We didn't experience a single issue with my work while we were away and, even if we had, it was extremely comforting knowing that I could have resolved the issue in the field if I'd had to.&lt;/p&gt;
&lt;p&gt;Should a similar challenge ever present itself again, I would certainly look at taking it on and, furthermore, would encourage others to do so also as you undoubtedly &lt;a href="https://hbr.org/2016/07/if-youre-not-outside-your-comfort-zone-you-wont-learn-anything"&gt;learn a lot more when working outside of your comfort zone&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="touring-europe"&gt;Touring Europe&lt;/h3&gt;
&lt;p&gt;All the prep done - well, as much as was possible in the time available - we left home on May 20th and didn't return again until July 17; totaling just over 8 weeks on the road. In this time we traveled &lt;strong&gt;in excess of 8000 miles and visited 22 countries&lt;/strong&gt; seeing numerous friends en-route and making many more in the process.&lt;/p&gt;
&lt;p&gt;Perhaps it was all the prep or perhaps we were just lucky but the trip went off without a hitch and everyone - including our little girl - had an amazing time. Both &lt;a href="https://bigspune.wordpress.com/"&gt;my partner&lt;/a&gt; and &lt;a href="http://ian.bebbs.co.uk/posts/WotNoBlogPosts"&gt;I&lt;/a&gt; blogged about the trip - for ourselves as much for any potential reader - and, six months on, are still reflecting on what a fantastic adventure it was.&lt;/p&gt;
&lt;p&gt;Without a shadow of a doubt, and even when considering the week's of preparation before leaving, this trip was time well spent. My partner and I learned a lot about each other (&amp;quot;hey, we &lt;em&gt;can&lt;/em&gt; spend several weeks in a confined space together, 24/7&amp;quot;) and our daughter and have accumulated memories that will last a lifetime. We have already talked about doing another similar trip in the future and have begun planning shorter breaks around the UK as a stop-gap until an opportunity for a new adventure comes along.&lt;/p&gt;
&lt;h3 id="study"&gt;Study&lt;/h3&gt;
&lt;p&gt;Upon my return, I came across a code for a free &lt;a href="https://borntolearn.mslearn.net/b/weblog/posts/sign-up-to-take-the-beta-exam-for-developing-mobile-apps-70-357-today"&gt;Microsoft beta exam about mobile application development&lt;/a&gt;. As I was interested in UWP app development and had already taken loads of these beta exams in previous years, I decided to sit the exam even though the code was only valid for a few weeks after signing up, which left very little time to study!!&lt;/p&gt;
&lt;p&gt;As I &lt;a href="https://en.wikipedia.org/wiki/Experiential_learning"&gt;learn&lt;/a&gt; &lt;a href="http://psycnet.apa.org/journals/bdb/17/1/1.pdf&amp;amp;productCode=pa"&gt;best&lt;/a&gt; &lt;a href="https://www.virgin.com/richard-branson/you-learn-by-doing-and-by-falling-over"&gt;by&lt;/a&gt; &lt;a href="https://news.uchicago.edu/article/2015/04/29/learning-doing-helps-students-perform-better-science"&gt;doing&lt;/a&gt; my study focused on writing a UWP app that incorporated as many of the &lt;a href="https://www.microsoft.com/en-us/learning/exam-70-357.aspx"&gt;examined technical aspects&lt;/a&gt; as possible. While the methodologies I used for this app were relatively new (i.e. CQRS/ES) the learning curve for this exam really came from some of the unique aspects of UWP app development such as designing for multiple devices/screen sizes, using &lt;a href="https://docs.microsoft.com/en-us/ef/core/"&gt;new persistence technologies&lt;/a&gt; and leveraging the huge new API surface available to UWP apps.&lt;/p&gt;
&lt;p&gt;Due to an awful dashboard implementation which &lt;a href="https://borntolearn.mslearn.net/b/weblog/posts/more-tips-about-beta-exams-what-to-expect-when-you-39-re-expecting-your-beta-results-that-is"&gt;causes much confusion for students who sit beta exams&lt;/a&gt;, I am still unsure as to whether I passed this exam or not. My dashboard has not changed to say I have passed the exam but I have not received a summary sheet from Microsoft with my scores nor am I able to access them from my MCP dashboard. In short, the current beta exam process is extremely poor and much worse than it was five or six years ago when I took (and passed) around a dozen such beta exams.&lt;/p&gt;
&lt;p&gt;Regardless, time spent on this study was a huge win. I learned a lot about a platform which is becoming increasingly prevalent in the Windows ecosystem. UWP apps are able to run on everything from Raspberry Pi to Hololens, and I have since deployed/released UWP apps for Raspberry Pi, Mobile (phone/table), PC and XBox. Indeed, after completing the exam, I continued to develop my UWP study app over the next few months.&lt;/p&gt;
&lt;h3 id="holiday"&gt;Holiday&lt;/h3&gt;
&lt;p&gt;Across the year, I allocated around 40 days (including bank-holidays and weekends) as non-work days (aka holiday). This included snowboarding with friends, trips abroad, visiting relatives and a long festive break over Xmas. Although more than the holiday allowance at most full time jobs (depending on how it's allocated), I feel this represents a fairly decent split between work and play.&lt;/p&gt;
&lt;h3 id="onecog.solutions"&gt;OneCog.Solutions&lt;/h3&gt;
&lt;p&gt;Once life had returned to normal following our tour of Europe and taking the Microsoft beta exam, I decided to work on a few projects that were interesting to me.&lt;/p&gt;
&lt;p&gt;Firstly, this was continuing my investigation of UWP, initially to &lt;a href="http://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl"&gt;flesh out&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/store/p/littlelittle/9nblggh51b1b"&gt;release&lt;/a&gt; the UWP app I had written while studying for the UWP exam but then to also evaluate UWP as a &lt;a href="http://ian.bebbs.co.uk/posts/MonsterPi"&gt;platform for IoT devices&lt;/a&gt;. I then proceeded to broaden my area of investigation into &lt;a href="http://ian.bebbs.co.uk/posts/DockerAndKafka"&gt;non-Microsoft technologies&lt;/a&gt; and even into areas that, while still technical, were &lt;a href="http://ian.bebbs.co.uk/posts/3DPrintingWithTheCelRobox"&gt;not directly involved with software development&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;During this time I endeavored to keep an up-to-date public profile. Through a &lt;a href="https://trello.com/b/KoTWuFUi/public-board"&gt;public Trello board&lt;/a&gt;, products I had released (&lt;a href="https://www.microsoft.com/en-gb/store/p/littlelittle/9nblggh51b1b"&gt;LittleLittle&lt;/a&gt; &amp;amp; &lt;a href="https://www.microsoft.com/en-gb/store/p/toddlerbox/9nblggh3zr4l"&gt;ToddlerBox&lt;/a&gt;), posts to &lt;a href="http://ian.bebbs.co.uk/"&gt;my blog&lt;/a&gt; and contributions to both &lt;a href="https://github.com/ibebbs"&gt;Github&lt;/a&gt; and &lt;a href="http://stackoverflow.com/users/628821/ibebbs"&gt;StackOverflow&lt;/a&gt; I tried to make sure as much of my time as possible was surfaced publicly. Indeed, having become extremely delivery-oriented since first drinking the agile (&lt;a href="https://medium.com/swlh/agile-is-the-new-waterfall-f7baef5d026d#.jpmks6gi4"&gt;lower-case 'a'&lt;/a&gt;) kool-aid several years ago, I feel the public-facing nature of these interactions substituted as a form of delivery; or, in Agile parlance, became my &lt;a href="https://www.agilealliance.org/glossary/definition-of-done/"&gt;&amp;quot;definition of done&amp;quot;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While, in retrospect, I had hoped to have investigated many more technologies than I actually managed during this time, overall I would consider this time well spent. In addition to releasing two applications to the Windows Store and contributing to several public Github projects (more on this later) I managed to rack up over 1000 rep on StackOverflow in just a couple of months.&lt;/p&gt;
&lt;p&gt;Unfortunately, during this time, I didn't achieve my primary goal; namely finding a project that could potentially be grown into a marketable product and form the basis of a company. While there were no shortage of ideas and there still remain a couple of &amp;quot;coals in the fire&amp;quot;, I don't think I've yet found the gap in the market I'm looking for. One slight positive note here is that I have, at the very least, determined a couple of markets I'm very keen on investigating further and in which I'd like to work in the future.&lt;/p&gt;
&lt;h2 id="health"&gt;Health&lt;/h2&gt;
&lt;p&gt;For this visualization I have employed step count (vertical bars), weight (yellow line with dotted yellow representing ideal weight) and fat-mass (red line with dotted red representing ideal fat-mass) as a (very rough) approximation of health. While, in theory, I should have had more leisure time available to exercise over the course of the year, in real terms I found that I did far less than expected. This was due to a number of factors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My previous employer, being a company that revolves around football, had regular football matches/tournaments between company staff which were of a very high standard. I played in as many of these as possible and, once I left, I very much missed the exercise.&lt;/li&gt;
&lt;li&gt;My commute to work each day involved a (voluntary) walk from St Pancras station to Camden Lock - and back again - every day. This constituted 30 minutes/5000 steps of valuable exercise each day that was no longer necessary when I started working from home.&lt;/li&gt;
&lt;li&gt;I ran a football team for my village that played in the local Bedfordshire league. Unfortunately, due to lack of players this team folded at the end of last season leaving me entirely bereft of football for the majority of the year.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At punching-weight, I aim to be 11st and 15% fat-mass. This used to be a fairly common occurrence while playing football regularly but, as can be seen, I've not managed to get back into a similar condition this year. Fortunately, I &lt;em&gt;have&lt;/em&gt; managed to avoid devolving into a complete bucket of lard thanks to several things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Parenthood - As any parent will tell you, being a parent is both exhausting and relentless. While previously I would undertake very little exercise in the evening, nowadays I expend a significant amount of energy each evening running around after my daughter. While not often recognised, this constitutes a fairly high level of activity.&lt;/li&gt;
&lt;li&gt;Preparation for Touring Europe - During this time I did &lt;strong&gt;a lot&lt;/strong&gt; of very physical work. From lugging construction materials and tools around to disassembling and reassembling the van, the average day was extremely active, especially when compared to sitting in an office chair for eight hours.&lt;/li&gt;
&lt;li&gt;European Tour - as can be seen from the step count, although a great deal of time was spent driving, our time away involved a lot of other activity. This activity (particularly loading and unloading the van each day!) provided a lot of exercise and helped keep me fit over the summer.&lt;/li&gt;
&lt;li&gt;Swimming - In a desperate attempt to remain in some sort of shape, I have recently started swimming semi-regularly.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In retrospect, something that came as no surprise but for which I failed to anticipate the true impact, was the effect of not exercising on my state of mind and general happiness. Having always been an active and optimistic individual, I completely underestimated the tight correlation between these two characteristics. Mid-November saw me at my least active and, as I've come to realise, my least productive/focused (as evidenced by the sudden surge in StackOverflow rep!). Fortunately I try be somewhat self-reflective and, recognising that my diminished level of activity might be a possible cause for a perceived lack of progress, I decided to start swimming again as a means to address this.&lt;/p&gt;
&lt;p&gt;Now, while I'm still not exercise as much as I would like, I at least feel like my activity levels are sufficient to allow me to focus on projects and achieve my deliverables. Moving forward I very much hope to re-establish the village football team in time for next season or join another team such that I get at least a couple of games a month.&lt;/p&gt;
&lt;h2 id="finances"&gt;Finances&lt;/h2&gt;
&lt;p&gt;In counterpoint to the Health visualization described above, the Finances visualization shows a relative interpretation of my financial health across the year.&lt;/p&gt;
&lt;p&gt;At the beginning of the year, when considering a career-break, I tried to calculate a monthly &amp;quot;burn-rate&amp;quot; (i.e. total out-goings per month). Given I was not planning to change my lifestyle at all and my partner and I had already planned a number of holidays, I arrived at a rough estimate of £3k per month. This was affordable and, while it would put a dent in my savings, wouldn't leave me worrying about money at the end of the year.&lt;/p&gt;
&lt;p&gt;Through-out the year there were a number of factors that further affected my finances:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Touring Europe in the van cost significantly more than I estimated.&lt;/li&gt;
&lt;li&gt;My daughter's nursery care was cheaper than expected since moving her from four days a week to three (instead having an additional 'daddy-day-care' day).&lt;/li&gt;
&lt;li&gt;While I typically spend a significant amount on computer hardware, this year I required very little but for a relatively cheap new server.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, looking back across the year (and excluding large one-off payments like buying the van) it seems my burn-rate was closer to £2k, one third less than I had planned. This coupled with receiving returns on previous investments meant I actually ended the year significantly better off than I started it. While this definitely wouldn't be the case were I to continue the career-break for a second year, it is very reassuring to know that I could, should I decide to do so.&lt;/p&gt;
&lt;h2 id="github-contributions"&gt;Github contributions&lt;/h2&gt;
&lt;p&gt;Across the year - although predominantly in the last few months - I made 368 commits to Github. These were spread across a couple of dozen repositories but mostly focused on the (private) repository for &lt;a href="https://www.microsoft.com/en-gb/store/p/littlelittle/9nblggh51b1b"&gt;LittleLittle&lt;/a&gt; and my (statically generated &amp;amp; github-pages hosted) &lt;a href="https://github.com/ibebbs/ibebbs.github.io"&gt;blog&lt;/a&gt;. Additionally, I contributed to several open source repositories, most notably the &lt;a href="https://github.com/Microsoft/UWPCommunityToolkit"&gt;UWP Community Toolkit&lt;/a&gt; (1000 stars) and &lt;a href="https://github.com/beto-rodriguez/Live-Charts"&gt;Live-Charts&lt;/a&gt; (875 stars).&lt;/p&gt;
&lt;p&gt;Given 2016 was a leap-year, 368 commits in 366 days averages (just!) over one a day. Overall I'm quite pleased with this level of commitment and the quantity of work it represents, especially considering the amount of time this year spent not working. Additionally, for the last three months of this year, my partner and I have both elected to work four-day weeks as we felt it represented a better balance between parental and nursery care for our daughter. For me this meant Thursdays became &amp;quot;daddy-day-care&amp;quot; so that I could take my daughter swimming - something we both really enjoy - but which adversely affected my productivity.&lt;/p&gt;
&lt;p&gt;Moving forward I intend to start publishing much more of my work to public repositories including regular updates to my &lt;a href="https://github.com/ibebbs/Spikes"&gt;&amp;quot;Spikes&amp;quot;&lt;/a&gt; repository which contains investigative projects and examples for solutions to various StackOverflow questions.&lt;/p&gt;
&lt;h2 id="stackoverflow"&gt;StackOverflow&lt;/h2&gt;
&lt;p&gt;Talking of StackOverflow questions, the next visualization shows StackOverflow Reputation accumulation across the year (light blue line) with gains shown day-by-day (dark blue boxes). While I predominantly consider it a distraction, I really enjoy answering questions on StackOverflow, probably due to the awesome &lt;a href="https://en.wikipedia.org/wiki/Gamification"&gt;gamification&lt;/a&gt; employed on the &lt;a href="http://stackexchange.com/"&gt;StackExchange&lt;/a&gt; sites.&lt;/p&gt;
&lt;p&gt;While there is a low level of fairly constant reputation gain, most of the gains came in short bursts. As discussed above, I attribute this losing focus on my main projects due to inactivity. Still, there are far worse forms of procrastination than helping people and I consider this a relatively good use of time.&lt;/p&gt;
&lt;p&gt;I am currently endeavoring to get the 'Fanatic' badge (visit StackOverflow for 100 days consecutively) but trying not to let it get in the way of other work. This usually means only answering questions when I can quickly point the asker in the right direction but I will occasionally field a more challenging question when it's &lt;a href="http://stackoverflow.com/questions/tagged/system.reactive"&gt;something I'm particularly interested in&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="blog-posts"&gt;Blog posts&lt;/h2&gt;
&lt;p&gt;Over the course of the year I have written and published 22 blog posts - totaling nearly 24,000 words - across a range of subjects including:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;3D PRINTING (1) APACHE KAFKA (1) APACHE ZOOKEEPER (1) ATTACHED PROPERTY (1) BDD (1) BEHAVIORAL (1) BLOG (3) CAREER BREAK (1) CLIENT-SIDE FRAMEWORK (2) CQRS (1) DART (1) DATAFLOW (1) DOCKER (1) DVD RIPPING (1) EF (1) ELASTIC STACK (4) ELASTICSEARCH (4) EVENT SOURCING (1) EVENTS (1) EVENTSOURCING (1) FUTURE (1) GITHUB (2) GROWTH (1) HYPERLINK (1) IOT (1) JAVASCRIPT (2) JS (1) KIBANA (4) LITTLELITTLE (1) LOGSTASH (4) MAPLIN (1) MONITORING (4) MVVM (1) NANOSERVER (1) NETWORKING (4) PARENTHOOD (1) PATTERNS (1) PRODUCTIVITY (1) RASPBERRYPI (1) REACTIVE (7) REST (1) ROBOX (1) RX (7) SQL (1) STATE MACHINES (1) SVG (1) SYSLOG (4) TESTING (1) TODDLERBOX (3) TOOLKIT (2) TPL (2) TRAVEL (1) TYPESCRIPT (1) UWP (7) VISUAL STUDIO (2) VISUAL STUDIO CODE (1) WEBRX (2) WINDOWS SERVER 2016 (1) WYAM (1) XAML (2) XBOX (3)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This content garners an average of around 110 unique visitors and 400 page views every month.&lt;/p&gt;
&lt;p&gt;One of these posts - &lt;a href="https://blogs.msdn.microsoft.com/dotnet/2016/09/07/the-week-in-net-972016/"&gt;&amp;quot;The absolute easiest way to use SVG icons in UWP apps&amp;quot;&lt;/a&gt; was featured in &lt;a href="https://blogs.msdn.microsoft.com/dotnet/2016/09/07/the-week-in-net-972016/"&gt;&amp;quot;The week in .NET – 9/7/2016&amp;quot;&lt;/a&gt;. Furthermore, blog posts I have shared with people on other platforms (i.e. StackOverflow, MSDN, etc) have been understood and well received.&lt;/p&gt;
&lt;p&gt;All in, I think I've added some valuable content to my blog this last year but feel like I should have tried harder to increase it's reach. While writing these blog posts inevitably takes a considerably amount of time, I intend to continue making as many new posts as possible, hopefully across an increased range of subjects and - by submitting to various aggregation blogs - with increased readership.&lt;/p&gt;
&lt;h2 id="commitments"&gt;Commitments&lt;/h2&gt;
&lt;p&gt;This timeline displays any days I had expected to work yet was unable to for a variety of reasons. Over the course of the year this accounted for 42 days, mostly the Thursdays that have become my &amp;quot;daddy-day-care&amp;quot; day and during which I take my daughter swimming. While these &amp;quot;commitments&amp;quot; would have been worked around had I been in full-time employment, the flexibility of working when I can as opposed to when I have to has undoubtedly led to a greater degree of motiviation and concentration when I am in front of the computer.&lt;/p&gt;
&lt;h1 id="summary"&gt;Summary&lt;/h1&gt;
&lt;p&gt;Given this fairly comprehensive look back across the year, it's time to perform the retrospective.&lt;/p&gt;
&lt;h3 id="what-went-well"&gt;What went well?&lt;/h3&gt;
&lt;p&gt;There were numerous wins across the year including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Getting to spend the year with my partner and baby which included spending two months traveling Europe in a camper-van.&lt;/li&gt;
&lt;li&gt;Releasing applications to the Windows Store for phone, tablet, PC and XBox.&lt;/li&gt;
&lt;li&gt;Furthering the breadth of my technical knowledge of various platforms, technologies and methodologies.&lt;/li&gt;
&lt;li&gt;Adding a significant amount of content to my blog.&lt;/li&gt;
&lt;li&gt;Contributing to numerous repositories on Github including several for popular open-source projects.&lt;/li&gt;
&lt;li&gt;Increasing my StackOverflow Reputation level by answering questions on a variety of subjects.&lt;/li&gt;
&lt;li&gt;Fully realising the importance of exercise on productivity.&lt;/li&gt;
&lt;li&gt;Completing the year in better financial health than I had expected.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="what-didnt-go-so-well"&gt;What didn't go so well?&lt;/h3&gt;
&lt;p&gt;Given that, despite taking a career break, I continued to be productive in a variety of ways, I don't feel like too many things went badly this year. However there are a few things I would have liked to have achieved but didn't such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Not finding the &amp;quot;market gap&amp;quot; or having the &amp;quot;killer idea&amp;quot; I had hoped to translate into a start-up.&lt;/li&gt;
&lt;li&gt;Not investigating as many technologies as I had hoped across the course of the year.&lt;/li&gt;
&lt;li&gt;Lacking a significant amount of exercise and thereby loosing focus and momentum for ongoing projects.&lt;/li&gt;
&lt;li&gt;Shying away from increasing the exposure of my blog content via news aggregators, social media, etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="what-needs-to-change-moving-forward"&gt;What needs to change moving forward&lt;/h3&gt;
&lt;p&gt;Well, I gave myself the year to come up with the &amp;quot;killer idea&amp;quot; but didn't manage it so now it's time to change tack. In the coming months I will be starting to look for contract work which, ideally, I can do remotely. Fortunately there is no pressure for me to return to work so I can be quite picky about the roles I take. The ideal contract would ideally feature one or all of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UWP/WPF&lt;/li&gt;
&lt;li&gt;Rx/Streaming technologies&lt;/li&gt;
&lt;li&gt;.NET Core&lt;/li&gt;
&lt;li&gt;IoT&lt;/li&gt;
&lt;li&gt;NoSQL datastores&lt;/li&gt;
&lt;li&gt;CQRS/ES&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ideally in the following markets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Baby/Toddler/Child care/entertainment&lt;/li&gt;
&lt;li&gt;Social Justice&lt;/li&gt;
&lt;li&gt;Automation&lt;/li&gt;
&lt;li&gt;Agriculture&lt;/li&gt;
&lt;li&gt;Renewable Energy&lt;/li&gt;
&lt;li&gt;Automotive&lt;/li&gt;
&lt;li&gt;Economics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That said, given the large number of &lt;a href="https://blog.rjmetrics.com/2014/04/30/the-big-opportunities-in-the-unknown-unknowns/"&gt;&amp;quot;unknown unknowns&amp;quot;&lt;/a&gt;, perhaps there are other technologies / markets I've not encountered yet that would be equally enthralling.&lt;/p&gt;
&lt;p&gt;In the mean time, I will continue to investigate other interesting technologies and release updates to my existing products as appropriate.&lt;/p&gt;
&lt;p&gt;Regarding family life, well, in this respect I hope to continue the extremely rewarding work/life balance my partner and I have achieved over the last year. This could be difficult once the demands of external deadlines become a reality again but it's something I would be extremely reluctant to change.&lt;/p&gt;
&lt;h2 id="in-conclusion"&gt;In conclusion&lt;/h2&gt;
&lt;p&gt;It's been an amazing year and one I will remember for a long time. Regardless of what I end up doing, it is my aim to take another career break in the not too distant future in which I will endeavor to repeat the successes of this year, remedy the failures and remind myself that it's good to look up from the computer from time to time.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Dart web development with Visual Studio Code</title>
			<link>http://ian.bebbs.co.uk/posts/DartInVisualStudioCode</link>
			<description>&lt;p&gt;Visual Studio Code is rapidly becoming my go-to editor for anything not project-oriented C#/F#. I've switched from &lt;a href="https://atom.io/"&gt;Atom&lt;/a&gt; to &lt;a href="(https://code.visualstudio.com/)"&gt;VSC&lt;/a&gt; for editing my (&lt;a href="http://ian.bebbs.co.uk/posts/NewBlogUsingWyam"&gt;statically-generated, Markdown driven&lt;/a&gt;) blog and have used it for authoring powershell scripts, dockerfiles and much, much more. So, when I decided I wanted to write some &lt;a href="https://www.dartlang.org/"&gt;Dart&lt;/a&gt; code, it was the obvious choice.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/DartInVisualStudioCode</guid>
			<pubDate>Tue, 17 Jan 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Visual Studio Code is rapidly becoming my go-to editor for anything not project-oriented C#/F#. I've switched from &lt;a href="https://atom.io/"&gt;Atom&lt;/a&gt; to &lt;a href="(https://code.visualstudio.com/)"&gt;VSC&lt;/a&gt; for editing my (&lt;a href="http://ian.bebbs.co.uk/posts/NewBlogUsingWyam"&gt;statically-generated, Markdown driven&lt;/a&gt;) blog and have used it for authoring powershell scripts, dockerfiles and much, much more. So, when I decided I wanted to write some &lt;a href="https://www.dartlang.org/"&gt;Dart&lt;/a&gt; code, it was the obvious choice.&lt;/p&gt;
&lt;h2 id="why-dart"&gt;Why Dart?&lt;/h2&gt;
&lt;p&gt;Why did I decide on Dart? Well, I had project I wanted to undertake that featured some... shock horror... dynamic web content. If that isn't enough to send chills down your spine, you've either &lt;a href="https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.fqoett4pt"&gt;never had to look at getting started with modern web development&lt;/a&gt; or &lt;a href="https://medium.com/&amp;#64;pistacchio/i-m-a-web-developer-and-i-ve-been-stuck-with-the-simplest-app-for-the-last-10-days-fb5c50917df#.glf30ovv1"&gt;you've already drunk the cool-aid&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Either way, most rational people in the industry will (in the moments of clarity between writing off the last framework as dated and evangelising the next) reluctantly admit that &lt;a href="https://medium.com/&amp;#64;wob/the-sad-state-of-web-development-1603a861d29f#.lqu2r4xup"&gt;modern web development is a mess&lt;/a&gt;. But this is the world we live in and the best one can do is dodge the analysis paralysis and mitigate the majority of the risks. For me, this was adopting a &lt;a href="https://www.dartlang.org/guides/language/language-tour"&gt;strongly-typed modern development language&lt;/a&gt; that has a &lt;a href="https://webdev.dartlang.org/"&gt;strong web pedegry&lt;/a&gt; and just get on with it.&lt;/p&gt;
&lt;h2 id="but-in-visual-studio-code"&gt;But in Visual Studio Code?&lt;/h2&gt;
&lt;p&gt;Why not? It's a great editor and already has great support for Dart courtesy of Danny Tuppeny's &lt;a href="https://marketplace.visualstudio.com/items?itemName=DanTup.DartVS-VisualStudiosupportforGooglesDart"&gt;excellent Dart extension&lt;/a&gt;. Furthermore, I try to keep my development machine as lean and clean as possible so I didn't want to have to &lt;a href="https://www.jetbrains.com/webstorm/"&gt;install an IDE specifically for Dart development&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fortunately, as you'll see, getting set up for Dart development with Visual Studio Code is very easy, doesn't require any installation (everything is &amp;quot;xcopy&amp;quot; deployed) and you can start being productive almost right away.&lt;/p&gt;
&lt;h2 id="ingredients"&gt;Ingredients&lt;/h2&gt;
&lt;p&gt;You will need the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://code.visualstudio.com/Download"&gt;Visual Studio Code&lt;/a&gt; - obviously&lt;/li&gt;
&lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=DanTup.dart-code"&gt;DartVS&lt;/a&gt; - the Dart language extension for Visual Studio Code&lt;/li&gt;
&lt;li&gt;&lt;a href="https://storage.googleapis.com/dart-archive/channels/stable/release/1.21.0/sdk/dartsdk-windows-x64-release.zip"&gt;The Dart SDK&lt;/a&gt; - the code Dart binaries and tools needed for dart development&lt;/li&gt;
&lt;li&gt;&lt;a href="https://storage.googleapis.com/dart-archive/channels/stable/release/latest/dartium/dartium-windows-ia32-release.zip"&gt;Dartium&lt;/a&gt; - a version of Chrome (even called &amp;quot;Chrome.exe&amp;quot;) with a built in Dart runtime&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="steps"&gt;Steps&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Download and extract the Dart SDK to a location on your HD (I use &lt;code&gt;C:\Apps&lt;/code&gt; for &amp;quot;manually&amp;quot; installed tools/applications so will be using the path &lt;code&gt;C:\Apps\dart-sdk&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Download and extract Dartium to a location on your HD (&lt;code&gt;C:\Apps\chromium&lt;/code&gt; for me).&lt;/li&gt;
&lt;li&gt;Create a new directory wherever you keep your source files and name it &lt;code&gt;GettingStartedWithDart&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;In this directory, create two further directories named &lt;code&gt;lib&lt;/code&gt; and &lt;code&gt;web&lt;/code&gt; (this structure follows the &lt;a href="https://www.dartlang.org/tools/pub/package-layout"&gt;Pub Package Layout Conventions&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Start Visual Studio Code and open the &lt;code&gt;GettingStartedWithDart&lt;/code&gt; folder. You should see something like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt6eg.db.files.1drv.com/y4mKg-ed9pObuENRzhGZ4GomuDQEjP2uHxuIzDXoEcHXN8mvay-Ql0iHgo8vZsvkg0cKsqEyYC-1gmu6vbSt0Av3vw8Z9DnUKHp4w94uDv_g7niiD8i9M6n13gPFcsr7yDNA3RQQu8VIm_9mXDlxhmdvnVjptoOr0aVLsgz2yfqO_lLhmTnp1zZnr-5pPyy_ZCT_rqq_V_SLZlp0XZ05mQcUw?width=1010&amp;height=761&amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Empty Project"/&gt;
&lt;ol start="6"&gt;
&lt;li&gt;If you haven't already, install the DartVS extension by hitting &lt;code&gt;Ctrl-Shift-X&lt;/code&gt; (the keyboard shortcut for &amp;quot;View-&amp;gt;Extensions&amp;quot;) and type Dart in the search box. This should show the &amp;quot;Dart Code&amp;quot; extension by &amp;quot;Danny Tuppeny&amp;quot;. Click install and reload the window when complete.&lt;/li&gt;
&lt;li&gt;As we haven't elected to add the Dart SDK to the path, we need to tell the Dart extension where it can find the SDK. This is done by editing the User Settings (&lt;code&gt;File-&amp;gt;Preferences-&amp;gt;User Settings&lt;/code&gt;) and adding the following settings:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;    &amp;quot;dart.sdkPath&amp;quot;: &amp;quot;C:\\Apps\\dart-sdk&amp;quot;,
    &amp;quot;dart.debugSdkLibraries&amp;quot;: false,
    &amp;quot;dart.debugExternalLibraries&amp;quot;: false
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="8"&gt;
&lt;li&gt;Back in the Explorer view (&lt;code&gt;Ctrl-Shift-E&lt;/code&gt;) add a new file to the &lt;code&gt;web&lt;/code&gt; directory named &lt;code&gt;main.dart&lt;/code&gt;. We'll populate this file shortly but, for now, it's just so that VSC (and DartVS) realises that this is a Dart project.&lt;/li&gt;
&lt;li&gt;Add another new file named &lt;code&gt;pubspec.yaml&lt;/code&gt; to the root directory. This file tells the Dart compiler (named &lt;code&gt;Pub&lt;/code&gt;) how to build your Dart project and follows a very &lt;a href="https://www.dartlang.org/tools/pub/pubspec"&gt;simply format&lt;/a&gt;. In this file add &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;dependencies&lt;/code&gt; and &lt;code&gt;transformers&lt;/code&gt; as shown below:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;name: GettingStartedWithDart
dependencies:
transformers:
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="10"&gt;
&lt;li&gt;When you save this file, you should see the &lt;code&gt;Output&lt;/code&gt; panel appear showing the output of the &lt;code&gt;Pub&lt;/code&gt; command. This is a feature of the DartVS extension which runs a &lt;code&gt;pub get&lt;/code&gt; command whenever you save the &lt;code&gt;pubspec.yaml&lt;/code&gt; file. As you can probably guess from the output (shown below) the purpose of this command is to retrieve/update any dependencies you've declared in the &lt;code&gt;dependencies&lt;/code&gt; section. Also, once the &lt;code&gt;pub get&lt;/code&gt; command has run, you should see a new &lt;code&gt;pubspec.lock&lt;/code&gt; file appear in the root directory.&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt5eg.db.files.1drv.com/y4mnwQgOQd0b-9lA5T51HFDekSWJ33mcHaDaf-912HYnOcjL03IAbJMlG6IdpxYTwSW8vYOgdVv57ifpcn0PbFiT5xR1u-ymMcaGwZtRrt_a6SWPNUEro9hPfVXen1XPk2OyvtfZpBCE5I6gCV5cEAsyLCh4n8PsDoO_Mb6MRb_YvtMMWDqKuYPz0agq0colZF8we3biVaeKTJOQ387A-CqOw?width=1010&amp;height=761&amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Get Dependencies"/&gt;
&lt;ol start="11"&gt;
&lt;li&gt;As we're focusing on using Dart for web development, we'll also add an HTML document we'll manipulate using Dart. To do this, simply add new file named &lt;code&gt;index.html&lt;/code&gt; to the &lt;code&gt;web&lt;/code&gt; directory and populate it with the following:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;Getting Started With Dart&amp;lt;/title&amp;gt;
    &amp;lt;script type=&amp;quot;application/dart&amp;quot; src=&amp;quot;main.dart&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;h1 id=&amp;quot;header&amp;quot;&amp;gt;Hmm... what should I say?&amp;lt;/h1&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="12"&gt;
&lt;li&gt;At this point you should have the following layout in your project and we're ready start start writing some Dart.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
    [Source Directory]
    |-&gt; [Project Name] (i.e. "GettingStartedWithDart")
    | | -&gt; lib
    | | -&gt; web
    | | | -&gt; index.html
    | | | -&gt; main.dart
    | | -&gt; pubspec.lock
    | | -&gt; pubspec.yaml
&lt;/pre&gt;
&lt;ol start="13"&gt;
&lt;li&gt;In the &lt;code&gt;main.dart&lt;/code&gt; file, add the following code. (Note, if you type this code rather than copy-pasting it, you'll notice the excellent intellisense features provided by VSC and implemented beautifully by Dart VS.)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;import 'dart:html';

void main() {
  querySelector('#header').text = 'Ah yes... Hello World!!!';
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="14"&gt;
&lt;li&gt;Right, now we have an HTML file and some Dart code and we're ready to run. While you could run this code manually from the command line, if you're intending on doing more than just this getting started guide, I'd very much recommend setting up some task runners in VSC. This is done by opening the command palette (&lt;code&gt;Ctrl-Shift-P&lt;/code&gt;) and typing &lt;code&gt;Configure Task Runner&lt;/code&gt;, which should show you the command &lt;code&gt;Tasks: Configure Task Runner&lt;/code&gt;. Select this and you will see a list of build systems VSC can automatically create a task runner for (shown below). As Dart isn't one of the predefined templates, select &amp;quot;Others&amp;quot; to create an empty Tasks file.&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt4eg.db.files.1drv.com/y4mSM6y7mv-TeKZnWpnN0u40gfrHfe4UcGyWVrUBd9wpbJO6ifkhJsaqUUdFgdNKSZQCS2pRyMfWO78V_ysrOwwzyTqEMUXQ8LpI5I1yCibae5ROkRepy7sQqhQdYweI44xwt6WppsdMPMQu-LQRkUUpvnypu4RUO1V4IqTBtvdfyeuYu-za7s1pU6LIFH2TqmUsF1Yu39hxBFnFYGTW3r8DQ?width=1010&amp;height=761&amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Configure Task Runner"/&gt;
&lt;ol start="15"&gt;
&lt;li&gt;This command should create a new file called &lt;code&gt;tasks.json&lt;/code&gt; in a new &lt;code&gt;.vscode&lt;/code&gt; directory and will contain the following json.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;{
    // See https://go.microsoft.com/fwlink/?LinkId=733558
    // for the documentation about the tasks.json format
    &amp;quot;version&amp;quot;: &amp;quot;0.1.0&amp;quot;,
    &amp;quot;command&amp;quot;: &amp;quot;echo&amp;quot;,
    &amp;quot;isShellCommand&amp;quot;: true,
    &amp;quot;args&amp;quot;: [&amp;quot;Hello World&amp;quot;],
    &amp;quot;showOutput&amp;quot;: &amp;quot;always&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="16"&gt;
&lt;li&gt;If you're not familiar with configuring VSC task runners, I'd very much recommend clicking the link in this file to see what the task runner is able to do and how to configure it. However, for your convenience, I have provided my configuration below:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;{
    // See https://go.microsoft.com/fwlink/?LinkId=733558
    // for the documentation about the tasks.json format
    &amp;quot;version&amp;quot;: &amp;quot;0.1.0&amp;quot;,
    &amp;quot;command&amp;quot;: &amp;quot;C:\\Apps\\dart-sdk\\bin\\pub.bat&amp;quot;,
    &amp;quot;isShellCommand&amp;quot;: true,
    &amp;quot;args&amp;quot;: [],
    &amp;quot;showOutput&amp;quot;: &amp;quot;always&amp;quot;,
    &amp;quot;echoCommand&amp;quot;: true,
    &amp;quot;tasks&amp;quot;: [
        {
            &amp;quot;taskName&amp;quot;: &amp;quot;build&amp;quot;,
            &amp;quot;args&amp;quot;: [],
            &amp;quot;isWatching&amp;quot;: false
         },
        {
            &amp;quot;taskName&amp;quot;: &amp;quot;serve&amp;quot;,
            &amp;quot;args&amp;quot;: [],
            &amp;quot;isWatching&amp;quot;: true
         }
    ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="17"&gt;
&lt;li&gt;&lt;p&gt;As you will probably be able to determine, this file contains two tasks; one named &lt;code&gt;build&lt;/code&gt; and the other named &lt;code&gt;serve&lt;/code&gt;. The &lt;code&gt;build&lt;/code&gt; command compiles your code and checks for errors while the &lt;code&gt;serve&lt;/code&gt; command sets up a local web-server (by default bound to port 8080) capable of serving the content of the &lt;code&gt;web&lt;/code&gt; directory. Lets try both.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open the command palette (&lt;code&gt;Ctrl-Shift-P&lt;/code&gt;), delete the '&amp;gt;' prompt and then type &lt;code&gt;task&lt;/code&gt; followed by a space. You should see the two tasks defined above appear. Continue to &lt;code&gt;build&lt;/code&gt; and then hit return. At this point, the output pane should appear displaying the &lt;code&gt;Tasks&lt;/code&gt; output and your code should be compiled (and, transpiled into JS!). This is shown below:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://plt3eg.db.files.1drv.com/y4mL94jJczcWL7B2XhFHUxWsy27bBtRuANSUOLFONy2wOKkHeVYP_u5RDKlFD8qpdY679iDyfmqksumkLDQVJ_0z81Ur7xxBxewxL5cLHkVe1q1AMqthsufldLgA5YPcxF49t6SNi8ue18mGTmp8wSZtkem5aFk4rkn1DD1X2yZuPIpHKFbqd9xoNv8TLN7tRtqOraClK2Le9ns6b4Joswnqg?width=1010&amp;height=761&amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Tasks and Build output"/&gt;
&lt;ol start="19"&gt;
&lt;li&gt;&lt;p&gt;If everything is successful, you should see the message '&lt;code&gt;Built 2 files to &amp;quot;build&amp;quot;&lt;/code&gt;'. Now we can test our Dart code by serving it through &lt;code&gt;pub server&lt;/code&gt;. To do this, start the &lt;code&gt;task serve&lt;/code&gt; task in a similar manner to the &lt;code&gt;task build&lt;/code&gt; above. As this task is an &lt;code&gt;isWatching&lt;/code&gt; command, the task won't complete when run but will emit messages to the output pane when changes occur. This is shown below:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;With a local web-server serving out HTML file and Dart code, we can finally start to use Dartium to run the code. Note that, we're using Dartium because we'll be executing the Dart code directly (rather than the transpiled JavaScript) and Dartium has a built-in Dart runtime which allows for advanced debugging of our Dart code. Start Dartium but executing it from either command line or GUI (exists at &lt;code&gt;C:\Apps\chromium\chrome.exe&lt;/code&gt; for me) and, once started, navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; and you should see the following:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://nbtqeg.db.files.1drv.com/y4mWPsDJhQ9U-zvjoYwHuKOyw3q27w6U5hQb5e6yI4GNU9foPKXg1iMCZiRP4xAIjKjIfmWktUhv2iQtOjsG2CDsxsPFW8fY0-BqIGpnQphayCe_otBIrKip_zXH_g2W_FTMQFAwiH1rHCxdnv3pxtTGr-pq9qcmMA34AMVPCDu4wLaR6MRzLFQgqAByrfTtYS4UGKZw8uEoOP4MYfpB2UFeQ?width=813&amp;height=668&amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Success!!"/&gt;
&lt;p&gt;Congratulations, you've just run your first Dart code.&lt;/p&gt;
&lt;p&gt;If something went wrong and you don't see the header text change from 'Hmm... what should I say?' to 'Ah yes... Hello World!!!' then you can use Dartium's Developer Tools (&lt;code&gt;Ctrl-Shift-I&lt;/code&gt;) to view errors and add breakpoints so you can work out what has gone wrong. The developer tools are shown here:&lt;/p&gt;
&lt;img src="https://nbtpeg.db.files.1drv.com/y4mwRipCZE2K6E8BtWUFbeXmT_LHXc5GQoQ7ecYNO8Zo_9pqX5vi9-IRlSaEb_ONm5AU7TsKiqnil90PcWLbSSCH5vKCLuMURGYRsVUM1qcmyiei7q_-uGI21Sw8pbWnftGwPXtW2UxSq6KQHwTfxuSSIWZl4g3cy4s0bTEO_gzdp2815a37XYw8FaMoGlWH_WBpQUvTCD58RuIFWe13j3I5w?width=813&amp;height=668&amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Dartium Developer Tools"/&gt;
&lt;p&gt;You can find loads more information online about the &lt;a href="https://www.dartlang.org/"&gt;Dart Language&lt;/a&gt; and &lt;a href="https://webdev.dartlang.org/"&gt;Dart Web Development&lt;/a&gt;. Versions of Dart are changing rapidly (there was a minor update while writing this post!) and a thriving &lt;a href="https://www.dartlang.org/community"&gt;support community&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As a (mainly) C# developer I found Dart super easy to get up to speed with and the Visual Studio Code/Dartium combo to be extremely productive. Hopefully you will too.&lt;/p&gt;
&lt;p&gt;Have fun.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>Getting started with Docker and Apache Kafka</title>
			<link>http://ian.bebbs.co.uk/posts/DockerAndKafka</link>
			<description>&lt;p&gt;For my first blog post of the new year (Happy New Year everyone!!!), I'd like to share some of my recent adventures with Docker on Windows, or, more specifically, Docker on Windows using Nanoserver as the container OS.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/DockerAndKafka</guid>
			<pubDate>Wed, 04 Jan 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;For my first blog post of the new year (Happy New Year everyone!!!), I'd like to share some of my recent adventures with Docker on Windows, or, more specifically, Docker on Windows using Nanoserver as the container OS.&lt;/p&gt;
&lt;p&gt;I've been meaning to get up to speed with Docker for a while and, having &lt;a href="http://ian.bebbs.co.uk/posts/ARipStoringTime"&gt;recently acquired a decent new server for the purpose&lt;/a&gt;, decided that a festive period break from some of my &lt;a href="http://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl"&gt;longer term projects&lt;/a&gt;, would be an ideal time to finally dive in. In typical Bebbs style, &amp;quot;diving in&amp;quot; invariably involves the &amp;quot;deep end&amp;quot; and, as such, it seemed that a great initiation into the containerization waters would be to take &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; - a service typically run on Linux - and deploy it within a Windows &lt;a href="https://blogs.technet.microsoft.com/windowsserver/2015/04/08/microsoft-announces-nano-server-for-modern-apps-and-cloud/"&gt;Nanoserver&lt;/a&gt; container - a recent release from Microsoft and still a very-much bleeding-edge OS.&lt;/p&gt;
&lt;p&gt;I've been interested in Apache Kafka for quite a while. Described as a &amp;quot;distributed streaming platform&amp;quot; it very much resonates with my &amp;quot;everything is a stream&amp;quot; philosophy. Furthermore, some of &lt;a href="https://www.confluent.io/product/connectors/"&gt;it's connectors&lt;/a&gt; to various traditional RDBMS's offer an intriguing means of moving between 'state store' and 'event store' methodologies.&lt;/p&gt;
&lt;h2 id="getting-started"&gt;Getting started&lt;/h2&gt;
&lt;p&gt;For the host system, I started with a fresh install of Windows Server 2016 (Desktop Experience for convenience) on a &lt;a href="http://www.dell.com/uk/business/p/poweredge-t20/pd"&gt;Dell T20 Xeon&lt;/a&gt;. Following &lt;a href="https://msdn.microsoft.com/en-gb/virtualization/windowscontainers/quick_start/quick_start_windows_server"&gt;this quick start guide&lt;/a&gt; quickly led to an issue whereby the Docker package couldn't be verified by it's SHA256 hash and therefore refused to install. Fortunately I found a report of the issue and a work around &lt;a href="https://github.com/OneGet/MicrosoftDockerProvider/issues/15"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;I have since reinstalled docker on Windows Server 2016 and did not experience the issue again so it must have been resolved.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With Docker installed and the &lt;a href="https://hub.docker.com/r/microsoft/dotnet-samples/"&gt;dotnet-samples&lt;/a&gt; example container running, my attention turned to Nanoserver.&lt;/p&gt;
&lt;p&gt;A quick pull and run of the &lt;a href="https://hub.docker.com/r/microsoft/nanoserver/"&gt;Nanoserver image&lt;/a&gt; and I found myself at an interactive command prompt of a deployed container running Nanoserver. This can be done as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker pull microsoft/nanoserver:latest
docker run -it --rm microsoft/nanoserver:latest cmd
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="kafka-zookeeper"&gt;Kafka &amp;amp; Zookeeper&lt;/h2&gt;
&lt;p&gt;While looking for a pre-built image of Kafka running on Nanoserver, it quickly became apparent that in order to get an instance of &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; running, you first need a running instance of &lt;a href="https://zookeeper.apache.org/"&gt;Apache Zookeeper&lt;/a&gt;. While you could technically run both services from within a single container (indeed, Kafka is pre-configured to look for a Zookeeper instance on localhost) I wanted to utilize the core value propositions of containers vs VM instances; namely minimal overhead and composability.&lt;/p&gt;
&lt;p&gt;This meant that I would therefore be building two container images, one for Zookeeper and one for Kafka, both of which would be running on Nanoserver.&lt;/p&gt;
&lt;h2 id="building-the-zookeeper-image"&gt;Building the Zookeeper image&lt;/h2&gt;
&lt;h3 id="take-1"&gt;Take 1&lt;/h3&gt;
&lt;img src="https://mbt4mw.db.files.1drv.com/y4mwGowFjnDW_kYoMAx77RqJvYQ1qLT1X2m3zCD4aDb3EnkwJpwZ8fE03MwNlRTssPAlxLQ7E8TXAFpurKGAZL6KQgHgPS93Jgbo_yoaoLKt81ipcBn0YWgFl7gaeW6KDaCDT1taNRnwNWgxa4sOnOdY9ZStw1ihnv0djLL_-LZgQ6xzuM7H3X73DfOs0tk0orevmh8a4NgpHSl-2hI44900Q?width=690&amp;height=380&amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="I built this container up from nothing. When I started here, all there was was nanoserver. Other developers said it was daft to build Zookeeper on nanoserver, but I did it all the same. Just to show'em."&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;I built this [container] up from nothing. When I started here, all there was was [nanoserver]. Other [developers] said it was daft to build [Zookeeper] on [nanoserver], but I did it all the same. Just to show'em.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, from most of everything I have read about building docker images, it seemed the thing to do was use a &lt;a href="https://docs.docker.com/engine/reference/builder/"&gt;Dockerfile&lt;/a&gt; to start an intermediate container based on the source image (Microsoft/Nanoserver in this instance) then run a script within the intermediate container (as part of the dockerfile) to download, install and configure all the required components. The output of this docker build process would be a new image with the appropriate services running on startup.&lt;/p&gt;
&lt;p&gt;I therefore started by preparing a powershell script that would do just that. Following &lt;a href="http://stackoverflow.com/a/38895811"&gt;this post on StackOverflow&lt;/a&gt; I developed and tested a script on a Windows Server 2016 (Desktop Experience) Virtual Machine. This was done so that I could use &lt;a href="https://technet.microsoft.com/en-us/library/dn818483(v=ws.11).aspx"&gt;snapshotting&lt;/a&gt; in order to roll-back to a clean image anytime a issue with the script was encountered.&lt;/p&gt;
&lt;p&gt;Unfortunately, when it came time to try running Zookeeper I hit the following error at start-up:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;log4j:WARN No appenders could be found for logger (org.apache.zookeeper.server.quorum.QuorumPeerConfig).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
Invalid config, exiting abnormally
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some quick googling turned up &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c5"&gt;this issue&lt;/a&gt; but every subsequent comment seemed to suggest that the issue had been resolved. I tried a &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c8"&gt;frustrating&lt;/a&gt; &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c9"&gt;number&lt;/a&gt; of &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181487#c4"&gt;unsuccessful&lt;/a&gt; &lt;a href="http://tech.donghao.org/tag/zookeeper/"&gt;workarounds&lt;/a&gt; until I realized that it was a &lt;a href="https://en.wiktionary.org/wiki/PICNIC"&gt;PICNIC error&lt;/a&gt;. Specifically, while following the StackOverflow post above, I had failed to realize that the version of Zookeeper they specified wasn't actually the latest version and that the issue really had been resolved in a later version. This took a frustratingly and embarrassingly long time but hey, &lt;a href="http://www.goodreads.com/quotes/7678-when-people-say-it-s-always-the-last-place-you-look"&gt;it's always the last place you look&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, a morning of trial and error resulted in a thing of beauty; a script that would - completely automatically - download, extract, configure, install (as a service!) and run a Zookeeper instance. This is shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Download sources
$zipUri = &amp;quot;http://homeserver/download/7z1604-x64.exe&amp;quot; # http://www.7-zip.org/a/7z1604-x64.exe&amp;quot;;
$nssmUri = &amp;quot;http://homeserver/download/nssm-2.24.zip&amp;quot; # &amp;quot;https://nssm.cc/release/nssm-2.24.zip&amp;quot;
$javaUri = &amp;quot;http://homeserver/download/jre-8u111-windows-x64.exe&amp;quot; # &amp;quot;http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jre-8u111-windows-x64.exe&amp;quot;
$zookeeperUri = &amp;quot;http://homeserver/download/zookeeper-3.4.9.tar.gz&amp;quot; # &amp;quot;http://apache.mirrors.nublue.co.uk/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz&amp;quot;
$kafkaUri = &amp;quot;http://homeserver/download/kafka_2.11-0.10.1.0.tgz&amp;quot; # &amp;quot;http://apache.mirror.anlx.net/kafka/0.10.1.0/kafka_2.11-0.10.1.0.tgz&amp;quot;

## Application locations
$appDir = &amp;quot;c:\Apps&amp;quot;
$zipDir = $appDir + &amp;quot;\7zip&amp;quot;
$nssmDir = $appDir + &amp;quot;\nssm&amp;quot;
$zookeeperDir = $appDir + &amp;quot;\Zookeeper&amp;quot;

## Data locations
$zookeeperDataDir = $zookeeperDir + &amp;quot;\Data&amp;quot;

## Application executables
$zip = $zipDir + &amp;quot;\7z.exe&amp;quot;
$nssm = $nssmDir + &amp;quot;\nssm.exe&amp;quot;
$zookeeper = $zookeeperDir + &amp;quot;\bin\zkServer.cmd&amp;quot;

function New-TempPath()
{
    if (!(Test-Path -Path C:\Temp))
    {
        New-Item c:\Temp -ItemType Directory
    }
}

function Expand-File($zipFile, $targetPath)
{
    $args = &amp;#64;(&amp;quot;e&amp;quot;, $zipFile, &amp;quot;-o$targetPath&amp;quot;, '-y')
    &amp;amp;$zip $args
}

function Expand-Directory($zipFile, $targetPath)
{
    $args = &amp;#64;(&amp;quot;x&amp;quot;, $zipFile, &amp;quot;-o$targetPath&amp;quot;, '-aoa')
    &amp;amp;$zip $args
}

function Install-7zip()
{
    New-Item &amp;quot;c:\Temp\7zip&amp;quot; -ItemType Directory -Force
    Invoke-WebRequest -Uri $zipUri -OutFile c:\Temp\7zip\7zip.exe
    &amp;amp;&amp;quot;C:\Temp\7zip\7zip.exe&amp;quot; /S /D=$zipDir | Out-Null
    Remove-Item -Path &amp;quot;c:\Temp\7zip\7zip.exe&amp;quot;
}

function Install-NSSM()
{
    New-Item &amp;quot;c:\Temp\NSSM&amp;quot; -ItemType Directory -Force
    Invoke-WebRequest -Uri $nssmUri -OutFile c:\Temp\NSSM\NSSM.zip

    Expand-Directory c:\Temp\NSSM\NSSM.zip c:\Temp\NSSM

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path c:\Temp\NSSM -Filter &amp;quot;nssm-*&amp;quot;
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination c:\Temp\NSSM -Force

    New-Item $nssmDir -ItemType Directory -Force
    Copy-Item -Path &amp;quot;c:\Temp\NSSM\win64\nssm.exe&amp;quot; $nssm -Force
}

function Install-Java()
{
    New-Item c:\Temp\Java -ItemType Directory -Force
    Invoke-WebRequest -Uri $javaUri -OutFile c:\temp\Java\Java.exe

    Start-Process &amp;quot;C:\Temp\Java\Java.exe&amp;quot; -ArgumentList &amp;quot;INSTALL_SILENT=Enable INSTALLDIR=C:\Java\Jre AUTO_UPDATE=Disable WEB_JAVA=Disable WEB_ANALYTICS=Disable EULA=Disable REBOOT=Disable NOSTARTMENU=Enable SPONSORS=Disable REMOVEOUTOFDATEJRES=0&amp;quot; -NoNewWindow -Wait

    [Environment]::SetEnvironmentVariable(&amp;quot;JAVA_HOME&amp;quot;, &amp;quot;C:\Java\Jre&amp;quot;, &amp;quot;Machine&amp;quot;)

    Remove-Item -Path &amp;quot;C:\Temp\Java\Java.exe&amp;quot;
}

function Get-Zookeeper()
{
    New-Item c:\Temp\Zookeeper -ItemType Directory -Force
    Invoke-WebRequest -Uri $zookeeperUri -OutFile c:\temp\Zookeeper\Zookeeper.tar.gz
    Expand-File c:\temp\Zookeeper\Zookeeper.tar.gz c:\temp\Zookeeper
    Expand-Directory c:\temp\Zookeeper\Zookeeper.tar $zookeeperDir

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path $zookeeperDir -Filter &amp;quot;zookeeper-*&amp;quot;
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination $zookeeperDir -Force

    Remove-Item -Path $folder.FullName
    Remove-Item -Path &amp;quot;c:\temp\Zookeeper&amp;quot; -Recurse
}

function Initialize-Zookeeper()
{
    New-Item -Path $zookeeperDataDir -ItemType Directory -Force
    $zookeeperDataLinuxDir = $zookeeperDataDir.Replace('\', '/')

    Copy-Item -Path ($zookeeperDir + '\conf\zoo_sample.cfg') -Destination ($zookeeperDir + '\conf\zoo.cfg') -Force

    $configFile = $zookeeperDir + '\conf\zoo.cfg'
    $logFile = $zookeeperDir + '\conf\log4j.properties'

    $config = [IO.File]::ReadAllText($configFile) -replace &amp;quot;dataDir=[\/\w]*&amp;quot;, (&amp;quot;dataDir=&amp;quot; + $zookeeperDataLinuxDir)
    [IO.File]::WriteAllText($configFile, $config)

    $logProperties = [IO.File]::ReadAllText($logFile) -replace &amp;quot;#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE&amp;quot;, &amp;quot;log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE&amp;quot;
    [IO.File]::WriteAllText($logFile, $logProperties)
}

function Install-Zookeeper()
{
    &amp;amp;$nssm install Zookeeper $zookeeper | Out-Null
    &amp;amp;$nssm set Zookeeper AppDirectory $zookeeperDir | Out-Null

    &amp;amp;$nssm set Zookeeper DisplayName &amp;quot;Zookeeper&amp;quot; | Out-Null
    &amp;amp;$nssm set Zookeeper Description &amp;quot;Apache Zookeeper. Running from $zookeeperDir&amp;quot; | Out-Null
    &amp;amp;$nssm set Zookeeper Start SERVICE_AUTO_START | Out-Null
    &amp;amp;$nssm set Zookeeper ObjectName LocalSystem | Out-Null
    &amp;amp;$nssm set Zookeeper Type SERVICE_WIN32_OWN_PROCESS | Out-Null
}

function Start-Zookeeper()
{
    &amp;amp;$nssm start Zookeeper | Out-Null
}

function Stop-Zookeeper()
{
    &amp;amp;$nssm stop Zookeeper | Out-Null
}

New-TempPath

Install-7zip
Install-NSSM
Install-Java

Get-Zookeeper
Initialize-Zookeeper
Install-Zookeeper
Start-Zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this mighty script in hand I prepared the following dockerfile:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM microsoft/nanoserver
MAINTAINER Ian Bebbington &amp;lt;docker&amp;#64;bebbs.co.uk&amp;gt;
LABEL Description=&amp;quot;Zookeeper running on Microsoft Nanoserver&amp;quot; Version=&amp;quot;0.1&amp;quot;
ADD Install-Zookeeper.ps1 /
RUN [ &amp;quot;powershell.exe&amp;quot;, &amp;quot;C:/Install-Zookeeper.ps1&amp;quot; ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And watched in dismay as it completely failed to build a container.&lt;/p&gt;
&lt;p&gt;You see, while the script ran perfectly on Windows Server 2016, Nanoserver is a far more constrained environment. It has neither support for 32-bit assemblies nor any graphic stack to speak of so, in short-order, the 7zip utility, Java installer and &lt;a href="https://nssm.cc/"&gt;Non-Sucking Service Manager&lt;/a&gt; executables all failed.&lt;/p&gt;
&lt;p&gt;Well, crap.&lt;/p&gt;
&lt;h3 id="take-2"&gt;Take 2&lt;/h3&gt;
&lt;img src="https://mbt5mw.db.files.1drv.com/y4mxZXjdiHWlj0ey3Kb-IAePEYBT4Ii7wJP05J4x8byzM1Dh9EqI0hF29753PbOEWnQYmlIbbpCl-o1Rbk4AbYXbFUil-V-UHTMZd9s82a3ZzAvN9D86YIT21nX8SNNrGR1HXdY1W2xGKihnZ1IW49HpXNSQL9sfjrs0dMtAzZ9Gm9EbrMIxJqfwYKCTFzo8IbRT9mrcj4WBsNQRYpD5XKveA?width=690&amp;height=460&amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="So! I built a second one!"&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;So! I built a second one!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My next thought was to try salvaging as much of the script as possible by using &lt;a href="https://technet.microsoft.com/en-us/library/ff700227.aspx"&gt;Powershell Remoting&lt;/a&gt; to interactively install the required components and then &lt;a href="https://docs.docker.com/engine/reference/commandline/commit/"&gt;committing&lt;/a&gt; the changes to a new image.&lt;/p&gt;
&lt;p&gt;While, in retrospect, this was undoubtedly the wrong way forward, I was simultaneously fortunate and frustrated by the fact that it simply doesn't seem possible to use powershell remoting with Nanoserver when running within a container. Indeed, after learning more about &lt;a href="https://msdn.microsoft.com/en-us/library/aa384426(v=vs.85).aspx"&gt;WinRM&lt;/a&gt; than I thought possible, posting on &lt;a href="https://social.msdn.microsoft.com/Forums/en-US/e0652324-30e4-4ebb-8689-55205e6d8bc9/enterpssession-to-nanoserver-container-in-docker-access-is-denied?forum=windowscontainers"&gt;Microsoft's Windows Container forums&lt;/a&gt; and even offering my &lt;a href="http://stackoverflow.com/questions/39195068/powershell-remote-access-to-nanoserver-on-docker"&gt;first bounty on StackOverflow&lt;/a&gt; I simply could not find an answer to why it wasn't possible to establish a remote session.&lt;/p&gt;
&lt;p&gt;In the mean time...&lt;/p&gt;
&lt;h3 id="take-3"&gt;Take 3&lt;/h3&gt;
&lt;img src="https://mbt3mw.db.files.1drv.com/y4mAv0zjXUvVibhWqQEmH18FMtheebIg4cFV62i4APNEgm2eDQQ82ifHDQaRsU9xQD966EIcnmaUVA-CPms3_YhIBO4-AVk4tPt0_eoI4EUJgEcQqHZmvpzXgcVoegRGcJrMSOki5E6XNbwBCgNciaCqe25tEI3264z-EyBAz20V4Lz_ZMWzD6boo3fWUCfKc8Oit8Fj2UxQofTs1r-AQjQ-w?width=690&amp;height=461&amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="So, I built a third one..."&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;I built a third one...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Powershell remoting works beautifully with Nanoserver when running in a Hyper-V virtual machine but Hyper-V networking and Docker networking configurations don't seem to play well together. Indeed, after creating a new virtual-router so that I could access the Nanoserver virtual machine from the host PC, the Docker NAT network became inaccessible. Now, I'm sure it would be possible to dig into the virtual networking configuration and find a way to resolve this but, having spent an incredibly frustrating few hours reconfiguring WinRM, I decided it would be quicker to simply re-install the host OS and start from scratch.&lt;/p&gt;
&lt;h3 id="take-4"&gt;Take 4&lt;/h3&gt;
&lt;img src="https://oltxmw.db.files.1drv.com/y4mUljkhpGUqQULtuT0FcXzTOATDaeuixGBsY3Dy330TLnYARIubLRWshHYQ9s23uU4SeP5wn3t4Bsxlu0-_M_8NGBinr-N3crNs0pFIcsCtkMoZHSfrwI8kqCgRX-nHWXYVQcJRPb_nHVLERHJwCQ3mVoIjqeQ7mIQ_ab-gS0SdtJpwDjAYtZvlQ_cYvOyAOpFESPWHlq1FRjCPK04frsRCg?width=666&amp;height=500&amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="But the fourth one stayed up!"&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;But the fourth one stayed up!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To accompany the fresh host environment, I decided to employ a fresh approach to building the container image. Namely, use a script to build the container's file system structure on the host PC and then simply copy it wholesale to the container from within the dockerfile. This meant deploying the Java Runtime Environment from a compressed archive rather than silent executable and using the &lt;a href="https://docs.docker.com/engine/reference/builder/#/entrypoint"&gt;dockerfile entrypoint&lt;/a&gt; instruction to run Zookeeper rather than installing it as a service.&lt;/p&gt;
&lt;p&gt;After all the faff and frustration of the previous two attempts (not to mention reinstallation of OS on host PC), this approach was remarkably smooth. Again, in retrospect this was undoubtedly the correct approach but this approach almost certainly benefited from all the knowledge I had accrued from the previous failed attempts. As always, &lt;a href="http://www.goodreads.com/quotes/390439-we-learn-wisdom-from-failure-much-more-than-from-success"&gt;you can learn more from failure than success&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, in relatively short order, I had a script that prepared and configured the container's file system structure on the host PC and a dockerfile that copied this structure to a new image and set the Zookeeper service as the entrypoint for the image. These are shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Download sources
$zipUri = &amp;quot;http://homeserver/download/7z1604-x64.exe&amp;quot; # http://www.7-zip.org/a/7z1604-x64.exe&amp;quot;;
$javaUri = &amp;quot;http://homeserver/download/jre-8u111-windows-x64.tar.gz&amp;quot; # &amp;quot;http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jre-8u111-windows-x64.tar.gz&amp;quot;
$zookeeperUri = &amp;quot;http://homeserver/download/zookeeper-3.4.9.tar.gz&amp;quot; # &amp;quot;http://apache.mirrors.nublue.co.uk/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz&amp;quot;
$dockerModuleUri = &amp;quot;http://homeserver/download/Docker.0.1.0.zip&amp;quot; # &amp;quot;https://github.com/Microsoft/Docker-PowerShell/releases/download/v0.1.0/Docker.0.1.0.zip&amp;quot;

## Build location
$buildDir = Get-Location
$tmpDir = $buildDir.Path + &amp;quot;\Temp&amp;quot;
$rootDir = $buildDir.Path + &amp;quot;\Root&amp;quot;
$biuldAppDir = $rootDir + &amp;quot;\Apps&amp;quot;
$buildDataDir = $rootDir + &amp;quot;\Data&amp;quot;
$buildDockerZip = $tmpDir + &amp;quot;\Docker.zip&amp;quot;
$buildDockerModule = $tmpDir + &amp;quot;\Docker&amp;quot;
$buildZipDir = $tmpDir + &amp;quot;\7zip&amp;quot;
$buildJreDir = $biuldAppDir + &amp;quot;\Jre&amp;quot;
$buildZookeeperDir = $biuldAppDir + &amp;quot;\Zookeeper&amp;quot;
$buildZookeeperDataDir = $buildDataDir + &amp;quot;\Zookeeper&amp;quot;

## Temp files
$zipInstaller = $tmpDir + &amp;quot;\7zInstaller.exe&amp;quot;
$jreGzip = $tmpDir + &amp;quot;\Jre.tar.gz&amp;quot;
$jreTar = $tmpDir + &amp;quot;\Jre.tar&amp;quot;
$zooKeeperGzip = $tmpDir + &amp;quot;\Zookeeper.tar.gz&amp;quot;
$zooKeeperTar = $tmpDir + &amp;quot;\Zookeeper.tar&amp;quot;

## Target locations
$targetDir = &amp;quot;C:\&amp;quot;
$appDir = $targetDir + &amp;quot;\Apps&amp;quot;
$dataDir = $targetDir + &amp;quot;\Data&amp;quot;
$jreDir = $appDir + &amp;quot;\Jre&amp;quot;
$zookeeperDir = $appDir + &amp;quot;\Zookeeper&amp;quot;
$zookeeperDataDir = $dataDir + &amp;quot;\Zookeeper&amp;quot;

## Executables
$zip = $buildZipDir + &amp;quot;\7z.exe&amp;quot;
$zookeeper = $zookeeperDir + &amp;quot;\bin\zkServer.cmd&amp;quot;
$docker = &amp;quot;docker&amp;quot;

function New-TempPath()
{
    if (!(Test-Path -Path $tmpDir))
    {
        New-Item $tmpDir -ItemType Directory
    }
}

function Remove-TempPath()
{
    Remove-Item $tmpDir -Recurse -Force
}

function New-RootPath()
{
    Remove-Item $rootDir -Recurse -Force
    New-Item $rootDir -ItemType Directory
}

function Remove-RootPath()
{
    Remove-Item $rootDir -Recurse -Force
}

function Expand-File($zipFile, $targetPath)
{
    $args = &amp;#64;(&amp;quot;e&amp;quot;, $zipFile, &amp;quot;-o$targetPath&amp;quot;, '-y')
    &amp;amp;$zip $args | Out-Host
}

function Expand-Directory($zipFile, $targetPath)
{
    $args = &amp;#64;(&amp;quot;x&amp;quot;, $zipFile, &amp;quot;-o$targetPath&amp;quot;, '-aoa')
    &amp;amp;$zip $args | Out-Host
}

function Install-DockerModule()
{
    Invoke-WebRequest -Uri $dockerModuleUri -OutFile $buildDockerZip
    Expand-Archive -Path $buildDockerZip -DestinationPath $buildDockerModule -Force

    Import-Module $buildDockerModule
}

function Remove-DockerModule()
{
    Remove-Module $buildDockerModule
}

function Install-7zip()
{
    $folder = New-Item $buildZipDir -ItemType Directory -Force
    Invoke-WebRequest -Uri $zipUri -OutFile $zipInstaller
    &amp;amp;$zipInstaller /S /D=$folder | Out-Null
    Remove-Item -Path $zipInstaller
}

function Remove-7zip()
{
    Remove-Item $buildZipDir -Recurse -Force
}

function Get-Java()
{
    Invoke-WebRequest -Uri $javaUri -OutFile $jreGzip
    Expand-File $jreGzip $tmpDir
    Expand-Directory $jreTar $buildJreDir

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path $buildJreDir -Filter &amp;quot;jre*&amp;quot;
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination $buildJreDir -Force

    Remove-Item -Path $folder.FullName -Force
    Remove-Item -Path $jreGzip -Force
    Remove-Item -Path $jreTar -Force
}

function Get-Zookeeper()
{
    Invoke-WebRequest -Uri $zookeeperUri -OutFile $zooKeeperGzip
    Expand-File $zooKeeperGzip $tmpDir
    Expand-Directory $zooKeeperTar $buildZookeeperDir

    ## Above will expand to a directory containing version name which we want to remove
    ## so we'll move everything up a directory
    $folder = Get-ChildItem -Path $buildZookeeperDir -Filter &amp;quot;zookeeper-*&amp;quot;
    Get-ChildItem -Path $folder.FullName -Recurse | Move-Item -destination $buildZookeeperDir -Force

    Remove-Item -Path $folder.FullName -Force
    Remove-Item -Path $zooKeeperTar -Force
    Remove-Item -Path $zooKeeperGzip -Force
}

function Initialize-Zookeeper()
{
    New-Item -Path $buildDataDir -ItemType Directory -Force
    New-Item -Path $buildZookeeperDataDir -ItemType Directory -Force

    $zookeeperDataLinuxDir = $zookeeperDataDir.Replace('\', '/')

    Copy-Item -Path ($buildZookeeperDir + '\conf\zoo_sample.cfg') -Destination ($buildZookeeperDir + '\conf\zoo.cfg') -Force

    $configFile = $buildZookeeperDir + '\conf\zoo.cfg'
    $logFile = $buildZookeeperDir + '\conf\log4j.properties'

    $config = [IO.File]::ReadAllText($configFile) -replace &amp;quot;dataDir=[\/\w]*&amp;quot;, (&amp;quot;dataDir=&amp;quot; + $zookeeperDataLinuxDir)
    [IO.File]::WriteAllText($configFile, $config)

    $logProperties = [IO.File]::ReadAllText($logFile) -replace &amp;quot;#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE&amp;quot;, &amp;quot;log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE&amp;quot;
    [IO.File]::WriteAllText($logFile, $logProperties)
}

function New-DockerImage()
{
    Build-ContainerImage -Path $buildDir -Repository &amp;quot;ibebbs/nanozoo:latest&amp;quot;
}


# Setup directory structure
New-TempPath
New-RootPath

# Install required tools
Install-DockerModule
Install-7zip

# Get components
Get-Java
Get-Zookeeper
Initialize-Zookeeper

# Build docker image
New-DockerImage

# Cleanup
Remove-DockerModule
Remove-7zip
Remove-TempPath
Remove-RootPath
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;FROM microsoft/nanoserver
MAINTAINER Ian Bebbington &amp;lt;docker&amp;#64;bebbs.co.uk&amp;gt;
LABEL Description=&amp;quot;Zookeeper running on Microsoft Nanoserver&amp;quot; Version=&amp;quot;0.1&amp;quot;
ADD Root /
ADD Start-Zookeeper.ps1 /
RUN setx /M JAVA_HOME C:\Apps\Jre
EXPOSE 2181
ENTRYPOINT [ &amp;quot;powershell.exe&amp;quot;, &amp;quot;C:/Start-Zookeeper.ps1&amp;quot; ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And this one worked. This one started. This one stayed up!&lt;/p&gt;
&lt;h2 id="building-the-kafka-image"&gt;Building the Kafka image&lt;/h2&gt;
&lt;p&gt;With the Zookeeper scripts as a pattern, it was ludicrously easy to script up another image for Kafka. Just a few changes to file names and configuration parameters and Kafka started almost first time.&lt;/p&gt;
&lt;p&gt;I won't copy the script or dockerfile here as they're extremely similar to the Zookeeper versions. Instead, all scripts and files used above can be found in my &lt;a href="https://github.com/ibebbs/Docker"&gt;Docker repository on Github&lt;/a&gt; and the resultant images can be found on &lt;a href="https://hub.docker.com/r/ibebbs/"&gt;Docker hub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="moving-forward"&gt;Moving forward&lt;/h2&gt;
&lt;img src="https://oltymw.db.files.1drv.com/y4mI-m7GTvfSqDTdYfKQO6D0X9Yazi0fEvyfPNeD6grW3Xb88GvXNAhGmIZTQvpnGkFWtNQNkzQRX7i-uEBLeWj5fgtyJ1Y8fbP2VW0LI-HmKIM54Ojfkb_bbtImP41FGHPclzIq2IHCxXGbV78CpNSiOtdC8YjQGhqkh4cnHKgB623cjqmOiJafQxTcFbn0g3GfaDqJOxncoPfzxnf8K9aLQ?width=690&amp;height=388&amp;cropmode=none" class="img-responsive" style="margin: auto; width:600px; margin-top: 6px; margin-bottom: 6px;" alt="But I don't want any of that!"&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;But I don't want any of that!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Moving forward, I need to address a couple of short-comings in the Kafka script (specifically the hard-coded IP address for the Zookeeper container) and then look to use Docker Compose to automatically bring up Zookeeper and Kafka on demand.&lt;/p&gt;
&lt;p&gt;It's been an interesting journey so far and I've not even begun to actually use the deployed services yet! Still, it is truly magical to run a docker container and see it boot an entire Windows server and service in just 10-20 seconds and a few hundred Mb.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>CQRS/ES &amp; MVVM using RX, EF &amp; SQL in UWP &amp; PCL …</title>
			<link>http://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl</link>
			<description>&lt;p&gt;So, while ToddlerBox is riding high, I'd like to share some thoughts about another app I have in the store; &lt;a href="https://www.microsoft.com/en-gb/store/p/littlelittle/9nblggh51b1b"&gt;LittleLittle&lt;/a&gt;. This app has been the subject of most of my efforts over the last few months and is significantly more complex (and, frustratingly, less successful!) than ToddlerBox.&lt;/p&gt;</description>
			<guid>http://ian.bebbs.co.uk/posts/CqrsEsMvvmRxEfSqlUwpPcl</guid>
			<pubDate>Thu, 22 Dec 2016 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;So, while ToddlerBox is riding high, I'd like to share some thoughts about another app I have in the store; &lt;a href="https://www.microsoft.com/en-gb/store/p/littlelittle/9nblggh51b1b"&gt;LittleLittle&lt;/a&gt;. This app has been the subject of most of my efforts over the last few months and is significantly more complex (and, frustratingly, less successful!) than ToddlerBox.&lt;/p&gt;
&lt;p&gt;LittleLittle was started shortly after my baby girl started weaning and became constipated - apparently a very common occurrence. When we visited a paediatrician about it, they asked that we keep a record of her bowel movements so that we could track the condition to see if it was getting better or worse.&lt;/p&gt;
&lt;p&gt;&amp;quot;I wonder if there's an app for that&amp;quot;, I thought. And, of course, there was.&lt;/p&gt;
&lt;h2 id="opportunity-and-methodology"&gt;Opportunity and Methodology&lt;/h2&gt;
&lt;p&gt;However, while there are plenty of other baby tracking apps out there, very few work across platform (I use Windows Mobile while my partner uses Android) and even fewer work as I feel they should.&lt;/p&gt;
&lt;p&gt;Given the requirement to work across a variety of platforms, maximising code re-use was extremely desirable. As such, I decided that all of the core-logic for the app needed to be written in a PCL. Furthermore, particular care would be taken to observe a pure MVVM methodology so that ViewModels (an embodiment of the app's UX) could also be shared across platform.&lt;/p&gt;
&lt;p&gt;Finally, following some work in the CQRS/ES space at my previous employer, I wanted to write an app that used this methodology end-to-end. LittleLittle seemed a perfect opportunity to do so.&lt;/p&gt;
&lt;h2 id="technology-and-platform"&gt;Technology and Platform&lt;/h2&gt;
&lt;p&gt;To partner the &lt;a href="http://martinfowler.com/bliki/CQRS.html"&gt;CQRS&lt;/a&gt;/&lt;a href="http://martinfowler.com/eaaDev/EventSourcing.html"&gt;ES&lt;/a&gt; methodology, I was keen to use &lt;a href="https://msdn.microsoft.com/en-us/library/hh242985.aspx"&gt;Rx&lt;/a&gt; as the driving technology for implementation. As readers of my blog will know, I am very much of the opinion that &amp;quot;&lt;a href="http://slides.com/robwormald/everything-is-a-stream#/" title="Everything is a stream - Rob Wormald"&gt;everything&lt;/a&gt; &lt;a href="https://gist.github.com/staltz/868e7e9bc2a7b8c1f754" title="The introduction to Reactive Programming you've been missing - andrestaltz"&gt;is&lt;/a&gt; &lt;a href="http://weareadaptive.com/blog/2014/05/05/everything-is-a-stream/" title="Reactive Trader 2: Everything is a Stream - Matt Barrett"&gt;a&lt;/a&gt; &lt;a href="http://colintheshots.com/blog/?p=85" title="Be Reactive - Colintheshots"&gt;stream&lt;/a&gt;&amp;quot; and event sourcing from &amp;quot;a stream of events&amp;quot; seemed a perfect fit for Rx.&lt;/p&gt;
&lt;p&gt;Given that the Event Sourcing methodology - not to mention the nature of the app itself - required a persistence layer, I decided to use a recently new technology; &lt;a href="https://docs.microsoft.com/en-us/ef/core/"&gt;Entity Framework Core&lt;/a&gt;. I decided on EFCore simply because the tooling for the UWP platform was pretty good and I liked the 'code-first' approach to schema and migration generation. Coupled with this, I decided to use a &lt;a href="https://docs.microsoft.com/en-us/ef/core/providers/sqlite/"&gt;SQLite&lt;/a&gt; database as it was a proven data store for use with EFCore and across a variety of underlying platforms.&lt;/p&gt;
&lt;p&gt;Finally, when I started LittleLittle I was studying for the &lt;a href="https://www.microsoft.com/en-us/learning/exam-70-357.aspx"&gt;Microsoft Beta Exam &amp;quot;Developing Mobile Apps&amp;quot;&lt;/a&gt;. As such, while I was keen for the app to be cross-platform, the initial platform I wanted to support was UWP. I was - and still am - amazed by how, if you craft your code and views carefully, an application can run on an amazing number for platforms including RaspberryPi, Phone, Tablet, PC, Xbox and Hololens.&lt;/p&gt;
&lt;h2 id="and-heres-one-i-made-earlier"&gt;And here's one I made earlier…&lt;/h2&gt;
&lt;p&gt;After many weeks of work, innumerable iterations and much refactoring, I ended up with this:&lt;/p&gt;
  &lt;div class="horizontal_list"&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zuimew.db.files.1drv.com/y4mPxGKydLfQk1Ja93VVxZRGwlildIyNH2fDMTFjp04v21LFIlMQTHx578Nda9AMJh7KIWCnbmwBNpY9T5gle1BeP_JAe7KDBzRvP42T2DsK9fmJo4ifh8iDOkfDE_vTcHMC7zX_0QvmyIgP2OGdehESiXc7g9uLAOzreBI9ilGXrUu6U88ZwihXsj61axEWtDv1lDfagtfUTchXA6LmvJTtw?width=371&amp;height=660&amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="Splashscreen"/&gt;
    &lt;/div&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zuilew.db.files.1drv.com/y4mGPImTo96llsaeRg2IeX44grX98d5Xg6iNFLUfXmKcbHFMtPW0GDKhpuIjEhZW05LjJZvvSrW5afKKgSa6QJ52QSuwqaywfrsVCvKbIl6O9cW9D1C0RUQdaQ4nrO6i2nlaNvdPWeVcqqmdmmBIK2sRdUFDEN5ZSWuC7Q-TEMdB75AuyqVNawvoftaVLTlK3HUp4zn_DL8nLTwCa_yjrChfA?width=371&amp;height=660&amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="Available actions"/&gt;
    &lt;/div&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zuikew.db.files.1drv.com/y4mnRXd_uXCSFousyZvXcA2mKgd0ozHg2v3xDF4yFgi4-i2JJdRikuQ-uJ8wpXI9x51Zanti6PLC5xoMT4YT4Hpt_nkixl7UeoE6Id6FO9rbor9lukD7ayTwQ7HGOVfQqBPKT9Bnq4i3RSrsa0u1ZHf1pOS246CV-16yBgrK76IC-7KeABSY8xAQyBmS03pqEwK-LTNaLjan0t4gcyQlvM6Tw?width=371&amp;height=660&amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="History"/&gt;
    &lt;/div&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zuiiew.db.files.1drv.com/y4mXrgwh_eTv-bKJwtV0YHiFYgOGSdXJnuv-daC4oLcKDJxuIN3NAGibmsU4xMg_jzk7NjyntfSMm8-AXK2moJvZIG-jffO_xcJKsH4HTJRB7yOIjg2nOSSPYoFbOOVrDf7PZnmyJmDxlTaDSuM4MiFEPaDsrjzpCfDRP5Q-aPpYTfM8xTvkDVN3zM_A3sHXycxf0F9i1uwrBqhogj37JEsnQ?width=371&amp;height=660&amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="Height and weight charts"/&gt;
    &lt;/div&gt;
    &lt;div class="horizontal_list_item"&gt;
      &lt;img src="https://zeirew.db.files.1drv.com/y4mUWt_S4O6ysFpCRRhemi6UV4Kqpr60UBnBlE-B0ttoibVgsZM-KcTPXzw5RDBlJs7wJhayLqGn4hUyhaQtafL2A7yoMsiK_1l9MPpJGBVyyGtTQ9I8oH12hr95zY90ziB2YBnN-ow4l5phqt3kAN5Meb6YxD59ZoJH-UPdMXEUvJLjIPzAVQyygnes44KRph_GA_gdOzVYZvvT4aJ1Ev8sQ?width=371&amp;height=660&amp;cropmode=none" class="img-responsive" style="margin: auto; width:256px; margin-top: 6px; margin-bottom: 6px;" alt="Sleep and excretion charts"/&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;p&gt;And I'm extremely happy with the result. CQRS/ES and Rx are a perfect match and the technology stack in general has been extremely productive.&lt;/p&gt;
&lt;p&gt;This morning I drew up a (retrospective) architecture to illustrate how much of the application is portable and how simple yet extensible it is.&lt;/p&gt;
&lt;img src="https://bdliqq.db.files.1drv.com/y4mUPC3fgHhe1N8KTdz2hF-CR0GDq_Pe23GzQESO0UatcBJtZe63if9O0RL0PRo0p7tYMzQGLjjOQGPbHQ7QhUl9G-Z9eWjk9UYsXvfaOxkBOkuK0VzcFIu6-Z6kEWaw9G8WQ2vNUshGIhQJHFZkoqa5v9-e-OELFwbkFxoQOGhtdFnia0HGNLj0DVd72OJHG6E1r8_R8DJPLCAX18iRvf5dw?width=3207&amp;height=1959&amp;cropmode=none" class="img-responsive" style="margin: auto; width:800; margin-top: 6px; margin-bottom: 6px;" alt="Architecture diagram"&gt;
&lt;h2 id="the-proof-is-in-the-dog-fooding"&gt;&amp;quot;The proof is in the dog-fooding&amp;quot;&lt;/h2&gt;
&lt;p&gt;Apologies for the mixed metaphors but, suffice to say, while the technology choices may be deemed to be a success, the app can only be consider to be so if it is fit for purpose. As such, I have been using LittleLittle everyday for the past several weeks - across a number of iterations and versions - and I'm very, very pleased with the result. The UI is fast and efficient to use and the app has yet to crash or lose any data (either at runtime or between versions).&lt;/p&gt;
&lt;p&gt;Indeed, a little while ago my other half took our baby to stay with her grandparents for a several days and agreed to keep LittleLittle up to date while she was away. She came back with a couple of small suggestions but overall very impressed by how fast and easy to use it was.&lt;/p&gt;
&lt;p&gt;While it has yet to see a significant number of Windows Store acquisitions, Store Analytics shows there are a few people actively using the app and, so far, I have yet to see any crashes or failures. I intend to leverage the success of ToddlerBox to promote LittleLittle in the near future so, fingers crossed, it'll start getting some serious use and useful feedback.&lt;/p&gt;
&lt;h2 id="moving-forward"&gt;Moving forward&lt;/h2&gt;
&lt;p&gt;While I intend to put LittleLittle on hold for a little while in order to work on some other projects I've been meaning to look at, I very much intend to return to the project early in the new year. I have a backlog full of features I'd like to implement not to mention the need to write a version which runs on Android/iOS (which will probably be in Xamarin).&lt;/p&gt;
&lt;p&gt;In the mean time, I will be blogging about a few of the components in the architecture diagram above and sharing some of the approaches I have taken and successes (or problems!) I encountered.&lt;/p&gt;
</content:encoded>
		</item>
		<item>
			<title>ToddlerBox Tops 10,000 Users!!</title>
			<link>http://ian.bebbs.co.uk/posts/ToddlerBoxTopsTenThousandUsers</link>
			<description>&lt;p&gt;Really that got out of hand fast! I had no idea so many people would be interested in letting their toddler loose on their XBox controller. In fact, there have been many things that have surprised me about this app:&lt;/p&gt;</description>
			<enclosure url="https://zphykg.dm2302.livefilestore.com/y3mVAxtKFjUEGk7Hdhzjl4UZ2INnFdBbw9K-tnYZ8DYoJ-VoKxpAN6w8Ng0DFTYdSxpHY6IvL5-VwJpLkQl6qWRmMQXSExLXopz5CFuSxIbyaMLrnL2Vy3yPZlISAAknXZdT4HwiZJ55zg2UtKwucBL88-xHh6rn5Mh97yzfRsCPjI?width=1024&amp;height=574&amp;cropmode=none" length="0" type="image" />
			<guid>http://ian.bebbs.co.uk/posts/ToddlerBoxTopsTenThousandUsers</guid>
			<pubDate>Tue, 20 Dec 2016 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Really that got out of hand fast! I had no idea so many people would be interested in letting their toddler loose on their XBox controller. In fact, there have been many things that have surprised me about this app:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Acquisition rate has increased&lt;/p&gt;
&lt;p&gt;I kind of expected an initial burst of acquisitions then a slow tail off but this hasn't happened. As it's only been a little over a month since ToddlerBox was released to the store, I guess there's every possibility that it's still in the &amp;quot;burst&amp;quot; stage and theres just more interest in apps of this type. Well, here's hoping.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reviews have been extremely polarized&lt;/p&gt;
&lt;p&gt;Almost without exception, reviews have been 4-5 stars or 1 star. Also, while a couple of the 1 star ratings are to do with app functionality (it seems a couple of people have issues running even this basic UWP app) the overwhelming majority of 1 star ratings are due to peoples dislike of ads; because...&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ads are a very risky business&lt;/p&gt;
&lt;p&gt;As with most parents, I am extremely cautious about what my toddler is exposed to. Therefore I was extremely cautious about adding advertising as a means of revenue to ToddlerBox, regardless of how small or out of the way they were.
After completing the Ad-Mediation questions in the Windows Store and being assured that ads would be both age rated and not &amp;quot;tracking&amp;quot;, I felt a lot better about the idea and decided a small banner ad on the instructions screen would be pretty harmless. Furthermore, throughout the process of adding the banner, I didn't see a single advert I would be concerned about putting in front of my child; most were simple flashing inbox icons or the like.
However, after discussing ToddlerBox with a friend, he decided to install it on his Xbox and I was very upset to see that the ads being displayed were both more intrusive and more &amp;quot;click-baity&amp;quot; than any I had seen previously. I am now investigating ways to generate some revenue from the app but without upsetting parents.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The reviews shown in the store are not &amp;quot;all reviews&amp;quot;&lt;/p&gt;
&lt;p&gt;As the publisher of ToddlerBox, I get to see all reviews left about the app on the store. Due to all the previous points, the app is currently averaging about a 2.6 star rating across 50 odd reviews. However, when viewing the app in the Store on my friend's XBox, it was shown as having a 4.5 star rating from just 2 reviews. Now, while some of the reviews I can see are translated from foreign languages, most are in English and I'm therefore at a loss to explain why they're not being displayed when an XBox in the English local browses the store.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It's not just toddlers using ToddlerBox&lt;/p&gt;
&lt;p&gt;I've had more than one review stating how good this game is to play after consuming various illicit substances ;0P&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Anyway, as described above, while acquisition rate has fluctuated on a daily basis, the overall trend in acquisition shows unexpected growth:&lt;/p&gt;
&lt;img src="https://bnljqq.db.files.1drv.com/y4mj9WwQjdkoSF153rs96F4tLbYfCPYsfGBFfuJHWyRWvqQRmxgWzL6Gpn--H3FmrqgO0g7EXfn04MJnntS5EfJCdflhmF5KEJKx1hJ0y-gRoh7WvLA5hcQJY3naFY9GCguRBWN8jzsVK72uFHrUWQnMlYY8TC1YH4a2eC-bHO_G-ijc6jZ6fIBgeuc501kzDDvCmg3gjzBXEQWtyYqZZPWLw?width=921&amp;height=351&amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Acquisitions over App Lifetime"&gt;
&lt;p&gt;Daily usage also shows that a healthy number of acquisitions are being used regularly, with nearly 800 people using ToddlerBox nearly 1700 times just yesterday (19th December):&lt;/p&gt;
&lt;img src="https://bnlkqq.db.files.1drv.com/y4mm2fl7bqmrEBH2VV28iT2R9BUMr660TRFq4CmWTbqa0qpdXCbRfOVVpF8Uuz4yCNbFTu0PtiEHB8xJsZeq5xTscioCoUK2JHAJJeplFNtO5hyrPIW8hRPIDWZhOPDv8nVqplSQBWorr-RzRoxmRTb136QDL1H_-9RdfUMRKlIwNQZ4PNLRIl39j-T0EjJUoUXu05zqS6OmoGaRPW75Wvzbg?width=922&amp;height=348&amp;cropmode=none" class="img-responsive" style="margin: auto; width:660px; margin-top: 6px; margin-bottom: 6px;" alt="Daily usage"&gt;
&lt;p&gt;So, the Xmas break is almost upon us and I will be returning my attention to ToddlerBox (yes, despite the career break, I try to spend most of my time working on 'serious' projects or study). I have a number of new features in mind for it (including the #1 requested feature of &amp;quot;sound!!&amp;quot;) and will be looking to try out a couple of more features of the awesome Win2D library. It's going to be a lot of fun (for me and my little girl) and will hopefully allow ToddlerBox to reach the next major (although admittedly arbitrary) milestone of 25,000 acquisitions!&lt;/p&gt;
&lt;p&gt;Watch this space...&lt;/p&gt;
</content:encoded>
		</item>
	</channel>
</rss>